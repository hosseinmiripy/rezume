{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hosseinmiripy/rezume/blob/main/11%D8%A7%D8%B3%D8%AA%D8%B1%D8%A7%D8%AA%DA%98%DB%8C_%D8%A8%D8%B1%D8%AA%D8%B1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Iy71HyS4oYl",
        "outputId": "35c19379-4294-4ee0-f2da-ecf3a560e6fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Collecting ccxt\n",
            "  Downloading ccxt-4.4.78-py2.py3-none-any.whl.metadata (131 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m131.0/131.0 kB\u001b[0m \u001b[31m871.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Collecting mplfinance\n",
            "  Downloading mplfinance-0.12.10b0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting python-telegram-bot\n",
            "  Downloading python_telegram_bot-22.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (5.24.1)\n",
            "Collecting ta\n",
            "  Downloading ta-0.11.0.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: setuptools>=60.9.0 in /usr/local/lib/python3.11/dist-packages (from ccxt) (75.2.0)\n",
            "Requirement already satisfied: certifi>=2018.1.18 in /usr/local/lib/python3.11/dist-packages (from ccxt) (2025.4.26)\n",
            "Requirement already satisfied: cryptography>=2.6.1 in /usr/local/lib/python3.11/dist-packages (from ccxt) (43.0.3)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from ccxt) (4.13.2)\n",
            "Collecting aiohttp<=3.10.11 (from ccxt)\n",
            "  Downloading aiohttp-3.10.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting aiodns>=1.1.1 (from ccxt)\n",
            "  Downloading aiodns-3.3.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: yarl>=1.7.2 in /usr/local/lib/python3.11/dist-packages (from ccxt) (1.20.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: httpx~=0.27 in /usr/local/lib/python3.11/dist-packages (from python-telegram-bot) (0.28.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly) (9.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Collecting pycares>=4.0.0 (from aiodns>=1.1.1->ccxt)\n",
            "  Downloading pycares-4.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<=3.10.11->ccxt) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<=3.10.11->ccxt) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<=3.10.11->ccxt) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<=3.10.11->ccxt) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<=3.10.11->ccxt) (6.4.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=2.6.1->ccxt) (1.17.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx~=0.27->python-telegram-bot) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx~=0.27->python-telegram-bot) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx~=0.27->python-telegram-bot) (0.16.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: propcache>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from yarl>=1.7.2->ccxt) (0.3.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=2.6.1->ccxt) (2.22)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx~=0.27->python-telegram-bot) (1.3.1)\n",
            "Downloading ccxt-4.4.78-py2.py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mplfinance-0.12.10b0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_telegram_bot-22.0-py3-none-any.whl (673 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m673.5/673.5 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiodns-3.3.0-py3-none-any.whl (6.3 kB)\n",
            "Downloading aiohttp-3.10.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycares-4.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (626 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m626.2/626.2 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: ta\n",
            "  Building wheel for ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ta: filename=ta-0.11.0-py3-none-any.whl size=29412 sha256=6d691050f9a5cf2a23b96c24232653b2fa11f230f6c42e40e4177505b3caf969\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/d7/29/7781cc5eb9a3659d032d7d15bdd0f49d07d2b24fec29f44bc4\n",
            "Successfully built ta\n",
            "Installing collected packages: pycares, aiohttp, ta, python-telegram-bot, mplfinance, aiodns, ccxt\n",
            "  Attempting uninstall: aiohttp\n",
            "    Found existing installation: aiohttp 3.11.15\n",
            "    Uninstalling aiohttp-3.11.15:\n",
            "      Successfully uninstalled aiohttp-3.11.15\n",
            "Successfully installed aiodns-3.3.0 aiohttp-3.10.11 ccxt-4.4.78 mplfinance-0.12.10b0 pycares-4.8.0 python-telegram-bot-22.0 ta-0.11.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas numpy ccxt matplotlib mplfinance python-telegram-bot seaborn scikit-learn plotly ta requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Ø±Ø¨Ø§Øª ØªØ­Ù„ÛŒÙ„ Ùˆ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒØ¯Ù‡ÛŒ Ø§Ø±Ø² Ø¯ÛŒØ¬ÛŒØªØ§Ù„\n",
        "------------------------------------------------\n",
        "Ø§ÛŒÙ† Ø±Ø¨Ø§Øª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø±Ø²Ù‡Ø§ÛŒ Ø¯ÛŒØ¬ÛŒØªØ§Ù„ Ø±Ø§ Ø§Ø² ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø¯Ø±ÛŒØ§ÙØª Ú©Ø±Ø¯Ù‡ Ùˆ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ØŒ\n",
        "Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ Ø±Ø§ Ø¨Ù‡ Ú©Ø§Ù†Ø§Ù„ ØªÙ„Ú¯Ø±Ø§Ù… Ø§Ø±Ø³Ø§Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.\n",
        "\n",
        "ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§:\n",
        "- ØªØ­Ù„ÛŒÙ„ Ø¯Ø± ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…â€ŒÙ‡Ø§ÛŒ 15 Ø¯Ù‚ÛŒÙ‚Ù‡ØŒ 1 Ø³Ø§Ø¹ØªØŒ 4 Ø³Ø§Ø¹Øª Ùˆ Ø±ÙˆØ²Ø§Ù†Ù‡\n",
        "- Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² 12 Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ù…Ø®ØªÙ„Ù ØªØ­Ù„ÛŒÙ„ ÙÙ†ÛŒ\n",
        "- Ø±Ø³Ù… Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§ÛŒ Ø¨Ø§ Ú©ÛŒÙÛŒØª Ø¨Ø§Ù„Ø§\n",
        "- Ø§Ø±Ø³Ø§Ù„ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ Ø¨Ù‡ ØªÙ„Ú¯Ø±Ø§Ù… Ù‡Ù…Ø±Ø§Ù‡ Ø¨Ø§ Ù†Ù…ÙˆØ¯Ø§Ø±\n",
        "- Ù…Ø¯ÛŒØ±ÛŒØª Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø§ØªØµØ§Ù„ Ø¨Ù‡ ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§\n",
        "\"\"\"\n",
        "\n",
        "import tempfile\n",
        "import shutil\n",
        "import hashlib\n",
        "import gc\n",
        "from datetime import datetime, timedelta\n",
        "import threading\n",
        "import datetime\n",
        "import json  # Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ Ù‚Ø¨Ù„Ø§Ù‹ Ø¯Ø± Ú©Ø¯ ÙˆØ§Ø±Ø¯ Ø´Ø¯Ù‡\n",
        "import os  # Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ Ù‚Ø¨Ù„Ø§Ù‹ Ø¯Ø± Ú©Ø¯ ÙˆØ§Ø±Ø¯ Ø´Ø¯Ù‡\n",
        "import time  # Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ Ù‚Ø¨Ù„Ø§Ù‹ Ø¯Ø± Ú©Ø¯ ÙˆØ§Ø±Ø¯ Ø´Ø¯Ù‡\n",
        "import math  # Ø¨Ø±Ø§ÛŒ ØªØ§Ø¨Ø¹ ceil Ø¯Ø± ØªÙ‚Ø³ÛŒÙ…â€ŒØ¨Ù†Ø¯ÛŒ Ú¯Ø±ÙˆÙ‡â€ŒÙ‡Ø§\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ccxt\n",
        "import logging\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "import mplfinance as mpf\n",
        "from matplotlib.patches import Rectangle\n",
        "import seaborn as sns\n",
        "import telegram\n",
        "from telegram import InputFile\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.cm as cm\n",
        "import matplotlib.colors as mcolors\n",
        "from io import BytesIO\n",
        "import ta\n",
        "import warnings\n",
        "import datetime as dt\n",
        "from scipy.signal import argrelextrema\n",
        "from collections import deque, defaultdict\n",
        "import math\n",
        "import re\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import requests\n",
        "from threading import Lock\n",
        "import traceback\n",
        "from sklearn.cluster import KMeans\n",
        "import requests\n",
        "\n",
        "# ØªÙ†Ø¸ÛŒÙ… Ù…Ø­ÛŒØ· Ú¯ÙˆÚ¯Ù„ Ú©ÙˆÙ„Ø¨ - Ø§Ø®ØªÛŒØ§Ø±ÛŒ\n",
        "COLAB_ENV = False\n",
        "try:\n",
        "    import google.colab\n",
        "\n",
        "    COLAB_ENV = True\n",
        "    from google.colab import drive\n",
        "\n",
        "    print(\"ğŸŒŸ Ù…Ø­ÛŒØ· Ú¯ÙˆÚ¯Ù„ Ú©ÙˆÙ„Ø¨ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯ - ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù¾Ø§ÛŒØ¯Ø§Ø±...\")\n",
        "    # Ù†ØµØ¨ Ø¨Ù‡ Ú¯ÙˆÚ¯Ù„ Ø¯Ø±Ø§ÛŒÙˆ\n",
        "    drive.mount('/content/drive')\n",
        "    BASE_DIR = '/content/drive/MyDrive/crypto_analyzer'\n",
        "    os.makedirs(f\"{BASE_DIR}/cache/ohlcv\", exist_ok=True)\n",
        "    os.makedirs(f\"{BASE_DIR}/charts\", exist_ok=True)\n",
        "    os.makedirs(f\"{BASE_DIR}/logs\", exist_ok=True)\n",
        "except:\n",
        "    print(\"ğŸ–¥ï¸ Ù…Ø­ÛŒØ· Ù…Ø­Ù„ÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯ - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø­Ù„ÛŒ...\")\n",
        "    BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
        "    os.makedirs(f\"{BASE_DIR}/cache/ohlcv\", exist_ok=True)\n",
        "    os.makedirs(f\"{BASE_DIR}/charts\", exist_ok=True)\n",
        "    os.makedirs(f\"{BASE_DIR}/logs\", exist_ok=True)\n",
        "\n",
        "# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù„Ø§Ú¯\n",
        "logging.basicConfig(\n",
        "    filename=f\"{BASE_DIR}/logs/crypto_analyzer.log\",\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Ù†Ù…Ø§ÛŒØ´ Ù„Ø§Ú¯â€ŒÙ‡Ø§ Ø¯Ø± Ú©Ù†Ø³ÙˆÙ„ Ù‡Ù…\n",
        "console_handler = logging.StreamHandler()\n",
        "console_handler.setLevel(logging.INFO)\n",
        "console_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
        "console_handler.setFormatter(console_formatter)\n",
        "logger.addHandler(console_handler)\n",
        "\n",
        "# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø±Ø¨Ø§Øª ØªÙ„Ú¯Ø±Ø§Ù… - ØªÙˆÚ©Ù† Ùˆ Ø¢ÛŒØ¯ÛŒ Ú†Ù†Ù„ Ø®ÙˆØ¯ Ø±Ø§ Ø§ÛŒÙ†Ø¬Ø§ Ù‚Ø±Ø§Ø± Ø¯Ù‡ÛŒØ¯\n",
        "TELEGRAM_BOT_TOKEN = \"7307185304:AAF9zG3vM0Pc74WkiIDVEnRxu41OJYdyql8\"\n",
        "TELEGRAM_CHANNEL_ID = \"@hosseinbtb2\"  # Ù…Ø«Ø§Ù„: \"@your_channel_name\"\n",
        "\n",
        "# Ù…Ø®ÙÛŒ Ú©Ø±Ø¯Ù† Ù‡Ø´Ø¯Ø§Ø±Ù‡Ø§ÛŒ ØºÛŒØ±Ø¶Ø±ÙˆØ±ÛŒ\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ú¯Ù„ÙˆØ¨Ø§Ù„\n",
        "memory_cache = {}\n",
        "memory_cache_access_time = {}\n",
        "memory_cache_max_size = 500\n",
        "request_count_lock = Lock()\n",
        "last_analysis_times = {}\n",
        "last_signal_times = {}\n",
        "\n",
        "# ØªÙ†Ø¸ÛŒÙ…Ø§Øª ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§ - Ø¨Ø§ Ù…Ø¯ÛŒØ±ÛŒØª Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§\n",
        "EXCHANGES_CONFIG = {\n",
        "    'kucoin': {\n",
        "        'class': ccxt.kucoin,\n",
        "        'max_requests_per_minute': 15,\n",
        "        'cooldown_time': 60,\n",
        "        'weight': 1.0,\n",
        "        'backoff_factor': 1.5,\n",
        "        'max_cooldown': 300,\n",
        "        'min_cooldown': 30,\n",
        "    },\n",
        "    'gate': {\n",
        "        'class': ccxt.gate,\n",
        "        'max_requests_per_minute': 20,\n",
        "        'cooldown_time': 50,\n",
        "        'weight': 0.9,\n",
        "        'backoff_factor': 1.5,\n",
        "        'max_cooldown': 300,\n",
        "        'min_cooldown': 30,\n",
        "    },\n",
        "    'mexc': {\n",
        "        'class': ccxt.mexc,\n",
        "        'max_requests_per_minute': 30,\n",
        "        'cooldown_time': 40,\n",
        "        'weight': 1.2,\n",
        "        'backoff_factor': 1.5,\n",
        "        'max_cooldown': 300,\n",
        "        'min_cooldown': 30,\n",
        "    }\n",
        "}\n",
        "\n",
        "# ØªÙ†Ø¸ÛŒÙ… ÙˆØ¶Ø¹ÛŒØª Ø§ÙˆÙ„ÛŒÙ‡ ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§\n",
        "exchange_data = {}\n",
        "for exchange_id in EXCHANGES_CONFIG:\n",
        "    exchange_data[exchange_id] = {\n",
        "        'request_count': 0,\n",
        "        'last_reset_time': time.time(),\n",
        "        'success_count': 0,\n",
        "        'fail_count': 0,\n",
        "        'in_cooldown': False,\n",
        "        'cooldown_until': 0,\n",
        "        'consecutive_failures': 0,\n",
        "        'last_rate_limit': 0\n",
        "    }\n",
        "\n",
        "# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¨Ø§Øª\n",
        "BOT_SETTINGS = {\n",
        "    'memory_management': True,\n",
        "    'max_memory_cache_size': 500,\n",
        "    'min_time_between_signals': 1800,  # Ø­Ø¯Ø§Ù‚Ù„ ÙØ§ØµÙ„Ù‡ Ø¨ÛŒÙ† Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ ÛŒÚ© Ø§Ø±Ø² (Ø¨Ù‡ Ø«Ø§Ù†ÛŒÙ‡)\n",
        "    'signal_confidence_threshold': 75,  # Ø­Ø¯Ø§Ù‚Ù„ Ø¯Ø±ØµØ¯ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„ Ø³ÛŒÚ¯Ù†Ø§Ù„\n",
        "    'max_signals_per_day': 2000,  # Ø­Ø¯Ø§Ú©Ø«Ø± ØªØ¹Ø¯Ø§Ø¯ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø¯Ø± Ø±ÙˆØ²\n",
        "    'signal_cooldown_hours': 1,  # Ø²Ù…Ø§Ù† Ø§Ù†ØªØ¸Ø§Ø± Ø¨ÛŒÙ† Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø´Ø§Ø¨Ù‡\n",
        "    'disk_cache_dir': os.path.join(BASE_DIR, \"temp_cache\"),  # Ø¯Ø§ÛŒØ±Ú©ØªÙˆØ±ÛŒ Ú©Ø´ Ø¯ÛŒØ³Ú©\n",
        "    'disk_cache_max_age': 24,  # Ø­Ø¯Ø§Ú©Ø«Ø± Ø¹Ù…Ø± ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ú©Ø´ Ø¨Ù‡ Ø³Ø§Ø¹Øª\n",
        "}\n",
        "os.makedirs(BOT_SETTINGS['disk_cache_dir'], exist_ok=True)\n",
        "\n",
        "# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§Ø±Ø²Ù‡Ø§ Ùˆ ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…â€ŒÙ‡Ø§\n",
        "symbols = [\n",
        "    'BTC/USDT', 'ETH/USDT', 'XRP/USDT', 'SOL/USDT', 'ADA/USDT',\n",
        "    'DOGE/USDT', 'SHIB/USDT', 'TRX/USDT', 'TON/USDT', 'DOT/USDT',\n",
        "    'AVAX/USDT', 'LINK/USDT', 'PEPE/USDT', 'UNI/USDT', 'LTC/USDT',\n",
        "    'ATOM/USDT', 'XLM/USDT', 'BCH/USDT', 'NEAR/USDT', 'ETC/USDT',\n",
        "    'FIL/USDT', 'VET/USDT', 'HBAR/USDT', 'ALGO/USDT',\n",
        "    'QNT/USDT', 'AAVE/USDT', 'AXS/USDT', 'SAND/USDT', 'MANA/USDT',\n",
        "    'MEME/USDT', 'EOS/USDT', 'FLOW/USDT', 'RVN/USDT', 'CHZ/USDT',\n",
        "    'OP/USDT', 'NEO/USDT', 'CRV/USDT', 'ROSE/USDT', 'ZEC/USDT',\n",
        "    'ICP/USDT', 'ENJ/USDT', 'AR/USDT', 'ONE/USDT', 'BAT/USDT',\n",
        "    'ZIL/USDT', 'IOTA/USDT', 'LRC/USDT', 'YFI/USDT', 'SNX/USDT',\n",
        "    'COMP/USDT', 'DASH/USDT', 'MKR/USDT', 'RUNE/USDT', 'CAKE/USDT',\n",
        "    'DYDX/USDT', 'OMG/USDT', 'SRM/USDT', 'ICX/USDT', 'ONT/USDT',\n",
        "    'SXP/USDT', 'STORJ/USDT', 'CELO/USDT', 'QTUM/USDT',\n",
        "    'SUSHI/USDT', 'LDO/USDT', 'ANKR/USDT', 'IOST/USDT'\n",
        "]\n",
        "\n",
        "# ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…â€ŒÙ‡Ø§\n",
        "timeframes = ['15m', '1h', '4h', '1d']\n",
        "\n",
        "\n",
        "# ØªØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ Ø¨Ø±Ø§ÛŒ Ø§ÛŒØ¬Ø§Ø¯ Ú©Ù„ÛŒØ¯ Ú©Ø´\n",
        "def get_cache_key(function_name, *args):\n",
        "    \"\"\"Ø§ÛŒØ¬Ø§Ø¯ Ú©Ù„ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ú©Ø´ Ø­Ø§ÙØ¸Ù‡\"\"\"\n",
        "    return f\"{function_name}_{':'.join(str(arg) for arg in args)}\"\n",
        "\n",
        "\n",
        "# ØªØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ Ø¨Ø±Ø§ÛŒ Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ú©Ø´ Ø­Ø§ÙØ¸Ù‡\n",
        "# ØªØ§Ø¨Ø¹ Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡ Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ú©Ø´ Ø­Ø§ÙØ¸Ù‡\n",
        "def clean_memory_cache(max_items=200, force_cleanup=False):\n",
        "    \"\"\"\n",
        "    Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ú©Ø´ Ø­Ø§ÙØ¸Ù‡ Ø¨Ø§ Ø­ÙØ¸ Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ú©Ø§Ø±Ø¨Ø±Ø¯ Ùˆ Ù¾Ø´ØªÛŒØ¨Ø§Ù†â€ŒÚ¯ÛŒØ±ÛŒ Ø¨Ù‡ Ø¯ÛŒØ³Ú©\n",
        "\n",
        "    Args:\n",
        "        max_items: Ø­Ø¯Ø§Ú©Ø«Ø± Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ Ù…Ø¬Ø§Ø² Ø¯Ø± Ú©Ø´ Ø­Ø§ÙØ¸Ù‡\n",
        "        force_cleanup: Ø§Ø¬Ø¨Ø§Ø± Ø¨Ù‡ Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø­ØªÛŒ Ø§Ú¯Ø± ØªØ¹Ø¯Ø§Ø¯ Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§ Ú©Ù…ØªØ± Ø§Ø² Ø­Ø¯ Ù…Ø¬Ø§Ø² Ø¨Ø§Ø´Ø¯\n",
        "    \"\"\"\n",
        "    global memory_cache, memory_cache_access_time\n",
        "\n",
        "    # Ø§Ú¯Ø± Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø§Ø¬Ø¨Ø§Ø±ÛŒ Ù†Ø¨Ø§Ø´Ø¯ Ùˆ ØªØ¹Ø¯Ø§Ø¯ Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§ Ú©Ù…ØªØ± Ø§Ø² Ø­Ø¯ Ù…Ø¬Ø§Ø² Ø¨Ø§Ø´Ø¯ØŒ Ú©Ø§Ø±ÛŒ Ø§Ù†Ø¬Ø§Ù… Ù†Ù…ÛŒâ€ŒØ¯Ù‡ÛŒÙ…\n",
        "    if not force_cleanup and len(memory_cache) <= max_items:\n",
        "        return\n",
        "\n",
        "    # Ø«Ø¨Øª Ù…ÛŒØ²Ø§Ù† Ø­Ø§ÙØ¸Ù‡ Ø¢Ø²Ø§Ø¯ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù„Ø§Ú¯\n",
        "    initial_size = len(memory_cache)\n",
        "\n",
        "    try:\n",
        "        # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø²Ù…Ø§Ù† Ø¢Ø®Ø±ÛŒÙ† Ø¯Ø³ØªØ±Ø³ÛŒ\n",
        "        sorted_items = sorted(memory_cache_access_time.items(), key=lambda x: x[1])\n",
        "\n",
        "        # ØªØ¹ÛŒÛŒÙ† ØªØ¹Ø¯Ø§Ø¯ Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¨Ø§ÛŒØ¯ Ø­Ø°Ù Ø´ÙˆÙ†Ø¯\n",
        "        if force_cleanup:\n",
        "            items_to_remove = int(len(memory_cache) * 0.7)  # Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ 70% Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§ Ø¯Ø± Ø­Ø§Ù„Øª Ø§Ø¬Ø¨Ø§Ø±ÛŒ\n",
        "        else:\n",
        "            items_to_remove = len(memory_cache) - max_items\n",
        "\n",
        "        # Ø°Ø®ÛŒØ±Ù‡ Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù… OHLCV Ø¯Ø± Ø¯ÛŒØ³Ú© Ù‚Ø¨Ù„ Ø§Ø² Ø­Ø°Ù\n",
        "        saved_to_disk = 0\n",
        "        for i in range(min(items_to_remove, len(sorted_items))):\n",
        "            key = sorted_items[i][0]\n",
        "            if key in memory_cache and \"load_from_cache\" in key:\n",
        "                try:\n",
        "                    save_to_disk_cache(key, memory_cache[key])\n",
        "                    saved_to_disk += 1\n",
        "                except Exception as e:\n",
        "                    logger.error(f\"Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Ø¨Ù‡ Ø¯ÛŒØ³Ú©: {e}\")\n",
        "\n",
        "        # Ø­Ø°Ù Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ Ø§Ø² Ø­Ø§ÙØ¸Ù‡\n",
        "        removed_count = 0\n",
        "        for i in range(min(items_to_remove, len(sorted_items))):\n",
        "            key = sorted_items[i][0]\n",
        "            if key in memory_cache:\n",
        "                del memory_cache[key]\n",
        "                removed_count += 1\n",
        "            if key in memory_cache_access_time:\n",
        "                del memory_cache_access_time[key]\n",
        "\n",
        "        # ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ ØµØ±ÛŒØ­ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø²Ø¨Ø§Ù„Ù‡\n",
        "        gc.collect()\n",
        "\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ Ù…ÛŒØ²Ø§Ù† Ø­Ø§ÙØ¸Ù‡ Ø¢Ø²Ø§Ø¯ Ø´Ø¯Ù‡\n",
        "        freed_items = initial_size - len(memory_cache)\n",
        "        logger.info(f\"Ú©Ø´ Ø­Ø§ÙØ¸Ù‡ Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø´Ø¯: {freed_items} Ø¢ÛŒØªÙ… Ø­Ø°Ù Ø´Ø¯ØŒ {saved_to_disk} Ø¢ÛŒØªÙ… Ø¨Ù‡ Ø¯ÛŒØ³Ú© Ù…Ù†ØªÙ‚Ù„ Ø´Ø¯\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ú©Ø´ Ø­Ø§ÙØ¸Ù‡: {e}\")\n",
        "        # Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§ØŒ Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø§Ø¶Ø·Ø±Ø§Ø±ÛŒ Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ¯Ù‡ÛŒÙ…\n",
        "        try:\n",
        "            # Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ú©Ø§Ù…Ù„ Ú©Ø´ Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§\n",
        "            memory_cache.clear()\n",
        "            memory_cache_access_time.clear()\n",
        "            gc.collect()\n",
        "            logger.warning(\"Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø§Ø¶Ø·Ø±Ø§Ø±ÛŒ Ú©Ø´ Ø­Ø§ÙØ¸Ù‡ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯\")\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "\n",
        "# ØªØ§Ø¨Ø¹ Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ù¾Ø§ÛŒØ´ Ù…Ù†Ø§Ø¨Ø¹ Ø³ÛŒØ³ØªÙ… Ø¨Ø§ Ù…Ø¯ÛŒØ±ÛŒØª Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø­Ø§ÙØ¸Ù‡\n",
        "def monitor_resources(critical_threshold=90, warning_threshold=75):\n",
        "    \"\"\"\n",
        "    Ù¾Ø§ÛŒØ´ Ù…Ù†Ø§Ø¨Ø¹ Ø³ÛŒØ³ØªÙ… Ùˆ Ù…Ø¯ÛŒØ±ÛŒØª Ø®ÙˆØ¯Ú©Ø§Ø± Ø­Ø§ÙØ¸Ù‡ Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø²\n",
        "\n",
        "    Args:\n",
        "        critical_threshold: Ø¢Ø³ØªØ§Ù†Ù‡ Ø¨Ø­Ø±Ø§Ù†ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø­Ø§ÙØ¸Ù‡ (Ø¯Ø±ØµØ¯)\n",
        "        warning_threshold: Ø¢Ø³ØªØ§Ù†Ù‡ Ù‡Ø´Ø¯Ø§Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø­Ø§ÙØ¸Ù‡ (Ø¯Ø±ØµØ¯)\n",
        "\n",
        "    Returns:\n",
        "        ÙˆØ¶Ø¹ÛŒØª Ø³ÛŒØ³ØªÙ… (dict)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        import psutil\n",
        "\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø­Ø§ÙØ¸Ù‡\n",
        "        memory = psutil.virtual_memory()\n",
        "        memory_percent = memory.percent\n",
        "\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² CPU\n",
        "        cpu_percent = psutil.cpu_percent(interval=0.1)\n",
        "\n",
        "        # Ø«Ø¨Øª ÙˆØ¶Ø¹ÛŒØª Ù…Ù†Ø§Ø¨Ø¹\n",
        "        system_status = {\n",
        "            'memory_percent': memory_percent,\n",
        "            'cpu_percent': cpu_percent,\n",
        "            'cache_items': len(memory_cache),\n",
        "            'memory_free_gb': memory.available / (1024 ** 3)\n",
        "        }\n",
        "\n",
        "        # Ø§Ú¯Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø­Ø§ÙØ¸Ù‡ Ø¨Ø§Ù„Ø§ØªØ± Ø§Ø² Ø¢Ø³ØªØ§Ù†Ù‡ Ø¨Ø­Ø±Ø§Ù†ÛŒ Ø§Ø³ØªØŒ Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø§Ø¶Ø·Ø±Ø§Ø±ÛŒ\n",
        "        if memory_percent >= critical_threshold:\n",
        "            logger.warning(f\"ğŸš¨ ÙˆØ¶Ø¹ÛŒØª Ø¨Ø­Ø±Ø§Ù†ÛŒ Ø­Ø§ÙØ¸Ù‡: {memory_percent:.1f}% - Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø§Ø¶Ø·Ø±Ø§Ø±ÛŒ\")\n",
        "            clean_memory_cache(max_items=100, force_cleanup=True)\n",
        "\n",
        "            # Ø§Ú¯Ø± Ù‡Ù†ÙˆØ² Ø­Ø§ÙØ¸Ù‡ Ø¨Ø§Ù„Ø§Ø³ØªØŒ Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ú©Ø§Ù…Ù„ Ú©Ø´\n",
        "            if psutil.virtual_memory().percent >= critical_threshold:\n",
        "                memory_cache.clear()\n",
        "                memory_cache_access_time.clear()\n",
        "                gc.collect()\n",
        "                logger.warning(\"Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ú©Ø§Ù…Ù„ Ú©Ø´ Ø­Ø§ÙØ¸Ù‡ Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ ÙˆØ¶Ø¹ÛŒØª Ø¨Ø­Ø±Ø§Ù†ÛŒ\")\n",
        "\n",
        "        # Ø§Ú¯Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø­Ø§ÙØ¸Ù‡ Ø¨Ø§Ù„Ø§ØªØ± Ø§Ø² Ø¢Ø³ØªØ§Ù†Ù‡ Ù‡Ø´Ø¯Ø§Ø± Ø§Ø³ØªØŒ Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯\n",
        "        elif memory_percent >= warning_threshold:\n",
        "            logger.warning(f\"âš ï¸ Ù…ØµØ±Ù Ø­Ø§ÙØ¸Ù‡ Ø¨Ø§Ù„Ø§Ø³Øª: {memory_percent:.1f}% - Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯\")\n",
        "            clean_memory_cache(max_items=200)\n",
        "            gc.collect()\n",
        "\n",
        "        # Ø§Ú¯Ø± ØªØ¹Ø¯Ø§Ø¯ Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ Ú©Ø´ Ø¨ÛŒØ´ Ø§Ø² Ø­Ø¯ Ù…Ø¬Ø§Ø² Ø§Ø³ØªØŒ Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…\n",
        "        elif len(memory_cache) > BOT_SETTINGS['max_memory_cache_size']:\n",
        "            logger.info(f\"ØªØ¹Ø¯Ø§Ø¯ Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ Ú©Ø´ ({len(memory_cache)}) Ø¨ÛŒØ´ Ø§Ø² Ø­Ø¯ Ù…Ø¬Ø§Ø² Ø§Ø³Øª - Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ\")\n",
        "            clean_memory_cache(max_items=int(BOT_SETTINGS['max_memory_cache_size'] * 0.8))\n",
        "\n",
        "        return system_status\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø§ÛŒØ´ Ù…Ù†Ø§Ø¨Ø¹ Ø³ÛŒØ³ØªÙ…: {e}\")\n",
        "\n",
        "        # Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§ØŒ Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ¯Ù‡ÛŒÙ…\n",
        "        clean_memory_cache(force_cleanup=True)\n",
        "        gc.collect()\n",
        "\n",
        "        return {'error': str(e)}\n",
        "\n",
        "def get_disk_cache_key(key):\n",
        "    \"\"\"ØªØ¨Ø¯ÛŒÙ„ Ú©Ù„ÛŒØ¯ Ú©Ø´ Ø¨Ù‡ Ù†Ø§Ù… ÙØ§ÛŒÙ„ Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ø¯ÛŒØ³Ú©\"\"\"\n",
        "    # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² md5 Ø¨Ø±Ø§ÛŒ ØªØ¨Ø¯ÛŒÙ„ Ú©Ù„ÛŒØ¯ Ø¨Ù‡ Ø±Ø´ØªÙ‡ Ø§Ù…Ù† Ø¨Ø±Ø§ÛŒ Ù†Ø§Ù… ÙØ§ÛŒÙ„\n",
        "    return hashlib.md5(key.encode()).hexdigest() + \".pkl\"\n",
        "\n",
        "\n",
        "def save_to_disk_cache(key, data):\n",
        "    \"\"\"Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ø¯Ù‡ Ø¯Ø± Ú©Ø´ Ø¯ÛŒØ³Ú©\"\"\"\n",
        "    import pickle\n",
        "\n",
        "    filename = os.path.join(BOT_SETTINGS['disk_cache_dir'], get_disk_cache_key(key))\n",
        "    try:\n",
        "        with open(filename, 'wb') as f:\n",
        "            pickle.dump(data, f, protocol=4)  # Ù¾Ø±ÙˆØªÚ©Ù„ 4 Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø§ÛŒÛŒ Ø¨ÛŒØ´ØªØ±\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Ú©Ø´ Ø¯ÛŒØ³Ú© {filename}: {e}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "def load_from_disk_cache(key):\n",
        "    \"\"\"Ø¨Ø§Ø±Ú¯ÛŒØ±ÛŒ Ø¯Ø§Ø¯Ù‡ Ø§Ø² Ú©Ø´ Ø¯ÛŒØ³Ú©\"\"\"\n",
        "    import pickle\n",
        "\n",
        "    filename = os.path.join(BOT_SETTINGS['disk_cache_dir'], get_disk_cache_key(key))\n",
        "    if not os.path.exists(filename):\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        with open(filename, 'rb') as f:\n",
        "            data = pickle.load(f)\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯ÛŒØ±ÛŒ Ú©Ø´ Ø¯ÛŒØ³Ú© {filename}: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def cleanup_old_disk_cache():\n",
        "    \"\"\"Ø­Ø°Ù ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ú©Ø´ Ù‚Ø¯ÛŒÙ…ÛŒ Ø§Ø² Ø¯ÛŒØ³Ú©\"\"\"\n",
        "    now = time.time()\n",
        "    max_age_seconds = BOT_SETTINGS['disk_cache_max_age'] * 3600\n",
        "\n",
        "    try:\n",
        "        cache_dir = BOT_SETTINGS['disk_cache_dir']\n",
        "        count = 0\n",
        "        for filename in os.listdir(cache_dir):\n",
        "            filepath = os.path.join(cache_dir, filename)\n",
        "            if os.path.isfile(filepath) and filename.endswith('.pkl'):\n",
        "                file_age = now - os.path.getmtime(filepath)\n",
        "                if file_age > max_age_seconds:\n",
        "                    os.remove(filepath)\n",
        "                    count += 1\n",
        "\n",
        "        if count > 0:\n",
        "            logger.info(f\"Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ú©Ø´ Ø¯ÛŒØ³Ú©: {count} ÙØ§ÛŒÙ„ Ù‚Ø¯ÛŒÙ…ÛŒ Ø­Ø°Ù Ø´Ø¯.\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ú©Ø´ Ø¯ÛŒØ³Ú©: {e}\")\n",
        "\n",
        "# Ú©Ø¯ ØªÙˆØ§Ø¨Ø¹ Ù…Ø¯ÛŒØ±ÛŒØª Ø§ØªØµØ§Ù„ Ø¨Ù‡ ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§ Ùˆ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡\n",
        "def get_best_exchange(symbol, data_type=\"ohlcv\", depth=None):\n",
        "    \"\"\"Ø§Ù†ØªØ®Ø§Ø¨ Ø¨Ù‡ØªØ±ÛŒÙ† ØµØ±Ø§ÙÛŒ Ø¨Ø§ Ù…Ø¯ÛŒØ±ÛŒØª Ù‡ÙˆØ´Ù…Ù†Ø¯ Ùˆ Ù‡Ù…Ø§Ù‡Ù†Ú¯â€ŒØ³Ø§Ø²ÛŒ Ù†ÙˆØ¹ Ø¯Ø§Ø¯Ù‡\"\"\"\n",
        "    with request_count_lock:\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ Ùˆ Ø±ÛŒØ³Øª Ø´Ù…Ø§Ø±Ù†Ø¯Ù‡â€ŒÙ‡Ø§\n",
        "        current_time = time.time()\n",
        "\n",
        "        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø§Ù…ØªÛŒØ§Ø² Ø¬Ø±ÛŒÙ…Ù‡ Ø¨Ø±Ø§ÛŒ ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø§Ø®ÛŒØ±Ø§Ù‹ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ù†Ø±Ø® Ø¯Ø§Ø´ØªÙ‡â€ŒØ§Ù†Ø¯\n",
        "        penalty_scores = {}\n",
        "        for ex_id in EXCHANGES_CONFIG:\n",
        "            # ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø§Ø®ÛŒØ±Ø§Ù‹ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ù†Ø±Ø® Ø¯Ø§Ø´ØªÙ‡â€ŒØ§Ù†Ø¯ Ø¬Ø±ÛŒÙ…Ù‡ Ø¨ÛŒØ´ØªØ±ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯\n",
        "            recent_rate_limit = False\n",
        "            if current_time - exchange_data[ex_id].get('last_rate_limit', 0) < 300:\n",
        "                recent_rate_limit = True\n",
        "                penalty_scores[ex_id] = 0.5  # 50% Ø¬Ø±ÛŒÙ…Ù‡\n",
        "            else:\n",
        "                penalty_scores[ex_id] = 0\n",
        "\n",
        "        # Ù…Ù†Ø·Ù‚ Ø§Ù†ØªØ®Ø§Ø¨ ØµØ±Ø§ÙÛŒ\n",
        "        available_exchanges = []\n",
        "        for ex_id, ex_config in EXCHANGES_CONFIG.items():\n",
        "            # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª Ú©ÙˆÙ„Ø¯Ø§Ù†\n",
        "            if exchange_data[ex_id]['in_cooldown']:\n",
        "                if current_time > exchange_data[ex_id]['cooldown_until']:\n",
        "                    # Ù¾Ø§ÛŒØ§Ù† Ú©ÙˆÙ„Ø¯Ø§Ù†\n",
        "                    exchange_data[ex_id]['in_cooldown'] = False\n",
        "                    exchange_data[ex_id]['consecutive_failures'] = 0\n",
        "                    logger.info(f\"ØµØ±Ø§ÙÛŒ {ex_id} Ø§Ø² Ø­Ø§Ù„Øª Ú©ÙˆÙ„Ø¯Ø§Ù† Ø®Ø§Ø±Ø¬ Ø´Ø¯\")\n",
        "                else:\n",
        "                    # Ù‡Ù†ÙˆØ² Ø¯Ø± Ø­Ø§Ù„Øª Ú©ÙˆÙ„Ø¯Ø§Ù† Ø§Ø³Øª\n",
        "                    continue\n",
        "\n",
        "            # Ø¨Ø±Ø±Ø³ÛŒ Ø±ÛŒØ³Øª Ø´Ù…Ø§Ø±Ù†Ø¯Ù‡\n",
        "            if current_time - exchange_data[ex_id]['last_reset_time'] > 60:  # ÛŒÚ© Ø¯Ù‚ÛŒÙ‚Ù‡\n",
        "                exchange_data[ex_id]['request_count'] = 0\n",
        "                exchange_data[ex_id]['last_reset_time'] = current_time\n",
        "\n",
        "            # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª ØªØ¹Ø¯Ø§Ø¯ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¨Ø§ Ù…Ø§Ø±Ø¬ÛŒÙ† Ø§Ù…Ù†ÛŒØªÛŒ\n",
        "            request_limit_factor = 0.85\n",
        "            if data_type == \"orderbook\":\n",
        "                # Ø¨Ø±Ø§ÛŒ Ø¯ÙØªØ± Ø³ÙØ§Ø±Ø´ØŒ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø¨ÛŒØ´ØªØ±ÛŒ Ø§Ø¹Ù…Ø§Ù„ Ù…ÛŒâ€ŒØ´ÙˆØ¯\n",
        "                request_limit_factor = 0.7\n",
        "\n",
        "            if exchange_data[ex_id]['request_count'] < (ex_config['max_requests_per_minute'] * request_limit_factor):\n",
        "                # Ø§Ù…ØªÛŒØ§Ø² ØµØ±Ø§ÙÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ±Ú©ÛŒØ¨ ÙˆØ²Ù† Ùˆ Ù†Ø³Ø¨Øª Ù…ÙˆÙÙ‚ÛŒØª\n",
        "                success_ratio = 1.0\n",
        "                if exchange_data[ex_id]['success_count'] + exchange_data[ex_id]['fail_count'] > 0:\n",
        "                    success_ratio = exchange_data[ex_id]['success_count'] / (\n",
        "                            exchange_data[ex_id]['success_count'] + exchange_data[ex_id]['fail_count'])\n",
        "\n",
        "                # Ø§Ù…ØªÛŒØ§Ø² Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ø§ Ú©Ø³Ø± Ø¬Ø±ÛŒÙ…Ù‡\n",
        "                score = (ex_config['weight'] * (0.7 + 0.3 * success_ratio)) * (1 - penalty_scores[ex_id])\n",
        "\n",
        "                available_exchanges.append((ex_id, score))\n",
        "\n",
        "        if not available_exchanges:\n",
        "            # Ù‡ÛŒÚ† ØµØ±Ø§ÙÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª - Ø§Ù†ØªØ¸Ø§Ø± Ø¨Ø±Ø§ÛŒ Ø®Ø±ÙˆØ¬ Ø§Ø² Ú©ÙˆÙ„Ø¯Ø§Ù†\n",
        "            logger.warning(\"Ù‡Ù…Ù‡ ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§ Ø¯Ø± Ø­Ø§Ù„Øª Ú©ÙˆÙ„Ø¯Ø§Ù† Ù‡Ø³ØªÙ†Ø¯. Ø§Ù†ØªØ¸Ø§Ø± Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ...\")\n",
        "            # Ø§Ù†ØªØ®Ø§Ø¨ ØµØ±Ø§ÙÛŒ Ø¨Ø§ Ú©Ù…ØªØ±ÛŒÙ† Ø²Ù…Ø§Ù† Ú©ÙˆÙ„Ø¯Ø§Ù† Ø¨Ø§Ù‚ÛŒÙ…Ø§Ù†Ø¯Ù‡\n",
        "            min_cooldown_ex = min(EXCHANGES_CONFIG.keys(),\n",
        "                                  key=lambda x: exchange_data[x]['cooldown_until'] if exchange_data[x][\n",
        "                                      'in_cooldown'] else float('inf'))\n",
        "            wait_time = max(1, exchange_data[min_cooldown_ex]['cooldown_until'] - current_time)\n",
        "            time.sleep(wait_time)\n",
        "            # Ø¨Ø§Ø²Ú¯Ø´Øª Ø¨Ù‡ ØµÙˆØ±Øª Ø¨Ø§Ø²Ú¯Ø´ØªÛŒ\n",
        "            return get_best_exchange(symbol, data_type, depth)\n",
        "\n",
        "        # Ø§Ù†ØªØ®Ø§Ø¨ ØµØ±Ø§ÙÛŒ Ø¨Ø§ Ø¨Ø§Ù„Ø§ØªØ±ÛŒÙ† Ø§Ù…ØªÛŒØ§Ø²\n",
        "        best_exchange, _ = max(available_exchanges, key=lambda x: x[1])\n",
        "\n",
        "        # Ø§ÙØ²Ø§ÛŒØ´ Ø´Ù…Ø§Ø±Ù†Ø¯Ù‡ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¨Ø±Ø§ÛŒ ØµØ±Ø§ÙÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡\n",
        "        exchange_data[best_exchange]['request_count'] += 1\n",
        "\n",
        "        return best_exchange\n",
        "\n",
        "\n",
        "def handle_rate_limit(exchange_id):\n",
        "    \"\"\"Ù…Ø¯ÛŒØ±ÛŒØª ÙˆØ¶Ø¹ÛŒØª ØµØ±Ø§ÙÛŒ Ù‡Ù†Ú¯Ø§Ù… Ø¨Ø±Ø®ÙˆØ±Ø¯ Ø¨Ø§ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ù†Ø±Ø® Ø¨Ø§ ØªÙ†Ø¸ÛŒÙ… Ø®ÙˆØ¯Ú©Ø§Ø±\"\"\"\n",
        "    with request_count_lock:\n",
        "        exchange_data[exchange_id]['in_cooldown'] = True\n",
        "        cooldown_time = EXCHANGES_CONFIG[exchange_id]['cooldown_time']\n",
        "        exchange_data[exchange_id]['cooldown_until'] = time.time() + cooldown_time\n",
        "        # Ø«Ø¨Øª Ø²Ù…Ø§Ù† Ø¢Ø®Ø±ÛŒÙ† Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ù†Ø±Ø® Ùˆ Ø§ÙØ²Ø§ÛŒØ´ Ø´Ù…Ø§Ø±Ù†Ø¯Ù‡\n",
        "        exchange_data[exchange_id]['last_rate_limit'] = time.time()\n",
        "        exchange_data[exchange_id]['cooldown_count'] = exchange_data[exchange_id].get('cooldown_count', 0) + 1\n",
        "        # Ø§ÙØ²Ø§ÛŒØ´ Ø®ÙˆØ¯Ú©Ø§Ø± Ø²Ù…Ø§Ù† Ú©ÙˆÙ„Ø¯Ø§Ù† Ø§Ú¯Ø± ØµØ±Ø§ÙÛŒ Ø¨Ù‡ Ø·ÙˆØ± Ù…Ú©Ø±Ø± Ø¯Ú†Ø§Ø± Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø´ÙˆØ¯\n",
        "        if exchange_data[exchange_id]['cooldown_count'] > 10:\n",
        "            adjusted_cooldown = cooldown_time * 1.2  # Ø§ÙØ²Ø§ÛŒØ´ 20%\n",
        "            EXCHANGES_CONFIG[exchange_id]['cooldown_time'] = min(int(adjusted_cooldown), 120)  # Ø­Ø¯Ø§Ú©Ø«Ø± 2 Ø¯Ù‚ÛŒÙ‚Ù‡\n",
        "            logger.warning(\n",
        "                f\"Ø§ÙØ²Ø§ÛŒØ´ Ø®ÙˆØ¯Ú©Ø§Ø± Ø²Ù…Ø§Ù† Ú©ÙˆÙ„Ø¯Ø§Ù† Ø¨Ø±Ø§ÛŒ {exchange_id} Ø¨Ù‡ {EXCHANGES_CONFIG[exchange_id]['cooldown_time']} Ø«Ø§Ù†ÛŒÙ‡\")\n",
        "\n",
        "        # Ú©Ø§Ù‡Ø´ max_requests_per_minute Ø§Ú¯Ø± Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ù†Ø±Ø® Ø¨ÛŒØ´ Ø§Ø² Ø­Ø¯ ØªÚ©Ø±Ø§Ø± Ø´ÙˆØ¯\n",
        "        if exchange_data[exchange_id]['cooldown_count'] > 15:\n",
        "            current_max = EXCHANGES_CONFIG[exchange_id]['max_requests_per_minute']\n",
        "            adjusted_max = max(int(current_max * 0.8), 10)  # Ú©Ø§Ù‡Ø´ 20% Ø¨Ø§ Ø­Ø¯Ø§Ù‚Ù„ 10\n",
        "            EXCHANGES_CONFIG[exchange_id]['max_requests_per_minute'] = adjusted_max\n",
        "            logger.warning(f\"Ú©Ø§Ù‡Ø´ Ø®ÙˆØ¯Ú©Ø§Ø± max_requests_per_minute Ø¨Ø±Ø§ÛŒ {exchange_id} Ø¨Ù‡ {adjusted_max}\")\n",
        "\n",
        "        logger.warning(f\"ØµØ±Ø§ÙÛŒ {exchange_id} Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ù†Ø±Ø® Ø¯Ø± Ø­Ø§Ù„Øª Ú©ÙˆÙ„Ø¯Ø§Ù† Ø¨Ù‡ Ù…Ø¯Øª {cooldown_time} Ø«Ø§Ù†ÛŒÙ‡ Ù‚Ø±Ø§Ø± Ú¯Ø±ÙØª\")\n",
        "\n",
        "\n",
        "def get_cache_filename(symbol, timeframe, exchange_id):\n",
        "    \"\"\"Ø§ÛŒØ¬Ø§Ø¯ Ù†Ø§Ù… ÙØ§ÛŒÙ„ Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ú©Ø´\"\"\"\n",
        "    safe_symbol = symbol.replace('/', '_')\n",
        "    return os.path.join(BASE_DIR, f\"cache/ohlcv/{exchange_id}_{safe_symbol}_{timeframe}.csv\")\n",
        "\n",
        "\n",
        "def load_from_cache(symbol, timeframe, exchange_id, max_age_hours=None, legacy=False):\n",
        "    \"\"\"\n",
        "    Ø¨Ø§Ø±Ú¯ÛŒØ±ÛŒ Ø¯Ø§Ø¯Ù‡ Ø§Ø² Ú©Ø´ Ø¨Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² Ú©Ø´ Ø¯ÛŒØ³Ú©\n",
        "    \"\"\"\n",
        "    # ØªÙ†Ø¸ÛŒÙ… Ø¹Ù…Ø± Ú©Ø´ Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ… Ø§Ú¯Ø± Ù…Ù‚Ø¯Ø§Ø± ÙˆØ±ÙˆØ¯ÛŒ Ù†Ø¨Ø§Ø´Ø¯\n",
        "    if max_age_hours is None:\n",
        "        if timeframe == '15m':\n",
        "            max_age_hours = 0.25  # 15 Ø¯Ù‚ÛŒÙ‚Ù‡\n",
        "        elif timeframe == '1h':\n",
        "            max_age_hours = 1  # 1 Ø³Ø§Ø¹Øª\n",
        "        elif timeframe == '4h':\n",
        "            max_age_hours = 2  # 2 Ø³Ø§Ø¹Øª\n",
        "        else:\n",
        "            max_age_hours = 4  # Ø¨Ø±Ø§ÛŒ 1d Ùˆ Ø³Ø§ÛŒØ± ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…â€ŒÙ‡Ø§\n",
        "\n",
        "    # Ø¨Ø±Ø±Ø³ÛŒ Ú©Ø´ Ø­Ø§ÙØ¸Ù‡ Ø§Ø¨ØªØ¯Ø§\n",
        "    cache_key = get_cache_key(\"load_from_cache\", symbol, timeframe, exchange_id)\n",
        "\n",
        "    if cache_key in memory_cache:\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ Ø³Ù† Ø¯Ø§Ø¯Ù‡ Ø¯Ø± Ú©Ø´ Ø­Ø§ÙØ¸Ù‡\n",
        "        age_in_hours = (time.time() - memory_cache_access_time[cache_key]) / 3600\n",
        "        if age_in_hours <= max_age_hours:\n",
        "            # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø²Ù…Ø§Ù† Ø¯Ø³ØªØ±Ø³ÛŒ\n",
        "            memory_cache_access_time[cache_key] = time.time()\n",
        "            logger.info(f\"Ø¯Ø§Ø¯Ù‡ Ø§Ø² Ú©Ø´ Ø­Ø§ÙØ¸Ù‡ Ø¨Ø§Ø±Ú¯ÛŒØ±ÛŒ Ø´Ø¯: {symbol}/{timeframe} (Ø³Ù†: {age_in_hours:.2f} Ø³Ø§Ø¹Øª)\")\n",
        "            return memory_cache[cache_key]\n",
        "        else:\n",
        "            logger.info(f\"Ø¯Ø§Ø¯Ù‡ Ú©Ø´ Ø­Ø§ÙØ¸Ù‡ Ù‚Ø¯ÛŒÙ…ÛŒ Ø§Ø³Øª: {symbol}/{timeframe} (Ø³Ù†: {age_in_hours:.2f} Ø³Ø§Ø¹Øª)\")\n",
        "            # Ø­Ø°Ù Ø¯Ø§Ø¯Ù‡ Ù‚Ø¯ÛŒÙ…ÛŒ Ø§Ø² Ú©Ø´ Ø­Ø§ÙØ¸Ù‡\n",
        "            del memory_cache[cache_key]\n",
        "            del memory_cache_access_time[cache_key]\n",
        "\n",
        "    # Ø¨Ø±Ø±Ø³ÛŒ Ú©Ø´ Ø¯ÛŒØ³Ú©\n",
        "    disk_data = load_from_disk_cache(cache_key)\n",
        "    if disk_data is not None:\n",
        "        # Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¬Ø¯Ø¯ Ø¯Ø± Ú©Ø´ Ø­Ø§ÙØ¸Ù‡\n",
        "        memory_cache[cache_key] = disk_data\n",
        "        memory_cache_access_time[cache_key] = time.time()\n",
        "        logger.info(f\"Ø¯Ø§Ø¯Ù‡ Ø§Ø² Ú©Ø´ Ø¯ÛŒØ³Ú© Ø¨Ø§Ø±Ú¯ÛŒØ±ÛŒ Ø´Ø¯: {symbol}/{timeframe}\")\n",
        "\n",
        "        # Ù…Ø¯ÛŒØ±ÛŒØª Ø­Ø§ÙØ¸Ù‡\n",
        "        if BOT_SETTINGS['memory_management'] and len(memory_cache) > memory_cache_max_size:\n",
        "            clean_memory_cache()\n",
        "\n",
        "        return disk_data\n",
        "\n",
        "    # Ø§Ú¯Ø± exchange_id Ø¨Ø±Ø§Ø¨Ø± Ø¨Ø§ \"any\" Ø¨Ø§Ø´Ø¯ØŒ Ù‡Ù…Ù‡ Ú©Ø´â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…\n",
        "    if exchange_id == \"any\":\n",
        "        for ex_id in EXCHANGES_CONFIG:\n",
        "            result = load_from_cache(symbol, timeframe, ex_id, max_age_hours)\n",
        "            if result is not None:\n",
        "                return result\n",
        "\n",
        "        # Ø§Ú¯Ø± Ú©Ø´â€ŒÙ‡Ø§ÛŒ Ù…Ø¹Ù…ÙˆÙ„ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯ Ùˆ legacy ÙØ¹Ø§Ù„ Ø§Ø³ØªØŒ Ø§Ø² Ú©Ø´ Ù‚Ø¯ÛŒÙ…ÛŒâ€ŒØªØ± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒÙ…\n",
        "        if legacy:\n",
        "            for ex_id in EXCHANGES_CONFIG:\n",
        "                filename = get_cache_filename(symbol, timeframe, ex_id)\n",
        "                if os.path.exists(filename):\n",
        "                    file_mod_time = os.path.getmtime(filename)\n",
        "                    # Ø¨Ø±Ø§ÛŒ Ú©Ø´ Ù‚Ø¯ÛŒÙ…ÛŒâ€ŒØªØ±ØŒ Ø¢Ø³ØªØ§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ø³Ø®ØªÚ¯ÛŒØ±Ø§Ù†Ù‡â€ŒØªØ± Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø¹ØªØ¨Ø±\n",
        "                    if (time.time() - file_mod_time) < (max_age_hours * 2 * 3600):  # Ø¯Ùˆ Ø¨Ø±Ø§Ø¨Ø± max_age_hours\n",
        "                        try:\n",
        "                            df = pd.read_csv(filename)\n",
        "                            df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "                            df.set_index('timestamp', inplace=True)\n",
        "                            if len(df) >= 80:  # Ø­Ø¯Ø§Ù‚Ù„ 80 Ú©Ù†Ø¯Ù„\n",
        "                                logger.warning(f\"Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ú©Ø´ legacy Ø¨Ø±Ø§ÛŒ {symbol}/{timeframe} Ø§Ø² {ex_id}\")\n",
        "\n",
        "                                # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ú©Ø´ Ø­Ø§ÙØ¸Ù‡\n",
        "                                memory_cache[cache_key] = df\n",
        "                                memory_cache_access_time[cache_key] = time.time()\n",
        "\n",
        "                                return df\n",
        "                        except Exception as e:\n",
        "                            logger.warning(f\"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯ÛŒØ±ÛŒ Ú©Ø´ legacy: {e}\")\n",
        "\n",
        "        return None\n",
        "\n",
        "    filename = get_cache_filename(symbol, timeframe, exchange_id)\n",
        "    if not os.path.exists(filename):\n",
        "        return None\n",
        "\n",
        "    # Ø¨Ø±Ø±Ø³ÛŒ Ø³Ù† ÙØ§ÛŒÙ„\n",
        "    file_mod_time = os.path.getmtime(filename)\n",
        "    file_age_hours = (time.time() - file_mod_time) / 3600\n",
        "\n",
        "    if file_age_hours > max_age_hours:\n",
        "        logger.info(f\"Ú©Ø´ Ù‚Ø¯ÛŒÙ…ÛŒ Ø§Ø³Øª: {filename} (Ø³Ù†: {file_age_hours:.2f} Ø³Ø§Ø¹Øª)\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ ÙØ§ÛŒÙ„ ÙØ´Ø±Ø¯Ù‡\n",
        "        if filename.endswith('.gz'):\n",
        "            df = pd.read_csv(filename, compression='gzip')\n",
        "        else:\n",
        "            df = pd.read_csv(filename)\n",
        "\n",
        "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "        df.set_index('timestamp', inplace=True)\n",
        "        logger.info(f\"Ø¯Ø§Ø¯Ù‡ Ø§Ø² Ú©Ø´ Ø¨Ø§Ø±Ú¯ÛŒØ±ÛŒ Ø´Ø¯: {filename} (Ø³Ù†: {file_age_hours:.2f} Ø³Ø§Ø¹Øª)\")\n",
        "\n",
        "        # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ú©Ø´ Ø­Ø§ÙØ¸Ù‡\n",
        "        memory_cache[cache_key] = df\n",
        "        memory_cache_access_time[cache_key] = time.time()\n",
        "\n",
        "        # Ù…Ø¯ÛŒØ±ÛŒØª Ø­Ø§ÙØ¸Ù‡\n",
        "        if BOT_SETTINGS['memory_management'] and len(memory_cache) > memory_cache_max_size:\n",
        "            clean_memory_cache()\n",
        "\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯ÛŒØ±ÛŒ Ú©Ø´ {filename}: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def save_to_cache(df, symbol, timeframe, exchange_id):\n",
        "    \"\"\"Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ø¯Ù‡ Ø¯Ø± Ú©Ø´ Ø¨Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² Ú©Ø´ Ø¯ÛŒØ³Ú©\"\"\"\n",
        "    if df is None or len(df) == 0:\n",
        "        return False\n",
        "\n",
        "    # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ú©Ø´ Ø­Ø§ÙØ¸Ù‡\n",
        "    cache_key = get_cache_key(\"load_from_cache\", symbol, timeframe, exchange_id)\n",
        "    memory_cache[cache_key] = df\n",
        "    memory_cache_access_time[cache_key] = time.time()\n",
        "\n",
        "    # Ù…Ø¯ÛŒØ±ÛŒØª Ø­Ø§ÙØ¸Ù‡ - Ø¯Ø±ØµÙˆØ±Øª Ù†ÛŒØ§Ø² Ø¨Ù‡ Ú©Ø´ Ø¯ÛŒØ³Ú© Ù…Ù†ØªÙ‚Ù„ Ù…ÛŒâ€ŒØ´ÙˆØ¯\n",
        "    if BOT_SETTINGS['memory_management'] and len(memory_cache) > memory_cache_max_size:\n",
        "        clean_memory_cache()\n",
        "\n",
        "    filename = get_cache_filename(symbol, timeframe, exchange_id)\n",
        "    try:\n",
        "        # ØªØ¨Ø¯ÛŒÙ„ Ø´Ø§Ø®Øµ datetime Ø¨Ù‡ Ø³ØªÙˆÙ† Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡\n",
        "        df_to_save = df.reset_index()\n",
        "\n",
        "        # Ø°Ø®ÛŒØ±Ù‡ Ø¨Ø§ ÙØ±Ù…Øª ÙØ´Ø±Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø¯ÛŒØªØ§ÙØ±ÛŒÙ…â€ŒÙ‡Ø§ÛŒ Ø¨Ø²Ø±Ú¯\n",
        "        if len(df_to_save) > 500:\n",
        "            df_to_save.to_csv(filename + '.gz', index=False, compression='gzip')\n",
        "            # Ø§Ú¯Ø± Ù†Ø³Ø®Ù‡ ØºÛŒØ±ÙØ´Ø±Ø¯Ù‡ Ù‚Ø¨Ù„Ø§Ù‹ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø´ØªÙ‡ØŒ Ø¢Ù† Ø±Ø§ Ø­Ø°Ù Ú©Ù†ÛŒÙ…\n",
        "            if os.path.exists(filename):\n",
        "                os.remove(filename)\n",
        "            filename = filename + '.gz'\n",
        "        else:\n",
        "            df_to_save.to_csv(filename, index=False)\n",
        "\n",
        "        logger.info(f\"Ø¯Ø§Ø¯Ù‡ Ø¯Ø± Ú©Ø´ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {filename}\")\n",
        "\n",
        "        # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ú©Ø´ Ø¯ÛŒØ³Ú© Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø³Ø±ÛŒØ¹â€ŒØªØ±\n",
        "        save_to_disk_cache(cache_key, df)\n",
        "\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Ú©Ø´ {filename}: {e}\")\n",
        "        return False\n",
        "\n",
        "def validate_data(df):\n",
        "    \"\"\"Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ÛŒØ§ÙØªÙ‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØªÛŒ\"\"\"\n",
        "    if df is None or len(df) < 20:\n",
        "        return False\n",
        "\n",
        "    try:\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ù‚Ø§Ø¯ÛŒØ± Ú¯Ù…Ø´Ø¯Ù‡\n",
        "        null_count = df.isnull().sum().sum()\n",
        "        if null_count > 0:\n",
        "            if null_count < len(df) * 0.03:  # Ú©Ù…ØªØ± Ø§Ø² 3% Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§\n",
        "                df.ffill(inplace=True)\n",
        "                df.bfill(inplace=True)\n",
        "                if df.isnull().sum().sum() > 0:\n",
        "                    return False\n",
        "            else:\n",
        "                return False\n",
        "\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ ØªØºÛŒÛŒØ±Ø§Øª Ù‚ÛŒÙ…Øª ØºÛŒØ±Ø¹Ø§Ø¯ÛŒ\n",
        "        price_changes = df['close'].pct_change().abs()\n",
        "        if price_changes.max() > 0.5:  # ØªØºÛŒÛŒØ± Ø¨ÛŒØ´ Ø§Ø² 50%\n",
        "            extreme_changes = price_changes[price_changes > 0.25]\n",
        "            if len(extreme_changes) > len(df) * 0.05:\n",
        "                return False\n",
        "\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ Ø­Ø¬Ù… ØµÙØ±\n",
        "        zero_volume_ratio = (df['volume'] == 0).sum() / len(df)\n",
        "        if zero_volume_ratio > 0.15:\n",
        "            return False\n",
        "\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ ØªÚ©Ø±Ø§Ø± Ù…Ù‚Ø§Ø¯ÛŒØ± ÛŒÚ©Ø³Ø§Ù† (Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªÚ©Ø±Ø§Ø±ÛŒ)\n",
        "        repeated_close = (df['close'] == df['close'].shift(1)).mean()\n",
        "        if repeated_close > 0.5:\n",
        "            return False\n",
        "\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ ÙØ§ØµÙ„Ù‡â€ŒÙ‡Ø§ÛŒ Ø²Ù…Ø§Ù†ÛŒ Ú©Ù†Ø¯Ù„â€ŒÙ‡Ø§\n",
        "        if df.index.to_series().diff().dt.total_seconds().std() > 60:\n",
        "            return False\n",
        "\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ø¯Ø§Ø¯Ù‡: {e}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "def analyze_exchange_performance():\n",
        "    \"\"\"Ø¨Ø±Ø±Ø³ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø±\"\"\"\n",
        "    performance_report = {}\n",
        "\n",
        "    for ex_id in EXCHANGES_CONFIG:\n",
        "        total_requests = exchange_data[ex_id]['success_count'] + exchange_data[ex_id]['fail_count']\n",
        "        success_rate = exchange_data[ex_id]['success_count'] / total_requests if total_requests > 0 else 0\n",
        "        cooldown_count = exchange_data[ex_id].get('cooldown_count', 0)\n",
        "\n",
        "        performance_report[ex_id] = {\n",
        "            'success_rate': success_rate * 100,\n",
        "            'total_requests': total_requests,\n",
        "            'cooldown_count': cooldown_count,\n",
        "            'recommendation': 'Good' if success_rate > 0.8 and cooldown_count < 5 else 'Needs Adjustment'\n",
        "        }\n",
        "\n",
        "    print(\"\\n=== Ú¯Ø²Ø§Ø±Ø´ Ø¹Ù…Ù„Ú©Ø±Ø¯ ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§ ===\")\n",
        "    for ex_id, stats in performance_report.items():\n",
        "        print(\n",
        "            f\"{ex_id}: Ù†Ø±Ø® Ù…ÙˆÙÙ‚ÛŒØª {stats['success_rate']:.1f}%, ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ø¯Ø±Ø®ÙˆØ§Ø³Øª: {stats['total_requests']}, Ø¯ÙØ¹Ø§Øª Ù…Ø­Ø¯ÙˆØ¯ÛŒØª: {stats['cooldown_count']}\")\n",
        "        if stats['recommendation'] == 'Needs Adjustment':\n",
        "            print(f\"  âš ï¸ ØªÙˆØµÛŒÙ‡: Ú©Ø§Ù‡Ø´ max_requests_per_minute ÛŒØ§ Ø§ÙØ²Ø§ÛŒØ´ cooldown_time\")\n",
        "\n",
        "    return performance_report\n",
        "\n",
        "\n",
        "# Ú©Ø´ Ø¨Ø±Ø§ÛŒ Ø§ÙØ²Ø§ÛŒØ´ Ú©Ø§Ø±Ø§ÛŒÛŒ ØªØ§Ø¨Ø¹ fetch_data\n",
        "fetch_data_cache = {}\n",
        "\n",
        "\n",
        "def fetch_data(symbol, timeframe, limit=1000, max_retries=5, delay=2, force_fresh=False, max_age_hours=1,\n",
        "               incremental=False):\n",
        "    \"\"\"\n",
        "    Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø³ÛŒØ³ØªÙ… Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¨Ø§ Ù…Ø¯ÛŒØ±ÛŒØª Ø®Ø·Ø§ Ú©Ø§Ù…Ù„ Ùˆ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡ØŒ\n",
        "    Ù‡Ù…Ø±Ø§Ù‡ Ø¨Ø§ Ù‚Ø§Ø¨Ù„ÛŒØª Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ ØªØ¯Ø±ÛŒØ¬ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ùˆ Ù…Ø¯ÛŒØ±ÛŒØª Ø¨Ù‡ÛŒÙ†Ù‡ Ø­Ø§ÙØ¸Ù‡ Ø¯ÛŒØ³Ú©-Ù…Ø­ÙˆØ±\n",
        "\n",
        "    Args:\n",
        "        symbol: Ù†Ù…Ø§Ø¯ Ø§Ø±Ø²\n",
        "        timeframe: ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…\n",
        "        limit: ØªØ¹Ø¯Ø§Ø¯ Ú©Ù†Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¯Ø±Ø®ÙˆØ§Ø³ØªÛŒ\n",
        "        max_retries: Ø­Ø¯Ø§Ú©Ø«Ø± ØªØ¹Ø¯Ø§Ø¯ ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯\n",
        "        delay: ØªØ§Ø®ÛŒØ± Ø¨ÛŒÙ† ØªÙ„Ø§Ø´â€ŒÙ‡Ø§ Ø¨Ù‡ Ø«Ø§Ù†ÛŒÙ‡\n",
        "        force_fresh: Ø§Ø¬Ø¨Ø§Ø± Ø¨Ù‡ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ§Ø²Ù‡ Ùˆ Ø¹Ø¯Ù… Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ú©Ø´\n",
        "        max_age_hours: Ø­Ø¯Ø§Ú©Ø«Ø± Ø³Ù† Ù…Ø¬Ø§Ø² Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ø´ Ø¨Ù‡ Ø³Ø§Ø¹Øª\n",
        "        incremental: ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø±ÛŒØ§ÙØª ØªØ¯Ø±ÛŒØ¬ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ (ÙÙ‚Ø· Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯)\n",
        "\n",
        "    Returns:\n",
        "        Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø±Ú¯ÛŒØ±ÛŒ Ø´Ø¯Ù‡ ÛŒØ§ None Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§\n",
        "    \"\"\"\n",
        "    # Ú©Ù„ÛŒØ¯ Ú©Ø´ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ø¯Ø±Ø®ÙˆØ§Ø³Øª\n",
        "    cache_key = get_cache_key(\"fetch_data\", symbol, timeframe, limit)\n",
        "\n",
        "    try:\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ Ú©Ø´ Ø­Ø§ÙØ¸Ù‡ Ø¯Ø± ØµÙˆØ±Øª Ø¹Ø¯Ù… Ø§Ø¬Ø¨Ø§Ø± Ø¨Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ§Ø²Ù‡\n",
        "        if not force_fresh and cache_key in memory_cache:\n",
        "            cache_age_seconds = time.time() - memory_cache_access_time[cache_key]\n",
        "            # Ø¨Ø±Ø±Ø³ÛŒ Ø³Ù† Ú©Ø´ (Ø§Ú¯Ø± Ú©Ù…ØªØ± Ø§Ø² 5 Ø¯Ù‚ÛŒÙ‚Ù‡ Ø¨Ø§Ø´Ø¯ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…)\n",
        "            if cache_age_seconds < 300:  # 5 Ø¯Ù‚ÛŒÙ‚Ù‡\n",
        "                # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø²Ù…Ø§Ù† Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ø¯ÙˆÙ† Ø§ÛŒØ¬Ø§Ø¯ Ø¯Ø§Ø¯Ù‡ Ø¬Ø¯ÛŒØ¯\n",
        "                memory_cache_access_time[cache_key] = time.time()\n",
        "                return memory_cache[cache_key]\n",
        "            logger.info(f\"Ú©Ø´ Ø­Ø§ÙØ¸Ù‡ Ù‚Ø¯ÛŒÙ…ÛŒ Ø§Ø³Øª: {symbol}/{timeframe} (Ø³Ù†: {cache_age_seconds / 60:.1f} Ø¯Ù‚ÛŒÙ‚Ù‡)\")\n",
        "\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ Ú©Ø´ Ø¯ÛŒØ³Ú© Ø§Ú¯Ø± Ø¯Ø± Ø­Ø§ÙØ¸Ù‡ Ù†Ø¨Ø§Ø´Ø¯\n",
        "        if not force_fresh:\n",
        "            disk_data = load_from_disk_cache(cache_key)\n",
        "            if disk_data is not None:\n",
        "                # Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¬Ø¯Ø¯ Ø¯Ø± Ú©Ø´ Ø­Ø§ÙØ¸Ù‡\n",
        "                memory_cache[cache_key] = disk_data\n",
        "                memory_cache_access_time[cache_key] = time.time()\n",
        "                logger.info(f\"Ø¯Ø§Ø¯Ù‡ Ø§Ø² Ú©Ø´ Ø¯ÛŒØ³Ú© Ø¨Ø§Ø±Ú¯ÛŒØ±ÛŒ Ø´Ø¯: {symbol}/{timeframe}\")\n",
        "\n",
        "                # Ù…Ø¯ÛŒØ±ÛŒØª Ø­Ø§ÙØ¸Ù‡\n",
        "                if BOT_SETTINGS['memory_management'] and len(memory_cache) > BOT_SETTINGS['max_memory_cache_size']:\n",
        "                    clean_memory_cache()\n",
        "\n",
        "                return disk_data\n",
        "\n",
        "        # Ù„ÛŒØ³Øª ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ ØªØ§ Ø¨Ù‡ Ø­Ø§Ù„ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ø¬ÙØª Ø§Ø±Ø²/ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ… Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯Ù‡â€ŒØ§Ù†Ø¯\n",
        "        successful_exchanges_key = f\"{symbol}_{timeframe}_successful\"\n",
        "        successful_exchanges = fetch_data_cache.get(successful_exchanges_key, [])\n",
        "\n",
        "        # Ù„Ø§Ú¯ÛŒÙ†Ú¯ Ú©Ø§Ø± Ø¨Ø§ ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆÙÙ‚\n",
        "        if successful_exchanges:\n",
        "            logger.info(f\"ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆÙÙ‚ Ù‚Ø¨Ù„ÛŒ Ø¨Ø±Ø§ÛŒ {symbol}/{timeframe}: {successful_exchanges}\")\n",
        "\n",
        "        attempts_failed = []\n",
        "\n",
        "        # Ø§Ú¯Ø± Ø§Ø¬Ø¨Ø§Ø± Ø¨Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ§Ø²Ù‡ Ù†ÛŒØ³Øª Ùˆ Ø­Ø§Ù„Øª ØªØ¯Ø±ÛŒØ¬ÛŒ ÙØ¹Ø§Ù„ Ø§Ø³ØªØŒ Ø§Ø² ØªØ±Ú©ÛŒØ¨ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ø´ Ø¨Ø§ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…\n",
        "        if incremental and not force_fresh:\n",
        "            df_cached = None\n",
        "            latest_timestamp = None\n",
        "\n",
        "            # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ø¯Ø± Ú©Ø´\n",
        "            for ex_id in successful_exchanges:\n",
        "                df_cached = load_from_cache(symbol, timeframe, ex_id, max_age_hours)\n",
        "                if df_cached is not None and len(df_cached) >= 50:\n",
        "                    if validate_data(df_cached):\n",
        "                        # Ø¢Ø®Ø±ÛŒÙ† ØªØ§Ø±ÛŒØ® Ù…ÙˆØ¬ÙˆØ¯ Ø¯Ø± Ú©Ø´ Ø±Ø§ Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…\n",
        "                        latest_timestamp = df_cached.index[-1]\n",
        "                        logger.info(\n",
        "                            f\"Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ø´ Ù…Ø¹ØªØ¨Ø± Ø¨Ø±Ø§ÛŒ {symbol}/{timeframe} ÛŒØ§ÙØª Ø´Ø¯. Ø¢Ø®Ø±ÛŒÙ† ØªØ§Ø±ÛŒØ®: {latest_timestamp}\")\n",
        "                        break\n",
        "\n",
        "            if df_cached is not None and latest_timestamp is not None:\n",
        "                logger.info(f\"Ø¯Ø±ÛŒØ§ÙØª ØªØ¯Ø±ÛŒØ¬ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ {symbol}/{timeframe} Ø§Ø² ØªØ§Ø±ÛŒØ® {latest_timestamp}\")\n",
        "\n",
        "                # ØªØ¨Ø¯ÛŒÙ„ ØªØ§Ø±ÛŒØ® Ø¢Ø®Ø±ÛŒÙ† Ú©Ù†Ø¯Ù„ Ø¨Ù‡ Ù…ÛŒÙ„ÛŒâ€ŒØ«Ø§Ù†ÛŒÙ‡ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¯Ø± API\n",
        "                since_timestamp = int(latest_timestamp.timestamp() * 1000)\n",
        "\n",
        "                # Ù‡Ù…ÛŒØ´Ù‡ Ø­Ø¯Ø§Ù‚Ù„ Ú†Ù†Ø¯ Ú©Ù†Ø¯Ù„ Ø¢Ø®Ø± Ø±Ø§ Ù…Ø¬Ø¯Ø¯Ø§Ù‹ Ø¯Ø±ÛŒØ§ÙØª Ú©Ù† Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² ØµØ­Øª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§\n",
        "                # ØªØ¹ÛŒÛŒÙ† ØªØ¹Ø¯Ø§Ø¯ Ú©Ù†Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª (Ø¨Ø§ Ù…Ø§Ø±Ø¬ÛŒÙ† Ø§Ù…Ù†ÛŒØªÛŒ)\n",
        "                fetch_limit = min(20, limit)  # Ø¯Ø±ÛŒØ§ÙØª Ø­Ø¯Ø§Ú©Ø«Ø± 20 Ú©Ù†Ø¯Ù„ Ø¢Ø®Ø±\n",
        "\n",
        "                # Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯\n",
        "                df_new = fetch_recent_data(symbol, timeframe, since_timestamp, fetch_limit)\n",
        "\n",
        "                if df_new is not None and len(df_new) > 0:\n",
        "                    # Ø§Ø¯ØºØ§Ù… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ Ø¨Ø§ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ\n",
        "                    df_merged = merge_dataframes(df_cached, df_new)\n",
        "\n",
        "                    if df_merged is not None and validate_data(df_merged):\n",
        "                        # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ±Ú©ÛŒØ¨ÛŒ Ø¯Ø± Ú©Ø´\n",
        "                        save_to_cache(df_merged, symbol, timeframe,\n",
        "                                      successful_exchanges[0] if successful_exchanges else \"kucoin\")\n",
        "\n",
        "                        # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ú©Ø´ Ø­Ø§ÙØ¸Ù‡\n",
        "                        memory_cache[cache_key] = df_merged\n",
        "                        memory_cache_access_time[cache_key] = time.time()\n",
        "\n",
        "                        logger.info(f\"Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ ØªØ¯Ø±ÛŒØ¬ÛŒ Ù…ÙˆÙÙ‚ Ø¨Ø±Ø§ÛŒ {symbol}/{timeframe}: {len(df_new)} Ú©Ù†Ø¯Ù„ Ø¬Ø¯ÛŒØ¯\")\n",
        "\n",
        "                        # Ø¢Ø²Ø§Ø¯Ø³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆÙ‚Øª\n",
        "                        del df_new\n",
        "                        gc.collect()\n",
        "\n",
        "                        return df_merged\n",
        "\n",
        "        # Ø§Ú¯Ø± Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ ØªØ¯Ø±ÛŒØ¬ÛŒ Ù…ÙˆÙÙ‚ Ù†Ø¨ÙˆØ¯ ÛŒØ§ ØºÛŒØ±ÙØ¹Ø§Ù„ Ø¨ÙˆØ¯ØŒ Ø§Ø² Ø±ÙˆØ´ Ù…Ø¹Ù…ÙˆÙ„ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…\n",
        "        # 1. Ø§Ø¨ØªØ¯Ø§ Ø§Ø² Ú©Ø´ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù†ÛŒÙ… (Ø§Ú¯Ø± Ø§Ø¬Ø¨Ø§Ø± Ø¨Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ§Ø²Ù‡ Ù†Ø¨Ø§Ø´Ø¯)\n",
        "        if not force_fresh:\n",
        "            for exchange_id in EXCHANGES_CONFIG:\n",
        "                cached_df = load_from_cache(symbol, timeframe, exchange_id, max_age_hours=max_age_hours)\n",
        "                if cached_df is not None and len(cached_df) >= 80:\n",
        "                    # Ø¨Ø±Ø±Ø³ÛŒ Ø²Ù…Ø§Ù† Ø¢Ø®Ø±ÛŒÙ† Ú©Ù†Ø¯Ù„\n",
        "                    latest_candle_time = cached_df.index[-1]\n",
        "                    current_time = pd.Timestamp.now(latest_candle_time.tz)\n",
        "                    time_diff = (current_time - latest_candle_time).total_seconds() / 60  # ØªÙØ§ÙˆØª Ø¨Ù‡ Ø¯Ù‚ÛŒÙ‚Ù‡\n",
        "\n",
        "                    # Ø§Ú¯Ø± Ø¢Ø®Ø±ÛŒÙ† Ú©Ù†Ø¯Ù„ Ù‚Ø¯ÛŒÙ…ÛŒ Ø§Ø³ØªØŒ Ú©Ø´ Ø±Ø§ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ø¨Ú¯ÛŒØ±\n",
        "                    if time_diff > timeframe_to_minutes(timeframe) * 2:\n",
        "                        logger.warning(f\"Ø¢Ø®Ø±ÛŒÙ† Ú©Ù†Ø¯Ù„ Ø¯Ø± Ú©Ø´ {time_diff:.1f} Ø¯Ù‚ÛŒÙ‚Ù‡ Ù‚Ø¯ÛŒÙ…ÛŒ Ø§Ø³Øª - Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ\")\n",
        "                        cached_df = None\n",
        "                    # Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ø´\n",
        "                    if validate_data(cached_df):\n",
        "                        # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ú©Ø´ Ø­Ø§ÙØ¸Ù‡\n",
        "                        memory_cache[cache_key] = cached_df\n",
        "                        memory_cache_access_time[cache_key] = time.time()\n",
        "\n",
        "                        # Ø¢Ø²Ø§Ø¯Ø³Ø§Ø²ÛŒ Ø­Ø§ÙØ¸Ù‡\n",
        "                        gc.collect()\n",
        "                        return cached_df\n",
        "                    else:\n",
        "                        logger.warning(f\"Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ø´ Ø¨Ø±Ø§ÛŒ {symbol}/{timeframe} Ø§Ø² {exchange_id} Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª\")\n",
        "                        # Ø¢Ø²Ø§Ø¯Ø³Ø§Ø²ÛŒ Ú©Ø´ Ù†Ø§Ù…Ø¹ØªØ¨Ø±\n",
        "                        del cached_df\n",
        "\n",
        "        # Ù„Ø§Ú¯ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ§Ø²Ù‡\n",
        "        if force_fresh:\n",
        "            logger.info(f\"Ø§Ø¬Ø¨Ø§Ø± Ø¨Ù‡ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ§Ø²Ù‡ Ø¨Ø±Ø§ÛŒ {symbol}/{timeframe}\")\n",
        "\n",
        "        # 2. Ø§Ù†ØªØ®Ø§Ø¨ Ø¨Ù‡ØªØ±ÛŒÙ† ØµØ±Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡\n",
        "        best_exchange = get_best_exchange(symbol)\n",
        "        logger.info(f\"ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ Ø§Ø² ØµØ±Ø§ÙÛŒ Ø¨Ø±ØªØ±: {best_exchange}\")\n",
        "\n",
        "        # 3. ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ Ø§Ø² ØµØ±Ø§ÙÛŒ Ø¨Ø±ØªØ±\n",
        "        df = fetch_from_single_exchange(symbol, timeframe, best_exchange, limit, max_retries, delay)\n",
        "        if df is not None and len(df) >= 80:\n",
        "            if validate_data(df):  # Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ø¯Ø§Ø¯Ù‡\n",
        "                # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù„ÛŒØ³Øª ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆÙÙ‚\n",
        "                successful_exchanges = [best_exchange] + [ex for ex in successful_exchanges if ex != best_exchange]\n",
        "                successful_exchanges = successful_exchanges[:3]  # Ø­Ø¯Ø§Ú©Ø«Ø± 3 ØµØ±Ø§ÙÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´ÙˆØ¯\n",
        "                fetch_data_cache[successful_exchanges_key] = successful_exchanges\n",
        "\n",
        "                save_to_cache(df, symbol, timeframe, best_exchange)\n",
        "                # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ú©Ø´ Ø¯ÛŒØ³Ú© Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¨Ø¹Ø¯ÛŒ\n",
        "                save_to_disk_cache(cache_key, df)\n",
        "\n",
        "                gc.collect()\n",
        "                return df\n",
        "            else:\n",
        "                logger.warning(f\"Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØªÛŒ Ø§Ø² {best_exchange} Ø¨Ø±Ø§ÛŒ {symbol}/{timeframe} Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª\")\n",
        "                attempts_failed.append(best_exchange)\n",
        "                # Ø¢Ø²Ø§Ø¯Ø³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡ Ù†Ø§Ù…Ø¹ØªØ¨Ø±\n",
        "                del df\n",
        "\n",
        "        # 4. Ø§Ú¯Ø± ØµØ±Ø§ÙÛŒ Ø¨Ø±ØªØ± Ù…ÙˆÙÙ‚ Ù†Ø¨ÙˆØ¯ØŒ Ø³Ø§ÛŒØ± ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§ Ø±Ø§ Ø§Ù…ØªØ­Ø§Ù† Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…\n",
        "        logger.warning(f\"ØµØ±Ø§ÙÛŒ Ø¨Ø±ØªØ± {best_exchange} Ø¨Ø±Ø§ÛŒ {symbol}/{timeframe} Ù…ÙˆÙÙ‚ Ù†Ø¨ÙˆØ¯. Ø§Ù…ØªØ­Ø§Ù† Ø³Ø§ÛŒØ± ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§\")\n",
        "\n",
        "        # Ù„ÛŒØ³Øª Ù‡Ù…Ù‡ ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§ Ø¨Ù‡ Ø¬Ø² best_exchange\n",
        "        other_exchanges = [ex for ex in EXCHANGES_CONFIG.keys() if ex != best_exchange]\n",
        "        random.shuffle(other_exchanges)  # ØªØ±ØªÛŒØ¨ ØªØµØ§Ø¯ÙÛŒ\n",
        "\n",
        "        for exchange_id in other_exchanges:\n",
        "            # Ø§ÙØ²Ø§ÛŒØ´ ØªØ§Ø®ÛŒØ± Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² rate limit\n",
        "            current_delay = delay + 1.0\n",
        "            logger.info(f\"ØªÙ„Ø§Ø´ Ø¨Ø§ ØµØ±Ø§ÙÛŒ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ†: {exchange_id}\")\n",
        "\n",
        "            df = fetch_from_single_exchange(symbol, timeframe, exchange_id, limit, max_retries, current_delay)\n",
        "            if df is not None and len(df) >= 80:\n",
        "                if validate_data(df):  # Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ø¯Ø§Ø¯Ù‡\n",
        "                    # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù„ÛŒØ³Øª ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆÙÙ‚\n",
        "                    successful_exchanges = [exchange_id] + [ex for ex in successful_exchanges if ex != exchange_id]\n",
        "                    successful_exchanges = successful_exchanges[:3]  # Ø­Ø¯Ø§Ú©Ø«Ø± 3 ØµØ±Ø§ÙÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´ÙˆØ¯\n",
        "                    fetch_data_cache[successful_exchanges_key] = successful_exchanges\n",
        "\n",
        "                    save_to_cache(df, symbol, timeframe, exchange_id)\n",
        "                    # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ú©Ø´ Ø¯ÛŒØ³Ú© Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¨Ø¹Ø¯ÛŒ\n",
        "                    save_to_disk_cache(cache_key, df)\n",
        "\n",
        "                    gc.collect()\n",
        "                    return df\n",
        "                else:\n",
        "                    logger.warning(f\"Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØªÛŒ Ø§Ø² {exchange_id} Ø¨Ø±Ø§ÛŒ {symbol}/{timeframe} Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª\")\n",
        "                    # Ø¢Ø²Ø§Ø¯Ø³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡ Ù†Ø§Ù…Ø¹ØªØ¨Ø±\n",
        "                    del df\n",
        "\n",
        "            attempts_failed.append(exchange_id)\n",
        "\n",
        "        # 5. Ø¯Ø± ØµÙˆØ±Øª Ø¹Ø¯Ù… Ù…ÙˆÙÙ‚ÛŒØª Ù‡Ù…Ù‡ ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§ØŒ Ø§Ø² Ú©Ø´ Ù‚Ø¯ÛŒÙ…ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… (ÙÙ‚Ø· Ø§Ú¯Ø± force_fresh Ù†Ø¨Ø§Ø´Ø¯)\n",
        "        if not force_fresh:\n",
        "            logger.error(f\"âŒ Ù‡Ù…Ù‡ ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ {symbol}/{timeframe} Ø´Ú©Ø³Øª Ø®ÙˆØ±Ø¯Ù†Ø¯. ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ú©Ø´ Ù‚Ø¯ÛŒÙ…ÛŒ\")\n",
        "\n",
        "            # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ú©Ø´ Ù‚Ø¯ÛŒÙ…ÛŒâ€ŒØªØ± (ØªØ§ 6 Ø³Ø§Ø¹Øª)\n",
        "            cached_df = load_from_cache(symbol, timeframe, \"any\", max_age_hours=6)\n",
        "            if cached_df is not None and len(cached_df) >= 80:\n",
        "                logger.warning(f\"Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ú©Ø´ Ù‚Ø¯ÛŒÙ…ÛŒ (ØªØ§ 6 Ø³Ø§Ø¹Øª) Ø¨Ø±Ø§ÛŒ {symbol}/{timeframe}\")\n",
        "\n",
        "                gc.collect()\n",
        "                return cached_df\n",
        "\n",
        "            # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ú©Ø´ legacy (ØªØ§ 12 Ø³Ø§Ø¹Øª)\n",
        "            cached_df = load_from_cache(symbol, timeframe, \"any\", max_age_hours=12, legacy=True)\n",
        "            if cached_df is not None:\n",
        "                gc.collect()\n",
        "                return cached_df\n",
        "        else:\n",
        "            logger.error(f\"âŒ Ù‡Ù…Ù‡ ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ {symbol}/{timeframe} Ø´Ú©Ø³Øª Ø®ÙˆØ±Ø¯Ù†Ø¯ Ùˆ Ø§Ø¬Ø¨Ø§Ø± Ø¨Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ§Ø²Ù‡ ÙØ¹Ø§Ù„ Ø§Ø³Øª\")\n",
        "\n",
        "        # Ø§Ú¯Ø± Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯ØŒ None Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†ÛŒÙ…\n",
        "        logger.error(f\"âŒ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ {symbol}/{timeframe} Ú©Ø§Ù…Ù„Ø§Ù‹ Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯\")\n",
        "\n",
        "        # Ø¢Ø²Ø§Ø¯Ø³Ø§Ø²ÛŒ Ù…Ù†Ø§Ø¨Ø¹ Ø­Ø§ÙØ¸Ù‡\n",
        "        gc.collect()\n",
        "        return None\n",
        "\n",
        "    except Exception as e:\n",
        "        # Ø­ØªÛŒ Ø§Ú¯Ø± Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± Ú©Ù„ ÙØ±Ø¢ÛŒÙ†Ø¯ Ø±Ø® Ø¯Ø§Ø¯ØŒ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ù†Ø¨Ø§ÛŒØ¯ Ù…ØªÙˆÙ‚Ù Ø´ÙˆØ¯\n",
        "        logger.error(f\"ğŸš¨ Ø®Ø·Ø§ÛŒ Ø³ÛŒØ³ØªÙ…ÛŒ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ {symbol}/{timeframe}: {str(e)}\")\n",
        "\n",
        "        # Ø¢Ø²Ø§Ø¯Ø³Ø§Ø²ÛŒ ØµØ±ÛŒØ­ Ø­Ø§ÙØ¸Ù‡ Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§\n",
        "        gc.collect()\n",
        "\n",
        "        return None\n",
        "\n",
        "def timeframe_to_minutes(timeframe):\n",
        "    \"\"\"ØªØ¨Ø¯ÛŒÙ„ ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ… Ø¨Ù‡ Ø¯Ù‚ÛŒÙ‚Ù‡\"\"\"\n",
        "    try:\n",
        "        unit = timeframe[-1]\n",
        "        value = int(timeframe[:-1])\n",
        "\n",
        "        if unit == 'm':\n",
        "            return value\n",
        "        elif unit == 'h':\n",
        "            return value * 60\n",
        "        elif unit == 'd':\n",
        "            return value * 24 * 60\n",
        "        elif unit == 'w':\n",
        "            return value * 7 * 24 * 60\n",
        "        else:\n",
        "            return 60  # Ù¾ÛŒØ´â€ŒÙØ±Ø¶: 1 Ø³Ø§Ø¹Øª\n",
        "    except:\n",
        "        return 60  # Ù¾ÛŒØ´â€ŒÙØ±Ø¶: 1 Ø³Ø§Ø¹Øª\n",
        "\n",
        "def get_triangulated_price(symbol):\n",
        "    \"\"\"Ø¯Ø±ÛŒØ§ÙØª Ù‚ÛŒÙ…Øª Ø§Ø² Ú†Ù†Ø¯ÛŒÙ† ØµØ±Ø§ÙÛŒ Ùˆ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† ÙˆØ²Ù†ÛŒ Ø¨Ø±Ø§ÛŒ Ø§ÙØ²Ø§ÛŒØ´ Ø¯Ù‚Øª\"\"\"\n",
        "    prices = []\n",
        "    weights = []\n",
        "\n",
        "    # Ø¯Ø±ÛŒØ§ÙØª Ù‚ÛŒÙ…Øª Ø§Ø² ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù\n",
        "    for exchange_id in ['kucoin', 'gate', 'mexc']:\n",
        "        try:\n",
        "            exchange_class = EXCHANGES_CONFIG[exchange_id]['class']\n",
        "            exchange = exchange_class()\n",
        "            ticker = exchange.fetch_ticker(symbol)\n",
        "\n",
        "            if ticker and 'last' in ticker and ticker['last']:\n",
        "                # Ø§ÙØ²ÙˆØ¯Ù† Ù‚ÛŒÙ…Øª Ùˆ ÙˆØ²Ù† Ø¢Ù† (Ø¨Ø± Ø§Ø³Ø§Ø³ Ø­Ø¬Ù… Ù…Ø¹Ø§Ù…Ù„Ø§Øª)\n",
        "                prices.append(ticker['last'])\n",
        "                # ÙˆØ²Ù† Ø¨ÛŒØ´ØªØ± Ø¨Ù‡ ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§ÛŒ Ø¨Ø§ Ø­Ø¬Ù… Ø¨Ø§Ù„Ø§ØªØ±\n",
        "                weights.append(ticker.get('quoteVolume', 1000000) / 1000000)\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    if not prices:\n",
        "        return None\n",
        "\n",
        "    # Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† ÙˆØ²Ù†ÛŒ Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§\n",
        "    if sum(weights) > 0:\n",
        "        triangulated_price = sum(p * w for p, w in zip(prices, weights)) / sum(weights)\n",
        "    else:\n",
        "        # Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø³Ø§Ø¯Ù‡ Ø¯Ø± ØµÙˆØ±Øª Ù†Ø¨ÙˆØ¯ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø­Ø¬Ù…\n",
        "        triangulated_price = sum(prices) / len(prices)\n",
        "\n",
        "    return triangulated_price\n",
        "\n",
        "\n",
        "def fetch_recent_data(symbol, timeframe, since_timestamp, limit=100, max_retries=5):\n",
        "    \"\"\"\n",
        "    Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø®ÛŒØ± Ø§Ø² ÛŒÚ© ØªØ§Ø±ÛŒØ® Ù…Ø´Ø®Øµ Ø¨Ø§ Ø³ÛŒØ³ØªÙ… ØªØ£ÛŒÛŒØ¯ Ú†Ù†Ø¯Ú¯Ø§Ù†Ù‡ Ù‚ÛŒÙ…Øª Ùˆ ØªØµØ­ÛŒØ­ Ø®ÙˆØ¯Ú©Ø§Ø±\n",
        "\n",
        "    Args:\n",
        "        symbol: Ù†Ù…Ø§Ø¯ Ø§Ø±Ø²\n",
        "        timeframe: ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…\n",
        "        since_timestamp: ØªØ§Ø±ÛŒØ® Ø´Ø±ÙˆØ¹ Ø¨Ù‡ Ù…ÛŒÙ„ÛŒâ€ŒØ«Ø§Ù†ÛŒÙ‡\n",
        "        limit: ØªØ¹Ø¯Ø§Ø¯ Ú©Ù†Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¯Ø±Ø®ÙˆØ§Ø³ØªÛŒ\n",
        "        max_retries: Ø­Ø¯Ø§Ú©Ø«Ø± ØªØ¹Ø¯Ø§Ø¯ ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯\n",
        "\n",
        "    Returns:\n",
        "        Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø®ÛŒØ± ÛŒØ§ None Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§\n",
        "    \"\"\"\n",
        "    # Ù„ÛŒØ³Øª ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ ØªØ§ Ø¨Ù‡ Ø­Ø§Ù„ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ø¬ÙØª Ø§Ø±Ø²/ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ… Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯Ù‡â€ŒØ§Ù†Ø¯\n",
        "    successful_exchanges_key = f\"{symbol}_{timeframe}_successful\"\n",
        "    successful_exchanges = fetch_data_cache.get(successful_exchanges_key, [])\n",
        "\n",
        "    # Ø§Ø¨ØªØ¯Ø§ ÛŒÚ© Ù‚ÛŒÙ…Øª Ù…Ø±Ø¬Ø¹ Ø§Ø² Ú†Ù†Ø¯ÛŒÙ† ØµØ±Ø§ÙÛŒ Ø¯Ø±ÛŒØ§ÙØª Ú©Ù†ÛŒÙ…\n",
        "    reference_price = get_market_reference_price(symbol)\n",
        "\n",
        "    # ØªØ±Ø¬ÛŒØ­ Ø¯Ø§Ø¯Ù† ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆÙÙ‚ Ù‚Ø¨Ù„ÛŒ\n",
        "    if successful_exchanges:\n",
        "        exchange_list = successful_exchanges + [ex for ex in EXCHANGES_CONFIG.keys() if ex not in successful_exchanges]\n",
        "    else:\n",
        "        exchange_list = list(EXCHANGES_CONFIG.keys())\n",
        "        random.shuffle(exchange_list)  # ØªØ±ØªÛŒØ¨ ØªØµØ§Ø¯ÙÛŒ\n",
        "\n",
        "    all_dataframes = []  # Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬ Ø§Ø² ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù\n",
        "\n",
        "    for exchange_id in exchange_list:\n",
        "        exchange_class = EXCHANGES_CONFIG[exchange_id]['class']\n",
        "\n",
        "        try:\n",
        "            # Ø¨Ø±Ø±Ø³ÛŒ Ú©ÙˆÙ„Ø¯Ø§Ù† ØµØ±Ø§ÙÛŒ\n",
        "            with request_count_lock:\n",
        "                if exchange_data[exchange_id]['in_cooldown']:\n",
        "                    current_time = time.time()\n",
        "                    if current_time <= exchange_data[exchange_id]['cooldown_until']:\n",
        "                        logger.info(f\"ØµØ±Ø§ÙÛŒ {exchange_id} Ø¯Ø± Ø­Ø§Ù„Øª Ú©ÙˆÙ„Ø¯Ø§Ù† Ø§Ø³Øª. ØªÙ„Ø§Ø´ Ø¨Ø§ ØµØ±Ø§ÙÛŒ Ø¨Ø¹Ø¯ÛŒ...\")\n",
        "                        continue\n",
        "                    else:\n",
        "                        # Ù¾Ø§ÛŒØ§Ù† Ú©ÙˆÙ„Ø¯Ø§Ù†\n",
        "                        exchange_data[exchange_id]['in_cooldown'] = False\n",
        "                        exchange_data[exchange_id]['consecutive_failures'] = 0\n",
        "                        logger.info(f\"ØµØ±Ø§ÙÛŒ {exchange_id} Ø§Ø² Ø­Ø§Ù„Øª Ú©ÙˆÙ„Ø¯Ø§Ù† Ø®Ø§Ø±Ø¬ Ø´Ø¯\")\n",
        "\n",
        "            exchange = exchange_class()\n",
        "\n",
        "            for attempt in range(max_retries):\n",
        "                try:\n",
        "                    # ÛŒÚ© ØªØ§Ø®ÛŒØ± Ú©ÙˆÚ†Ú© Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§ÛŒ Ù‡Ù…Ø²Ù…Ø§Ù†\n",
        "                    if attempt > 0:\n",
        "                        time.sleep(1 + attempt)\n",
        "\n",
        "                    # Ú©Ø§Ù‡Ø´ Ø²Ù…Ø§Ù† since Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ù…Ø·Ù…Ø¦Ù†â€ŒØªØ± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§\n",
        "                    # Ø§Ø² Û² Ú©Ù†Ø¯Ù„ Ù‚Ø¨Ù„â€ŒØªØ± Ø´Ø±ÙˆØ¹ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… ØªØ§ Ú©Ù†Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ Ù‡Ù… Ø§Ú¯Ø± ØªØºÛŒÛŒØ± Ú©Ø±Ø¯Ù‡â€ŒØ§Ù†Ø¯ØŒ Ø¯Ø±ÛŒØ§ÙØª Ø´ÙˆÙ†Ø¯\n",
        "                    tf_seconds = timeframe_to_seconds(timeframe)\n",
        "                    adjusted_since = since_timestamp - (tf_seconds * 2 * 1000)  # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ù…ÛŒÙ„ÛŒâ€ŒØ«Ø§Ù†ÛŒÙ‡\n",
        "\n",
        "                    # Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù¾Ø§Ø±Ø§Ù…ØªØ± since\n",
        "                    ohlcv = exchange.fetch_ohlcv(symbol, timeframe=timeframe, since=adjusted_since, limit=limit)\n",
        "\n",
        "                    if not ohlcv or len(ohlcv) == 0:\n",
        "                        logger.warning(\n",
        "                            f\"Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø§Ø² {exchange_id} Ø¨Ø±Ø§ÛŒ {symbol}/{timeframe} Ø§Ø² {pd.to_datetime(since_timestamp, unit='ms')} Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯\")\n",
        "                        break\n",
        "\n",
        "                    df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n",
        "                    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
        "                    df.set_index('timestamp', inplace=True)\n",
        "\n",
        "                    # Ø¨Ø±Ø±Ø³ÛŒ Ø¢Ø®Ø±ÛŒÙ† Ù‚ÛŒÙ…Øª Ø¨Ø§ Ù‚ÛŒÙ…Øª Ù…Ø±Ø¬Ø¹ (Ø§Ú¯Ø± Ù‚ÛŒÙ…Øª Ù…Ø±Ø¬Ø¹ Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ø´Ø¯)\n",
        "                    if reference_price and len(df) > 0:\n",
        "                        last_price = df['close'].iloc[-1]\n",
        "                        price_difference = abs(last_price / reference_price - 1)\n",
        "\n",
        "                        if price_difference > 0.05:  # Ø§Ø®ØªÙ„Ø§Ù Ø¨ÛŒØ´ Ø§Ø² 5%\n",
        "                            logger.warning(\n",
        "                                f\"âš ï¸ Ø§Ø®ØªÙ„Ø§Ù Ù‚ÛŒÙ…Øª Ø²ÛŒØ§Ø¯ Ø¯Ø± {exchange_id} Ø¨Ø±Ø§ÛŒ {symbol}: {price_difference * 100:.2f}% (Ù…Ø±Ø¬Ø¹: {reference_price}, Ø¯Ø±ÛŒØ§ÙØªÛŒ: {last_price})\")\n",
        "                            # Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø±Ø§ Ø°Ø®ÛŒØ±Ù‡ Ø§Ù…Ø§ Ø¹Ù„Ø§Ù…Øªâ€ŒÚ¯Ø°Ø§Ø±ÛŒ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…\n",
        "                            df.attrs['price_deviation'] = price_difference\n",
        "                        elif price_difference > 0.01:  # Ø§Ø®ØªÙ„Ø§Ù Ø¨ÛŒÙ† 1% ØªØ§ 5%\n",
        "                            logger.info(\n",
        "                                f\"Ø§Ø®ØªÙ„Ø§Ù Ù‚ÛŒÙ…Øª Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡ Ø¯Ø± {exchange_id} Ø¨Ø±Ø§ÛŒ {symbol}: {price_difference * 100:.2f}%\")\n",
        "                            df.attrs['price_deviation'] = price_difference\n",
        "                        else:\n",
        "                            # Ù‚ÛŒÙ…Øª Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª\n",
        "                            df.attrs['price_deviation'] = 0\n",
        "\n",
        "                    # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù¾Ø§ÛŒÙ‡\n",
        "                    df['price_change'] = df['close'].pct_change() * 100\n",
        "                    df['volume_change'] = df['volume'].pct_change() * 100\n",
        "                    df['norm_volume'] = df['volume'] / df['volume'].rolling(window=20).mean()\n",
        "                    df['volatility'] = (df['high'] - df['low']) / df['low'] * 100\n",
        "                    df['exchange_source'] = exchange_id  # Ø°Ø®ÛŒØ±Ù‡ Ù…Ù†Ø¨Ø¹ Ø¯Ø§Ø¯Ù‡\n",
        "\n",
        "                    # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø¢Ù…Ø§Ø± Ù…ÙˆÙÙ‚ÛŒØª\n",
        "                    with request_count_lock:\n",
        "                        exchange_data[exchange_id]['success_count'] += 1\n",
        "                        exchange_data[exchange_id]['consecutive_failures'] = 0\n",
        "\n",
        "                    logger.info(\n",
        "                        f\"Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø®ÛŒØ± Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø² {exchange_id} Ø¨Ø±Ø§ÛŒ {symbol}/{timeframe} Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯: {len(df)} Ú©Ù†Ø¯Ù„\")\n",
        "\n",
        "                    # Ø°Ø®ÛŒØ±Ù‡ Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… Ø¨Ø±Ø§ÛŒ ØªØ±Ú©ÛŒØ¨ Ø¨Ø¹Ø¯ÛŒ\n",
        "                    all_dataframes.append(df)\n",
        "\n",
        "                    # Ø§Ú¯Ø± Ø§ÛŒÙ† ØµØ±Ø§ÙÛŒ Ø§Ø®ØªÙ„Ø§Ù Ù‚ÛŒÙ…Øª Ú©Ù…ÛŒ Ø¯Ø§Ø±Ø¯ØŒ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ø§ÙˆÙ„ÛŒÙ† Ù†ØªÛŒØ¬Ù‡ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†ÛŒÙ…\n",
        "                    if hasattr(df, 'attrs') and df.attrs.get('price_deviation', 1) < 0.01:\n",
        "                        return df\n",
        "\n",
        "                    # Ø§Ø¯Ø§Ù…Ù‡ Ø¨Ø§ ØµØ±Ø§ÙÛŒ Ø¨Ø¹Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ù‚Ø§ÛŒØ³Ù‡\n",
        "                    break\n",
        "\n",
        "                except ccxt.RateLimitExceeded:\n",
        "                    logger.warning(f\"âš ï¸ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ù†Ø±Ø® Ø¯Ø± {exchange_id} Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø®ÛŒØ± {symbol}/{timeframe}\")\n",
        "                    handle_rate_limit(exchange_id)\n",
        "                    break\n",
        "\n",
        "                except Exception as e:\n",
        "                    logger.warning(\n",
        "                        f\"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± ØªÙ„Ø§Ø´ {attempt + 1}/{max_retries} Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø®ÛŒØ± Ø§Ø² {exchange_id}: {str(e)}\")\n",
        "\n",
        "            # Ø§Ú¯Ø± Ø¨Ù‡ Ø§ÛŒÙ†Ø¬Ø§ Ø±Ø³ÛŒØ¯Ù‡â€ŒØ§ÛŒÙ…ØŒ ØµØ±Ø§ÙÛŒ ÙØ¹Ù„ÛŒ Ù…ÙˆÙÙ‚ Ù†Ø¨ÙˆØ¯Ù‡ Ø§Ø³Øª ÛŒØ§ Ù†ØªÛŒØ¬Ù‡â€ŒØ§Ø´ Ù…Ù†Ø§Ø³Ø¨ Ù†Ø¨ÙˆØ¯Ù‡\n",
        "            with request_count_lock:\n",
        "                if len(all_dataframes) == 0:  # ÙÙ‚Ø· Ø§Ú¯Ø± Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ù†Ú©Ø±Ø¯Ù‡ Ø¨Ø§Ø´ÛŒÙ…\n",
        "                    exchange_data[exchange_id]['fail_count'] += 1\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ğŸš¨ Ø®Ø·Ø§ÛŒ Ø§ØªØµØ§Ù„ Ø¨Ù‡ {exchange_id} Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø®ÛŒØ±: {str(e)}\")\n",
        "            with request_count_lock:\n",
        "                exchange_data[exchange_id]['fail_count'] += 1\n",
        "\n",
        "    # Ø§Ú¯Ø± Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ù†Ú©Ø±Ø¯ÛŒÙ…\n",
        "    if len(all_dataframes) == 0:\n",
        "        logger.error(f\"âŒ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø®ÛŒØ± Ø¨Ø±Ø§ÛŒ {symbol}/{timeframe} Ø§Ø² ØªÙ…Ø§Ù… ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§ Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯\")\n",
        "        return None\n",
        "\n",
        "    # Ø§Ú¯Ø± Ø¨ÛŒØ´ Ø§Ø² ÛŒÚ© Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… Ø¯Ø±ÛŒØ§ÙØª Ú©Ø±Ø¯ÛŒÙ…ØŒ Ø¨Ù‡ØªØ±ÛŒÙ† Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ ÛŒØ§ ØªØ±Ú©ÛŒØ¨ Ú©Ù†ÛŒÙ…\n",
        "    if len(all_dataframes) > 1:\n",
        "        return merge_and_correct_data(all_dataframes, reference_price, symbol, timeframe)\n",
        "\n",
        "    # Ø§Ú¯Ø± ØªÙ†Ù‡Ø§ ÛŒÚ© Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… Ø¯Ø§Ø±ÛŒÙ…ØŒ Ù‡Ù…Ø§Ù† Ø±Ø§ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†ÛŒÙ…\n",
        "    return all_dataframes[0]\n",
        "\n",
        "\n",
        "def get_market_reference_price(symbol, timeout=3):\n",
        "    \"\"\"\n",
        "    Ø¯Ø±ÛŒØ§ÙØª Ù‚ÛŒÙ…Øª Ù…Ø±Ø¬Ø¹ Ø§Ø² Ú†Ù†Ø¯ÛŒÙ† Ù…Ù†Ø¨Ø¹ Ø¨Ø±Ø§ÛŒ Ù…Ù‚Ø§ÛŒØ³Ù‡\n",
        "\n",
        "    Args:\n",
        "        symbol: Ù†Ù…Ø§Ø¯ Ø§Ø±Ø²\n",
        "        timeout: Ø²Ù…Ø§Ù† Ø§Ù†ØªØ¸Ø§Ø± Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª (Ø«Ø§Ù†ÛŒÙ‡)\n",
        "\n",
        "    Returns:\n",
        "        Ù‚ÛŒÙ…Øª Ù…Ø±Ø¬Ø¹ ÛŒØ§ None Ø¯Ø± ØµÙˆØ±Øª Ø¹Ø¯Ù… Ø¯Ø±ÛŒØ§ÙØª\n",
        "    \"\"\"\n",
        "    prices = []\n",
        "    weights = []\n",
        "\n",
        "    # Ø¯Ø±ÛŒØ§ÙØª Ù‚ÛŒÙ…Øª Ø§Ø² Ø³Ø±ÙˆÛŒØ³â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù\n",
        "    # 1. Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² CCXT - Ø§Ø² Ù…Ù†Ø§Ø¨Ø¹ Ù…ÙˆÙÙ‚ Ù…ØªØ¹Ø¯Ø¯\n",
        "    for exchange_id in ['binance', 'kucoin', 'gate', 'mexc']:\n",
        "        try:\n",
        "            exchange_class = getattr(ccxt, exchange_id)\n",
        "            exchange = exchange_class()\n",
        "            ticker = exchange.fetch_ticker(symbol)\n",
        "            if ticker and 'last' in ticker and ticker['last']:\n",
        "                prices.append(ticker['last'])\n",
        "                # ÙˆØ²Ù† Ø¨Ø±Ø§Ø³Ø§Ø³ Ø§Ø¹ØªØ¨Ø§Ø± ØµØ±Ø§ÙÛŒ\n",
        "                if exchange_id == 'binance':\n",
        "                    weights.append(10)  # ÙˆØ²Ù† Ø¨ÛŒØ´ØªØ± Ø¨Ø±Ø§ÛŒ Ø¨Ø§ÛŒÙ†Ù†Ø³ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† ØµØ±Ø§ÙÛŒ Ù…Ø±Ø¬Ø¹\n",
        "                else:\n",
        "                    weights.append(5)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    # 2. Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² CoinGecko API (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)\n",
        "    try:\n",
        "        coin_id = symbol.split('/')[0].lower()\n",
        "        response = requests.get(f\"https://api.coingecko.com/api/v3/simple/price?ids={coin_id}&vs_currencies=usd\",\n",
        "                                timeout=timeout)\n",
        "        if response.status_code == 200:\n",
        "            data = response.json()\n",
        "            if coin_id in data and 'usd' in data[coin_id]:\n",
        "                prices.append(data[coin_id]['usd'])\n",
        "                weights.append(3)  # ÙˆØ²Ù† Ú©Ù…ØªØ± Ø¨Ø±Ø§ÛŒ CoinGecko\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # Ø§Ú¯Ø± Ù‡ÛŒÚ† Ù‚ÛŒÙ…ØªÛŒ Ø¯Ø±ÛŒØ§ÙØª Ù†Ú©Ø±Ø¯ÛŒÙ…\n",
        "    if not prices:\n",
        "        return None\n",
        "\n",
        "    # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† ÙˆØ²Ù†ÛŒ Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§\n",
        "    if sum(weights) > 0:\n",
        "        reference_price = sum(p * w for p, w in zip(prices, weights)) / sum(weights)\n",
        "    else:\n",
        "        # Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø³Ø§Ø¯Ù‡\n",
        "        reference_price = sum(prices) / len(prices)\n",
        "\n",
        "    return reference_price\n",
        "\n",
        "\n",
        "def merge_and_correct_data(dataframes, reference_price, symbol, timeframe):\n",
        "    \"\"\"\n",
        "    ØªØ±Ú©ÛŒØ¨ Ùˆ ØªØµØ­ÛŒØ­ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯Ù‡ Ø§Ø² Ù…Ù†Ø§Ø¨Ø¹ Ù…Ø®ØªÙ„Ù\n",
        "\n",
        "    Args:\n",
        "        dataframes: Ù„ÛŒØ³Øª Ø¯ÛŒØªØ§ÙØ±ÛŒÙ…â€ŒÙ‡Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØªÛŒ\n",
        "        reference_price: Ù‚ÛŒÙ…Øª Ù…Ø±Ø¬Ø¹ Ø¨Ø±Ø§ÛŒ ØªØµØ­ÛŒØ­\n",
        "        symbol: Ù†Ù…Ø§Ø¯ Ø§Ø±Ø²\n",
        "        timeframe: ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…\n",
        "\n",
        "    Returns:\n",
        "        Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… ØªØ±Ú©ÛŒØ¨ Ø´Ø¯Ù‡ Ùˆ ØªØµØ­ÛŒØ­ Ø´Ø¯Ù‡\n",
        "    \"\"\"\n",
        "    if len(dataframes) == 0:\n",
        "        return None\n",
        "\n",
        "    # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø±Ø§Ø³Ø§Ø³ Ø§Ø®ØªÙ„Ø§Ù Ù‚ÛŒÙ…Øª (Ø§Ø² Ú©Ù…ØªØ±ÛŒÙ† Ø¨Ù‡ Ø¨ÛŒØ´ØªØ±ÛŒÙ†)\n",
        "    sorted_dfs = sorted(dataframes, key=lambda df: df.attrs.get('price_deviation', 1) if hasattr(df, 'attrs') else 1)\n",
        "\n",
        "    # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… Ø¨Ø§ Ú©Ù…ØªØ±ÛŒÙ† Ø§Ø®ØªÙ„Ø§Ù Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ù¾Ø§ÛŒÙ‡\n",
        "    base_df = sorted_dfs[0].copy()\n",
        "\n",
        "    # Ø§Ú¯Ø± ÙÙ‚Ø· ÛŒÚ© Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… Ø¯Ø§Ø±ÛŒÙ… ÛŒØ§ Ù‚ÛŒÙ…Øª Ù…Ø±Ø¬Ø¹ Ù†Ø¯Ø§Ø±ÛŒÙ…\n",
        "    if len(sorted_dfs) == 1 or not reference_price:\n",
        "        logger.info(f\"Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… {base_df['exchange_source'].iloc[0]} Ø¨Ø±Ø§ÛŒ {symbol}/{timeframe}\")\n",
        "        return base_df\n",
        "\n",
        "    # ØªØ±Ú©ÛŒØ¨ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø§Ø² Ù…Ù†Ø§Ø¨Ø¹ Ù…Ø®ØªÙ„Ù Ø¨Ø§ ÙˆØ²Ù†â€ŒØ¯Ù‡ÛŒ Ø¨Ø±Ø§Ø³Ø§Ø³ Ø§Ø®ØªÙ„Ø§Ù Ù‚ÛŒÙ…Øª\n",
        "    for i in range(1, len(sorted_dfs)):\n",
        "        df = sorted_dfs[i]\n",
        "        # ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ú©Ù†Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø´ØªØ±Ú©\n",
        "        common_indices = base_df.index.intersection(df.index)\n",
        "\n",
        "        if len(common_indices) > 0:\n",
        "            # ÙˆØ²Ù† Ø¨Ø±Ø§Ø³Ø§Ø³ Ø§Ù†Ø­Ø±Ø§Ù Ù‚ÛŒÙ…Øª - ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§ÛŒ Ø¨Ø§ Ø§Ù†Ø­Ø±Ø§Ù Ú©Ù…ØªØ± ÙˆØ²Ù† Ø¨ÛŒØ´ØªØ±ÛŒ Ø¯Ø§Ø±Ù†Ø¯\n",
        "            weight_base = 1 / (base_df.attrs.get('price_deviation', 0.01) + 0.01)\n",
        "            weight_df = 1 / (df.attrs.get('price_deviation', 0.01) + 0.01)\n",
        "\n",
        "            for col in ['open', 'high', 'low', 'close']:\n",
        "                # Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† ÙˆØ²Ù†ÛŒ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø³ØªÙˆÙ†\n",
        "                weights_sum = weight_base + weight_df\n",
        "                base_df.loc[common_indices, col] = (\n",
        "                                                           (base_df.loc[common_indices, col] * weight_base) +\n",
        "                                                           (df.loc[common_indices, col] * weight_df)\n",
        "                                                   ) / weights_sum\n",
        "\n",
        "    # ØªØµØ­ÛŒØ­ Ù†Ù‡Ø§ÛŒÛŒ Ù‚ÛŒÙ…Øª Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù‚ÛŒÙ…Øª Ù…Ø±Ø¬Ø¹ (Ø§Ú¯Ø± Ø§Ø®ØªÙ„Ø§Ù Ø²ÛŒØ§Ø¯ Ø¨Ø§Ø´Ø¯)\n",
        "    if reference_price:\n",
        "        last_close = base_df['close'].iloc[-1]\n",
        "        diff_pct = abs(last_close / reference_price - 1)\n",
        "\n",
        "        if diff_pct > 0.02:  # Ø§Ø®ØªÙ„Ø§Ù Ø¨ÛŒØ´ Ø§Ø² 2%\n",
        "            logger.warning(f\"ØªØµØ­ÛŒØ­ Ù†Ù‡Ø§ÛŒÛŒ Ù‚ÛŒÙ…Øª {symbol} Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù‚ÛŒÙ…Øª Ù…Ø±Ø¬Ø¹. Ø§Ø®ØªÙ„Ø§Ù: {diff_pct * 100:.2f}%\")\n",
        "\n",
        "            # Ø¶Ø±ÛŒØ¨ ØªØµØ­ÛŒØ­\n",
        "            correction_factor = reference_price / last_close\n",
        "\n",
        "            # Ø§Ø¹Ù…Ø§Ù„ Ø¶Ø±ÛŒØ¨ ÙÙ‚Ø· Ø¨Ù‡ Ø¢Ø®Ø±ÛŒÙ† Ú©Ù†Ø¯Ù„\n",
        "            base_df.loc[base_df.index[-1], 'open'] *= correction_factor\n",
        "            base_df.loc[base_df.index[-1], 'high'] *= correction_factor\n",
        "            base_df.loc[base_df.index[-1], 'low'] *= correction_factor\n",
        "            base_df.loc[base_df.index[-1], 'close'] *= correction_factor\n",
        "\n",
        "            # Ø¨Ø§Ø²Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù…Ø´ØªÙ‚ Ø´Ø¯Ù‡\n",
        "            base_df['price_change'] = base_df['close'].pct_change() * 100\n",
        "            base_df['volatility'] = (base_df['high'] - base_df['low']) / base_df['low'] * 100\n",
        "\n",
        "    logger.info(f\"ØªØ±Ú©ÛŒØ¨ Ù…ÙˆÙÙ‚ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø§Ø² {len(sorted_dfs)} Ù…Ù†Ø¨Ø¹ Ø¨Ø±Ø§ÛŒ {symbol}/{timeframe}\")\n",
        "    return base_df\n",
        "\n",
        "\n",
        "def get_fallback_price(symbol):\n",
        "    \"\"\"Ø¯Ø±ÛŒØ§ÙØª Ù‚ÛŒÙ…Øª Ø§Ø² Ù…Ù†Ø§Ø¨Ø¹ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§ Ø¯Ø± Ù…Ù†Ø§Ø¨Ø¹ Ø§ØµÙ„ÛŒ\"\"\"\n",
        "    try:\n",
        "        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² API Ø¹Ù…ÙˆÙ…ÛŒ Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ù‚ÛŒÙ…Øª\n",
        "        response = requests.get(\n",
        "            f\"https://api.coingecko.com/api/v3/simple/price?ids={symbol.split('/')[0].lower()}&vs_currencies=usd\",\n",
        "            timeout=5)\n",
        "        if response.status_code == 200:\n",
        "            data = response.json()\n",
        "            if symbol.split('/')[0].lower() in data:\n",
        "                return data[symbol.split('/')[0].lower()]['usd']\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Binance Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ù…Ù†Ø¨Ø¹ Ù…Ø±Ø¬Ø¹\n",
        "    try:\n",
        "        binance = ccxt.binance()\n",
        "        ticker = binance.fetch_ticker(symbol)\n",
        "        if ticker and 'last' in ticker:\n",
        "            return ticker['last']\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    return None\n",
        "\n",
        "def merge_dataframes(df_old, df_new):\n",
        "    \"\"\"\n",
        "    Ø§Ø¯ØºØ§Ù… Ø¯Ùˆ Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… Ø¨Ø§ Ù…Ø¯ÛŒØ±ÛŒØª Ù‡Ù…Ù¾ÙˆØ´Ø§Ù†ÛŒ\n",
        "\n",
        "    Args:\n",
        "        df_old: Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… Ù‚Ø¯ÛŒÙ…ÛŒ\n",
        "        df_new: Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… Ø¬Ø¯ÛŒØ¯ Ø¨Ø§ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ§Ø²Ù‡\n",
        "\n",
        "    Returns:\n",
        "        Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… ØªØ±Ú©ÛŒØ¨ Ø´Ø¯Ù‡\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if df_old is None or df_new is None:\n",
        "            return df_old if df_old is not None else df_new\n",
        "\n",
        "        # Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ø§ÛŒÙ†Ú©Ù‡ Ù‡Ø± Ø¯Ùˆ Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… timestamp Ø±Ø§ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ø´Ø§Ø®Øµ Ø¯Ø§Ø±Ù†Ø¯\n",
        "        if 'timestamp' in df_old.columns:\n",
        "            df_old = df_old.set_index('timestamp')\n",
        "\n",
        "        if 'timestamp' in df_new.columns:\n",
        "            df_new = df_new.set_index('timestamp')\n",
        "\n",
        "        # ØªØ±Ú©ÛŒØ¨ Ø¯Ùˆ Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… Ø¨Ø§ Ø­Ø°Ù Ù‡Ù…Ù¾ÙˆØ´Ø§Ù†ÛŒ\n",
        "        df_combined = pd.concat([df_old, df_new])\n",
        "\n",
        "        # Ø­Ø°Ù Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§ÛŒ ØªÚ©Ø±Ø§Ø±ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø´Ø§Ø®Øµ (timestamp)\n",
        "        df_combined = df_combined[~df_combined.index.duplicated(keep='last')]\n",
        "\n",
        "        # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ§Ø±ÛŒØ®\n",
        "        df_combined = df_combined.sort_index()\n",
        "\n",
        "        # Ù¾Ø± Ú©Ø±Ø¯Ù† Ù…Ù‚Ø§Ø¯ÛŒØ± NaN Ø§Ø­ØªÙ…Ø§Ù„ÛŒ\n",
        "        if df_combined.isnull().sum().sum() > 0:\n",
        "            df_combined = df_combined.ffill().bfill()\n",
        "\n",
        "        return df_combined\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø¯ØºØ§Ù… Ø¯ÛŒØªØ§ÙØ±ÛŒÙ…â€ŒÙ‡Ø§: {e}\")\n",
        "        # Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§ØŒ Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… Ù‚Ø¯ÛŒÙ…ÛŒ Ø±Ø§ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†ÛŒÙ…\n",
        "        return df_old\n",
        "\n",
        "\n",
        "def correct_price_data(df, symbol):\n",
        "    \"\"\"ØªØµØ­ÛŒØ­ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù‚ÛŒÙ…Øª Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ù†Ø§Ø¨Ø¹ Ù…Ø®ØªÙ„Ù\"\"\"\n",
        "    if df is None or len(df) == 0:\n",
        "        return df\n",
        "\n",
        "    try:\n",
        "        # Ø¯Ø±ÛŒØ§ÙØª Ù‚ÛŒÙ…Øª ÙØ¹Ù„ÛŒ Ø¨Ø§Ø²Ø§Ø±\n",
        "        market_price = get_triangulated_price(symbol)\n",
        "        if not market_price:\n",
        "            market_price = get_fallback_price(symbol)\n",
        "\n",
        "        if market_price:\n",
        "            last_price = df['close'].iloc[-1]\n",
        "            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¯Ø±ØµØ¯ Ø§Ø®ØªÙ„Ø§Ù\n",
        "            diff_pct = abs(last_price / market_price - 1) * 100\n",
        "\n",
        "            if diff_pct > 5:\n",
        "                # Ø§Ø®ØªÙ„Ø§Ù Ø®ÛŒÙ„ÛŒ Ø²ÛŒØ§Ø¯ - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ø§Ù…Ù„ Ø§Ø² Ù‚ÛŒÙ…Øª Ø¨Ø§Ø²Ø§Ø±\n",
        "                logger.warning(f\"Ø§Ø®ØªÙ„Ø§Ù Ù‚ÛŒÙ…Øª Ø¨Ø³ÛŒØ§Ø± Ø²ÛŒØ§Ø¯ Ø¨Ø±Ø§ÛŒ {symbol}: {diff_pct:.2f}% - ØªØµØ­ÛŒØ­ Ú©Ø§Ù…Ù„\")\n",
        "                df['close'].iloc[-1] = market_price\n",
        "                df['open'].iloc[-1] = (df['open'].iloc[-1] * market_price / last_price)\n",
        "                df['high'].iloc[-1] = max(df['high'].iloc[-1] * market_price / last_price, market_price)\n",
        "                df['low'].iloc[-1] = min(df['low'].iloc[-1] * market_price / last_price, market_price)\n",
        "            elif diff_pct > 1:\n",
        "                # Ø§Ø®ØªÙ„Ø§Ù Ù…ØªÙˆØ³Ø· - ØªØ±Ú©ÛŒØ¨ Ù‚ÛŒÙ…Øª Ø¯Ø§Ø¯Ù‡ Ùˆ Ø¨Ø§Ø²Ø§Ø±\n",
        "                logger.info(f\"ØªØµØ­ÛŒØ­ Ø¬Ø²Ø¦ÛŒ Ù‚ÛŒÙ…Øª {symbol}: {diff_pct:.2f}%\")\n",
        "                weight_market = min(diff_pct / 5, 0.8)  # Ø­Ø¯Ø§Ú©Ø«Ø± 80% ÙˆØ²Ù† Ø¨Ù‡ Ù‚ÛŒÙ…Øª Ø¨Ø§Ø²Ø§Ø±\n",
        "                weight_data = 1 - weight_market\n",
        "                df['close'].iloc[-1] = (market_price * weight_market) + (last_price * weight_data)\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Ø®Ø·Ø§ Ø¯Ø± ØªØµØ­ÛŒØ­ Ù‚ÛŒÙ…Øª {symbol}: {e}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "def timeframe_to_seconds(timeframe):\n",
        "    \"\"\"\n",
        "    ØªØ¨Ø¯ÛŒÙ„ ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ… Ø¨Ù‡ Ø«Ø§Ù†ÛŒÙ‡\n",
        "\n",
        "    Args:\n",
        "        timeframe: ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ… Ù…Ø§Ù†Ù†Ø¯ \"15m\", \"1h\", \"4h\", \"1d\"\n",
        "\n",
        "    Returns:\n",
        "        Ù…Ù‚Ø¯Ø§Ø± Ù…Ø¹Ø§Ø¯Ù„ Ø¨Ù‡ Ø«Ø§Ù†ÛŒÙ‡\n",
        "    \"\"\"\n",
        "    try:\n",
        "        unit = timeframe[-1]\n",
        "        value = int(timeframe[:-1])\n",
        "\n",
        "        if unit == 'm':\n",
        "            return value * 60\n",
        "        elif unit == 'h':\n",
        "            return value * 60 * 60\n",
        "        elif unit == 'd':\n",
        "            return value * 24 * 60 * 60\n",
        "        elif unit == 'w':\n",
        "            return value * 7 * 24 * 60 * 60\n",
        "        else:\n",
        "            return 3600  # Ù¾ÛŒØ´â€ŒÙØ±Ø¶: 1 Ø³Ø§Ø¹Øª\n",
        "    except:\n",
        "        return 3600  # Ù¾ÛŒØ´â€ŒÙØ±Ø¶: 1 Ø³Ø§Ø¹Øª\n",
        "\n",
        "\n",
        "def track_last_analysis_time(symbol, timeframe, timestamp=None):\n",
        "    \"\"\"\n",
        "    Ø«Ø¨Øª Ø²Ù…Ø§Ù† Ø¢Ø®Ø±ÛŒÙ† ØªØ­Ù„ÛŒÙ„ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ù†Ù…Ø§Ø¯ Ùˆ ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…\n",
        "\n",
        "    Args:\n",
        "        symbol: Ù†Ù…Ø§Ø¯ Ø§Ø±Ø²\n",
        "        timeframe: ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…\n",
        "        timestamp: Ø²Ù…Ø§Ù† ØªØ­Ù„ÛŒÙ„ (None Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø²Ù…Ø§Ù† ÙØ¹Ù„ÛŒ)\n",
        "\n",
        "    Returns:\n",
        "        Ø²Ù…Ø§Ù† Ø«Ø¨Øª Ø´Ø¯Ù‡\n",
        "    \"\"\"\n",
        "    global last_analysis_times\n",
        "\n",
        "    key = f\"{symbol}_{timeframe}\"\n",
        "\n",
        "    # Ø§Ú¯Ø± timestamp Ø¯Ø§Ø¯Ù‡ Ù†Ø´Ø¯Ù‡ØŒ Ø§Ø² Ø²Ù…Ø§Ù† ÙØ¹Ù„ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…\n",
        "    current_time = timestamp if timestamp is not None else time.time()\n",
        "\n",
        "    # Ø«Ø¨Øª Ø²Ù…Ø§Ù†\n",
        "    last_analysis_times[key] = current_time\n",
        "\n",
        "    return current_time\n",
        "\n",
        "\n",
        "def get_last_analysis_time(symbol, timeframe):\n",
        "    \"\"\"\n",
        "    Ø¯Ø±ÛŒØ§ÙØª Ø²Ù…Ø§Ù† Ø¢Ø®Ø±ÛŒÙ† ØªØ­Ù„ÛŒÙ„ Ø¨Ø±Ø§ÛŒ ÛŒÚ© Ù†Ù…Ø§Ø¯ Ùˆ ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ… Ø®Ø§Øµ\n",
        "\n",
        "    Args:\n",
        "        symbol: Ù†Ù…Ø§Ø¯ Ø§Ø±Ø²\n",
        "        timeframe: ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…\n",
        "\n",
        "    Returns:\n",
        "        Ø²Ù…Ø§Ù† Ø¢Ø®Ø±ÛŒÙ† ØªØ­Ù„ÛŒÙ„ ÛŒØ§ None Ø§Ú¯Ø± ØªØ­Ù„ÛŒÙ„ÛŒ Ø§Ù†Ø¬Ø§Ù… Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª\n",
        "    \"\"\"\n",
        "    global last_analysis_times\n",
        "\n",
        "    key = f\"{symbol}_{timeframe}\"\n",
        "\n",
        "    return last_analysis_times.get(key, None)\n",
        "\n",
        "\n",
        "def force_latest_data(symbol, timeframe, limit=100):\n",
        "    \"\"\"\n",
        "    Ø¯Ø±ÛŒØ§ÙØª Ø§Ø¬Ø¨Ø§Ø±ÛŒ Ø¢Ø®Ø±ÛŒÙ† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø§Ø² Ø¨Ø§Ø²Ø§Ø± Ø¨Ø¯ÙˆÙ† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ú©Ø´\n",
        "\n",
        "    Args:\n",
        "        symbol: Ù†Ù…Ø§Ø¯ Ø§Ø±Ø²\n",
        "        timeframe: ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…\n",
        "        limit: ØªØ¹Ø¯Ø§Ø¯ Ú©Ù†Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¯Ø±Ø®ÙˆØ§Ø³ØªÛŒ\n",
        "\n",
        "    Returns:\n",
        "        Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ ÛŒØ§ None Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§\n",
        "    \"\"\"\n",
        "    logger.info(f\"ğŸ”„ Ø¯Ø±ÛŒØ§ÙØª Ø§Ø¬Ø¨Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ {symbol}/{timeframe}\")\n",
        "\n",
        "    # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¨Ø§ÛŒÙ†Ù†Ø³ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ù…Ù†Ø¨Ø¹ Ø§ØµÙ„ÛŒ Ø§Ú¯Ø± Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ø¨Ø§Ø´Ø¯\n",
        "    primary_exchanges = ['binance', 'kucoin', 'gate', 'mexc', 'bitfinex', 'huobi']\n",
        "    all_results = []\n",
        "\n",
        "    for exchange_id in primary_exchanges:\n",
        "        try:\n",
        "            # Ø§ÛŒØ¬Ø§Ø¯ Ù†Ù…ÙˆÙ†Ù‡ ØµØ±Ø§ÙÛŒ\n",
        "            if exchange_id not in EXCHANGES_CONFIG and hasattr(ccxt, exchange_id):\n",
        "                exchange = getattr(ccxt, exchange_id)()\n",
        "            else:\n",
        "                exchange_class = EXCHANGES_CONFIG.get(exchange_id, {}).get('class')\n",
        "                if not exchange_class:\n",
        "                    continue\n",
        "                exchange = exchange_class()\n",
        "\n",
        "            # ØªÙ†Ø¸ÛŒÙ… Ø²Ù…Ø§Ù† Ø§Ù†Ù‚Ø¶Ø§ÛŒ Ø¯Ø±Ø®ÙˆØ§Ø³Øª\n",
        "            exchange.options['timeout'] = 10000  # 10 Ø«Ø§Ù†ÛŒÙ‡\n",
        "\n",
        "            # Ø¯Ø±ÛŒØ§ÙØª Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨Ø§Ø²Ø§Ø± Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù†Ù…Ø§Ø¯\n",
        "            if symbol not in exchange.load_markets():\n",
        "                continue\n",
        "\n",
        "            # Ø¯Ø±ÛŒØ§ÙØª Ø²Ù…Ø§Ù† Ø³Ø±ÙˆØ± Ø¨Ø±Ø§ÛŒ ØªØ·Ø¨ÛŒÙ‚ Ø²Ù…Ø§Ù†\n",
        "            server_time = exchange.fetch_time() if hasattr(exchange, 'fetch_time') else int(time.time() * 1000)\n",
        "\n",
        "            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø²Ù…Ø§Ù† Ø´Ø±ÙˆØ¹ Ø¨Ø±Ø§Ø³Ø§Ø³ ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…\n",
        "            seconds_per_candle = timeframe_to_seconds(timeframe)\n",
        "            start_timestamp = server_time - (seconds_per_candle * limit * 1000)\n",
        "\n",
        "            # Ø¯Ø±ÛŒØ§ÙØª Ú©Ù†Ø¯Ù„â€ŒÙ‡Ø§\n",
        "            ohlcv = exchange.fetch_ohlcv(symbol, timeframe=timeframe, since=start_timestamp, limit=limit)\n",
        "\n",
        "            if not ohlcv or len(ohlcv) < limit * 0.8:  # Ø§Ú¯Ø± Ú©Ù…ØªØ± Ø§Ø² 80% Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¯Ø±Ø®ÙˆØ§Ø³ØªÛŒ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù‡ Ø´Ø¯\n",
        "                logger.warning(f\"Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² {exchange_id} Ø¨Ø±Ø§ÛŒ {symbol}/{timeframe}\")\n",
        "                continue\n",
        "\n",
        "            # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ø¯ÛŒØªØ§ÙØ±ÛŒÙ…\n",
        "            df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n",
        "            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
        "\n",
        "            # Ø¨Ø±Ø±Ø³ÛŒ ØªØ§Ø²Ú¯ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§\n",
        "            current_time = pd.Timestamp.now()\n",
        "            latest_candle_time = df['timestamp'].max()\n",
        "            time_diff = (current_time - latest_candle_time).total_seconds() / 60  # ØªÙØ§ÙˆØª Ø¨Ù‡ Ø¯Ù‚ÛŒÙ‚Ù‡\n",
        "\n",
        "            # Ø§ÙØ²ÙˆØ¯Ù† Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©ÛŒÙÛŒØª Ø¨Ù‡ Ø¯ÛŒØªØ§ÙØ±ÛŒÙ…\n",
        "            df['time_lag'] = time_diff\n",
        "            df['data_source'] = exchange_id\n",
        "\n",
        "            logger.info(\n",
        "                f\"Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø§Ø² {exchange_id} Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯ - Ø¢Ø®Ø±ÛŒÙ† Ú©Ù†Ø¯Ù„: {latest_candle_time}, ØªØ§Ø®ÛŒØ±: {time_diff:.1f} Ø¯Ù‚ÛŒÙ‚Ù‡\")\n",
        "\n",
        "            # Ø°Ø®ÛŒØ±Ù‡ Ù†ØªÛŒØ¬Ù‡\n",
        "            all_results.append((df, time_diff))\n",
        "\n",
        "            # Ø§Ú¯Ø± ØªØ§Ø®ÛŒØ± Ú©Ù…ØªØ± Ø§Ø² Ù…Ø¯Øª ÛŒÚ© Ú©Ù†Ø¯Ù„ Ø§Ø³ØªØŒ Ù†ØªÛŒØ¬Ù‡ Ø±Ø§ Ù…Ø³ØªÙ‚ÛŒÙ…Ø§Ù‹ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†\n",
        "            if time_diff < seconds_per_candle / 60:\n",
        "                df.set_index('timestamp', inplace=True)\n",
        "                return df\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø§Ø² {exchange_id}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "    # Ø§Ú¯Ø± Ù†ØªÛŒØ¬Ù‡â€ŒØ§ÛŒ Ù†Ø¯Ø§Ø±ÛŒÙ…\n",
        "    if not all_results:\n",
        "        logger.error(f\"âŒ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ {symbol}/{timeframe} Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯\")\n",
        "        return None\n",
        "\n",
        "    # Ø§Ù†ØªØ®Ø§Ø¨ Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… Ø¨Ø§ Ú©Ù…ØªØ±ÛŒÙ† ØªØ§Ø®ÛŒØ±\n",
        "    all_results.sort(key=lambda x: x[1])  # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø±Ø§Ø³Ø§Ø³ ØªØ§Ø®ÛŒØ±\n",
        "    best_df = all_results[0][0]\n",
        "    best_df.set_index('timestamp', inplace=True)\n",
        "\n",
        "    # Ø§ÙØ²ÙˆØ¯Ù† Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²\n",
        "    best_df['price_change'] = best_df['close'].pct_change() * 100\n",
        "    best_df['volume_change'] = best_df['volume'].pct_change() * 100\n",
        "    best_df['norm_volume'] = best_df['volume'] / best_df['volume'].rolling(window=20).mean()\n",
        "    best_df['volatility'] = (best_df['high'] - best_df['low']) / best_df['low'] * 100\n",
        "\n",
        "    logger.info(\n",
        "        f\"Ø¨Ù‡ØªØ±ÛŒÙ† Ø¯Ø§Ø¯Ù‡ Ø§Ø² {best_df['data_source'].iloc[0]} Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯ - ØªØ§Ø®ÛŒØ±: {best_df['time_lag'].iloc[0]:.1f} Ø¯Ù‚ÛŒÙ‚Ù‡\")\n",
        "    return best_df\n",
        "\n",
        "def fetch_from_single_exchange(symbol, timeframe, exchange_id, limit=1000, max_retries=3, delay=2):\n",
        "    \"\"\"Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ Ø§Ø² ÛŒÚ© ØµØ±Ø§ÙÛŒ Ù…Ø´Ø®Øµ Ø¨Ø§ Ù…Ø¯ÛŒØ±ÛŒØª Ø®Ø·Ø§Ù‡Ø§\"\"\"\n",
        "    exchange_class = EXCHANGES_CONFIG[exchange_id]['class']\n",
        "\n",
        "    try:\n",
        "        exchange = exchange_class()\n",
        "\n",
        "        for attempt in range(max_retries):\n",
        "            try:\n",
        "                # Ø§ÙØ²ÙˆØ¯Ù† ØªØ§Ø®ÛŒØ± Ù‚Ø¨Ù„ Ø§Ø² Ù‡Ø± ØªÙ„Ø§Ø´ (Ø¨Ù‡ Ø¬Ø² Ø§ÙˆÙ„ÛŒÙ† ØªÙ„Ø§Ø´)\n",
        "                if attempt > 0:\n",
        "                    sleep_time = delay * (attempt + 1) + random.uniform(0, 2)\n",
        "                    time.sleep(sleep_time)\n",
        "\n",
        "                # ØªÙ†Ø¸ÛŒÙ… Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª ØªØ¹Ø¯Ø§Ø¯ Ú©Ù†Ø¯Ù„â€ŒÙ‡Ø§\n",
        "                if timeframe in ['15m']:\n",
        "                    # Ø¨Ø±Ø§ÛŒ ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…â€ŒÙ‡Ø§ÛŒ Ú©ÙˆØªØ§Ù‡ØŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨ÛŒØ´ØªØ±ÛŒ Ù†ÛŒØ§Ø² Ø¯Ø§Ø±ÛŒÙ…\n",
        "                    actual_limit = min(1500, limit)\n",
        "                else:\n",
        "                    actual_limit = limit\n",
        "\n",
        "                ohlcv = exchange.fetch_ohlcv(symbol, timeframe=timeframe, limit=actual_limit)\n",
        "\n",
        "                if not ohlcv or len(ohlcv) < 80:\n",
        "                    logger.warning(\n",
        "                        f\"Ø¯Ø§Ø¯Ù‡ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² {exchange_id} Ø¨Ø±Ø§ÛŒ {symbol}/{timeframe}: {len(ohlcv) if ohlcv else 0} Ú©Ù†Ø¯Ù„\")\n",
        "                    continue\n",
        "\n",
        "                df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n",
        "                df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
        "                df.set_index('timestamp', inplace=True)\n",
        "\n",
        "                # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù¾Ø§ÛŒÙ‡\n",
        "                df['price_change'] = df['close'].pct_change() * 100\n",
        "                df['volume_change'] = df['volume'].pct_change() * 100\n",
        "                df['norm_volume'] = df['volume'] / df['volume'].rolling(window=20).mean()\n",
        "                df['volatility'] = (df['high'] - df['low']) / df['low'] * 100\n",
        "\n",
        "                # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø¢Ù…Ø§Ø± Ù…ÙˆÙÙ‚ÛŒØª\n",
        "                with request_count_lock:\n",
        "                    exchange_data[exchange_id]['success_count'] += 1\n",
        "                    # Ø±ÛŒØ³Øª Ø®Ø·Ø§Ù‡Ø§ÛŒ Ù…ØªÙˆØ§Ù„ÛŒ\n",
        "                    exchange_data[exchange_id]['consecutive_failures'] = 0\n",
        "\n",
        "                logger.info(f\"Ø¯Ø§Ø¯Ù‡ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø² {exchange_id} Ø¨Ø±Ø§ÛŒ {symbol}/{timeframe} Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯: {len(df)} Ú©Ù†Ø¯Ù„\")\n",
        "                return df\n",
        "\n",
        "            except ccxt.RateLimitExceeded:\n",
        "                logger.warning(f\"âš ï¸ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ù†Ø±Ø® Ø¯Ø± {exchange_id} Ø¨Ø±Ø§ÛŒ {symbol}/{timeframe}\")\n",
        "                handle_rate_limit(exchange_id)\n",
        "\n",
        "            except ccxt.RequestTimeout:\n",
        "                logger.warning(\n",
        "                    f\"âš ï¸ Ø®Ø·Ø§ÛŒ Ø²Ù…Ø§Ù† Ù¾Ø§Ø³Ø®Ú¯ÙˆÛŒÛŒ Ø§Ø² {exchange_id} Ø¨Ø±Ø§ÛŒ {symbol}/{timeframe}. ØªÙ„Ø§Ø´ {attempt + 1}/{max_retries}\")\n",
        "\n",
        "            except ccxt.ExchangeNotAvailable:\n",
        "                logger.warning(f\"âš ï¸ ØµØ±Ø§ÙÛŒ {exchange_id} Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª. ØªÙ„Ø§Ø´ {attempt + 1}/{max_retries}\")\n",
        "\n",
        "            except ccxt.DDoSProtection:\n",
        "                logger.warning(f\"âš ï¸ Ø­ÙØ§Ø¸Øª DDoS Ø¯Ø± {exchange_id}. Ø§ÙØ²Ø§ÛŒØ´ ØªØ§Ø®ÛŒØ±...\")\n",
        "                time.sleep(delay * 10)  # ØªØ§Ø®ÛŒØ± Ø¨ÛŒØ´ØªØ±\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.error(f\"ğŸš¨ Ø®Ø·Ø§ Ø§Ø² {exchange_id} Ø¨Ø±Ø§ÛŒ {symbol}/{timeframe}: {str(e)}\")\n",
        "                break\n",
        "\n",
        "        # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø¢Ù…Ø§Ø± Ø´Ú©Ø³Øª\n",
        "        with request_count_lock:\n",
        "            exchange_data[exchange_id]['fail_count'] += 1\n",
        "\n",
        "        return None\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ğŸš¨ Ø®Ø·Ø§ÛŒ Ø§ØªØµØ§Ù„ Ø¨Ù‡ {exchange_id}: {str(e)}\")\n",
        "        with request_count_lock:\n",
        "            exchange_data[exchange_id]['fail_count'] += 1\n",
        "        return None\n",
        "\n",
        "\n",
        "def fetch_order_book(symbol, depth=20):\n",
        "    \"\"\"Ø¯Ø±ÛŒØ§ÙØª Ø¯ÙØªØ± Ø³ÙØ§Ø±Ø´ Ø¨Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² Ú†Ù†Ø¯ÛŒÙ† ØµØ±Ø§ÙÛŒ Ùˆ Ù…Ø¯ÛŒØ±ÛŒØª Ø®Ø·Ø§\"\"\"\n",
        "    # Ú©Ù„ÛŒØ¯ Ú©Ø´\n",
        "    cache_key = get_cache_key(\"fetch_order_book\", symbol, depth)\n",
        "\n",
        "    # Ø¨Ø±Ø±Ø³ÛŒ Ú©Ø´ Ø­Ø§ÙØ¸Ù‡ (Ø¨Ø§ Ø²Ù…Ø§Ù† Ø§Ù†Ù‚Ø¶Ø§ÛŒ Ú©ÙˆØªØ§Ù‡â€ŒØªØ± Ø¨Ø±Ø§ÛŒ Ø¯ÙØªØ± Ø³ÙØ§Ø±Ø´)\n",
        "    if cache_key in memory_cache and time.time() - memory_cache_access_time[cache_key] < 30:  # 30 Ø«Ø§Ù†ÛŒÙ‡\n",
        "        return memory_cache[cache_key]\n",
        "\n",
        "    # Ù„ÛŒØ³Øª ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ ØªØ§ Ø¨Ù‡ Ø­Ø§Ù„ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ø¬ÙØª Ø§Ø±Ø²/ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ… Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯Ù‡â€ŒØ§Ù†Ø¯\n",
        "    successful_exchanges_key = f\"{symbol}_orderbook_successful\"\n",
        "    successful_exchanges = fetch_data_cache.get(successful_exchanges_key, [])\n",
        "\n",
        "    # Ø§Ø¨ØªØ¯Ø§ ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆÙÙ‚ Ù‚Ø¨Ù„ÛŒ Ø±Ø§ Ø§Ù…ØªØ­Ø§Ù† Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…\n",
        "    if successful_exchanges:\n",
        "        for ex_id in successful_exchanges:\n",
        "            try:\n",
        "                exchange_class = EXCHANGES_CONFIG[ex_id]['class']\n",
        "                if not exchange_class:\n",
        "                    continue\n",
        "\n",
        "                exchange = exchange_class()\n",
        "                order_book = exchange.fetch_order_book(symbol, limit=depth)\n",
        "\n",
        "                if order_book and 'bids' in order_book and 'asks' in order_book:\n",
        "                    if len(order_book['bids']) > 0 and len(order_book['asks']) > 0:\n",
        "                        with request_count_lock:\n",
        "                            exchange_data[ex_id]['success_count'] += 1\n",
        "                        logger.info(f\"Ø¯ÙØªØ± Ø³ÙØ§Ø±Ø´ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø² {ex_id} Ø¨Ø±Ø§ÛŒ {symbol} Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯\")\n",
        "\n",
        "                        # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ú©Ø´ Ø­Ø§ÙØ¸Ù‡\n",
        "                        memory_cache[cache_key] = order_book\n",
        "                        memory_cache_access_time[cache_key] = time.time()\n",
        "\n",
        "                        return order_book\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "    # Ø§Ú¯Ø± ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆÙÙ‚ Ù‚Ø¨Ù„ÛŒ Ú©Ø§Ø± Ù†Ú©Ø±Ø¯Ù†Ø¯ØŒ Ø¨Ù‡ØªØ±ÛŒÙ† ØµØ±Ø§ÙÛŒ Ø±Ø§ Ø§Ù…ØªØ­Ø§Ù† Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…\n",
        "    best_exchange = get_best_exchange(symbol, \"orderbook\", depth)\n",
        "    exchanges_to_try = [best_exchange] + [ex for ex in EXCHANGES_CONFIG.keys() if ex != best_exchange]\n",
        "\n",
        "    for exchange_id in exchanges_to_try:\n",
        "        try:\n",
        "            exchange_class = EXCHANGES_CONFIG[exchange_id]['class']\n",
        "            if not exchange_class:\n",
        "                continue\n",
        "\n",
        "            exchange = exchange_class()\n",
        "            order_book = exchange.fetch_order_book(symbol, limit=depth)\n",
        "\n",
        "            if order_book and 'bids' in order_book and 'asks' in order_book:\n",
        "                if len(order_book['bids']) > 0 and len(order_book['asks']) > 0:\n",
        "                    with request_count_lock:\n",
        "                        exchange_data[exchange_id]['success_count'] += 1\n",
        "\n",
        "                    # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù„ÛŒØ³Øª ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆÙÙ‚\n",
        "                    successful_exchanges = [exchange_id] + [ex for ex in successful_exchanges if ex != exchange_id]\n",
        "                    successful_exchanges = successful_exchanges[:3]  # Ø­Ø¯Ø§Ú©Ø«Ø± 3 ØµØ±Ø§ÙÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´ÙˆØ¯\n",
        "                    fetch_data_cache[successful_exchanges_key] = successful_exchanges\n",
        "\n",
        "                    logger.info(f\"Ø¯ÙØªØ± Ø³ÙØ§Ø±Ø´ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø² {exchange_id} Ø¨Ø±Ø§ÛŒ {symbol} Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯\")\n",
        "\n",
        "                    # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ú©Ø´ Ø­Ø§ÙØ¸Ù‡\n",
        "                    memory_cache[cache_key] = order_book\n",
        "                    memory_cache_access_time[cache_key] = time.time()\n",
        "\n",
        "                    return order_book\n",
        "\n",
        "            # ØªØ§Ø®ÛŒØ± Ø¨ÛŒÙ† Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§\n",
        "            time.sleep(1 + random.uniform(0, 1))\n",
        "\n",
        "        except ccxt.RateLimitExceeded:\n",
        "            handle_rate_limit(exchange_id)\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¯ÙØªØ± Ø³ÙØ§Ø±Ø´ Ø§Ø² {exchange_id} Ø¨Ø±Ø§ÛŒ {symbol}: {str(e)}\")\n",
        "            with request_count_lock:\n",
        "                exchange_data[exchange_id]['fail_count'] += 1\n",
        "\n",
        "    logger.error(f\"âŒ Ø¯Ø±ÛŒØ§ÙØª Ø¯ÙØªØ± Ø³ÙØ§Ø±Ø´ Ø¨Ø±Ø§ÛŒ {symbol} Ø§Ø² ØªÙ…Ø§Ù… ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§ Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯\")\n",
        "    return None\n",
        "\n",
        "\n",
        "# Ú©Ù„Ø§Ø³ Ø§ØµÙ„ÛŒ ØªØ­Ù„ÛŒÙ„Ú¯Ø± Ø§Ø±Ø² Ø¯ÛŒØ¬ÛŒØªØ§Ù„\n",
        "class CryptoAnalyzer:\n",
        "    def __init__(self, telegram_bot_token=None, telegram_channel_id=None):\n",
        "        self.telegram_bot_token = telegram_bot_token\n",
        "        self.telegram_channel_id = telegram_channel_id\n",
        "        self.telegram_bot = None\n",
        "        self.telegram_connected = False  # Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯Ù‡\n",
        "        self.signal_count = 0\n",
        "        self.state_file = f\"{BASE_DIR}/bot_state.json\"\n",
        "        self.last_save_time = time.time()\n",
        "        self.save_interval = 300  # Ûµ Ø¯Ù‚ÛŒÙ‚Ù‡\n",
        "        self.signal_history = {}\n",
        "        self.strategy_confidence = {\n",
        "            'market_structure': 0.92,  # Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø³Ø§Ø®ØªØ§Ø± Ø¨Ø§Ø²Ø§Ø±\n",
        "            'order_block': 0.90,  # Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø¨Ù„ÙˆÚ© Ø³ÙØ§Ø±Ø´\n",
        "            'buying_selling_pressure': 0.88,  # Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ ÙØ´Ø§Ø± Ø®Ø±ÛŒØ¯/ÙØ±ÙˆØ´\n",
        "            'whale_activity': 0.87,  # Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ ÙØ¹Ø§Ù„ÛŒØª Ù†Ù‡Ù†Ú¯â€ŒÙ‡Ø§\n",
        "            'ema_strategy': 0.85,  # Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…ØªØ­Ø±Ú© Ù†Ù…Ø§ÛŒÛŒ\n",
        "            'rsi_strategy': 0.84,  # Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø´Ø§Ø®Øµ Ù‚Ø¯Ø±Øª Ù†Ø³Ø¨ÛŒ\n",
        "            'divergence': 0.92,  # Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ ÙˆØ§Ú¯Ø±Ø§ÛŒÛŒ\n",
        "            'bbrsi_macd': 0.86,  # Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ ØªØ±Ú©ÛŒØ¨ÛŒ Ø¨Ø§Ù†Ø¯Ù‡Ø§ÛŒ Ø¨ÙˆÙ„ÛŒÙ†Ú¯Ø±ØŒ RSI Ùˆ MACD\n",
        "            'darvas_box': 0.80,  # Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø¬Ø¹Ø¨Ù‡ Ø¯Ø§Ø±ÙˆØ§Ø³\n",
        "            'ichimoku': 0.88,  # Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø§ÛŒÚ†ÛŒÙ…ÙˆÚ©Ùˆ\n",
        "            'fibonacci': 0.85,  # Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ\n",
        "            'market_structure_analysis': 0.93,  # Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ ØªØ­Ù„ÛŒÙ„ Ø³Ø§Ø®ØªØ§Ø± Ø¨Ø§Ø²Ø§Ø±\n",
        "            'golden_strategy': 0.95,  # Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø·Ù„Ø§ÛŒÛŒ ØªØ±Ú©ÛŒØ¨ÛŒ\n",
        "            'special_strategy': 0.89,  # Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ ÙˆÛŒÚ˜Ù‡\n",
        "        }\n",
        "\n",
        "        # ØªÙ†Ø¸ÛŒÙ… Ø´ÛŒÙˆÙ‡ Ù†Ù…Ø§ÛŒØ´ Ø¨Ø±Ø§ÛŒ Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§\n",
        "        plt.style.use('dark_background')\n",
        "        sns.set_style(\"darkgrid\")\n",
        "\n",
        "        # ØªÙ†Ø¸ÛŒÙ… Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ø±Ø¨Ø§Øª ØªÙ„Ú¯Ø±Ø§Ù…\n",
        "        self.setup_telegram()\n",
        "\n",
        "        # Ø´Ù…Ø§Ø±Ù†Ø¯Ù‡ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§\n",
        "        self.daily_signal_count = 0\n",
        "        self.last_signal_reset = time.time()\n",
        "\n",
        "        logger.info(\"âœ… Ø³ÛŒØ³ØªÙ… ØªØ­Ù„ÛŒÙ„Ú¯Ø± Ø§Ø±Ø² Ø¯ÛŒØ¬ÛŒØªØ§Ù„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø´Ø¯\")\n",
        "\n",
        "    def setup_telegram(self):\n",
        "        \"\"\"ØªÙ†Ø¸ÛŒÙ… Ø§ØªØµØ§Ù„ Ø¨Ù‡ ØªÙ„Ú¯Ø±Ø§Ù… Ø¨Ø§ Ø±ÙˆØ´ HTTP Ù…Ø³ØªÙ‚ÛŒÙ… Ø¨Ø¬Ø§ÛŒ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡\"\"\"\n",
        "        if self.telegram_bot_token and self.telegram_channel_id:\n",
        "            try:\n",
        "                # Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… ØªØ³Øª Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ Ø§ØªØµØ§Ù„\n",
        "                welcome_message = \"ğŸ¤– Ø±Ø¨Ø§Øª ØªØ­Ù„ÛŒÙ„Ú¯Ø± Ø§Ø±Ø² Ø¯ÛŒØ¬ÛŒØªØ§Ù„ ÙØ¹Ø§Ù„ Ø´Ø¯\\nØ¯Ø± Ø­Ø§Ù„ Ø¨Ø±Ø±Ø³ÛŒ Ø¨Ø§Ø²Ø§Ø± Ùˆ Ø§Ø±Ø³Ø§Ù„ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ...\"\n",
        "\n",
        "                url = f'https://api.telegram.org/bot{self.telegram_bot_token}/sendMessage'\n",
        "                payload = {\n",
        "                    'chat_id': self.telegram_channel_id,\n",
        "                    'text': welcome_message,\n",
        "                    'parse_mode': 'HTML'\n",
        "                }\n",
        "\n",
        "                response = requests.post(url, data=payload, timeout=10)\n",
        "\n",
        "                if response.status_code == 200:\n",
        "                    logger.info(\"âœ… Ø§ØªØµØ§Ù„ Ø¨Ù‡ ØªÙ„Ú¯Ø±Ø§Ù… Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø±Ù‚Ø±Ø§Ø± Ø´Ø¯ Ùˆ Ù¾ÛŒØ§Ù… ØªØ³Øª Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯\")\n",
        "                    self.telegram_connected = True\n",
        "                else:\n",
        "                    logger.error(f\"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§ØªØµØ§Ù„ Ø¨Ù‡ ØªÙ„Ú¯Ø±Ø§Ù…: {response.status_code} - {response.text}\")\n",
        "                    self.telegram_connected = False\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.error(f\"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§ØªØµØ§Ù„ Ø¨Ù‡ ØªÙ„Ú¯Ø±Ø§Ù…: {e}\")\n",
        "                logger.error(traceback.format_exc())\n",
        "                self.telegram_connected = False\n",
        "        else:\n",
        "            logger.warning(\"âš ï¸ Ù…Ù‚Ø§Ø¯ÛŒØ± ØªÙˆÚ©Ù† Ùˆ Ø¢ÛŒØ¯ÛŒ Ú©Ø§Ù†Ø§Ù„ ØªÙ„Ú¯Ø±Ø§Ù… ØªÙ†Ø¸ÛŒÙ… Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª\")\n",
        "            self.telegram_connected = False\n",
        "\n",
        "    def send_telegram_message(self, message, image_path=None):\n",
        "        \"\"\"Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… Ø¨Ù‡ Ú©Ø§Ù†Ø§Ù„ ØªÙ„Ú¯Ø±Ø§Ù… Ø¨Ø§ ØªØµÙˆÛŒØ± Ø§Ø®ØªÛŒØ§Ø±ÛŒ - Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø±ÙˆØ´ HTTP Ù…Ø³ØªÙ‚ÛŒÙ…\"\"\"\n",
        "        if not self.telegram_connected:\n",
        "            logger.warning(\"âš ï¸ Ø§ØªØµØ§Ù„ ØªÙ„Ú¯Ø±Ø§Ù… Ø¨Ø±Ù‚Ø±Ø§Ø± Ù†ÛŒØ³Øª\")\n",
        "            return False\n",
        "\n",
        "        try:\n",
        "            # ØªÙ†Ø¸ÛŒÙ… Ø­Ø¯Ø§Ú©Ø«Ø± Ø·ÙˆÙ„ Ù…Ø¬Ø§Ø² Ù¾ÛŒØ§Ù…\n",
        "            MAX_MESSAGE_LENGTH = 4000\n",
        "            RETRY_COUNT = 3\n",
        "            RETRY_DELAY = 2\n",
        "\n",
        "            # Ø§Ú¯Ø± ØªØµÙˆÛŒØ± Ø¯Ø§Ø±ÛŒÙ…ØŒ Ø§Ø² Ù…ØªØ¯ Ø§Ø±Ø³Ø§Ù„ Ø¹Ú©Ø³ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…\n",
        "            if image_path:\n",
        "                if not os.path.exists(image_path):\n",
        "                    logger.error(f\"âŒ ÙØ§ÛŒÙ„ ØªØµÙˆÛŒØ± ÛŒØ§ÙØª Ù†Ø´Ø¯: {image_path}\")\n",
        "                    return False\n",
        "\n",
        "                # Ø¨Ø±Ø±Ø³ÛŒ Ø­Ø¬Ù… ØªØµÙˆÛŒØ± Ùˆ Ú©Ø§Ù‡Ø´ Ø¢Ù† Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø²\n",
        "                file_size = os.path.getsize(image_path) / (1024 * 1024)  # Ø¨Ù‡ Ù…Ú¯Ø§Ø¨Ø§ÛŒØª\n",
        "                if file_size > 5:\n",
        "                    logger.warning(f\"âš ï¸ Ø­Ø¬Ù… ØªØµÙˆÛŒØ± Ø²ÛŒØ§Ø¯ Ø§Ø³Øª ({file_size:.1f} MB). Ø¯Ø± Ø­Ø§Ù„ Ú©Ø§Ù‡Ø´ Ú©ÛŒÙÛŒØª...\")\n",
        "                    # Ú©Ø§Ù‡Ø´ Ú©ÛŒÙÛŒØª ØªØµÙˆÛŒØ± Ø¨Ø§ PIL\n",
        "                    try:\n",
        "                        from PIL import Image\n",
        "                        img = Image.open(image_path)\n",
        "\n",
        "                        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†Ø³Ø¨Øª Ú©Ø§Ù‡Ø´ Ø³Ø§ÛŒØ²\n",
        "                        quality = min(95, int(5 * 100 / file_size))\n",
        "\n",
        "                        # Ø§ÛŒØ¬Ø§Ø¯ Ù†Ø§Ù… ÙØ§ÛŒÙ„ Ø¬Ø¯ÛŒØ¯\n",
        "                        new_path = image_path.replace('.png', '_compressed.jpg')\n",
        "                        img.save(new_path, 'JPEG', quality=quality)\n",
        "                        image_path = new_path\n",
        "                        logger.info(f\"âœ… Ø­Ø¬Ù… ØªØµÙˆÛŒØ± Ú©Ø§Ù‡Ø´ ÛŒØ§ÙØª. ÙØ§ÛŒÙ„ Ø¬Ø¯ÛŒØ¯: {image_path}\")\n",
        "                    except Exception as img_err:\n",
        "                        logger.error(f\"âŒ Ø®Ø·Ø§ Ø¯Ø± Ú©Ø§Ù‡Ø´ Ø­Ø¬Ù… ØªØµÙˆÛŒØ±: {img_err}\")\n",
        "\n",
        "                # ØªÙ‚Ø³ÛŒÙ… Ù¾ÛŒØ§Ù… Ø§Ú¯Ø± Ø·ÙˆÙ„Ø§Ù†ÛŒ Ø§Ø³Øª\n",
        "                if len(message) > MAX_MESSAGE_LENGTH:\n",
        "                    # Ø§Ø¨ØªØ¯Ø§ ØªØµÙˆÛŒØ± Ø±Ø§ Ø¨Ø§ Ø¨Ø®Ø´ Ø§ÙˆÙ„ Ù¾ÛŒØ§Ù… Ø§Ø±Ø³Ø§Ù„ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…\n",
        "                    first_part = message[:MAX_MESSAGE_LENGTH] + \"\\n...(Ø§Ø¯Ø§Ù…Ù‡ Ø¯Ø§Ø±Ø¯)\"\n",
        "\n",
        "                    # Ø§Ø±Ø³Ø§Ù„ ØªØµÙˆÛŒØ± Ø¨Ø§ Ø¨Ø®Ø´ Ø§ÙˆÙ„ Ù¾ÛŒØ§Ù…\n",
        "                    url = f'https://api.telegram.org/bot{self.telegram_bot_token}/sendPhoto'\n",
        "\n",
        "                    for attempt in range(RETRY_COUNT):\n",
        "                        try:\n",
        "                            with open(image_path, 'rb') as photo:\n",
        "                                files = {'photo': photo}\n",
        "                                data = {\n",
        "                                    'chat_id': self.telegram_channel_id,\n",
        "                                    'caption': first_part,\n",
        "                                    'parse_mode': 'HTML'\n",
        "                                }\n",
        "                                response = requests.post(url, data=data, files=files, timeout=30)\n",
        "\n",
        "                                if response.status_code != 200:\n",
        "                                    logger.error(f\"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ ØªØµÙˆÛŒØ±: {response.status_code} - {response.text}\")\n",
        "                                    time.sleep(RETRY_DELAY)\n",
        "                                    continue\n",
        "                                else:\n",
        "                                    # Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ù‚ÛŒÙ…Ø§Ù†Ø¯Ù‡ Ù¾ÛŒØ§Ù… Ø±Ø§ Ø¯Ø± Ù‚Ø§Ù„Ø¨ Ù…ØªÙ† Ø§Ø±Ø³Ø§Ù„ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…\n",
        "                                    remaining_text = message[MAX_MESSAGE_LENGTH:]\n",
        "\n",
        "                                    # Ø§Ú¯Ø± Ù…ØªÙ† Ø¨Ø§Ù‚ÛŒÙ…Ø§Ù†Ø¯Ù‡ Ø¯Ø§Ø±ÛŒÙ…ØŒ Ø¢Ù† Ø±Ø§ Ø§Ø±Ø³Ø§Ù„ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…\n",
        "                                    if remaining_text:\n",
        "                                        text_url = f'https://api.telegram.org/bot{self.telegram_bot_token}/sendMessage'\n",
        "                                        text_data = {\n",
        "                                            'chat_id': self.telegram_channel_id,\n",
        "                                            'text': \"(Ø§Ø¯Ø§Ù…Ù‡) \" + remaining_text,\n",
        "                                            'parse_mode': 'HTML'\n",
        "                                        }\n",
        "                                        text_response = requests.post(text_url, data=text_data, timeout=10)\n",
        "\n",
        "                                        if text_response.status_code != 200:\n",
        "                                            logger.error(f\"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ø§Ø¯Ø§Ù…Ù‡ Ù¾ÛŒØ§Ù…: {text_response.status_code}\")\n",
        "                                            return False\n",
        "\n",
        "                                    logger.info(f\"âœ… Ù¾ÛŒØ§Ù… Ø¨Ø§ ØªØµÙˆÛŒØ± Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ù‡ ØªÙ„Ú¯Ø±Ø§Ù… Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯\")\n",
        "                                    return True\n",
        "\n",
        "                        except Exception as e:\n",
        "                            logger.error(f\"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ ØªØµÙˆÛŒØ± (ØªÙ„Ø§Ø´ {attempt + 1}): {e}\")\n",
        "                            time.sleep(RETRY_DELAY)\n",
        "\n",
        "                    return False\n",
        "                else:\n",
        "                    # Ù¾ÛŒØ§Ù… Ú©ÙˆØªØ§Ù‡ Ø§Ø³ØªØŒ Ù…Ø³ØªÙ‚ÛŒÙ…Ø§Ù‹ Ø¨Ø§ ØªØµÙˆÛŒØ± Ø§Ø±Ø³Ø§Ù„ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…\n",
        "                    url = f'https://api.telegram.org/bot{self.telegram_bot_token}/sendPhoto'\n",
        "\n",
        "                    for attempt in range(RETRY_COUNT):\n",
        "                        try:\n",
        "                            with open(image_path, 'rb') as photo:\n",
        "                                files = {'photo': photo}\n",
        "                                data = {\n",
        "                                    'chat_id': self.telegram_channel_id,\n",
        "                                    'caption': message,\n",
        "                                    'parse_mode': 'HTML'\n",
        "                                }\n",
        "                                response = requests.post(url, data=data, files=files, timeout=30)\n",
        "\n",
        "                                if response.status_code != 200:\n",
        "                                    logger.error(f\"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ ØªØµÙˆÛŒØ±: {response.status_code} - {response.text}\")\n",
        "                                    if \"Bad Request: can't parse entities\" in response.text:\n",
        "                                        logger.error(\"Ù…Ø´Ú©Ù„ Ø¯Ø± ØªÚ¯â€ŒÙ‡Ø§ÛŒ HTML Ù¾ÛŒØ§Ù…. Ø§Ø±Ø³Ø§Ù„ Ø¨Ø¯ÙˆÙ† parse_mode...\")\n",
        "                                        data['parse_mode'] = None\n",
        "                                        response = requests.post(url, data=data, files=files, timeout=30)\n",
        "                                        if response.status_code == 200:\n",
        "                                            logger.info(f\"âœ… Ù¾ÛŒØ§Ù… Ø¨Ø§ ØªØµÙˆÛŒØ± Ø¨Ø¯ÙˆÙ† parse_mode Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯\")\n",
        "                                            return True\n",
        "                                    time.sleep(RETRY_DELAY)\n",
        "                                    continue\n",
        "                                else:\n",
        "                                    logger.info(f\"âœ… Ù¾ÛŒØ§Ù… Ø¨Ø§ ØªØµÙˆÛŒØ± Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ù‡ ØªÙ„Ú¯Ø±Ø§Ù… Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯\")\n",
        "                                    return True\n",
        "\n",
        "                        except Exception as e:\n",
        "                            logger.error(f\"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ ØªØµÙˆÛŒØ± (ØªÙ„Ø§Ø´ {attempt + 1}): {e}\")\n",
        "                            time.sleep(RETRY_DELAY)\n",
        "\n",
        "                    return False\n",
        "\n",
        "            else:\n",
        "                # Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… Ù…ØªÙ†ÛŒ Ø¨Ø¯ÙˆÙ† ØªØµÙˆÛŒØ±\n",
        "                url = f'https://api.telegram.org/bot{self.telegram_bot_token}/sendMessage'\n",
        "\n",
        "                # ØªÙ‚Ø³ÛŒÙ… Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ø·ÙˆÙ„Ø§Ù†ÛŒ\n",
        "                if len(message) <= MAX_MESSAGE_LENGTH:\n",
        "                    message_parts = [message]\n",
        "                else:\n",
        "                    message_parts = []\n",
        "                    # ØªÙ‚Ø³ÛŒÙ… Ù¾ÛŒØ§Ù… Ø¨Ø§ Ø¯Ù‚Øª Ø¯Ø± Ù…Ø­Ù„ Ù‡Ø§ÛŒ Ù…Ù†Ø§Ø³Ø¨\n",
        "                    while len(message) > MAX_MESSAGE_LENGTH:\n",
        "                        # ÛŒØ§ÙØªÙ† Ù…Ø­Ù„ Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø±Ø§ÛŒ ØªÙ‚Ø³ÛŒÙ… (Ù¾Ø§ÛŒØ§Ù† Ø®Ø·)\n",
        "                        split_index = message[:MAX_MESSAGE_LENGTH].rfind('\\n')\n",
        "                        if split_index == -1:  # Ø§Ú¯Ø± Ù¾Ø§ÛŒØ§Ù† Ø®Ø· Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯\n",
        "                            split_index = MAX_MESSAGE_LENGTH\n",
        "\n",
        "                        message_parts.append(message[:split_index])\n",
        "                        message = message[split_index:].strip()\n",
        "\n",
        "                    if message:  # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¨Ø®Ø´ Ø¨Ø§Ù‚ÛŒÙ…Ø§Ù†Ø¯Ù‡\n",
        "                        message_parts.append(message)\n",
        "\n",
        "                # Ø§Ø±Ø³Ø§Ù„ Ù‡Ø± Ø¨Ø®Ø´ Ø§Ø² Ù¾ÛŒØ§Ù…\n",
        "                success = True\n",
        "                for i, msg_part in enumerate(message_parts):\n",
        "                    clean_message = msg_part\n",
        "                    if i < len(message_parts) - 1:\n",
        "                        clean_message += \"\\n(Ø§Ø¯Ø§Ù…Ù‡ Ø¯Ø§Ø±Ø¯...)\"\n",
        "                    elif i > 0:\n",
        "                        clean_message = \"(Ø§Ø¯Ø§Ù…Ù‡) \" + clean_message\n",
        "\n",
        "                    # Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… Ø¨Ø§ ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯ Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§\n",
        "                    sent = False\n",
        "                    for attempt in range(RETRY_COUNT):\n",
        "                        try:\n",
        "                            payload = {\n",
        "                                'chat_id': self.telegram_channel_id,\n",
        "                                'text': clean_message,\n",
        "                                'parse_mode': 'HTML'\n",
        "                            }\n",
        "                            response = requests.post(url, data=payload, timeout=10)\n",
        "\n",
        "                            if response.status_code != 200:\n",
        "                                # Ø¨Ø±Ø±Ø³ÛŒ Ø®Ø·Ø§ÛŒ ØªÚ¯ HTML\n",
        "                                if \"Bad Request: can't parse entities\" in response.text:\n",
        "                                    logger.error(\"Ù…Ø´Ú©Ù„ Ø¯Ø± ØªÚ¯â€ŒÙ‡Ø§ÛŒ HTML Ù¾ÛŒØ§Ù…. Ø§Ø±Ø³Ø§Ù„ Ø¨Ø¯ÙˆÙ† parse_mode...\")\n",
        "                                    payload['parse_mode'] = None\n",
        "                                    response = requests.post(url, data=payload, timeout=10)\n",
        "                                    if response.status_code == 200:\n",
        "                                        logger.info(\n",
        "                                            f\"âœ… Ø¨Ø®Ø´ {i + 1}/{len(message_parts)} Ù¾ÛŒØ§Ù… Ø¨Ø¯ÙˆÙ† parse_mode Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯\")\n",
        "                                        sent = True\n",
        "                                        break\n",
        "\n",
        "                                error_msg = f\"Ø®Ø·Ø§ÛŒ API ØªÙ„Ú¯Ø±Ø§Ù… ({response.status_code}): {response.text}\"\n",
        "                                logger.error(error_msg)\n",
        "                                time.sleep(RETRY_DELAY)\n",
        "                            else:\n",
        "                                logger.info(f\"âœ… Ø¨Ø®Ø´ {i + 1}/{len(message_parts)} Ù¾ÛŒØ§Ù… Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯\")\n",
        "                                sent = True\n",
        "                                break\n",
        "                        except Exception as e:\n",
        "                            logger.error(f\"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… (ØªÙ„Ø§Ø´ {attempt + 1}): {e}\")\n",
        "                            time.sleep(RETRY_DELAY)\n",
        "\n",
        "                    if not sent:\n",
        "                        success = False\n",
        "\n",
        "                return success\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"âŒ Ø®Ø·Ø§ÛŒ Ú©Ù„ÛŒ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… Ø¨Ù‡ ØªÙ„Ú¯Ø±Ø§Ù…: {e}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return False\n",
        "\n",
        "    def send_signal(self, symbol, timeframe, signal_type, entry_price, stop_loss, take_profit,\n",
        "                    strategies, confidence, description, chart_path=None):\n",
        "        \"\"\"Ø§Ø±Ø³Ø§Ù„ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø¨Ù‡ Ú©Ø§Ù†Ø§Ù„ ØªÙ„Ú¯Ø±Ø§Ù…\"\"\"\n",
        "\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ Ø²Ù…Ø§Ù† Ø¢Ø®Ø±ÛŒÙ† Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ø§Ø±Ø²\n",
        "        last_signal_key = f\"{symbol}_{signal_type}\"\n",
        "        current_time = time.time()\n",
        "\n",
        "        if last_signal_key in self.signal_history:\n",
        "            last_time = self.signal_history[last_signal_key]\n",
        "            # Ø§Ú¯Ø± Ú©Ù…ØªØ± Ø§Ø² Ø²Ù…Ø§Ù† ØªØ¹ÛŒÛŒÙ† Ø´Ø¯Ù‡ Ø§Ø² Ø¢Ø®Ø±ÛŒÙ† Ø³ÛŒÚ¯Ù†Ø§Ù„ Ú¯Ø°Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯ØŒ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø¬Ø¯ÛŒØ¯ Ø§Ø±Ø³Ø§Ù„ Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯\n",
        "            if current_time - last_time < BOT_SETTINGS['signal_cooldown_hours'] * 3600:\n",
        "                hours_ago = (current_time - last_time) / 3600\n",
        "                logger.info(\n",
        "                    f\"â³ Ø³ÛŒÚ¯Ù†Ø§Ù„ {signal_type} Ø¨Ø±Ø§ÛŒ {symbol} {hours_ago:.1f} Ø³Ø§Ø¹Øª Ù¾ÛŒØ´ Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯Ù‡ Ùˆ Ø¯Ø± Ø­Ø§Ù„Øª Ø§Ù†ØªØ¸Ø§Ø± Ø§Ø³Øª\")\n",
        "                return False\n",
        "\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª ØªØ¹Ø¯Ø§Ø¯ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø±ÙˆØ²Ø§Ù†Ù‡\n",
        "        if current_time - self.last_signal_reset > 86400:  # 24 Ø³Ø§Ø¹Øª\n",
        "            self.daily_signal_count = 0\n",
        "            self.last_signal_reset = current_time\n",
        "\n",
        "        if self.daily_signal_count >= BOT_SETTINGS['max_signals_per_day']:\n",
        "            logger.warning(f\"âš ï¸ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª ØªØ¹Ø¯Ø§Ø¯ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø±ÙˆØ²Ø§Ù†Ù‡ ({BOT_SETTINGS['max_signals_per_day']}) Ø±Ø³ÛŒØ¯Ù‡ Ø§Ø³Øª\")\n",
        "            return False\n",
        "\n",
        "        # Ø³Ø§Ø®Øª Ù¾ÛŒØ§Ù… Ø³ÛŒÚ¯Ù†Ø§Ù„\n",
        "        signal_emoji = \"ğŸŸ¢\" if signal_type == \"Ø®Ø±ÛŒØ¯\" else \"ğŸ”´\"\n",
        "\n",
        "        message = f\"{signal_emoji} <b>Ø³ÛŒÚ¯Ù†Ø§Ù„ {signal_type} | {symbol} | {timeframe}</b>\\n\\n\"\n",
        "        message += f\"âš¡ï¸ <b>Ø¯Ø±ØµØ¯ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†:</b> {confidence}%\\n\"\n",
        "        message += f\"ğŸ’µ <b>Ù‚ÛŒÙ…Øª ÙˆØ±ÙˆØ¯:</b> {entry_price:.4f}\\n\"\n",
        "        message += f\"ğŸ›‘ <b>Ø­Ø¯ Ø¶Ø±Ø±:</b> {stop_loss:.4f}\\n\"\n",
        "        message += f\"ğŸ¯ <b>Ø­Ø¯ Ø³ÙˆØ¯:</b> {take_profit:.4f}\\n\\n\"\n",
        "\n",
        "        message += \"<b>Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§ÛŒ ØªØ£ÛŒÛŒØ¯Ú©Ù†Ù†Ø¯Ù‡:</b>\\n\"\n",
        "        for strategy, conf in strategies.items():\n",
        "            emoji = \"âœ…\" if conf >= 80 else \"âš ï¸\"\n",
        "            message += f\"{emoji} {strategy}: {conf}%\\n\"\n",
        "\n",
        "        message += f\"\\n<b>ØªÙˆØ¶ÛŒØ­Ø§Øª:</b>\\n{description}\\n\\n\"\n",
        "        message += f\"â—ï¸ <i>Ø§ÛŒÙ† Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ ØµØ±ÙØ§Ù‹ Ø¬Ù†Ø¨Ù‡ Ø¢Ù…ÙˆØ²Ø´ÛŒ Ø¯Ø§Ø´ØªÙ‡ Ùˆ ØªÙˆØµÛŒÙ‡ Ø³Ø±Ù…Ø§ÛŒÙ‡â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ù†ÛŒØ³Øª.</i>\"\n",
        "\n",
        "        # Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… Ø¨Ù‡ ØªÙ„Ú¯Ø±Ø§Ù…\n",
        "        send_success = self.send_telegram_message(message, chart_path)\n",
        "\n",
        "        if send_success:\n",
        "            # ÙÙ‚Ø· Ø¯Ø± ØµÙˆØ±Øª Ù…ÙˆÙÙ‚ÛŒØªØŒ Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ Ùˆ Ø§ÙØ²Ø§ÛŒØ´ Ø´Ù…Ø§Ø±Ù†Ø¯Ù‡\n",
        "            self.signal_history[last_signal_key] = current_time\n",
        "            self.daily_signal_count += 1\n",
        "            self.signal_count += 1\n",
        "            logger.info(f\"ğŸš€ Ø³ÛŒÚ¯Ù†Ø§Ù„ {signal_type} Ø¨Ø±Ø§ÛŒ {symbol} Ø¯Ø± ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ… {timeframe} Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯\")\n",
        "            return True\n",
        "        else:\n",
        "            logger.error(f\"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ø³ÛŒÚ¯Ù†Ø§Ù„ {signal_type} Ø¨Ø±Ø§ÛŒ {symbol} Ø¯Ø± ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ… {timeframe}\")\n",
        "            return False\n",
        "\n",
        "    def send_conditional_signal(self, symbol, timeframe, signal_type, entry_condition, entry_price,\n",
        "                                stop_loss, take_profit_levels, strategies, confidence, description, chart_path=None):\n",
        "        \"\"\"\n",
        "        Ø§Ø±Ø³Ø§Ù„ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø´Ø±Ø·ÛŒ Ø¨Ù‡ Ú©Ø§Ù†Ø§Ù„ ØªÙ„Ú¯Ø±Ø§Ù…\n",
        "\n",
        "        Args:\n",
        "            symbol: Ù†Ù…Ø§Ø¯ Ø§Ø±Ø²\n",
        "            timeframe: ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…\n",
        "            signal_type: Ù†ÙˆØ¹ Ø³ÛŒÚ¯Ù†Ø§Ù„ (Ø®Ø±ÛŒØ¯ ÛŒØ§ ÙØ±ÙˆØ´)\n",
        "            entry_condition: Ø´Ø±Ø· ÙˆØ±ÙˆØ¯ Ø¨Ù‡ Ù…Ø¹Ø§Ù…Ù„Ù‡\n",
        "            entry_price: Ù‚ÛŒÙ…Øª ÙˆØ±ÙˆØ¯\n",
        "            stop_loss: Ø­Ø¯ Ø¶Ø±Ø±\n",
        "            take_profit_levels: Ù„ÛŒØ³ØªÛŒ Ø§Ø² Ø­Ø¯Ù‡Ø§ÛŒ Ø³ÙˆØ¯ Ø¯Ø± Ø³Ø·ÙˆØ­ Ù…Ø®ØªÙ„Ù (list)\n",
        "            strategies: Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§ÛŒ ØªØ£ÛŒÛŒØ¯Ú©Ù†Ù†Ø¯Ù‡ (dict)\n",
        "            confidence: Ø¯Ø±ØµØ¯ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†\n",
        "            description: ØªÙˆØ¶ÛŒØ­Ø§Øª\n",
        "            chart_path: Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ Ù†Ù…ÙˆØ¯Ø§Ø± (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)\n",
        "\n",
        "        Returns:\n",
        "            Ù†ØªÛŒØ¬Ù‡ Ø§Ø±Ø³Ø§Ù„ Ø³ÛŒÚ¯Ù†Ø§Ù„ (True ÛŒØ§ False)\n",
        "        \"\"\"\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ Ø²Ù…Ø§Ù† Ø¢Ø®Ø±ÛŒÙ† Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ø§Ø±Ø²\n",
        "        last_signal_key = f\"{symbol}_{signal_type}_conditional\"\n",
        "        current_time = time.time()\n",
        "\n",
        "        if last_signal_key in self.signal_history:\n",
        "            last_time = self.signal_history[last_signal_key]\n",
        "            # Ø§Ú¯Ø± Ú©Ù…ØªØ± Ø§Ø² Ø²Ù…Ø§Ù† ØªØ¹ÛŒÛŒÙ† Ø´Ø¯Ù‡ Ø§Ø² Ø¢Ø®Ø±ÛŒÙ† Ø³ÛŒÚ¯Ù†Ø§Ù„ Ú¯Ø°Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯ØŒ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø¬Ø¯ÛŒØ¯ Ø§Ø±Ø³Ø§Ù„ Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯\n",
        "            if current_time - last_time < BOT_SETTINGS['signal_cooldown_hours'] * 3600:\n",
        "                hours_ago = (current_time - last_time) / 3600\n",
        "                logger.info(\n",
        "                    f\"â³ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø´Ø±Ø·ÛŒ {signal_type} Ø¨Ø±Ø§ÛŒ {symbol} {hours_ago:.1f} Ø³Ø§Ø¹Øª Ù¾ÛŒØ´ Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯Ù‡ Ùˆ Ø¯Ø± Ø­Ø§Ù„Øª Ø§Ù†ØªØ¸Ø§Ø± Ø§Ø³Øª\")\n",
        "                return False\n",
        "\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª ØªØ¹Ø¯Ø§Ø¯ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø±ÙˆØ²Ø§Ù†Ù‡\n",
        "        if current_time - self.last_signal_reset > 86400:  # 24 Ø³Ø§Ø¹Øª\n",
        "            self.daily_signal_count = 0\n",
        "            self.last_signal_reset = current_time\n",
        "\n",
        "        if self.daily_signal_count >= BOT_SETTINGS['max_signals_per_day']:\n",
        "            logger.warning(f\"âš ï¸ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª ØªØ¹Ø¯Ø§Ø¯ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø±ÙˆØ²Ø§Ù†Ù‡ ({BOT_SETTINGS['max_signals_per_day']}) Ø±Ø³ÛŒØ¯Ù‡ Ø§Ø³Øª\")\n",
        "            return False\n",
        "\n",
        "        # Ø³Ø§Ø®Øª Ù¾ÛŒØ§Ù… Ø³ÛŒÚ¯Ù†Ø§Ù„\n",
        "        signal_emoji = \"ğŸŸ¢\" if signal_type == \"Ø®Ø±ÛŒØ¯\" else \"ğŸ”´\"\n",
        "        condition_emoji = \"âš¡\"\n",
        "\n",
        "        message = f\"{signal_emoji} <b>Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø´Ø±Ø·ÛŒ {signal_type} | {symbol} | {timeframe}</b>\\n\\n\"\n",
        "        message += f\"{condition_emoji} <b>Ø´Ø±Ø· ÙˆØ±ÙˆØ¯:</b> {entry_condition}\\n\"\n",
        "        message += f\"âš¡ï¸ <b>Ø¯Ø±ØµØ¯ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†:</b> {confidence}%\\n\"\n",
        "        message += f\"ğŸ’µ <b>Ù‚ÛŒÙ…Øª ÙˆØ±ÙˆØ¯ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ:</b> {entry_price:.6f}\\n\"\n",
        "        message += f\"ğŸ›‘ <b>Ø­Ø¯ Ø¶Ø±Ø±:</b> {stop_loss:.6f}\\n\"\n",
        "\n",
        "        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø­Ø¯Ù‡Ø§ÛŒ Ø³ÙˆØ¯ Ú†Ù†Ø¯Ú¯Ø§Ù†Ù‡\n",
        "        for i, tp in enumerate(take_profit_levels, 1):\n",
        "            message += f\"ğŸ¯ <b>Ø­Ø¯ Ø³ÙˆØ¯ {i}:</b> {tp:.6f}\\n\"\n",
        "\n",
        "        message += \"\\n<b>Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§ÛŒ ØªØ£ÛŒÛŒØ¯Ú©Ù†Ù†Ø¯Ù‡:</b>\\n\"\n",
        "        for strategy, conf in strategies.items():\n",
        "            emoji = \"âœ…\" if conf >= 80 else \"âš ï¸\"\n",
        "            message += f\"{emoji} {strategy}: {conf}%\\n\"\n",
        "\n",
        "        message += f\"\\n<b>ØªÙˆØ¶ÛŒØ­Ø§Øª:</b>\\n{description}\\n\\n\"\n",
        "        message += f\"â—ï¸ <i>Ø§ÛŒÙ† Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ ØµØ±ÙØ§Ù‹ Ø¬Ù†Ø¨Ù‡ Ø¢Ù…ÙˆØ²Ø´ÛŒ Ø¯Ø§Ø´ØªÙ‡ Ùˆ ØªÙˆØµÛŒÙ‡ Ø³Ø±Ù…Ø§ÛŒÙ‡â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ù†ÛŒØ³Øª.</i>\"\n",
        "\n",
        "        # Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… Ø¨Ù‡ ØªÙ„Ú¯Ø±Ø§Ù…\n",
        "        send_success = self.send_telegram_message(message, chart_path)\n",
        "\n",
        "        if send_success:\n",
        "            # ÙÙ‚Ø· Ø¯Ø± ØµÙˆØ±Øª Ù…ÙˆÙÙ‚ÛŒØªØŒ Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ Ùˆ Ø§ÙØ²Ø§ÛŒØ´ Ø´Ù…Ø§Ø±Ù†Ø¯Ù‡\n",
        "            self.signal_history[last_signal_key] = current_time\n",
        "            self.daily_signal_count += 1\n",
        "            self.signal_count += 1\n",
        "            logger.info(f\"ğŸš€ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø´Ø±Ø·ÛŒ {signal_type} Ø¨Ø±Ø§ÛŒ {symbol} Ø¯Ø± ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ… {timeframe} Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯\")\n",
        "            return True\n",
        "        else:\n",
        "            logger.error(f\"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø´Ø±Ø·ÛŒ {signal_type} Ø¨Ø±Ø§ÛŒ {symbol} Ø¯Ø± ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ… {timeframe}\")\n",
        "            return False\n",
        "\n",
        "    def add_colab_survival_mechanisms(self):\n",
        "        \"\"\"Ø§ÙØ²ÙˆØ¯Ù† Ù…Ú©Ø§Ù†ÛŒØ³Ù…â€ŒÙ‡Ø§ÛŒ Ø¨Ù‚Ø§ Ø¯Ø± Ù…Ø­ÛŒØ· Ú¯ÙˆÚ¯Ù„ Ú©ÙˆÙ„Ø¨\"\"\"\n",
        "        self.state_file = f\"{BASE_DIR}/bot_state.json\"\n",
        "        self.last_save_time = time.time()\n",
        "        self.save_interval = 300  # Ûµ Ø¯Ù‚ÛŒÙ‚Ù‡\n",
        "\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ Ùˆ Ø§ÛŒØ¬Ø§Ø¯ Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§ÛŒ Ù„Ø§Ø²Ù…\n",
        "        if COLAB_ENV:\n",
        "            import IPython\n",
        "            from IPython.display import display, Javascript\n",
        "            import threading\n",
        "\n",
        "            logger.info(\"ğŸ›¡ï¸ Ù…Ú©Ø§Ù†ÛŒØ³Ù…â€ŒÙ‡Ø§ÛŒ Ù…Ø­Ø§ÙØ¸Øª Ø§Ø² Ù‚Ø·Ø¹ Ø§ØªØµØ§Ù„ Ú©ÙˆÙ„Ø¨ ÙØ¹Ø§Ù„ Ø´Ø¯\")\n",
        "\n",
        "            # Û±. ØªØ§Ø¨Ø¹ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ ÙˆØ¶Ø¹ÛŒØª Ù‚Ø¨Ù„ÛŒ\n",
        "            self.load_state()\n",
        "\n",
        "            # Û². ØªØ§Ø¨Ø¹ Ø²Ù†Ø¯Ù‡ Ù†Ú¯Ù‡ Ø¯Ø§Ø´ØªÙ† Ú©ÙˆÙ„Ø¨\n",
        "            def keep_alive():\n",
        "                # Ú©Ø¯ Ø¬Ø§ÙˆØ§Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ù‚Ø·Ø¹ Ø´Ø¯Ù† Ø§ØªØµØ§Ù„ Ú©ÙˆÙ„Ø¨ Ø¨Ø§ Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ ÙØ¹Ø§Ù„ÛŒØª Ú©Ø§Ø±Ø¨Ø±\n",
        "                display(Javascript('''\n",
        "                function ClickConnect(){\n",
        "                    console.log(\"Ú©Ù„ÛŒÚ© Ø§ØªÙˆÙ…Ø§ØªÛŒÚ©\");\n",
        "                    document.querySelector(\"colab-toolbar-button#connect\").click()\n",
        "                }\n",
        "                setInterval(ClickConnect, 60000)\n",
        "\n",
        "                // Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ ÙØ¹Ø§Ù„ÛŒØª Ú©Ø§Ø±Ø¨Ø± Ø¨Ø§ Ø§Ø³Ú©Ø±ÙˆÙ„ Ú©Ø±Ø¯Ù† ØµÙØ­Ù‡\n",
        "                function keepAlive() {\n",
        "                    document.body.dispatchEvent(new KeyboardEvent('keydown', {key: 'ArrowUp'}));\n",
        "                    setTimeout(function() {\n",
        "                        document.body.dispatchEvent(new KeyboardEvent('keydown', {key: 'ArrowDown'}));\n",
        "                    }, 500);\n",
        "                }\n",
        "                setInterval(keepAlive, 30000);\n",
        "                '''))\n",
        "\n",
        "                # Ø²Ù†Ø¯Ù‡ Ù†Ú¯Ù‡ Ø¯Ø§Ø´ØªÙ† Ø§ØªØµØ§Ù„ Ø¨Ø§ Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§ÛŒ Ù…Ù†Ø¸Ù…\n",
        "                while True:\n",
        "                    try:\n",
        "                        # Ø§ÛŒÙ† Ú©Ø¯ Ù¾Ø§Ø³Ø® Ù†Ø®ÙˆØ§Ù‡Ø¯ Ø¯Ø§Ø¯ Ø§Ù…Ø§ Ø¨Ø§Ø¹Ø« ÙØ¹Ø§Ù„ÛŒØª Ù…ÛŒâ€ŒØ´ÙˆØ¯\n",
        "                        temp_var = 1 + 1\n",
        "                        # Ø°Ø®ÛŒØ±Ù‡ Ù…Ù†Ø¸Ù… ÙˆØ¶Ø¹ÛŒØª\n",
        "                        current_time = time.time()\n",
        "                        if current_time - self.last_save_time > self.save_interval:\n",
        "                            self.save_state()\n",
        "                            self.last_save_time = current_time\n",
        "\n",
        "                        # Ù‡Ø± Ûµ Ø¯Ù‚ÛŒÙ‚Ù‡ ÛŒÚ© Ú¯Ø²Ø§Ø±Ø´ Ø³Ù„Ø§Ù…Øª Ø§Ø±Ø³Ø§Ù„ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…\n",
        "                        if int(current_time) % 300 < 10:\n",
        "                            logger.info(f\"ğŸ’“ Ø±Ø¨Ø§Øª ÙØ¹Ø§Ù„ Ø§Ø³Øª - Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯Ù‡: {self.signal_count}\")\n",
        "\n",
        "                        time.sleep(30)  # Ù‡Ø± Û³Û° Ø«Ø§Ù†ÛŒÙ‡ Ø¨Ø±Ø±Ø³ÛŒ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…\n",
        "                    except Exception as e:\n",
        "                        logger.error(f\"Ø®Ø·Ø§ Ø¯Ø± Ù…Ú©Ø§Ù†ÛŒØ³Ù… Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ Ø§ØªØµØ§Ù„: {e}\")\n",
        "                        time.sleep(60)\n",
        "\n",
        "            # Ø´Ø±ÙˆØ¹ ØªØ§Ø¨Ø¹ Ø²Ù†Ø¯Ù‡ Ù†Ú¯Ù‡ Ø¯Ø§Ø´ØªÙ† Ø¯Ø± ÛŒÚ© ØªØ±Ø¯ Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡\n",
        "            keep_alive_thread = threading.Thread(target=keep_alive, daemon=True)\n",
        "            keep_alive_thread.start()\n",
        "\n",
        "            # Û³. Ø´Ø±ÙˆØ¹ ÛŒÚ© ØªØ±Ø¯ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ú¯Ø²Ø§Ø±Ø´ Ù‡Ø§ÛŒ ÙˆØ¶Ø¹ÛŒØª\n",
        "            def show_status():\n",
        "                while True:\n",
        "                    try:\n",
        "                        print(\n",
        "                            f\"\\rğŸ“¡ Ø±Ø¨Ø§Øª ÙØ¹Ø§Ù„ - Ø¢Ø®Ø±ÛŒÙ† Ø°Ø®ÛŒØ±Ù‡: {time.strftime('%H:%M:%S', time.localtime(self.last_save_time))} - Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§: {self.signal_count}\",\n",
        "                            end=\"\")\n",
        "                        time.sleep(10)\n",
        "                    except:\n",
        "                        time.sleep(30)\n",
        "\n",
        "            status_thread = threading.Thread(target=show_status, daemon=True)\n",
        "            status_thread.start()\n",
        "\n",
        "    def save_state(self):\n",
        "        \"\"\"Ø°Ø®ÛŒØ±Ù‡ ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ Ø±Ø¨Ø§Øª Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø¯Ø± ØµÙˆØ±Øª Ù‚Ø·Ø¹ Ø§ØªØµØ§Ù„\"\"\"\n",
        "        try:\n",
        "            state = {\n",
        "                'signal_count': self.signal_count,\n",
        "                'signal_history': self.signal_history,\n",
        "                'last_signal_reset': self.last_signal_reset,\n",
        "                'daily_signal_count': self.daily_signal_count,\n",
        "                'last_analysis_times': last_analysis_times,\n",
        "                'timestamp': time.time()\n",
        "            }\n",
        "\n",
        "            with open(self.state_file, 'w') as f:\n",
        "                json.dump(state, f)\n",
        "\n",
        "            # Ø°Ø®ÛŒØ±Ù‡ ÙˆØ¶Ø¹ÛŒØª ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§\n",
        "            exchange_state_file = f\"{BASE_DIR}/exchange_state.json\"\n",
        "            with open(exchange_state_file, 'w') as f:\n",
        "                json.dump(exchange_data, f)\n",
        "\n",
        "            logger.info(f\"ğŸ’¾ ÙˆØ¶Ø¹ÛŒØª Ø±Ø¨Ø§Øª Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯ - {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ ÙˆØ¶Ø¹ÛŒØª Ø±Ø¨Ø§Øª: {e}\")\n",
        "\n",
        "    def load_state(self):\n",
        "        \"\"\"Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù‡ Ù‚Ø¨Ù„ÛŒ Ø¯Ø± ØµÙˆØ±Øª ÙˆØ¬ÙˆØ¯\"\"\"\n",
        "        global last_analysis_times\n",
        "\n",
        "        try:\n",
        "            if os.path.exists(self.state_file):\n",
        "                with open(self.state_file, 'r') as f:\n",
        "                    state = json.load(f)\n",
        "\n",
        "                # Ø¨Ø±Ø±Ø³ÛŒ ØªØ§Ø²Ú¯ÛŒ ÙˆØ¶Ø¹ÛŒØª (Ø­Ø¯Ø§Ú©Ø«Ø± Û¶ Ø³Ø§Ø¹Øª)\n",
        "                if time.time() - state.get('timestamp', 0) < 6 * 3600:\n",
        "                    self.signal_count = state.get('signal_count', 0)\n",
        "                    self.signal_history = state.get('signal_history', {})\n",
        "                    self.last_signal_reset = state.get('last_signal_reset', time.time())\n",
        "                    self.daily_signal_count = state.get('daily_signal_count', 0)\n",
        "                    last_analysis_times = state.get('last_analysis_times', {})\n",
        "\n",
        "                    # Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ§Ù… Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ\n",
        "                    logger.info(f\"ğŸ”„ ÙˆØ¶Ø¹ÛŒØª Ù‚Ø¨Ù„ÛŒ Ø±Ø¨Ø§Øª Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø´Ø¯ - {len(self.signal_history)} Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø¯Ø± ØªØ§Ø±ÛŒØ®Ú†Ù‡\")\n",
        "\n",
        "                    # Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø¨Ù‡ ØªÙ„Ú¯Ø±Ø§Ù…\n",
        "                    if self.telegram_connected:\n",
        "                        restart_message = f\"ğŸ”„ Ø±Ø¨Ø§Øª Ù¾Ø³ Ø§Ø² Ù‚Ø·Ø¹ Ø§ØªØµØ§Ù„ Ù…Ø¬Ø¯Ø¯Ø§ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø´Ø¯\\n\"\n",
        "                        restart_message += f\"ğŸ“Š ØªØ¹Ø¯Ø§Ø¯ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯Ù‡ ØªØ§ Ú©Ù†ÙˆÙ†: {self.signal_count}\\n\"\n",
        "                        restart_message += f\"â° Ø²Ù…Ø§Ù† Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ: {time.strftime('%Y-%m-%d %H:%M:%S')}\"\n",
        "\n",
        "                        self.send_telegram_message(restart_message)\n",
        "                else:\n",
        "                    logger.warning(\"âš ï¸ ÙˆØ¶Ø¹ÛŒØª Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù‡ Ù‚Ø¯ÛŒÙ…ÛŒ Ø§Ø³Øª (Ø¨ÛŒØ´ Ø§Ø² Û¶ Ø³Ø§Ø¹Øª) Ùˆ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ù†Ø´Ø¯\")\n",
        "\n",
        "                # Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ ÙˆØ¶Ø¹ÛŒØª ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§\n",
        "                exchange_state_file = f\"{BASE_DIR}/exchange_state.json\"\n",
        "                if os.path.exists(exchange_state_file):\n",
        "                    with open(exchange_state_file, 'r') as f:\n",
        "                        global exchange_data\n",
        "                        exchange_data = json.load(f)\n",
        "        except Exception as e:\n",
        "            logger.error(f\"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø±Ø¨Ø§Øª: {e}\")\n",
        "\n",
        "\n",
        "    def diagnose_signals(self):\n",
        "        \"\"\"Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ Ùˆ Ø´Ù…Ø§Ø±Ù†Ø¯Ù‡â€ŒÙ‡Ø§\"\"\"\n",
        "        logger.info(f\"ğŸ“Š ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯Ù‡: {self.signal_count}\")\n",
        "        logger.info(f\"ğŸ“Š ØªØ¹Ø¯Ø§Ø¯ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ù…Ø±ÙˆØ²: {self.daily_signal_count}/{BOT_SETTINGS['max_signals_per_day']}\")\n",
        "        logger.info(\n",
        "            f\"ğŸ“Š Ø²Ù…Ø§Ù† Ø¢Ø®Ø±ÛŒÙ† Ø±ÛŒØ³Øª Ø´Ù…Ø§Ø±Ù†Ø¯Ù‡: {dt.datetime.fromtimestamp(self.last_signal_reset).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§\n",
        "        logger.info(f\"ğŸ“Š ØªØ¹Ø¯Ø§Ø¯ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø¯Ø± ØªØ§Ø±ÛŒØ®Ú†Ù‡: {len(self.signal_history)}\")\n",
        "\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ Ø§ØªØµØ§Ù„ Ø¨Ù‡ ØªÙ„Ú¯Ø±Ø§Ù…\n",
        "        if self.telegram_bot:\n",
        "            logger.info(\"âœ… Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ø±Ø¨Ø§Øª ØªÙ„Ú¯Ø±Ø§Ù… Ø¨Ø±Ù‚Ø±Ø§Ø± Ø§Ø³Øª\")\n",
        "            # Ø§Ø±Ø³Ø§Ù„ ÛŒÚ© Ù¾ÛŒØ§Ù… ØªØ³Øª ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ\n",
        "            try:\n",
        "                self.telegram_bot.get_me()\n",
        "                logger.info(\"âœ… API ØªÙ„Ú¯Ø±Ø§Ù… Ø¨Ù‡ Ø¯Ø±Ø³ØªÛŒ Ù¾Ø§Ø³Ø® Ù…ÛŒâ€ŒØ¯Ù‡Ø¯\")\n",
        "            except Exception as e:\n",
        "                logger.error(f\"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§ØªØµØ§Ù„ Ø¨Ù‡ API ØªÙ„Ú¯Ø±Ø§Ù…: {e}\")\n",
        "        else:\n",
        "            logger.error(\"âŒ Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ø±Ø¨Ø§Øª ØªÙ„Ú¯Ø±Ø§Ù… Ø¨Ø±Ù‚Ø±Ø§Ø± Ù†ÛŒØ³Øª\")\n",
        "\n",
        "    def create_candlestick_chart(self, df, symbol, timeframe, strategies=None, indicators=None,\n",
        "                                 support_resistance=None, patterns=None, entry_exit=None, title=None):\n",
        "        \"\"\"\n",
        "        Ø§ÛŒØ¬Ø§Ø¯ Ù†Ù…ÙˆØ¯Ø§Ø± Ú©Ù†Ø¯Ù„â€ŒØ§Ø³ØªÛŒÚ© Ø¨Ø§ Ù‡Ù…Ù‡ Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§ Ùˆ Ø¹Ù„Ø§Ù…Øªâ€ŒÚ¯Ø°Ø§Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ Ù„Ø§Ø²Ù… - Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡ Ùˆ Ø¨Ø§ Ù…Ø¯ÛŒØ±ÛŒØª Ø®Ø·Ø§\n",
        "\n",
        "        Args:\n",
        "            df: Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§\n",
        "            symbol: Ù†Ù…Ø§Ø¯ Ø§Ø±Ø²\n",
        "            timeframe: ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…\n",
        "            strategies: Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§ Ùˆ Ù†ØªØ§ÛŒØ¬ Ø¢Ù†â€ŒÙ‡Ø§ (dict)\n",
        "            indicators: Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¯Ù‡ (dict)\n",
        "            support_resistance: Ø³Ø·ÙˆØ­ Ø­Ù…Ø§ÛŒØª Ùˆ Ù…Ù‚Ø§ÙˆÙ…Øª (dict)\n",
        "            patterns: Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯Ù‡ (dict)\n",
        "            entry_exit: Ù†Ù‚Ø§Ø· ÙˆØ±ÙˆØ¯ Ùˆ Ø®Ø±ÙˆØ¬ (dict)\n",
        "            title: Ø¹Ù†ÙˆØ§Ù† Ù†Ù…ÙˆØ¯Ø§Ø± (str)\n",
        "\n",
        "        Returns:\n",
        "            Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ Ù†Ù…ÙˆØ¯Ø§Ø± Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù‡\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Ú¯Ø±ÙØªÙ† Ø²ÛŒØ±Ù…Ø¬Ù…ÙˆØ¹Ù‡ Ø¢Ø®Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¨Ù‡ØªØ± Ø¯Ø± Ù†Ù…ÙˆØ¯Ø§Ø±\n",
        "            if len(df) > 150:\n",
        "                plot_df = df.iloc[-150:]\n",
        "            else:\n",
        "                plot_df = df\n",
        "\n",
        "            # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø¹ØªØ¨Ø± Ø¨ÙˆØ¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§\n",
        "            if len(plot_df) < 5:\n",
        "                logger.warning(f\"Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ø±Ø³Ù… Ù†Ù…ÙˆØ¯Ø§Ø± {symbol} - {timeframe}\")\n",
        "                # Ø±Ø³Ù… ÛŒÚ© Ù†Ù…ÙˆØ¯Ø§Ø± Ø³Ø§Ø¯Ù‡ Ø¨Ø¯ÙˆÙ† Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§\n",
        "                chart_filename = f\"{BASE_DIR}/charts/{symbol.replace('/', '_')}_{timeframe}_{int(time.time())}.png\"\n",
        "                plt.figure(figsize=(10, 6))\n",
        "                plt.title(f\"{symbol} - {timeframe} - Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ\")\n",
        "                plt.text(0.5, 0.5, \"Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ø±Ø³Ù… Ù†Ù…ÙˆØ¯Ø§Ø±\",\n",
        "                         horizontalalignment='center', verticalalignment='center',\n",
        "                         transform=plt.gca().transAxes, fontsize=14)\n",
        "                plt.savefig(chart_filename, dpi=200)\n",
        "                plt.close()\n",
        "                return chart_filename\n",
        "\n",
        "            # ØªØ¨Ø¯ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ù‡ ÙØ±Ù…Øª Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø±Ø§ÛŒ mplfinance\n",
        "            ohlc_data = plot_df[['open', 'high', 'low', 'close', 'volume']].copy()\n",
        "\n",
        "            # ØªÙ†Ø¸ÛŒÙ… Ø§Ø³ØªØ§ÛŒÙ„ Ù†Ù…ÙˆØ¯Ø§Ø±\n",
        "            mc = mpf.make_marketcolors(up='#00b060', down='#fe3032',\n",
        "                                       edge='inherit',\n",
        "                                       wick={'up': '#00b060', 'down': '#fe3032'},\n",
        "                                       volume={'up': '#007046', 'down': '#a11d20'})\n",
        "\n",
        "            s = mpf.make_mpf_style(base_mpf_style='charles', marketcolors=mc,\n",
        "                                   rc={'font.size': 10, 'axes.labelsize': 12},\n",
        "                                   y_on_right=False)\n",
        "\n",
        "            # ØªÙ†Ø¸ÛŒÙ… Ù¾Ù†Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§\n",
        "            additional_panels = []\n",
        "\n",
        "            # Ø§ÙØ²ÙˆØ¯Ù† Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø¨Ù‡ Ù†Ù…ÙˆØ¯Ø§Ø±\n",
        "            apds = []\n",
        "\n",
        "            # Ø±Ù†Ú¯â€ŒÙ‡Ø§\n",
        "            colors = ['#f5d742', '#5cc9f5', '#da70d6', '#ff7f0e', '#e377c2', '#bcbd22', '#17becf']\n",
        "\n",
        "            # Ù†Ù…Ø§ÛŒØ´ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†â€ŒÙ‡Ø§ÛŒ Ù…ØªØ­Ø±Ú© Ø§Ú¯Ø± Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ø´Ù†Ø¯\n",
        "            if indicators and 'ema' in indicators and indicators['ema']:\n",
        "                ema_data = []\n",
        "                for i, period in enumerate([8, 21, 50, 200]):\n",
        "                    try:\n",
        "                        if f'ema_{period}' in plot_df.columns:\n",
        "                            ema_series = plot_df[f'ema_{period}']\n",
        "                        elif f'ema_{period}' in df.columns:\n",
        "                            # Ø§Ú¯Ø± Ø¯Ø± plot_df Ù†ÛŒØ³Øª ÙˆÙ„ÛŒ Ø¯Ø± df Ø§ØµÙ„ÛŒ Ù‡Ø³ØªØŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ú©Ù†ÛŒÙ…\n",
        "                            ema_series = df[f'ema_{period}'].iloc[-len(plot_df):]\n",
        "                        else:\n",
        "                            # Ø§Ú¯Ø± Ø¯Ø± Ù‡ÛŒÚ†Ú©Ø¯Ø§Ù… Ù†ÛŒØ³ØªØŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ú©Ù†ÛŒÙ…\n",
        "                            ema_series = ta.trend.ema_indicator(plot_df['close'], window=period)\n",
        "\n",
        "                        # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø¹ØªØ¨Ø± Ø¨ÙˆØ¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§\n",
        "                        if not ema_series.isnull().all() and len(ema_series.dropna()) > 0:\n",
        "                            # Ù…Ù‚Ø§Ø¯ÛŒØ± NaN Ø±Ø§ Ø¨Ø§ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ú©Ù†ÛŒÙ…\n",
        "                            mean_value = ema_series.mean()\n",
        "                            ema_series = ema_series.fillna(mean_value)\n",
        "\n",
        "                            color = colors[i % len(colors)]\n",
        "                            ema_data.append(\n",
        "                                mpf.make_addplot(ema_series, color=color, width=1,\n",
        "                                                 label=f'EMA {period}')\n",
        "                            )\n",
        "                            plot_df[f'ema_{period}'] = ema_series\n",
        "                    except Exception as e:\n",
        "                        logger.warning(f\"Ø®Ø·Ø§ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ EMA {period}: {e}\")\n",
        "\n",
        "                if ema_data:\n",
        "                    apds.extend(ema_data)\n",
        "\n",
        "            # Ù†Ù…Ø§ÛŒØ´ Ø¨Ø§Ù†Ø¯Ù‡Ø§ÛŒ Ø¨ÙˆÙ„ÛŒÙ†Ú¯Ø± Ø§Ú¯Ø± Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ø´Ù†Ø¯\n",
        "            if indicators and 'bollinger' in indicators and indicators['bollinger']:\n",
        "                try:\n",
        "                    if not all(x in plot_df.columns for x in ['bb_upper', 'bb_middle', 'bb_lower']):\n",
        "                        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¨Ø§Ù†Ø¯Ù‡Ø§ÛŒ Ø¨ÙˆÙ„ÛŒÙ†Ú¯Ø±\n",
        "                        bb_ind = ta.volatility.BollingerBands(plot_df['close'], window=20, window_dev=2)\n",
        "                        plot_df['bb_upper'] = bb_ind.bollinger_hband()\n",
        "                        plot_df['bb_middle'] = bb_ind.bollinger_mavg()\n",
        "                        plot_df['bb_lower'] = bb_ind.bollinger_lband()\n",
        "\n",
        "                    # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø¹ØªØ¨Ø± Ø¨ÙˆØ¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§\n",
        "                    for bb_col in ['bb_upper', 'bb_middle', 'bb_lower']:\n",
        "                        if not plot_df[bb_col].isnull().all() and len(plot_df[bb_col].dropna()) > 0:\n",
        "                            # Ù…Ù‚Ø§Ø¯ÛŒØ± NaN Ø±Ø§ Ø¨Ø§ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ú©Ù†ÛŒÙ…\n",
        "                            mean_value = plot_df[bb_col].mean()\n",
        "                            plot_df[bb_col] = plot_df[bb_col].fillna(mean_value)\n",
        "\n",
        "                    apds.append(mpf.make_addplot(plot_df['bb_upper'], color='#6fa8dc', width=0.7, linestyle='--'))\n",
        "                    apds.append(mpf.make_addplot(plot_df['bb_middle'], color='#6fa8dc', width=0.7))\n",
        "                    apds.append(mpf.make_addplot(plot_df['bb_lower'], color='#6fa8dc', width=0.7, linestyle='--'))\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"Ø®Ø·Ø§ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¨Ø§Ù†Ø¯Ù‡Ø§ÛŒ Ø¨ÙˆÙ„ÛŒÙ†Ú¯Ø±: {e}\")\n",
        "\n",
        "            # Ù†Ù…Ø§ÛŒØ´ Ø³Ø·ÙˆØ­ ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ Ø§Ú¯Ø± Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ø´Ù†Ø¯\n",
        "            if indicators and 'fibonacci' in indicators and indicators['fibonacci'] and 'fibonacci_data' in indicators:\n",
        "                try:\n",
        "                    fib_data = indicators['fibonacci_data']\n",
        "                    if 'fibonacci_retracements' in fib_data and fib_data['fibonacci_retracements']:\n",
        "                        # Ø±Ø³Ù… Ø¢Ø®Ø±ÛŒÙ† retracement\n",
        "                        last_retracement = fib_data['fibonacci_retracements'][-1]\n",
        "                        fib_levels = last_retracement['levels']\n",
        "\n",
        "                        for level, value in fib_levels.items():\n",
        "                            if isinstance(level, (int, float)):  # Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ø§ÛŒÙ†Ú©Ù‡ Ú©Ù„ÛŒØ¯ ÛŒÚ© Ø¹Ø¯Ø¯ Ø§Ø³Øª\n",
        "                                level_label = f\"Fib {level}\"\n",
        "                                color = '#edb879' if level != 0.5 else '#e36f7a'  # Ø³Ø·Ø­ 0.5 Ø±Ø§ Ø¨Ø§ Ø±Ù†Ú¯ Ù…ØªÙØ§ÙˆØª Ù†Ù…Ø§ÛŒØ´ Ù…ÛŒâ€ŒØ¯Ù‡ÛŒÙ…\n",
        "                                # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø¹ØªØ¨Ø± Ø¨ÙˆØ¯Ù† Ù…Ù‚Ø¯Ø§Ø±\n",
        "                                if not np.isnan(value) and np.isfinite(value):\n",
        "                                    apds.append(\n",
        "                                        mpf.make_addplot([value] * len(plot_df), color=color, width=0.7,\n",
        "                                                         linestyle='--', panel=0)\n",
        "                                    )\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"Ø®Ø·Ø§ Ø¯Ø± Ø±Ø³Ù… Ø³Ø·ÙˆØ­ ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ: {e}\")\n",
        "\n",
        "            # Ù†Ù…Ø§ÛŒØ´ Ø§ÛŒÚ†ÛŒÙ…ÙˆÚ©Ùˆ Ø§Ú¯Ø± Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ø´Ø¯\n",
        "            if indicators and 'ichimoku' in indicators and indicators['ichimoku']:\n",
        "                try:\n",
        "                    # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø®Ø·ÙˆØ· Ø§ÛŒÚ†ÛŒÙ…ÙˆÚ©Ùˆ Ø§Ú¯Ø± Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³ØªÙ†Ø¯\n",
        "                    if not all(x in plot_df.columns for x in ['tenkan_sen', 'kijun_sen']):\n",
        "                        # ØªÙ†Ú©Ø§Ù†-Ø³Ù† (Tenkan-sen) - Ø®Ø· ØªØ¨Ø¯ÛŒÙ„\n",
        "                        high_9 = plot_df['high'].rolling(window=9).max()\n",
        "                        low_9 = plot_df['low'].rolling(window=9).min()\n",
        "                        plot_df['tenkan_sen'] = (high_9 + low_9) / 2\n",
        "\n",
        "                        # Ú©ÛŒØ¬ÙˆÙ†-Ø³Ù† (Kijun-sen) - Ø®Ø· Ù¾Ø§ÛŒÙ‡\n",
        "                        high_26 = plot_df['high'].rolling(window=26).max()\n",
        "                        low_26 = plot_df['low'].rolling(window=26).min()\n",
        "                        plot_df['kijun_sen'] = (high_26 + low_26) / 2\n",
        "\n",
        "                    # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø¹ØªØ¨Ø± Ø¨ÙˆØ¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§\n",
        "                    for col in ['tenkan_sen', 'kijun_sen']:\n",
        "                        if col in plot_df.columns and not plot_df[col].isnull().all() and len(\n",
        "                                plot_df[col].dropna()) > 0:\n",
        "                            # Ù…Ù‚Ø§Ø¯ÛŒØ± NaN Ø±Ø§ Ø¨Ø§ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ú©Ù†ÛŒÙ…\n",
        "                            mean_value = plot_df[col].mean()\n",
        "                            plot_df[col] = plot_df[col].fillna(mean_value)\n",
        "\n",
        "                            if col == 'tenkan_sen':\n",
        "                                apds.append(mpf.make_addplot(plot_df[col], color='#f5d742', width=0.7))\n",
        "                            else:  # kijun_sen\n",
        "                                apds.append(mpf.make_addplot(plot_df[col], color='#5cc9f5', width=0.7))\n",
        "\n",
        "                    # Cloud (ÙÙ‚Ø· Ø§Ú¯Ø± Ù‡Ø± Ø¯Ùˆ Ø³ØªÙˆÙ† senkou_span_a Ùˆ senkou_span_b Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ø´Ù†Ø¯ ÛŒØ§ Ø¨ØªÙˆØ§Ù†ÛŒÙ… Ù…Ø­Ø§Ø³Ø¨Ù‡ Ú©Ù†ÛŒÙ…)\n",
        "                    if not all(x in plot_df.columns for x in ['senkou_span_a', 'senkou_span_b']):\n",
        "                        # Ù…Ø­Ø§Ø³Ø¨Ù‡ senkou span\n",
        "                        if 'tenkan_sen' in plot_df.columns and 'kijun_sen' in plot_df.columns:\n",
        "                            plot_df['senkou_span_a'] = ((plot_df['tenkan_sen'] + plot_df['kijun_sen']) / 2).shift(26)\n",
        "\n",
        "                            # Ø³Ù†Ú©Ùˆ Ø§Ø³Ù¾Ù† B\n",
        "                            high_52 = plot_df['high'].rolling(window=52).max()\n",
        "                            low_52 = plot_df['low'].rolling(window=52).min()\n",
        "                            plot_df['senkou_span_b'] = ((high_52 + low_52) / 2).shift(26)\n",
        "\n",
        "                    # ÙÙ‚Ø· Ø§Ú¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ú©Ø§ÙÛŒ Ø¨Ø§Ø´Ù†Ø¯ØŒ Ø§Ø¶Ø§ÙÙ‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…\n",
        "                    span_cols = ['senkou_span_a', 'senkou_span_b']\n",
        "                    for i, col in enumerate(span_cols):\n",
        "                        if col in plot_df.columns and not plot_df[col].isnull().all() and len(\n",
        "                                plot_df[col].dropna()) > 0:\n",
        "                            # Ù…Ù‚Ø§Ø¯ÛŒØ± NaN Ø±Ø§ Ø¨Ø§ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ú©Ù†ÛŒÙ… ÛŒØ§ Ø­Ø°Ù Ú©Ù†ÛŒÙ…\n",
        "                            non_null_values = plot_df[col].dropna().values\n",
        "                            if len(non_null_values) > 0:\n",
        "                                # ÙÙ‚Ø· Ø¯Ø± ØµÙˆØ±ØªÛŒ Ú©Ù‡ Ù…Ù‚Ø§Ø¯ÛŒØ± ØºÛŒØ± NaN Ø¯Ø§Ø±ÛŒÙ…\n",
        "                                mean_value = non_null_values.mean()\n",
        "                                filled_series = plot_df[col].fillna(mean_value)\n",
        "\n",
        "                                color = '#11a171' if i == 0 else '#e36f7a'\n",
        "                                apds.append(mpf.make_addplot(filled_series, color=color, width=0.5))\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"Ø®Ø·Ø§ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§ÛŒÚ†ÛŒÙ…ÙˆÚ©Ùˆ: {e}\")\n",
        "\n",
        "            # Ù†Ù…Ø§ÛŒØ´ RSI Ø¯Ø± ÛŒÚ© Ù¾Ù†Ù„ Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡\n",
        "            if indicators and 'rsi' in indicators and indicators['rsi']:\n",
        "                try:\n",
        "                    if 'rsi' not in plot_df.columns:\n",
        "                        plot_df['rsi'] = ta.momentum.rsi(plot_df['close'], window=14)\n",
        "\n",
        "                    # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø¹ØªØ¨Ø± Ø¨ÙˆØ¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§\n",
        "                    if not plot_df['rsi'].isnull().all() and len(plot_df['rsi'].dropna()) > 0:\n",
        "                        # Ù…Ù‚Ø§Ø¯ÛŒØ± NaN Ø±Ø§ Ø¨Ø§ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ú©Ù†ÛŒÙ…\n",
        "                        rsi_mean = plot_df['rsi'].dropna().mean()\n",
        "                        plot_df['rsi'] = plot_df['rsi'].fillna(rsi_mean)\n",
        "\n",
        "                        apds.append(\n",
        "                            mpf.make_addplot(plot_df['rsi'], panel=1, color='#edb879', width=1,\n",
        "                                             ylim=(0, 100))\n",
        "                        )\n",
        "                        # Ø®Ø·ÙˆØ· Ø³Ø·ÙˆØ­ Ø§Ø´Ø¨Ø§Ø¹ Ø®Ø±ÛŒØ¯ Ùˆ ÙØ±ÙˆØ´\n",
        "                        apds.append(mpf.make_addplot([70] * len(plot_df), panel=1, color='#e36f7a',\n",
        "                                                     width=0.5, linestyle='--'))\n",
        "                        apds.append(mpf.make_addplot([30] * len(plot_df), panel=1, color='#11a171',\n",
        "                                                     width=0.5, linestyle='--'))\n",
        "                        additional_panels.append('RSI')\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"Ø®Ø·Ø§ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ RSI: {e}\")\n",
        "\n",
        "            # Ù†Ù…Ø§ÛŒØ´ MACD Ø¯Ø± ÛŒÚ© Ù¾Ù†Ù„ Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡\n",
        "            if indicators and 'macd' in indicators and indicators['macd']:\n",
        "                try:\n",
        "                    # Ù…Ø­Ø§Ø³Ø¨Ù‡ MACD Ø§Ú¯Ø± Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª\n",
        "                    if not all(x in plot_df.columns for x in ['macd', 'macd_signal']):\n",
        "                        macd_ind = ta.trend.MACD(plot_df['close'], window_slow=26, window_fast=12, window_sign=9)\n",
        "                        plot_df['macd'] = macd_ind.macd()\n",
        "                        plot_df['macd_signal'] = macd_ind.macd_signal()\n",
        "                        plot_df['macd_diff'] = macd_ind.macd_diff()\n",
        "\n",
        "                    # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø¹ØªØ¨Ø± Ø¨ÙˆØ¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§\n",
        "                    valid_macd = (\n",
        "                            not plot_df['macd'].isnull().all() and\n",
        "                            not plot_df['macd_signal'].isnull().all() and\n",
        "                            len(plot_df['macd'].dropna()) > 0 and\n",
        "                            len(plot_df['macd_signal'].dropna()) > 0\n",
        "                    )\n",
        "\n",
        "                    if valid_macd:\n",
        "                        # Ù…Ù‚Ø§Ø¯ÛŒØ± NaN Ø±Ø§ Ø¨Ø§ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ú©Ù†ÛŒÙ…\n",
        "                        for col in ['macd', 'macd_signal']:\n",
        "                            mean_value = plot_df[col].dropna().mean()\n",
        "                            plot_df[col] = plot_df[col].fillna(mean_value)\n",
        "\n",
        "                        macd_panel = 2 if 'RSI' in additional_panels else 1\n",
        "\n",
        "                        apds.append(\n",
        "                            mpf.make_addplot(plot_df['macd'], panel=macd_panel, color='#5cc9f5', width=1)\n",
        "                        )\n",
        "                        apds.append(\n",
        "                            mpf.make_addplot(plot_df['macd_signal'], panel=macd_panel, color='#f5d742', width=1)\n",
        "                        )\n",
        "\n",
        "                        # Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù‡ÛŒØ³ØªÙˆÚ¯Ø±Ø§Ù… MACD\n",
        "                        macd_hist = plot_df['macd'] - plot_df['macd_signal']\n",
        "\n",
        "                        # Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ†ÛŒ Ù…Ù‚Ø§Ø¯ÛŒØ± NaN\n",
        "                        macd_hist = macd_hist.fillna(0)\n",
        "\n",
        "                        apds.append(\n",
        "                            mpf.make_addplot(macd_hist, type='bar', panel=macd_panel,\n",
        "                                             color=['#11a171' if x > 0 else '#e36f7a' for x in macd_hist])\n",
        "                        )\n",
        "\n",
        "                        additional_panels.append('MACD')\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"Ø®Ø·Ø§ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ MACD: {e}\")\n",
        "\n",
        "            # Ù†Ù…Ø§ÛŒØ´ Ø­Ø¬Ù… Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø¯Ø± ÛŒÚ© Ù¾Ù†Ù„ Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡\n",
        "            volume_panel = len(additional_panels) + 1\n",
        "            if 'volume' in plot_df.columns and not plot_df['volume'].isnull().all() and plot_df['volume'].sum() > 0:\n",
        "                try:\n",
        "                    # Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ù…Ø¹ØªØ¨Ø± Ø¨ÙˆØ¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø­Ø¬Ù…\n",
        "                    plot_df['volume'] = plot_df['volume'].fillna(0)\n",
        "\n",
        "                    # Ø±Ù†Ú¯â€ŒØ¨Ù†Ø¯ÛŒ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø­Ø¬Ù…\n",
        "                    volume_colors = []\n",
        "                    for i in range(len(plot_df)):\n",
        "                        if i >= len(plot_df) or not all(col in plot_df.columns for col in ['open', 'close']):\n",
        "                            volume_colors.append('#11a171')  # Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø³Ø¨Ø²\n",
        "                        else:\n",
        "                            color = '#11a171' if plot_df['close'].iloc[i] >= plot_df['open'].iloc[i] else '#e36f7a'\n",
        "                            volume_colors.append(color)\n",
        "\n",
        "                    apds.append(\n",
        "                        mpf.make_addplot(plot_df['volume'], panel=volume_panel, type='bar',\n",
        "                                         color=volume_colors)\n",
        "                    )\n",
        "                    additional_panels.append('Volume')\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"Ø®Ø·Ø§ Ø¯Ø± Ù†Ù…Ø§ÛŒØ´ Ø­Ø¬Ù… Ù…Ø¹Ø§Ù…Ù„Ø§Øª: {e}\")\n",
        "\n",
        "            # Ø§Ú¯Ø± Ù‡ÛŒÚ† Ù¾Ù†Ù„ Ø§Ø¶Ø§ÙÛŒ Ù†Ø¯Ø§Ø±ÛŒÙ…ØŒ Ø­Ø¯Ø§Ù‚Ù„ ÛŒÚ© Ù¾Ù†Ù„ Ø®Ø§Ù„ÛŒ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†ÛŒÙ…\n",
        "            if not additional_panels:\n",
        "                additional_panels.append('No Data')\n",
        "\n",
        "            # ØªÙ†Ø¸ÛŒÙ… Ø¹Ù†ÙˆØ§Ù† Ù†Ù…ÙˆØ¯Ø§Ø±\n",
        "            if not title:\n",
        "                title = f\"{symbol} - {timeframe} - {plot_df.index[-1].strftime('%Y-%m-%d %H:%M')}\"\n",
        "\n",
        "            # Ø§ÛŒØ¬Ø§Ø¯ Ù†Ù…ÙˆØ¯Ø§Ø±\n",
        "            fig, axes = mpf.plot(\n",
        "                ohlc_data,\n",
        "                type='candle',\n",
        "                style=s,\n",
        "                figsize=(14, 12 + len(additional_panels) * 2),\n",
        "                title=title,\n",
        "                ylabel='Ù‚ÛŒÙ…Øª',\n",
        "                volume=False,  # Ø§Ø² Ù¾Ù†Ù„ Ø­Ø¬Ù… Ø¯Ø§Ø®Ù„ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…ØŒ Ø²ÛŒØ±Ø§ Ø®ÙˆØ¯Ù…Ø§Ù† Ø¢Ù† Ø±Ø§ Ø§Ø¶Ø§ÙÙ‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…\n",
        "                panel_ratios=(4, *([1] * len(additional_panels))),\n",
        "                addplot=apds,\n",
        "                returnfig=True\n",
        "            )\n",
        "\n",
        "            # Ø§ÙØ²ÙˆØ¯Ù† Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ù¾Ù†Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ\n",
        "            for i, panel_name in enumerate(additional_panels):\n",
        "                if i + 1 < len(axes):  # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ø¢Ø±Ø§ÛŒÙ‡\n",
        "                    axes[i + 1].set_ylabel(panel_name)\n",
        "\n",
        "            # Ø§ÙØ²ÙˆØ¯Ù† Ù†Ù‚Ø§Ø· ÙˆØ±ÙˆØ¯ Ùˆ Ø®Ø±ÙˆØ¬ØŒ Ø³Ø·ÙˆØ­ Ø­Ù…Ø§ÛŒØª Ùˆ Ù…Ù‚Ø§ÙˆÙ…Øª Ùˆ ØºÛŒØ±Ù‡\n",
        "            ax = axes[0]  # Ø§ÙˆÙ„ÛŒÙ† Ù…Ø­ÙˆØ± Ø¨Ø±Ø§ÛŒ Ù†Ù…ÙˆØ¯Ø§Ø± Ø§ØµÙ„ÛŒ\n",
        "\n",
        "            # ==== Ø§ÙØ²ÙˆØ¯Ù† Ø³Ø·ÙˆØ­ Ø­Ù…Ø§ÛŒØª Ùˆ Ù…Ù‚Ø§ÙˆÙ…Øª ====\n",
        "            if support_resistance:\n",
        "                for level_type, levels in support_resistance.items():\n",
        "                    color = '#11a171' if level_type == 'support' else '#e36f7a'\n",
        "                    for level in levels:\n",
        "                        # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø¹ØªØ¨Ø± Ø¨ÙˆØ¯Ù† Ù…Ù‚Ø¯Ø§Ø±\n",
        "                        if not np.isnan(level) and np.isfinite(level):\n",
        "                            ax.axhline(level, color=color, linestyle='--', alpha=0.7, linewidth=1)\n",
        "\n",
        "            # ==== Ø§ÙØ²ÙˆØ¯Ù† Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯Ù‡ ====\n",
        "            if patterns:\n",
        "                for pattern_type, pattern_points in patterns.items():\n",
        "                    for point in pattern_points:\n",
        "                        try:\n",
        "                            # ØªØ·Ø¨ÛŒÙ‚ Ø¨Ø§ Ø³Ø§Ø®ØªØ§Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ MSB Ùˆ Order Block\n",
        "                            if pattern_type == 'market_structure_break_bullish':\n",
        "                                # Ø§Ú¯Ø± point ÛŒÚ© tuple Ø§Ø³Øª (index, price)\n",
        "                                if isinstance(point, tuple) and len(point) >= 2:\n",
        "                                    orig_idx, price = point[0], point[1]\n",
        "                                    # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø¹ØªØ¨Ø± Ø¨ÙˆØ¯Ù† Ù…Ù‚Ø§Ø¯ÛŒØ±\n",
        "                                    if not isinstance(orig_idx, (int, np.integer)) or np.isnan(\n",
        "                                            price) or not np.isfinite(price):\n",
        "                                        continue\n",
        "\n",
        "                                    # Ø¨Ø±Ø±Ø³ÛŒ Ø´Ø§Ø®Øµ Ø¯Ø± Ù…Ø­Ø¯ÙˆØ¯Ù‡\n",
        "                                    if orig_idx >= len(df) - len(plot_df) and orig_idx < len(df):\n",
        "                                        idx = orig_idx - (len(df) - len(plot_df))\n",
        "                                        ax.scatter(idx, price, color='green', marker='^', s=120, alpha=0.8)\n",
        "                                        ax.annotate('MSB', xy=(idx, price), xytext=(idx, price * 1.02),\n",
        "                                                    color='green', fontsize=8, ha='center')\n",
        "                                # Ø§Ú¯Ø± point ÛŒÚ© dictionary Ø§Ø³Øª\n",
        "                                elif isinstance(point, dict) and 'index' in point and 'price' in point:\n",
        "                                    orig_idx, price = point['index'], point['price']\n",
        "                                    # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø¹ØªØ¨Ø± Ø¨ÙˆØ¯Ù† Ù…Ù‚Ø§Ø¯ÛŒØ±\n",
        "                                    if not isinstance(orig_idx, (int, np.integer)) or np.isnan(\n",
        "                                            price) or not np.isfinite(price):\n",
        "                                        continue\n",
        "\n",
        "                                    if orig_idx >= len(df) - len(plot_df) and orig_idx < len(df):\n",
        "                                        idx = orig_idx - (len(df) - len(plot_df))\n",
        "                                        ax.scatter(idx, price, color='green', marker='^', s=120, alpha=0.8)\n",
        "                                        ax.annotate('MSB', xy=(idx, price), xytext=(idx, price * 1.02),\n",
        "                                                    color='green', fontsize=8, ha='center')\n",
        "\n",
        "                            elif pattern_type == 'market_structure_break_bearish':\n",
        "                                # Ø§Ú¯Ø± point ÛŒÚ© tuple Ø§Ø³Øª (index, price)\n",
        "                                if isinstance(point, tuple) and len(point) >= 2:\n",
        "                                    orig_idx, price = point[0], point[1]\n",
        "                                    # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø¹ØªØ¨Ø± Ø¨ÙˆØ¯Ù† Ù…Ù‚Ø§Ø¯ÛŒØ±\n",
        "                                    if not isinstance(orig_idx, (int, np.integer)) or np.isnan(\n",
        "                                            price) or not np.isfinite(price):\n",
        "                                        continue\n",
        "\n",
        "                                    # Ø¨Ø±Ø±Ø³ÛŒ Ø´Ø§Ø®Øµ Ø¯Ø± Ù…Ø­Ø¯ÙˆØ¯Ù‡\n",
        "                                    if orig_idx >= len(df) - len(plot_df) and orig_idx < len(df):\n",
        "                                        idx = orig_idx - (len(df) - len(plot_df))\n",
        "                                        ax.scatter(idx, price, color='red', marker='v', s=120, alpha=0.8)\n",
        "                                        ax.annotate('MSB', xy=(idx, price), xytext=(idx, price * 0.98),\n",
        "                                                    color='red', fontsize=8, ha='center')\n",
        "                                # Ø§Ú¯Ø± point ÛŒÚ© dictionary Ø§Ø³Øª\n",
        "                                elif isinstance(point, dict) and 'index' in point and 'price' in point:\n",
        "                                    orig_idx, price = point['index'], point['price']\n",
        "                                    # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø¹ØªØ¨Ø± Ø¨ÙˆØ¯Ù† Ù…Ù‚Ø§Ø¯ÛŒØ±\n",
        "                                    if not isinstance(orig_idx, (int, np.integer)) or np.isnan(\n",
        "                                            price) or not np.isfinite(price):\n",
        "                                        continue\n",
        "\n",
        "                                    if orig_idx >= len(df) - len(plot_df) and orig_idx < len(df):\n",
        "                                        idx = orig_idx - (len(df) - len(plot_df))\n",
        "                                        ax.scatter(idx, price, color='red', marker='v', s=120, alpha=0.8)\n",
        "                                        ax.annotate('MSB', xy=(idx, price), xytext=(idx, price * 0.98),\n",
        "                                                    color='red', fontsize=8, ha='center')\n",
        "\n",
        "                            elif pattern_type == 'order_block_bullish':\n",
        "                                # Ø¨Ø±Ø±Ø³ÛŒ Ø§Ú¯Ø± point ÛŒÚ© dict Ø§Ø³Øª\n",
        "                                if isinstance(point, dict) and 'index' in point and 'high' in point and 'low' in point:\n",
        "                                    orig_idx = point['index']\n",
        "                                    high = point['high']\n",
        "                                    low = point['low']\n",
        "\n",
        "                                    # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø¹ØªØ¨Ø± Ø¨ÙˆØ¯Ù† Ù…Ù‚Ø§Ø¯ÛŒØ±\n",
        "                                    if (not isinstance(orig_idx, (int, np.integer)) or\n",
        "                                            np.isnan(high) or not np.isfinite(high) or\n",
        "                                            np.isnan(low) or not np.isfinite(low)):\n",
        "                                        continue\n",
        "\n",
        "                                    # Ø¨Ø±Ø±Ø³ÛŒ Ø´Ø§Ø®Øµ Ø¯Ø± Ù…Ø­Ø¯ÙˆØ¯Ù‡\n",
        "                                    if orig_idx >= len(df) - len(plot_df) and orig_idx < len(df):\n",
        "                                        idx = orig_idx - (len(df) - len(plot_df))\n",
        "                                        rect = Rectangle((idx - 0.4, low), 0.8, high - low,\n",
        "                                                         color='green', alpha=0.3)\n",
        "                                        ax.add_patch(rect)\n",
        "                                        ax.annotate('OB', xy=(idx, low), xytext=(idx, low * 0.99),\n",
        "                                                    color='green', fontsize=8, ha='center')\n",
        "                                        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø®Ø· Ù…ÛŒØªØ³ÙˆØ¨Ùˆ\n",
        "                                        if 'mitsubo' in point and not np.isnan(point['mitsubo']) and np.isfinite(\n",
        "                                                point['mitsubo']):\n",
        "                                            ax.axhline(y=point['mitsubo'], linestyle='--', color='green', alpha=0.6,\n",
        "                                                       xmin=(idx - 1) / (len(plot_df)),\n",
        "                                                       xmax=(idx + 1) / (len(plot_df)))\n",
        "\n",
        "                            elif pattern_type == 'order_block_bearish':\n",
        "                                # Ø¨Ø±Ø±Ø³ÛŒ Ø§Ú¯Ø± point ÛŒÚ© dict Ø§Ø³Øª\n",
        "                                if isinstance(point, dict) and 'index' in point and 'high' in point and 'low' in point:\n",
        "                                    orig_idx = point['index']\n",
        "                                    high = point['high']\n",
        "                                    low = point['low']\n",
        "\n",
        "                                    # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø¹ØªØ¨Ø± Ø¨ÙˆØ¯Ù† Ù…Ù‚Ø§Ø¯ÛŒØ±\n",
        "                                    if (not isinstance(orig_idx, (int, np.integer)) or\n",
        "                                            np.isnan(high) or not np.isfinite(high) or\n",
        "                                            np.isnan(low) or not np.isfinite(low)):\n",
        "                                        continue\n",
        "\n",
        "                                    # Ø¨Ø±Ø±Ø³ÛŒ Ø´Ø§Ø®Øµ Ø¯Ø± Ù…Ø­Ø¯ÙˆØ¯Ù‡\n",
        "                                    if orig_idx >= len(df) - len(plot_df) and orig_idx < len(df):\n",
        "                                        idx = orig_idx - (len(df) - len(plot_df))\n",
        "                                        rect = Rectangle((idx - 0.4, low), 0.8, high - low,\n",
        "                                                         color='red', alpha=0.3)\n",
        "                                        ax.add_patch(rect)\n",
        "                                        ax.annotate('OB', xy=(idx, high), xytext=(idx, high * 1.01),\n",
        "                                                    color='red', fontsize=8, ha='center')\n",
        "                                        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø®Ø· Ù…ÛŒØªØ³ÙˆØ¨Ùˆ\n",
        "                                        if 'mitsubo' in point and not np.isnan(point['mitsubo']) and np.isfinite(\n",
        "                                                point['mitsubo']):\n",
        "                                            ax.axhline(y=point['mitsubo'], linestyle='--', color='red', alpha=0.6,\n",
        "                                                       xmin=(idx - 1) / (len(plot_df)),\n",
        "                                                       xmax=(idx + 1) / (len(plot_df)))\n",
        "                        except Exception as e:\n",
        "                            logger.warning(f\"Ø®Ø·Ø§ Ø¯Ø± Ø±Ø³Ù… Ø§Ù„Ú¯ÙˆÛŒ {pattern_type}: {e}\")\n",
        "\n",
        "            # ==== Ø§Ú¯Ø± Ù†Ù‚Ø§Ø· ÙˆØ±ÙˆØ¯ Ùˆ Ø®Ø±ÙˆØ¬ ØªØ¹Ø±ÛŒÙ Ø´Ø¯Ù‡ Ø¨Ø§Ø´Ù†Ø¯ØŒ Ø¢Ù†â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ù‡ Ù†Ù…ÙˆØ¯Ø§Ø± Ø§Ø¶Ø§ÙÙ‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… ====\n",
        "            if entry_exit:\n",
        "                try:\n",
        "                    if 'entries' in entry_exit:\n",
        "                        for entry in entry_exit['entries']:\n",
        "                            # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ entry ÛŒÚ© dictionary Ø§Ø³Øª ÛŒØ§ ÛŒÚ© tuple\n",
        "                            if isinstance(entry, dict):\n",
        "                                orig_idx = entry.get('index')\n",
        "                                price = entry.get('price')\n",
        "                                if orig_idx is None or price is None:\n",
        "                                    continue\n",
        "                            elif isinstance(entry, tuple) and len(entry) >= 2:\n",
        "                                orig_idx = entry[0]\n",
        "                                price = entry[1]\n",
        "                            else:\n",
        "                                continue\n",
        "\n",
        "                            # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø¹ØªØ¨Ø± Ø¨ÙˆØ¯Ù† Ù…Ù‚Ø§Ø¯ÛŒØ±\n",
        "                            if not isinstance(orig_idx, (int, np.integer)) or np.isnan(price) or not np.isfinite(price):\n",
        "                                continue\n",
        "\n",
        "                            # Ø¨Ø±Ø±Ø³ÛŒ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… Ú©Ù‡ Ø¢ÛŒØ§ Ø´Ø§Ø®Øµ Ø¯Ø± Ù…Ø­Ø¯ÙˆØ¯Ù‡ plot_df Ø§Ø³Øª\n",
        "                            if orig_idx >= len(df) - len(plot_df) and orig_idx < len(df):\n",
        "                                # Ù†Ú¯Ø§Ø´Øª Ø´Ø§Ø®Øµ Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ Ø¨Ù‡ plot_df\n",
        "                                idx = orig_idx - (len(df) - len(plot_df))\n",
        "\n",
        "                                # Ø±Ø³Ù… Ù†Ù‚Ø·Ù‡ ÙˆØ±ÙˆØ¯\n",
        "                                ax.scatter(idx, price, color='blue', marker='o', s=100, alpha=0.8)\n",
        "                                ax.annotate('ÙˆØ±ÙˆØ¯', xy=(idx, price),\n",
        "                                            xytext=(idx, price * 1.02),\n",
        "                                            color='blue', fontsize=9, ha='center',\n",
        "                                            arrowprops=dict(facecolor='blue', shrink=0.05, alpha=0.6))\n",
        "\n",
        "                    # Ø±Ø³Ù… Ø­Ø¯ Ø¶Ø±Ø±\n",
        "                    if 'stop_loss' in entry_exit and not np.isnan(entry_exit['stop_loss']) and np.isfinite(\n",
        "                            entry_exit['stop_loss']):\n",
        "                        stop_loss = entry_exit['stop_loss']\n",
        "                        ax.axhline(y=stop_loss, color='red', linestyle='--', alpha=0.8, linewidth=1)\n",
        "                        ax.text(len(plot_df) - 10, stop_loss, 'Ø­Ø¯ Ø¶Ø±Ø±', color='red', fontsize=9, ha='right')\n",
        "\n",
        "                    # Ø±Ø³Ù… Ø­Ø¯Ù‡Ø§ÛŒ Ø³ÙˆØ¯\n",
        "                    if 'take_profit' in entry_exit:\n",
        "                        if isinstance(entry_exit['take_profit'], list):\n",
        "                            # Ø§Ú¯Ø± Ú†Ù†Ø¯ÛŒÙ† Ø­Ø¯ Ø³ÙˆØ¯ Ø¯Ø§Ø±ÛŒÙ…\n",
        "                            for i, tp in enumerate(entry_exit['take_profit'], 1):\n",
        "                                if not np.isnan(tp) and np.isfinite(tp):\n",
        "                                    ax.axhline(y=tp, color='green', linestyle='--', alpha=0.8, linewidth=1)\n",
        "                                    ax.text(len(plot_df) - 10, tp, f'Ø­Ø¯ Ø³ÙˆØ¯ {i}', color='green', fontsize=9, ha='right')\n",
        "                        else:\n",
        "                            # Ø§Ú¯Ø± ÛŒÚ© Ø­Ø¯ Ø³ÙˆØ¯ Ø¯Ø§Ø±ÛŒÙ…\n",
        "                            tp = entry_exit['take_profit']\n",
        "                            if not np.isnan(tp) and np.isfinite(tp):\n",
        "                                ax.axhline(y=tp, color='green', linestyle='--', alpha=0.8, linewidth=1)\n",
        "                                ax.text(len(plot_df) - 10, tp, 'Ø­Ø¯ Ø³ÙˆØ¯', color='green', fontsize=9, ha='right')\n",
        "\n",
        "                    if 'exits' in entry_exit:\n",
        "                        for exit in entry_exit['exits']:\n",
        "                            # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ exit ÛŒÚ© dictionary Ø§Ø³Øª ÛŒØ§ ÛŒÚ© tuple\n",
        "                            if isinstance(exit, dict):\n",
        "                                orig_idx = exit.get('index')\n",
        "                                if orig_idx is None:\n",
        "                                    continue\n",
        "                            elif isinstance(exit, tuple) and len(exit) >= 1:\n",
        "                                orig_idx = exit[0]\n",
        "                            else:\n",
        "                                continue\n",
        "\n",
        "                            # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø¹ØªØ¨Ø± Ø¨ÙˆØ¯Ù† Ù…Ù‚Ø¯Ø§Ø±\n",
        "                            if not isinstance(orig_idx, (int, np.integer)):\n",
        "                                continue\n",
        "\n",
        "                            # Ø¨Ø±Ø±Ø³ÛŒ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… Ú©Ù‡ Ø¢ÛŒØ§ Ø´Ø§Ø®Øµ Ø¯Ø± Ù…Ø­Ø¯ÙˆØ¯Ù‡ plot_df Ø§Ø³Øª\n",
        "                            if orig_idx >= len(df) - len(plot_df) and orig_idx < len(df):\n",
        "                                # Ù†Ú¯Ø§Ø´Øª Ø´Ø§Ø®Øµ Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ Ø¨Ù‡ plot_df\n",
        "                                idx = orig_idx - (len(df) - len(plot_df))\n",
        "\n",
        "                                # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ idx Ø¯Ø± Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª\n",
        "                                if 0 <= idx < len(plot_df):\n",
        "                                    high_val = plot_df['high'].iloc[idx]\n",
        "                                    if not np.isnan(high_val) and np.isfinite(high_val):\n",
        "                                        ax.annotate('Ø®Ø±ÙˆØ¬', xy=(idx, high_val * 1.005),\n",
        "                                                    xytext=(idx, high_val * 1.015),\n",
        "                                                    color='#e36f7a', fontsize=9, ha='center')\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"Ø®Ø·Ø§ Ø¯Ø± Ø±Ø³Ù… Ù†Ù‚Ø§Ø· ÙˆØ±ÙˆØ¯ Ùˆ Ø®Ø±ÙˆØ¬: {e}\")\n",
        "\n",
        "            # Ø§ÙØ²ÙˆØ¯Ù† Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø¨Ù‡ Ù†Ù…ÙˆØ¯Ø§Ø±\n",
        "            if strategies:\n",
        "                try:\n",
        "                    # Ø¬Ø§Ø¨Ø¬Ø§ Ú©Ø±Ø¯Ù† Ù…ØªÙ† Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø¨Ù‡ Ø¨Ø§Ù„Ø§ Ø³Ù…Øª Ú†Ù¾ Ù†Ù…ÙˆØ¯Ø§Ø±\n",
        "                    info_text = \"\"\n",
        "                    total_strength = 0\n",
        "                    count = 0\n",
        "\n",
        "                    for name, strength in strategies.items():\n",
        "                        # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø¹ØªØ¨Ø± Ø¨ÙˆØ¯Ù† Ù…Ù‚Ø¯Ø§Ø±\n",
        "                        if not isinstance(strength, (int, float)) or np.isnan(strength) or not np.isfinite(strength):\n",
        "                            continue\n",
        "\n",
        "                        info_text += f\"{name}: {strength:.0f}%\\n\"\n",
        "                        total_strength += strength\n",
        "                        count += 1\n",
        "\n",
        "                    if count > 0:\n",
        "                        avg_strength = total_strength / count\n",
        "                        info_text += f\"\\nØ§Ø·Ù…ÛŒÙ†Ø§Ù† Ú©Ù„ÛŒ: {avg_strength:.0f}%\"\n",
        "\n",
        "                    # Ù†Ù…Ø§ÛŒØ´ Ù…ØªÙ† Ø¯Ø± Ø³Ù…Øª Ú†Ù¾ Ø¨Ø§Ù„Ø§\n",
        "                    if info_text:  # ÙÙ‚Ø· Ø§Ú¯Ø± Ù…ØªÙ† Ø¯Ø§Ø±ÛŒÙ…\n",
        "                        plt.figtext(0.02, 0.95, info_text, fontsize=9, bbox=dict(facecolor='white', alpha=0.7))\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"Ø®Ø·Ø§ Ø¯Ø± Ù†Ù…Ø§ÛŒØ´ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ: {e}\")\n",
        "\n",
        "            # Ø°Ø®ÛŒØ±Ù‡ Ù†Ù…ÙˆØ¯Ø§Ø±\n",
        "            chart_filename = f\"{BASE_DIR}/charts/{symbol.replace('/', '_')}_{timeframe}_{int(time.time())}.png\"\n",
        "            plt.savefig(chart_filename, dpi=180, bbox_inches='tight')\n",
        "            plt.close(fig)\n",
        "\n",
        "            # ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ ØµØ±ÛŒØ­ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø²Ø¨Ø§Ù„Ù‡ Ùˆ Ø¢Ø²Ø§Ø¯Ø³Ø§Ø²ÛŒ Ø­Ø§ÙØ¸Ù‡\n",
        "            plt.close('all')\n",
        "            gc.collect()\n",
        "\n",
        "            return chart_filename\n",
        "\n",
        "        except Exception as e:\n",
        "            # Ø¯Ø± ØµÙˆØ±Øª Ù‡Ø± Ú¯ÙˆÙ†Ù‡ Ø®Ø·Ø§ØŒ ÛŒÚ© Ù†Ù…ÙˆØ¯Ø§Ø± Ø³Ø§Ø¯Ù‡ Ø¨Ø¯ÙˆÙ† Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§ Ø¨Ø±Ù…ÛŒÚ¯Ø±Ø¯Ø§Ù†ÛŒÙ…\n",
        "            logger.error(f\"Ø®Ø·Ø§ Ø¯Ø± Ø±Ø³Ù… Ù†Ù…ÙˆØ¯Ø§Ø± {symbol} - {timeframe}: {e}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "\n",
        "            try:\n",
        "                # Ø±Ø³Ù… ÛŒÚ© Ù†Ù…ÙˆØ¯Ø§Ø± Ø³Ø§Ø¯Ù‡ Ø¨Ø§ Ù¾ÛŒØ§Ù… Ø®Ø·Ø§\n",
        "                chart_filename = f\"{BASE_DIR}/charts/{symbol.replace('/', '_')}_{timeframe}_{int(time.time())}_error.png\"\n",
        "                plt.figure(figsize=(10, 6))\n",
        "                plt.title(f\"{symbol} - {timeframe} - Ø®Ø·Ø§ Ø¯Ø± Ø±Ø³Ù… Ù†Ù…ÙˆØ¯Ø§Ø±\")\n",
        "                plt.text(0.5, 0.5, f\"Ø®Ø·Ø§ Ø¯Ø± Ø±Ø³Ù… Ù†Ù…ÙˆØ¯Ø§Ø±: {str(e)}\",\n",
        "                         horizontalalignment='center', verticalalignment='center',\n",
        "                         transform=plt.gca().transAxes, fontsize=12)\n",
        "                plt.savefig(chart_filename, dpi=200)\n",
        "                plt.close()\n",
        "                return chart_filename\n",
        "            except:\n",
        "                # Ø§Ú¯Ø± Ø­ØªÛŒ Ø¯Ø± Ø³Ø§Ø®Øª Ù†Ù…ÙˆØ¯Ø§Ø± Ø®Ø·Ø§ Ù‡Ù… Ù…Ø´Ú©Ù„ Ø¯Ø§Ø´ØªÛŒÙ…ØŒ Ø¢Ø¯Ø±Ø³ Ø®Ø§Ù„ÛŒ Ø¨Ø±Ù…ÛŒÚ¯Ø±Ø¯Ø§Ù†ÛŒÙ…\n",
        "                return None\n",
        "\n",
        "    def analyze_market_structure(self, df, window=10, fib_factor=0.273):\n",
        "        \"\"\"\n",
        "        ØªØ­Ù„ÛŒÙ„ Ø³Ø§Ø®ØªØ§Ø± Ø¨Ø§Ø²Ø§Ø± Ùˆ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ú©Ø³Øªâ€ŒÙ‡Ø§ÛŒ Ø³Ø§Ø®ØªØ§Ø±ÛŒ Ùˆ Ø¨Ù„ÙˆÚ©â€ŒÙ‡Ø§ÛŒ Ø³ÙØ§Ø±Ø´\n",
        "\n",
        "        Args:\n",
        "            df: Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§\n",
        "            window: Ù¾Ù†Ø¬Ø±Ù‡ Ø¨Ø±Ø§ÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø³ÙˆÛŒÙ†Ú¯â€ŒÙ‡Ø§ÛŒ Ù‚ÛŒÙ…ØªÛŒ\n",
        "            fib_factor: Ø¶Ø±ÛŒØ¨ ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¨Ù„ÙˆÚ©â€ŒÙ‡Ø§ÛŒ Ø³ÙØ§Ø±Ø´ (0.273 Ø¨Ø±Ø§ÛŒ ØªØ·Ø§Ø¨Ù‚ Ø¨Ø§ TradingView)\n",
        "\n",
        "        Returns:\n",
        "            Ù†ØªØ§ÛŒØ¬ ØªØ­Ù„ÛŒÙ„ Ø³Ø§Ø®ØªØ§Ø± Ø¨Ø§Ø²Ø§Ø± Ùˆ Ø¨Ù„ÙˆÚ©â€ŒÙ‡Ø§ÛŒ Ø³ÙØ§Ø±Ø´\n",
        "        \"\"\"\n",
        "        # Ø§ÛŒØ¬Ø§Ø¯ ÛŒÚ© Ú©Ù¾ÛŒ Ø§Ø² Ø¯ÛŒØªØ§ÙØ±ÛŒÙ…\n",
        "        df_ms = df.copy()\n",
        "\n",
        "        # ÛŒØ§ÙØªÙ† Ù†Ù‚Ø§Ø· Ø³ÙˆÛŒÙ†Ú¯ (Ø§ÙˆØ¬ Ùˆ Ø­Ø¶ÛŒØ¶ Ù…Ø­Ù„ÛŒ)\n",
        "        df_ms['swing_high'] = df_ms['high'].rolling(window=window, center=True).apply(\n",
        "            lambda x: 1 if x.iloc[window // 2] == max(x) else 0, raw=False)\n",
        "        df_ms['swing_low'] = df_ms['low'].rolling(window=window, center=True).apply(\n",
        "            lambda x: 1 if x.iloc[window // 2] == min(x) else 0, raw=False)\n",
        "\n",
        "        # Ø³Ø§Ø®ØªØ§Ø±Ù‡Ø§ÛŒ Ø¨Ø§Ø²Ø§Ø± Ø±Ø§ Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…\n",
        "        highs = []  # Ù„ÛŒØ³Øª Ø§ÙˆØ¬â€ŒÙ‡Ø§\n",
        "        lows = []  # Ù„ÛŒØ³Øª Ø­Ø¶ÛŒØ¶â€ŒÙ‡Ø§\n",
        "\n",
        "        # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† ØªÙ…Ø§Ù… Ù†Ù‚Ø§Ø· Ø³ÙˆÛŒÙ†Ú¯ Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ø¢Ù†Ù‡Ø§\n",
        "        for i in range(window, len(df_ms) - window):\n",
        "            if df_ms['swing_high'].iloc[i] == 1:\n",
        "                # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ Ø§ÛŒÙ† Ø§ÙˆØ¬ Ù…Ø­Ù„ÛŒ Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª\n",
        "                is_valid = True\n",
        "                # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÙˆØ¬â€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ Ù†Ø²Ø¯ÛŒÚ© - Ø­Ø°Ù Ù†Ù‚Ø§Ø· Ø³ÙˆÛŒÙ†Ú¯ Ø®ÛŒÙ„ÛŒ Ù†Ø²Ø¯ÛŒÚ© Ø¨Ù‡ Ù‡Ù…\n",
        "                for h in reversed(highs):\n",
        "                    if abs(i - h[0]) < window and abs(df_ms['high'].iloc[i] - h[1]) / h[1] < 0.005:\n",
        "                        is_valid = False\n",
        "                        break\n",
        "\n",
        "                if is_valid:\n",
        "                    highs.append((i, df_ms['high'].iloc[i]))\n",
        "\n",
        "            if df_ms['swing_low'].iloc[i] == 1:\n",
        "                # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ Ø§ÛŒÙ† Ø­Ø¶ÛŒØ¶ Ù…Ø­Ù„ÛŒ Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª\n",
        "                is_valid = True\n",
        "                # Ø¨Ø±Ø±Ø³ÛŒ Ø­Ø¶ÛŒØ¶â€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ Ù†Ø²Ø¯ÛŒÚ©\n",
        "                for l in reversed(lows):\n",
        "                    if abs(i - l[0]) < window and abs(df_ms['low'].iloc[i] - l[1]) / l[1] < 0.005:\n",
        "                        is_valid = False\n",
        "                        break\n",
        "\n",
        "                if is_valid:\n",
        "                    lows.append((i, df_ms['low'].iloc[i]))\n",
        "\n",
        "        # Ø¨Ø±Ú†Ø³Ø¨â€ŒØ²Ù†ÛŒ Ø±ÙˆÙ†Ø¯ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø§ÙˆØ¬â€ŒÙ‡Ø§ Ùˆ Ø­Ø¶ÛŒØ¶â€ŒÙ‡Ø§\n",
        "        df_ms['higher_high'] = np.nan\n",
        "        df_ms['lower_low'] = np.nan\n",
        "        df_ms['higher_low'] = np.nan\n",
        "        df_ms['lower_high'] = np.nan\n",
        "        df_ms['msb_bullish'] = np.nan  # Ø´Ú©Ø³Øª Ø³Ø§Ø®ØªØ§Ø±ÛŒ ØµØ¹ÙˆØ¯ÛŒ\n",
        "        df_ms['msb_bearish'] = np.nan  # Ø´Ú©Ø³Øª Ø³Ø§Ø®ØªØ§Ø±ÛŒ Ù†Ø²ÙˆÙ„ÛŒ\n",
        "        df_ms['orderblock_bullish'] = np.nan  # Ø¨Ù„ÙˆÚ© Ø³ÙØ§Ø±Ø´ ØµØ¹ÙˆØ¯ÛŒ\n",
        "        df_ms['orderblock_bearish'] = np.nan  # Ø¨Ù„ÙˆÚ© Ø³ÙØ§Ø±Ø´ Ù†Ø²ÙˆÙ„ÛŒ\n",
        "\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ Ø±ÙˆÙ†Ø¯Ù‡Ø§\n",
        "        for i in range(2, len(highs)):\n",
        "            # Ø§ÙˆØ¬ Ø¨Ø§Ù„Ø§ØªØ± (Higher High)\n",
        "            if highs[i][1] > highs[i - 1][1]:\n",
        "                df_ms['higher_high'].iloc[highs[i][0]] = highs[i][1]\n",
        "            # Ø§ÙˆØ¬ Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ± (Lower High)\n",
        "            else:\n",
        "                df_ms['lower_high'].iloc[highs[i][0]] = highs[i][1]\n",
        "\n",
        "        for i in range(2, len(lows)):\n",
        "            # Ø­Ø¶ÛŒØ¶ Ø¨Ø§Ù„Ø§ØªØ± (Higher Low)\n",
        "            if lows[i][1] > lows[i - 1][1]:\n",
        "                df_ms['higher_low'].iloc[lows[i][0]] = lows[i][1]\n",
        "            # Ø­Ø¶ÛŒØ¶ Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ± (Lower Low)\n",
        "            else:\n",
        "                df_ms['lower_low'].iloc[lows[i][0]] = lows[i][1]\n",
        "\n",
        "        # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ú©Ø³Øª Ø³Ø§Ø®ØªØ§Ø± Ø¨Ø§Ø²Ø§Ø± (Market Structure Break) - ØªØºÛŒÛŒØ± Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… Ù…Ø·Ø§Ø¨Ù‚ Ø¨Ø§ TradingView\n",
        "        msb_bullish = []\n",
        "        msb_bearish = []\n",
        "\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ Ø§Ù„Ú¯ÙˆÛŒ MSB ØµØ¹ÙˆØ¯ÛŒ Ùˆ Ù†Ø²ÙˆÙ„ÛŒ\n",
        "        for i in range(2, len(highs)):\n",
        "            # Ø´Ú©Ø³Øª ØµØ¹ÙˆØ¯ÛŒ: Ø§ÙˆØ¬ Ø¬Ø¯ÛŒØ¯ Ø¨Ø§Ù„Ø§ØªØ± Ø§Ø² Ø§ÙˆØ¬ Ù‚Ø¨Ù„ÛŒ + ÛŒÚ© Ø¯Ø±Ù‡ Ø¯Ø± Ø¨ÛŒÙ† Ø¢Ù†Ù‡Ø§\n",
        "            if highs[i][1] > highs[i - 1][1]:\n",
        "                # Ø¨Ø±Ø±Ø³ÛŒ Ø¢ÛŒØ§ ÛŒÚ© Ø¯Ø±Ù‡ Ø¨ÛŒÙ† Ø§ÛŒÙ† Ø¯Ùˆ Ø§ÙˆØ¬ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯\n",
        "                for l in lows:\n",
        "                    if highs[i - 1][0] < l[0] < highs[i][0]:\n",
        "                        df_ms['msb_bullish'].iloc[highs[i][0]] = df_ms['high'].iloc[highs[i][0]]\n",
        "                        msb_bullish.append((highs[i][0], df_ms['high'].iloc[highs[i][0]]))\n",
        "                        break\n",
        "\n",
        "        for i in range(2, len(lows)):\n",
        "            # Ø´Ú©Ø³Øª Ù†Ø²ÙˆÙ„ÛŒ: Ø­Ø¶ÛŒØ¶ Ø¬Ø¯ÛŒØ¯ Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ± Ø§Ø² Ø­Ø¶ÛŒØ¶ Ù‚Ø¨Ù„ÛŒ + ÛŒÚ© Ø§ÙˆØ¬ Ø¯Ø± Ø¨ÛŒÙ† Ø¢Ù†Ù‡Ø§\n",
        "            if lows[i][1] < lows[i - 1][1]:\n",
        "                # Ø¨Ø±Ø±Ø³ÛŒ Ø¢ÛŒØ§ ÛŒÚ© Ø§ÙˆØ¬ Ø¨ÛŒÙ† Ø§ÛŒÙ† Ø¯Ùˆ Ø­Ø¶ÛŒØ¶ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯\n",
        "                for h in highs:\n",
        "                    if lows[i - 1][0] < h[0] < lows[i][0]:\n",
        "                        df_ms['msb_bearish'].iloc[lows[i][0]] = df_ms['low'].iloc[lows[i][0]]\n",
        "                        msb_bearish.append((lows[i][0], df_ms['low'].iloc[lows[i][0]]))\n",
        "                        break\n",
        "\n",
        "        # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø¨Ù„ÙˆÚ©â€ŒÙ‡Ø§ÛŒ Ø³ÙØ§Ø±Ø´ (Order Blocks) Ø¨Ø§ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡\n",
        "        orderblock_bullish = []\n",
        "        orderblock_bearish = []\n",
        "\n",
        "        # ÛŒØ§ÙØªÙ† Ø¨Ù„ÙˆÚ© Ø³ÙØ§Ø±Ø´ ØµØ¹ÙˆØ¯ÛŒ (Ù‚Ø¨Ù„ Ø§Ø² MSB Ù†Ø²ÙˆÙ„ÛŒ)\n",
        "        for msb_idx, _ in msb_bearish:\n",
        "            # Ø¨Ø±Ø±Ø³ÛŒ Ûµ Ú©Ù†Ø¯Ù„ Ù‚Ø¨Ù„ Ø§Ø² MSB Ø¨Ø±Ø§ÛŒ ÛŒØ§ÙØªÙ† Ø¨Ù‡ØªØ±ÛŒÙ† Ú©Ù†Ø¯Ù„ ØµØ¹ÙˆØ¯ÛŒ\n",
        "            ob_idx = max(0, msb_idx - 5)\n",
        "            best_ob_idx = -1\n",
        "            max_body_size = 0\n",
        "\n",
        "            for i in range(max(0, msb_idx - 5), msb_idx):\n",
        "                # Ø§Ú¯Ø± Ú©Ù†Ø¯Ù„ ØµØ¹ÙˆØ¯ÛŒ Ø§Ø³Øª (Ø¨Ø³ØªÙ‡ Ø´Ø¯Ù† Ø¨Ø§Ù„Ø§ØªØ± Ø§Ø² Ù‚ÛŒÙ…Øª Ø¨Ø§Ø² Ø´Ø¯Ù†)\n",
        "                if df_ms['close'].iloc[i] > df_ms['open'].iloc[i]:\n",
        "                    body_size = abs(df_ms['close'].iloc[i] - df_ms['open'].iloc[i])\n",
        "                    if body_size > max_body_size:\n",
        "                        max_body_size = body_size\n",
        "                        best_ob_idx = i\n",
        "\n",
        "            if best_ob_idx != -1:\n",
        "                ob_high = df_ms['high'].iloc[best_ob_idx]\n",
        "                ob_low = df_ms['low'].iloc[best_ob_idx]\n",
        "                # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†Ø§Ø­ÛŒÙ‡ Ù…ÛŒØªØ³ÙˆØ¨Ùˆ (mitsubo zone) Ú©Ù‡ Ø¯Ø± TradingView Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯\n",
        "                mitsubo_level = ob_low + (ob_high - ob_low) * fib_factor\n",
        "\n",
        "                orderblock_bullish.append({\n",
        "                    'index': best_ob_idx,\n",
        "                    'high': ob_high,\n",
        "                    'low': ob_low,\n",
        "                    'mitsubo': mitsubo_level,\n",
        "                    'body_size': max_body_size\n",
        "                })\n",
        "                df_ms['orderblock_bullish'].iloc[best_ob_idx] = ob_low\n",
        "\n",
        "        # ÛŒØ§ÙØªÙ† Ø¨Ù„ÙˆÚ© Ø³ÙØ§Ø±Ø´ Ù†Ø²ÙˆÙ„ÛŒ (Ù‚Ø¨Ù„ Ø§Ø² MSB ØµØ¹ÙˆØ¯ÛŒ)\n",
        "        for msb_idx, _ in msb_bullish:\n",
        "            # Ø¨Ø±Ø±Ø³ÛŒ Ûµ Ú©Ù†Ø¯Ù„ Ù‚Ø¨Ù„ Ø§Ø² MSB Ø¨Ø±Ø§ÛŒ ÛŒØ§ÙØªÙ† Ø¨Ù‡ØªØ±ÛŒÙ† Ú©Ù†Ø¯Ù„ Ù†Ø²ÙˆÙ„ÛŒ\n",
        "            ob_idx = max(0, msb_idx - 5)\n",
        "            best_ob_idx = -1\n",
        "            max_body_size = 0\n",
        "\n",
        "            for i in range(max(0, msb_idx - 5), msb_idx):\n",
        "                # Ø§Ú¯Ø± Ú©Ù†Ø¯Ù„ Ù†Ø²ÙˆÙ„ÛŒ Ø§Ø³Øª (Ø¨Ø³ØªÙ‡ Ø´Ø¯Ù† Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ± Ø§Ø² Ù‚ÛŒÙ…Øª Ø¨Ø§Ø² Ø´Ø¯Ù†)\n",
        "                if df_ms['close'].iloc[i] < df_ms['open'].iloc[i]:\n",
        "                    body_size = abs(df_ms['close'].iloc[i] - df_ms['open'].iloc[i])\n",
        "                    if body_size > max_body_size:\n",
        "                        max_body_size = body_size\n",
        "                        best_ob_idx = i\n",
        "\n",
        "            if best_ob_idx != -1:\n",
        "                ob_high = df_ms['high'].iloc[best_ob_idx]\n",
        "                ob_low = df_ms['low'].iloc[best_ob_idx]\n",
        "                # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†Ø§Ø­ÛŒÙ‡ Ù…ÛŒØªØ³ÙˆØ¨Ùˆ (mitsubo zone) Ú©Ù‡ Ø¯Ø± TradingView Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯\n",
        "                mitsubo_level = ob_high - (ob_high - ob_low) * fib_factor\n",
        "\n",
        "                orderblock_bearish.append({\n",
        "                    'index': best_ob_idx,\n",
        "                    'high': ob_high,\n",
        "                    'low': ob_low,\n",
        "                    'mitsubo': mitsubo_level,\n",
        "                    'body_size': max_body_size\n",
        "                })\n",
        "                df_ms['orderblock_bearish'].iloc[best_ob_idx] = ob_high\n",
        "\n",
        "        # ØªØ­Ù„ÛŒÙ„ ÙˆØ¶Ø¹ÛŒØª Ú©Ù„ÛŒ Ø³Ø§Ø®ØªØ§Ø± Ø¨Ø§Ø²Ø§Ø±\n",
        "        msb_status = 'Ø±ÙˆÙ†Ø¯ Ù†Ø§Ù…Ø´Ø®Øµ'\n",
        "        msb_strength = 0\n",
        "\n",
        "        # Ø¢Ø®Ø±ÛŒÙ† Ø´Ú©Ø³Øªâ€ŒÙ‡Ø§ÛŒ Ø³Ø§Ø®ØªØ§Ø±ÛŒ\n",
        "        last_bullish_msb = None if not msb_bullish else msb_bullish[-1]\n",
        "        last_bearish_msb = None if not msb_bearish else msb_bearish[-1]\n",
        "\n",
        "        # Ø§Ú¯Ø± Ø§Ø®ÛŒØ±Ø§Ù‹ ÛŒÚ© Ø´Ú©Ø³Øª Ø³Ø§Ø®ØªØ§Ø±ÛŒ ØµØ¹ÙˆØ¯ÛŒ Ø¯Ø§Ø´ØªÙ‡â€ŒØ§ÛŒÙ…\n",
        "        if last_bullish_msb and (not last_bearish_msb or last_bullish_msb[0] > last_bearish_msb[0]):\n",
        "            # Ú†Ú© Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… Ø¢ÛŒØ§ Ù‚ÛŒÙ…Øª Ø¨Ø§Ù„Ø§ÛŒ Ø¢Ø®Ø±ÛŒÙ† Ø§ÙˆØ¬ Ø´Ú©Ø³ØªÙ‡ Ø´Ø¯Ù‡ Ø§Ø³Øª\n",
        "            if df_ms['close'].iloc[-1] > last_bullish_msb[1]:\n",
        "                msb_status = 'ØµØ¹ÙˆØ¯ÛŒ - ØªØ£ÛŒÛŒØ¯ Ø´Ø¯Ù‡'\n",
        "                msb_strength = 90\n",
        "            else:\n",
        "                msb_status = 'ØµØ¹ÙˆØ¯ÛŒ - Ø¯Ø± Ø§Ù†ØªØ¸Ø§Ø± ØªØ£ÛŒÛŒØ¯'\n",
        "                msb_strength = 70\n",
        "\n",
        "        # Ø§Ú¯Ø± Ø§Ø®ÛŒØ±Ø§Ù‹ ÛŒÚ© Ø´Ú©Ø³Øª Ø³Ø§Ø®ØªØ§Ø±ÛŒ Ù†Ø²ÙˆÙ„ÛŒ Ø¯Ø§Ø´ØªÙ‡â€ŒØ§ÛŒÙ…\n",
        "        elif last_bearish_msb and (not last_bullish_msb or last_bearish_msb[0] > last_bullish_msb[0]):\n",
        "            # Ú†Ú© Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… Ø¢ÛŒØ§ Ù‚ÛŒÙ…Øª Ø²ÛŒØ± Ø¢Ø®Ø±ÛŒÙ† Ø­Ø¶ÛŒØ¶ Ø´Ú©Ø³ØªÙ‡ Ø´Ø¯Ù‡ Ø§Ø³Øª\n",
        "            if df_ms['close'].iloc[-1] < last_bearish_msb[1]:\n",
        "                msb_status = 'Ù†Ø²ÙˆÙ„ÛŒ - ØªØ£ÛŒÛŒØ¯ Ø´Ø¯Ù‡'\n",
        "                msb_strength = 90\n",
        "            else:\n",
        "                msb_status = 'Ù†Ø²ÙˆÙ„ÛŒ - Ø¯Ø± Ø§Ù†ØªØ¸Ø§Ø± ØªØ£ÛŒÛŒØ¯'\n",
        "                msb_strength = 70\n",
        "\n",
        "        # Ø´Ù…Ø§Ø±Ø´ ØªØ¹Ø¯Ø§Ø¯ Ø³Ø§Ø®ØªØ§Ø±Ù‡Ø§ÛŒ Ø¨Ø§Ø²Ø§Ø± Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø±ÙˆÙ†Ø¯\n",
        "        hh_count = df_ms['higher_high'].count()\n",
        "        lh_count = df_ms['lower_high'].count()\n",
        "        hl_count = df_ms['higher_low'].count()\n",
        "        ll_count = df_ms['lower_low'].count()\n",
        "\n",
        "        trend_score = (hh_count + hl_count - lh_count - ll_count) / max(1,\n",
        "                                                                        hh_count + hl_count + lh_count + ll_count) * 100\n",
        "\n",
        "        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù†Ù‚Ø§Ø· ÙˆØ±ÙˆØ¯ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¨Ù„ÙˆÚ©â€ŒÙ‡Ø§ÛŒ Ø³ÙØ§Ø±Ø´\n",
        "        entry_points = []\n",
        "        current_price = df_ms['close'].iloc[-1]\n",
        "\n",
        "        # Ø¨Ø±Ø§ÛŒ Ø¨Ù„ÙˆÚ©â€ŒÙ‡Ø§ÛŒ Ø³ÙØ§Ø±Ø´ ØµØ¹ÙˆØ¯ÛŒ\n",
        "        for ob in orderblock_bullish:\n",
        "            # Ø§Ú¯Ø± Ù‚ÛŒÙ…Øª Ø¯Ø± Ù†Ø²Ø¯ÛŒÚ©ÛŒ Ø¨Ù„ÙˆÚ© Ø³ÙØ§Ø±Ø´ ØµØ¹ÙˆØ¯ÛŒ Ø§Ø³Øª\n",
        "            if current_price <= ob['high'] * 1.05 and current_price >= ob['low'] * 0.95:\n",
        "                # ÙˆØ±ÙˆØ¯: Ù†Ø²Ø¯ÛŒÚ© Ø¨Ù‡ Ø³Ø·Ø­ Ù…ÛŒØªØ³ÙˆØ¨Ùˆ\n",
        "                entry_price = ob['mitsubo']\n",
        "                # Ø­Ø¯ Ø¶Ø±Ø±: Ú©Ù…ÛŒ Ø²ÛŒØ± Ú©Ù Ø¨Ù„ÙˆÚ© Ø³ÙØ§Ø±Ø´\n",
        "                stop_loss = ob['low'] * 0.995\n",
        "                # Ø­Ø¯ Ø³ÙˆØ¯: Ø¨Ø±Ø§Ø³Ø§Ø³ Ø³Ø§Ø®ØªØ§Ø± Ø¨Ø§Ø²Ø§Ø± (ÙØ§ØµÙ„Ù‡ ØªØ§ Ø¨Ù„ÙˆÚ© Ø¨Ø¹Ø¯ÛŒ ÛŒØ§ Ø´Ú©Ø³Øª Ø³Ø§Ø®ØªØ§Ø±ÛŒ Ø¨Ø¹Ø¯ÛŒ)\n",
        "                risk = entry_price - stop_loss\n",
        "                take_profit1 = entry_price + risk  # 1:1\n",
        "                take_profit2 = entry_price + risk * 2  # 1:2\n",
        "                take_profit3 = entry_price + risk * 3  # 1:3\n",
        "\n",
        "                entry_points.append({\n",
        "                    'type': 'conditional_long',\n",
        "                    'index': ob['index'],\n",
        "                    'price': entry_price,\n",
        "                    'stop_loss': stop_loss,\n",
        "                    'take_profit1': take_profit1,\n",
        "                    'take_profit2': take_profit2,\n",
        "                    'take_profit3': take_profit3,\n",
        "                    'condition': f'Ù‚ÛŒÙ…Øª Ø¨Ù‡ {entry_price:.6f} ÛŒØ§ Ú©Ù…ØªØ± Ø¨Ø±Ø³Ø¯',\n",
        "                    'strength': 85\n",
        "                })\n",
        "\n",
        "        # Ø¨Ø±Ø§ÛŒ Ø¨Ù„ÙˆÚ©â€ŒÙ‡Ø§ÛŒ Ø³ÙØ§Ø±Ø´ Ù†Ø²ÙˆÙ„ÛŒ\n",
        "        for ob in orderblock_bearish:\n",
        "            # Ø§Ú¯Ø± Ù‚ÛŒÙ…Øª Ø¯Ø± Ù†Ø²Ø¯ÛŒÚ©ÛŒ Ø¨Ù„ÙˆÚ© Ø³ÙØ§Ø±Ø´ Ù†Ø²ÙˆÙ„ÛŒ Ø§Ø³Øª\n",
        "            if current_price >= ob['low'] * 0.95 and current_price <= ob['high'] * 1.05:\n",
        "                # ÙˆØ±ÙˆØ¯: Ù†Ø²Ø¯ÛŒÚ© Ø¨Ù‡ Ø³Ø·Ø­ Ù…ÛŒØªØ³ÙˆØ¨Ùˆ\n",
        "                entry_price = ob['mitsubo']\n",
        "                # Ø­Ø¯ Ø¶Ø±Ø±: Ú©Ù…ÛŒ Ø¨Ø§Ù„Ø§ÛŒ Ø³Ù‚Ù Ø¨Ù„ÙˆÚ© Ø³ÙØ§Ø±Ø´\n",
        "                stop_loss = ob['high'] * 1.005\n",
        "                # Ø­Ø¯ Ø³ÙˆØ¯: Ø¨Ø±Ø§Ø³Ø§Ø³ Ø³Ø§Ø®ØªØ§Ø± Ø¨Ø§Ø²Ø§Ø± (ÙØ§ØµÙ„Ù‡ ØªØ§ Ø¨Ù„ÙˆÚ© Ø¨Ø¹Ø¯ÛŒ ÛŒØ§ Ø´Ú©Ø³Øª Ø³Ø§Ø®ØªØ§Ø±ÛŒ Ø¨Ø¹Ø¯ÛŒ)\n",
        "                risk = stop_loss - entry_price\n",
        "                take_profit1 = entry_price - risk  # 1:1\n",
        "                take_profit2 = entry_price - risk * 2  # 1:2\n",
        "                take_profit3 = entry_price - risk * 3  # 1:3\n",
        "\n",
        "                entry_points.append({\n",
        "                    'type': 'conditional_short',\n",
        "                    'index': ob['index'],\n",
        "                    'price': entry_price,\n",
        "                    'stop_loss': stop_loss,\n",
        "                    'take_profit1': take_profit1,\n",
        "                    'take_profit2': take_profit2,\n",
        "                    'take_profit3': take_profit3,\n",
        "                    'condition': f'Ù‚ÛŒÙ…Øª Ø¨Ù‡ {entry_price:.6f} ÛŒØ§ Ø¨ÛŒØ´ØªØ± Ø¨Ø±Ø³Ø¯',\n",
        "                    'strength': 85\n",
        "                })\n",
        "\n",
        "        # Ù†ØªØ§ÛŒØ¬ Ù†Ù‡Ø§ÛŒÛŒ\n",
        "        result = {\n",
        "            'market_structure': {\n",
        "                'status': msb_status,\n",
        "                'strength': msb_strength,\n",
        "                'trend_score': trend_score,\n",
        "                'higher_highs': hh_count,\n",
        "                'lower_highs': lh_count,\n",
        "                'higher_lows': hl_count,\n",
        "                'lower_lows': ll_count\n",
        "            },\n",
        "            'msb_bullish': msb_bullish,\n",
        "            'msb_bearish': msb_bearish,\n",
        "            'orderblock_bullish': orderblock_bullish,\n",
        "            'orderblock_bearish': orderblock_bearish,\n",
        "            'entry_points': entry_points,\n",
        "            'dataframe': df_ms\n",
        "        }\n",
        "\n",
        "        return result\n",
        "\n",
        "    def analyze_buying_selling_pressure(self, df, volume_threshold=1.5, price_threshold=1.0):\n",
        "        \"\"\"\n",
        "        ØªØ­Ù„ÛŒÙ„ ÙØ´Ø§Ø± Ø®Ø±ÛŒØ¯ ÛŒØ§ ÙØ±ÙˆØ´ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø­Ø¬Ù… Ùˆ Ù‚ÛŒÙ…Øª\n",
        "\n",
        "        Args:\n",
        "            df: Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§\n",
        "            volume_threshold: Ø¢Ø³ØªØ§Ù†Ù‡ Ø§ÙØ²Ø§ÛŒØ´ Ø­Ø¬Ù… Ù†Ø³Ø¨Øª Ø¨Ù‡ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†\n",
        "            price_threshold: Ø¢Ø³ØªØ§Ù†Ù‡ ØªØºÛŒÛŒØ±Ø§Øª Ù‚ÛŒÙ…Øª\n",
        "\n",
        "        Returns:\n",
        "            Ù†ØªØ§ÛŒØ¬ ØªØ­Ù„ÛŒÙ„ ÙØ´Ø§Ø± Ø®Ø±ÛŒØ¯/ÙØ±ÙˆØ´\n",
        "        \"\"\"\n",
        "        # Ú©Ù¾ÛŒ Ø§Ø² Ø¯ÛŒØªØ§ÙØ±ÛŒÙ…\n",
        "        df_pressure = df.copy()\n",
        "\n",
        "        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø­Ø¬Ù… Ø¨Ø±Ø§ÛŒ Ù…Ù‚Ø§ÛŒØ³Ù‡\n",
        "        df_pressure['volume_sma20'] = df_pressure['volume'].rolling(window=20).mean()\n",
        "        df_pressure['volume_ratio'] = df_pressure['volume'] / df_pressure['volume_sma20']\n",
        "\n",
        "        # Ù…Ø­Ø§Ø³Ø¨Ù‡ ØªØºÛŒÛŒØ±Ø§Øª Ù‚ÛŒÙ…Øª\n",
        "        df_pressure['price_change_pct'] = df_pressure['close'].pct_change() * 100\n",
        "\n",
        "        # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ú©Ù†Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¨Ø§ ÙØ´Ø§Ø± Ø®Ø±ÛŒØ¯\n",
        "        df_pressure['buying_pressure'] = ((df_pressure['close'] > df_pressure['open']) &\n",
        "                                          (df_pressure['volume_ratio'] > volume_threshold) &\n",
        "                                          (df_pressure['price_change_pct'] > price_threshold))\n",
        "\n",
        "        # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ú©Ù†Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¨Ø§ ÙØ´Ø§Ø± ÙØ±ÙˆØ´\n",
        "        df_pressure['selling_pressure'] = ((df_pressure['close'] < df_pressure['open']) &\n",
        "                                           (df_pressure['volume_ratio'] > volume_threshold) &\n",
        "                                           (df_pressure['price_change_pct'] < -price_threshold))\n",
        "\n",
        "        # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ ÙØ´Ø§Ø± Ø®Ø±ÛŒØ¯ Ù…ØªÙˆØ§Ù„ÛŒ\n",
        "        consecutive_buying = 0\n",
        "        buying_patterns = []\n",
        "\n",
        "        for i in range(1, len(df_pressure)):\n",
        "            if df_pressure['buying_pressure'].iloc[i]:\n",
        "                consecutive_buying += 1\n",
        "\n",
        "                # Ø§Ú¯Ø± Ø­Ø¯Ø§Ù‚Ù„ Ø¯Ùˆ Ú©Ù†Ø¯Ù„ ÙØ´Ø§Ø± Ø®Ø±ÛŒØ¯ Ù…ØªÙˆØ§Ù„ÛŒ Ø¯Ø§Ø´ØªÛŒÙ…ØŒ Ø§Ù„Ú¯Ùˆ Ø±Ø§ Ø«Ø¨Øª Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…\n",
        "                if consecutive_buying >= 2:\n",
        "                    buying_patterns.append({\n",
        "                        'index': i,\n",
        "                        'strength': min(100, consecutive_buying * 20 + df_pressure['volume_ratio'].iloc[i] * 10),\n",
        "                        'volume_ratio': df_pressure['volume_ratio'].iloc[i]\n",
        "                    })\n",
        "            else:\n",
        "                consecutive_buying = 0\n",
        "\n",
        "        # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ ÙØ´Ø§Ø± ÙØ±ÙˆØ´ Ù…ØªÙˆØ§Ù„ÛŒ\n",
        "        consecutive_selling = 0\n",
        "        selling_patterns = []\n",
        "\n",
        "        for i in range(1, len(df_pressure)):\n",
        "            if df_pressure['selling_pressure'].iloc[i]:\n",
        "                consecutive_selling += 1\n",
        "\n",
        "                # Ø§Ú¯Ø± Ø­Ø¯Ø§Ù‚Ù„ Ø¯Ùˆ Ú©Ù†Ø¯Ù„ ÙØ´Ø§Ø± ÙØ±ÙˆØ´ Ù…ØªÙˆØ§Ù„ÛŒ Ø¯Ø§Ø´ØªÛŒÙ…ØŒ Ø§Ù„Ú¯Ùˆ Ø±Ø§ Ø«Ø¨Øª Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…\n",
        "                if consecutive_selling >= 2:\n",
        "                    selling_patterns.append({\n",
        "                        'index': i,\n",
        "                        'strength': min(100, consecutive_selling * 20 + df_pressure['volume_ratio'].iloc[i] * 10),\n",
        "                        'volume_ratio': df_pressure['volume_ratio'].iloc[i]\n",
        "                    })\n",
        "            else:\n",
        "                consecutive_selling = 0\n",
        "\n",
        "        # Ø¢Ù†Ø§Ù„ÛŒØ² ÙØ´Ø§Ø± Ø¯Ø± 10 Ú©Ù†Ø¯Ù„ Ø¢Ø®Ø±\n",
        "        recent_candles = 10\n",
        "        recent_buying = df_pressure['buying_pressure'].iloc[-recent_candles:].sum()\n",
        "        recent_selling = df_pressure['selling_pressure'].iloc[-recent_candles:].sum()\n",
        "\n",
        "        # ØªØ¹ÛŒÛŒÙ† ÙˆØ¶Ø¹ÛŒØª Ú©Ù„ÛŒ ÙØ´Ø§Ø± Ø¨Ø§Ø²Ø§Ø±\n",
        "        pressure_status = 'Ø®Ù†Ø«ÛŒ'\n",
        "        pressure_strength = 50\n",
        "\n",
        "        if recent_buying > recent_selling:\n",
        "            # ÙØ´Ø§Ø± Ø®Ø±ÛŒØ¯ Ø¨ÛŒØ´ØªØ± Ø§Ø³Øª\n",
        "            pressure_status = 'Ø®Ø±ÛŒØ¯'\n",
        "            pressure_strength = 50 + (recent_buying - recent_selling) * 10\n",
        "\n",
        "            # Ø¨Ø±Ø±Ø³ÛŒ ÛŒÚ© Ø§Ù„Ú¯ÙˆÛŒ Ù‚ÙˆÛŒâ€ŒØªØ±: ÙØ´Ø§Ø± Ø®Ø±ÛŒØ¯ Ø¨Ø¹Ø¯ Ø§Ø² ÛŒÚ© Ø±ÙˆÙ†Ø¯ Ù†Ø²ÙˆÙ„ÛŒ\n",
        "            if df_pressure['close'].iloc[-15:-5].mean() > df_pressure['close'].iloc[-5:].mean():\n",
        "                pressure_status = 'Ø®Ø±ÛŒØ¯ Ù¾Ø³ Ø§Ø² Ø§ØµÙ„Ø§Ø­'\n",
        "                pressure_strength += 10\n",
        "\n",
        "        elif recent_selling > recent_buying:\n",
        "            # ÙØ´Ø§Ø± ÙØ±ÙˆØ´ Ø¨ÛŒØ´ØªØ± Ø§Ø³Øª\n",
        "            pressure_status = 'ÙØ±ÙˆØ´'\n",
        "            pressure_strength = 50 + (recent_selling - recent_buying) * 10\n",
        "\n",
        "            # Ø¨Ø±Ø±Ø³ÛŒ ÛŒÚ© Ø§Ù„Ú¯ÙˆÛŒ Ù‚ÙˆÛŒâ€ŒØªØ±: ÙØ´Ø§Ø± ÙØ±ÙˆØ´ Ø¨Ø¹Ø¯ Ø§Ø² ÛŒÚ© Ø±ÙˆÙ†Ø¯ ØµØ¹ÙˆØ¯ÛŒ\n",
        "            if df_pressure['close'].iloc[-15:-5].mean() < df_pressure['close'].iloc[-5:].mean():\n",
        "                pressure_status = 'ÙØ±ÙˆØ´ Ù¾Ø³ Ø§Ø² ØµØ¹ÙˆØ¯'\n",
        "                pressure_strength += 10\n",
        "\n",
        "        # Ù†ØªØ§ÛŒØ¬ Ù†Ù‡Ø§ÛŒÛŒ\n",
        "        result = {\n",
        "            'pressure_status': pressure_status,\n",
        "            'pressure_strength': min(100, pressure_strength),\n",
        "            'recent_buying': recent_buying,\n",
        "            'recent_selling': recent_selling,\n",
        "            'buying_patterns': buying_patterns,\n",
        "            'selling_patterns': selling_patterns,\n",
        "            'dataframe': df_pressure\n",
        "        }\n",
        "\n",
        "        return result\n",
        "\n",
        "    def detect_whale_activity(self, df, volume_multiplier=3.0, price_impact=1.5):\n",
        "        \"\"\"\n",
        "        ØªØ´Ø®ÛŒØµ ÙØ¹Ø§Ù„ÛŒØª Ù†Ù‡Ù†Ú¯â€ŒÙ‡Ø§ Ø¨Ø¯ÙˆÙ† Ù†ÛŒØ§Ø² Ø¨Ù‡ API Ø®Ø§Ø±Ø¬ÛŒ Ø¨Ø§ ØªØ­Ù„ÛŒÙ„ Ø­Ø¬Ù… Ùˆ Ù‚ÛŒÙ…Øª\n",
        "\n",
        "        Args:\n",
        "            df: Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§\n",
        "            volume_multiplier: Ø¶Ø±ÛŒØ¨ Ø§ÙØ²Ø§ÛŒØ´ Ø­Ø¬Ù… Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ ÙØ¹Ø§Ù„ÛŒØª Ù†Ù‡Ù†Ú¯â€ŒÙ‡Ø§\n",
        "            price_impact: Ø­Ø¯Ø§Ù‚Ù„ ØªØ£Ø«ÛŒØ± Ù‚ÛŒÙ…ØªÛŒ Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ ÙØ¹Ø§Ù„ÛŒØª Ù†Ù‡Ù†Ú¯â€ŒÙ‡Ø§\n",
        "\n",
        "        Returns:\n",
        "            Ù†ØªØ§ÛŒØ¬ ØªØ´Ø®ÛŒØµ ÙØ¹Ø§Ù„ÛŒØª Ù†Ù‡Ù†Ú¯â€ŒÙ‡Ø§\n",
        "        \"\"\"\n",
        "        # Ú©Ù¾ÛŒ Ø§Ø² Ø¯ÛŒØªØ§ÙØ±ÛŒÙ…\n",
        "        df_whale = df.copy()\n",
        "\n",
        "        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² Ú©Ù‡ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¯Ø± Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… Ø§ØµÙ„ÛŒ Ù†Ø¨Ø§Ø´Ù†Ø¯\n",
        "        # Ù…Ø­Ø§Ø³Ø¨Ù‡ ØªØºÛŒÛŒØ±Ø§Øª Ù‚ÛŒÙ…Øª Ø¨Ù‡ ØµÙˆØ±Øª Ø¯Ø±ØµØ¯\n",
        "        df_whale['price_change_pct'] = df_whale['close'].pct_change() * 100\n",
        "\n",
        "        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†â€ŒÙ‡Ø§ÛŒ Ù…ØªØ­Ø±Ú© Ø­Ø¬Ù…\n",
        "        df_whale['volume_sma20'] = df_whale['volume'].rolling(window=20).mean()\n",
        "        df_whale['volume_sma50'] = df_whale['volume'].rolling(window=50).mean()\n",
        "\n",
        "        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù†Ø­Ø±Ø§Ù Ù…Ø¹ÛŒØ§Ø± Ø­Ø¬Ù… Ùˆ Ù‚ÛŒÙ…Øª\n",
        "        df_whale['volume_std20'] = df_whale['volume'].rolling(window=20).std()\n",
        "        df_whale['close_std20'] = df_whale['close'].rolling(window=20).std()\n",
        "\n",
        "        # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ú©Ù†Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¨Ø§ Ø­Ø¬Ù… ØºÛŒØ±Ø¹Ø§Ø¯ÛŒ (Ù†Ù‡Ù†Ú¯â€ŒÙ‡Ø§)\n",
        "        df_whale['abnormal_volume'] = df_whale['volume'] > (\n",
        "                df_whale['volume_sma50'] + df_whale['volume_std20'] * volume_multiplier)\n",
        "\n",
        "        # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ ØªØ£Ø«ÛŒØ± Ù‚ÛŒÙ…ØªÛŒ Ù…Ù‡Ù…\n",
        "        df_whale['price_impact'] = np.abs(df_whale['close'] - df_whale['open']) / df_whale['open'] * 100\n",
        "        df_whale['significant_impact'] = df_whale['price_impact'] > price_impact\n",
        "\n",
        "        # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ ÙØ¹Ø§Ù„ÛŒØª Ù†Ù‡Ù†Ú¯â€ŒÙ‡Ø§ÛŒ Ø®Ø±ÛŒØ¯Ø§Ø±\n",
        "        df_whale['whale_buying'] = ((df_whale['abnormal_volume']) &\n",
        "                                    (df_whale['significant_impact']) &\n",
        "                                    (df_whale['close'] > df_whale['open']))\n",
        "\n",
        "        # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ ÙØ¹Ø§Ù„ÛŒØª Ù†Ù‡Ù†Ú¯â€ŒÙ‡Ø§ÛŒ ÙØ±ÙˆØ´Ù†Ø¯Ù‡\n",
        "        df_whale['whale_selling'] = ((df_whale['abnormal_volume']) &\n",
        "                                     (df_whale['significant_impact']) &\n",
        "                                     (df_whale['close'] < df_whale['open']))\n",
        "\n",
        "        # ØªØ­Ù„ÛŒÙ„ ØªØ¬Ù…Ø¹ÛŒ ÙØ¹Ø§Ù„ÛŒØª Ù†Ù‡Ù†Ú¯â€ŒÙ‡Ø§ Ø¯Ø± Ø¨Ø§Ø²Ù‡ Ø§Ø®ÛŒØ±\n",
        "        recent_whale_buying = []\n",
        "        recent_whale_selling = []\n",
        "\n",
        "        for i in range(max(50, len(df_whale) - 100), len(df_whale)):\n",
        "            if df_whale['whale_buying'].iloc[i]:\n",
        "                recent_whale_buying.append({\n",
        "                    'index': i,\n",
        "                    'date': df_whale.index[i],\n",
        "                    'volume': df_whale['volume'].iloc[i],\n",
        "                    'volume_ratio': df_whale['volume'].iloc[i] / df_whale['volume_sma50'].iloc[i],\n",
        "                    'price_impact': df_whale['price_impact'].iloc[i]\n",
        "                })\n",
        "\n",
        "            if df_whale['whale_selling'].iloc[i]:\n",
        "                recent_whale_selling.append({\n",
        "                    'index': i,\n",
        "                    'date': df_whale.index[i],\n",
        "                    'volume': df_whale['volume'].iloc[i],\n",
        "                    'volume_ratio': df_whale['volume'].iloc[i] / df_whale['volume_sma50'].iloc[i],\n",
        "                    'price_impact': df_whale['price_impact'].iloc[i]\n",
        "                })\n",
        "\n",
        "        # ØªØ­Ù„ÛŒÙ„ Ø§Ù„Ú¯ÙˆÛŒ Ø§Ù†Ø¨Ø§Ø´Øª ÛŒØ§ ØªÙˆØ²ÛŒØ¹\n",
        "        accumulation_pattern = False\n",
        "        distribution_pattern = False\n",
        "        consolidation_after_whale = False\n",
        "\n",
        "        # Ø§Ù†Ø¨Ø§Ø´Øª: Ú†Ù†Ø¯ÛŒÙ† ÙØ¹Ø§Ù„ÛŒØª Ø®Ø±ÛŒØ¯ Ø¨Ø²Ø±Ú¯ Ø¯Ø± Ø¨Ø§Ø²Ù‡ Ú©ÙˆØªØ§Ù‡ Ø¨Ø§ Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ÛŒ Ù†Ø³Ø¨ØªØ§Ù‹ Ø«Ø§Ø¨Øª\n",
        "        if len(recent_whale_buying) >= 2:\n",
        "            recent_buying_indices = [item['index'] for item in recent_whale_buying[-3:]]\n",
        "            if max(recent_buying_indices) - min(recent_buying_indices) < 20:  # Ø¯Ø± 20 Ú©Ù†Ø¯Ù„ Ø§Ø®ÛŒØ±\n",
        "                price_range = df_whale['close'].iloc[min(recent_buying_indices):max(recent_buying_indices) + 1].max() / \\\n",
        "                              df_whale['close'].iloc[\n",
        "                              min(recent_buying_indices):max(recent_buying_indices) + 1].min() - 1\n",
        "\n",
        "                if price_range < 0.05:  # Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ù‚ÛŒÙ…Øª Ú©Ù…ØªØ± Ø§Ø² 5%\n",
        "                    accumulation_pattern = True\n",
        "\n",
        "        # ØªÙˆØ²ÛŒØ¹: Ú†Ù†Ø¯ÛŒÙ† ÙØ¹Ø§Ù„ÛŒØª ÙØ±ÙˆØ´ Ø¨Ø²Ø±Ú¯ Ø¯Ø± Ø¨Ø§Ø²Ù‡ Ú©ÙˆØªØ§Ù‡ Ø¨Ø§ Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ÛŒ Ù†Ø³Ø¨ØªØ§Ù‹ Ø«Ø§Ø¨Øª\n",
        "        if len(recent_whale_selling) >= 2:\n",
        "            recent_selling_indices = [item['index'] for item in recent_whale_selling[-3:]]\n",
        "            if max(recent_selling_indices) - min(recent_selling_indices) < 20:  # Ø¯Ø± 20 Ú©Ù†Ø¯Ù„ Ø§Ø®ÛŒØ±\n",
        "                price_range = df_whale['close'].iloc[\n",
        "                              min(recent_selling_indices):max(recent_selling_indices) + 1].max() / \\\n",
        "                              df_whale['close'].iloc[\n",
        "                              min(recent_selling_indices):max(recent_selling_indices) + 1].min() - 1\n",
        "\n",
        "                if price_range < 0.05:  # Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ù‚ÛŒÙ…Øª Ú©Ù…ØªØ± Ø§Ø² 5%\n",
        "                    distribution_pattern = True\n",
        "\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ ØªØ­Ú©ÛŒÙ… Ù¾Ø³ Ø§Ø² ÙØ¹Ø§Ù„ÛŒØª Ù†Ù‡Ù†Ú¯â€ŒÙ‡Ø§\n",
        "        if recent_whale_buying or recent_whale_selling:\n",
        "            last_whale_idx = max([item['index'] for item in recent_whale_buying + recent_whale_selling])\n",
        "            if len(df_whale) - last_whale_idx > 5:  # Ø­Ø¯Ø§Ù‚Ù„ 5 Ú©Ù†Ø¯Ù„ Ø¨Ø¹Ø¯ Ø§Ø² Ø¢Ø®Ø±ÛŒÙ† ÙØ¹Ø§Ù„ÛŒØª\n",
        "                recent_volatility = df_whale['close_std20'].iloc[-1] / df_whale['close'].iloc[-1]\n",
        "                if recent_volatility < 0.02:  # Ù†ÙˆØ³Ø§Ù† Ú©Ù… Ù¾Ø³ Ø§Ø² ÙØ¹Ø§Ù„ÛŒØª Ù†Ù‡Ù†Ú¯\n",
        "                    consolidation_after_whale = True\n",
        "\n",
        "        # ØªØ¹ÛŒÛŒÙ† ÙˆØ¶Ø¹ÛŒØª Ú©Ù„ÛŒ ÙØ¹Ø§Ù„ÛŒØª Ù†Ù‡Ù†Ú¯â€ŒÙ‡Ø§\n",
        "        whale_status = 'Ø¨Ø¯ÙˆÙ† ÙØ¹Ø§Ù„ÛŒØª Ù†Ù‡Ù†Ú¯ Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡'\n",
        "        whale_strength = 0\n",
        "        whale_signal = 'Ø®Ù†Ø«ÛŒ'\n",
        "\n",
        "        if len(recent_whale_buying) > len(recent_whale_selling) and len(recent_whale_buying) > 0:\n",
        "            whale_status = 'ÙØ¹Ø§Ù„ÛŒØª Ø®Ø±ÛŒØ¯ Ù†Ù‡Ù†Ú¯â€ŒÙ‡Ø§'\n",
        "            whale_strength = min(100, 50 + len(recent_whale_buying) * 10)\n",
        "            whale_signal = 'Ø®Ø±ÛŒØ¯'\n",
        "\n",
        "            if accumulation_pattern:\n",
        "                whale_status += ' - Ø§Ù„Ú¯ÙˆÛŒ Ø§Ù†Ø¨Ø§Ø´Øª'\n",
        "                whale_strength += 20\n",
        "\n",
        "            if consolidation_after_whale:\n",
        "                whale_status += ' - Ø¯ÙˆØ±Ù‡ ØªØ­Ú©ÛŒÙ… Ù¾Ø³ Ø§Ø² Ø®Ø±ÛŒØ¯'\n",
        "                whale_strength += 10\n",
        "\n",
        "        elif len(recent_whale_selling) > len(recent_whale_buying) and len(recent_whale_selling) > 0:\n",
        "            whale_status = 'ÙØ¹Ø§Ù„ÛŒØª ÙØ±ÙˆØ´ Ù†Ù‡Ù†Ú¯â€ŒÙ‡Ø§'\n",
        "            whale_strength = min(100, 50 + len(recent_whale_selling) * 10)\n",
        "            whale_signal = 'ÙØ±ÙˆØ´'\n",
        "\n",
        "            if distribution_pattern:\n",
        "                whale_status += ' - Ø§Ù„Ú¯ÙˆÛŒ ØªÙˆØ²ÛŒØ¹'\n",
        "                whale_strength += 20\n",
        "\n",
        "            if consolidation_after_whale:\n",
        "                whale_status += ' - Ø¯ÙˆØ±Ù‡ ØªØ­Ú©ÛŒÙ… Ù¾Ø³ Ø§Ø² ÙØ±ÙˆØ´'\n",
        "                whale_strength += 10\n",
        "\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ Ù„ÛŒÚ©ÙˆØ¦ÛŒØ¯ÛŒØ´Ù† (Ø¨Ø§ ØªØ­Ù„ÛŒÙ„ ØªØºÛŒÛŒØ±Ø§Øª Ù‚ÛŒÙ…Øª Ù†Ø§Ú¯Ù‡Ø§Ù†ÛŒ)\n",
        "        liquidation_events = []\n",
        "\n",
        "        for i in range(20, len(df_whale)):\n",
        "            # ØªØºÛŒÛŒØ± Ù‚ÛŒÙ…Øª Ù†Ø§Ú¯Ù‡Ø§Ù†ÛŒ Ø¨ÛŒØ´ Ø§Ø² 3% Ø¯Ø± ÛŒÚ© Ú©Ù†Ø¯Ù„ Ø¨Ø§ Ø­Ø¬Ù… Ø¨Ø§Ù„Ø§\n",
        "            if abs(df_whale['price_change_pct'].iloc[i]) > 3 and df_whale['volume'].iloc[i] > \\\n",
        "                    df_whale['volume_sma20'].iloc[i] * 2:\n",
        "                direction = 'Long Liquidation' if df_whale['close'].iloc[i] < df_whale['open'].iloc[\n",
        "                    i] else 'Short Liquidation'\n",
        "                liquidation_events.append({\n",
        "                    'index': i,\n",
        "                    'date': df_whale.index[i],\n",
        "                    'direction': direction,\n",
        "                    'price_change': df_whale['price_change_pct'].iloc[i],\n",
        "                    'volume_ratio': df_whale['volume'].iloc[i] / df_whale['volume_sma20'].iloc[i]\n",
        "                })\n",
        "\n",
        "        # Ù†ØªØ§ÛŒØ¬ Ù†Ù‡Ø§ÛŒÛŒ\n",
        "        result = {\n",
        "            'whale_status': whale_status,\n",
        "            'whale_strength': min(100, whale_strength),\n",
        "            'whale_signal': whale_signal,\n",
        "            'recent_whale_buying': recent_whale_buying,\n",
        "            'recent_whale_selling': recent_whale_selling,\n",
        "            'accumulation_pattern': accumulation_pattern,\n",
        "            'distribution_pattern': distribution_pattern,\n",
        "            'consolidation_after_whale': consolidation_after_whale,\n",
        "            'liquidation_events': liquidation_events,\n",
        "            'dataframe': df_whale\n",
        "        }\n",
        "\n",
        "        return result\n",
        "\n",
        "    def analyze_ema_strategy(self, df, short_period=8, mid_period=21, long_period=50, trend_period=200):\n",
        "        \"\"\"\n",
        "        Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ EMA Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ø±ÙˆÙ†Ø¯ Ùˆ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒØ¯Ù‡ÛŒ\n",
        "\n",
        "        Args:\n",
        "            df: Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§\n",
        "            short_period: Ø¯ÙˆØ±Ù‡ EMA Ú©ÙˆØªØ§Ù‡â€ŒÙ…Ø¯Øª\n",
        "            mid_period: Ø¯ÙˆØ±Ù‡ EMA Ù…ÛŒØ§Ù†â€ŒÙ…Ø¯Øª\n",
        "            long_period: Ø¯ÙˆØ±Ù‡ EMA Ø¨Ù„Ù†Ø¯Ù…Ø¯Øª\n",
        "            trend_period: Ø¯ÙˆØ±Ù‡ EMA Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ø±ÙˆÙ†Ø¯ Ø§ØµÙ„ÛŒ\n",
        "\n",
        "        Returns:\n",
        "            Ù†ØªØ§ÛŒØ¬ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ EMA\n",
        "        \"\"\"\n",
        "        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†â€ŒÙ‡Ø§ÛŒ Ù…ØªØ­Ø±Ú© Ù†Ù…Ø§ÛŒÛŒ (EMA)\n",
        "        df_ema = df.copy()\n",
        "\n",
        "        df_ema[f'ema_{short_period}'] = ta.trend.ema_indicator(df_ema['close'], window=short_period)\n",
        "        df_ema[f'ema_{mid_period}'] = ta.trend.ema_indicator(df_ema['close'], window=mid_period)\n",
        "        df_ema[f'ema_{long_period}'] = ta.trend.ema_indicator(df_ema['close'], window=long_period)\n",
        "        df_ema[f'ema_{trend_period}'] = ta.trend.ema_indicator(df_ema['close'], window=trend_period)\n",
        "\n",
        "        # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ú©Ø±Ø§Ø³â€ŒØ§ÙˆÙˆØ±â€ŒÙ‡Ø§\n",
        "        # Ú©Ø±Ø§Ø³ ØµØ¹ÙˆØ¯ÛŒ: EMA Ú©ÙˆØªØ§Ù‡â€ŒÙ…Ø¯Øª Ø¨Ø§Ù„Ø§ÛŒ EMA Ù…ÛŒØ§Ù†â€ŒÙ…Ø¯Øª\n",
        "        df_ema['ema_short_above_mid'] = df_ema[f'ema_{short_period}'] > df_ema[f'ema_{mid_period}']\n",
        "        df_ema['ema_bullish_cross'] = np.logical_and(\n",
        "            df_ema['ema_short_above_mid'],\n",
        "            np.logical_not(df_ema['ema_short_above_mid'].shift(1))\n",
        "        )\n",
        "\n",
        "        # Ú©Ø±Ø§Ø³ Ù†Ø²ÙˆÙ„ÛŒ: EMA Ú©ÙˆØªØ§Ù‡â€ŒÙ…Ø¯Øª Ø²ÛŒØ± EMA Ù…ÛŒØ§Ù†â€ŒÙ…Ø¯Øª\n",
        "        df_ema['ema_short_below_mid'] = df_ema[f'ema_{short_period}'] < df_ema[f'ema_{mid_period}']\n",
        "        df_ema['ema_bearish_cross'] = np.logical_and(\n",
        "            df_ema['ema_short_below_mid'],\n",
        "            np.logical_not(df_ema['ema_short_below_mid'].shift(1))\n",
        "        )\n",
        "\n",
        "        # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ ÙØ§ØµÙ„Ù‡ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†â€ŒÙ‡Ø§ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ø´Ø§Ø®Øµ Ù‚Ø¯Ø±Øª Ø±ÙˆÙ†Ø¯\n",
        "        df_ema['ema_spread'] = (df_ema[f'ema_{short_period}'] - df_ema[f'ema_{long_period}']) / df_ema[\n",
        "            f'ema_{long_period}'] * 100\n",
        "\n",
        "        # ØªØ´Ø®ÛŒØµ Ù‡Ù…Ø³ÙˆÛŒÛŒ EMAÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø±ÙˆÙ†Ø¯ Ù‚Ø¯Ø±ØªÙ…Ù†Ø¯\n",
        "        df_ema['ema_aligned_bullish'] = (df_ema[f'ema_{short_period}'] > df_ema[f'ema_{mid_period}']) & \\\n",
        "                                        (df_ema[f'ema_{mid_period}'] > df_ema[f'ema_{long_period}']) & \\\n",
        "                                        (df_ema['close'] > df_ema[f'ema_{short_period}'])\n",
        "\n",
        "        df_ema['ema_aligned_bearish'] = (df_ema[f'ema_{short_period}'] < df_ema[f'ema_{mid_period}']) & \\\n",
        "                                        (df_ema[f'ema_{mid_period}'] < df_ema[f'ema_{long_period}']) & \\\n",
        "                                        (df_ema['close'] < df_ema[f'ema_{short_period}'])\n",
        "\n",
        "        # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø±ÙˆÙ†Ø¯ Ø¨Ù„Ù†Ø¯Ù…Ø¯Øª (Ø¨Ø§ØªÙˆØ¬Ù‡ Ø¨Ù‡ EMA Ø¨Ù„Ù†Ø¯Ù…Ø¯Øª)\n",
        "        df_ema['long_term_uptrend'] = df_ema['close'] > df_ema[f'ema_{trend_period}']\n",
        "\n",
        "        # Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§\n",
        "        bullish_signals = []\n",
        "        bearish_signals = []\n",
        "\n",
        "        for i in range(max(trend_period, mid_period, long_period) + 10, len(df_ema)):\n",
        "            # Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ ØµØ¹ÙˆØ¯ÛŒ\n",
        "            if df_ema['ema_bullish_cross'].iloc[i]:\n",
        "                # Ø³ÛŒÚ¯Ù†Ø§Ù„ ØµØ¹ÙˆØ¯ÛŒ Ù‚ÙˆÛŒ: Ú©Ø±Ø§Ø³ ØµØ¹ÙˆØ¯ÛŒ Ø¯Ø± Ø±ÙˆÙ†Ø¯ ØµØ¹ÙˆØ¯ÛŒ\n",
        "                if df_ema['long_term_uptrend'].iloc[i]:\n",
        "                    strength = 80\n",
        "                    description = 'Ú©Ø±Ø§Ø³ ØµØ¹ÙˆØ¯ÛŒ Ù‚ÙˆÛŒ Ø¯Ø± Ø±ÙˆÙ†Ø¯ Ø§ØµÙ„ÛŒ ØµØ¹ÙˆØ¯ÛŒ'\n",
        "                else:\n",
        "                    strength = 60\n",
        "                    description = 'Ú©Ø±Ø§Ø³ ØµØ¹ÙˆØ¯ÛŒ Ø¯Ø± Ø±ÙˆÙ†Ø¯ Ù†Ø²ÙˆÙ„ÛŒ (Ø§Ø­ØªÙ…Ø§Ù„ Ø±ÛŒØ¨Ø§Ù†Ø¯)'\n",
        "\n",
        "                # Ø§ÙØ²Ø§ÛŒØ´ Ù‚Ø¯Ø±Øª Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø¯Ø± ØµÙˆØ±Øª Ù‡Ù…Ø³ÙˆÛŒÛŒ Ù‡Ù…Ù‡ EMAÙ‡Ø§\n",
        "                if df_ema['ema_aligned_bullish'].iloc[i:i + 3].any():\n",
        "                    strength += 10\n",
        "                    description += ' - Ù‡Ù…Ø³ÙˆÛŒÛŒ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†â€ŒÙ‡Ø§ÛŒ Ù…ØªØ­Ø±Ú©'\n",
        "\n",
        "                # Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø¨Ø§Ø²Ú¯Ø´Øª Ø±ÙˆÙ†Ø¯: Ù‚ÛŒÙ…Øª Ø§Ø² Ø²ÛŒØ± EMA Ø¨Ù„Ù†Ø¯Ù…Ø¯Øª Ø¨Ù‡ Ø¨Ø§Ù„Ø§ÛŒ Ø¢Ù† Ø­Ø±Ú©Øª Ù…ÛŒâ€ŒÚ©Ù†Ø¯\n",
        "                if not df_ema['long_term_uptrend'].iloc[i - 1] and df_ema['long_term_uptrend'].iloc[i]:\n",
        "                    strength += 15\n",
        "                    description += ' - Ø¨Ø§Ø²Ú¯Ø´Øª Ø±ÙˆÙ†Ø¯ Ø¨Ù„Ù†Ø¯Ù…Ø¯Øª Ø¨Ù‡ ØµØ¹ÙˆØ¯ÛŒ'\n",
        "\n",
        "                bullish_signals.append({\n",
        "                    'index': i,\n",
        "                    'date': df_ema.index[i],\n",
        "                    'price': df_ema['close'].iloc[i],\n",
        "                    'strength': min(100, strength),\n",
        "                    'description': description\n",
        "                })\n",
        "\n",
        "            # Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ù†Ø²ÙˆÙ„ÛŒ\n",
        "            if df_ema['ema_bearish_cross'].iloc[i]:\n",
        "                # Ø³ÛŒÚ¯Ù†Ø§Ù„ Ù†Ø²ÙˆÙ„ÛŒ Ù‚ÙˆÛŒ: Ú©Ø±Ø§Ø³ Ù†Ø²ÙˆÙ„ÛŒ Ø¯Ø± Ø±ÙˆÙ†Ø¯ Ù†Ø²ÙˆÙ„ÛŒ\n",
        "                if not df_ema['long_term_uptrend'].iloc[i]:\n",
        "                    strength = 80\n",
        "                    description = 'Ú©Ø±Ø§Ø³ Ù†Ø²ÙˆÙ„ÛŒ Ù‚ÙˆÛŒ Ø¯Ø± Ø±ÙˆÙ†Ø¯ Ø§ØµÙ„ÛŒ Ù†Ø²ÙˆÙ„ÛŒ'\n",
        "                else:\n",
        "                    strength = 60\n",
        "                    description = 'Ú©Ø±Ø§Ø³ Ù†Ø²ÙˆÙ„ÛŒ Ø¯Ø± Ø±ÙˆÙ†Ø¯ ØµØ¹ÙˆØ¯ÛŒ (Ø§Ø­ØªÙ…Ø§Ù„ Ø§ØµÙ„Ø§Ø­)'\n",
        "\n",
        "                # Ø§ÙØ²Ø§ÛŒØ´ Ù‚Ø¯Ø±Øª Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø¯Ø± ØµÙˆØ±Øª Ù‡Ù…Ø³ÙˆÛŒÛŒ Ù‡Ù…Ù‡ EMAÙ‡Ø§\n",
        "                if df_ema['ema_aligned_bearish'].iloc[i:i + 3].any():\n",
        "                    strength += 10\n",
        "                    description += ' - Ù‡Ù…Ø³ÙˆÛŒÛŒ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†â€ŒÙ‡Ø§ÛŒ Ù…ØªØ­Ø±Ú©'\n",
        "\n",
        "                # Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø¨Ø§Ø²Ú¯Ø´Øª Ø±ÙˆÙ†Ø¯: Ù‚ÛŒÙ…Øª Ø§Ø² Ø¨Ø§Ù„Ø§ÛŒ EMA Ø¨Ù„Ù†Ø¯Ù…Ø¯Øª Ø¨Ù‡ Ø²ÛŒØ± Ø¢Ù† Ø­Ø±Ú©Øª Ù…ÛŒâ€ŒÚ©Ù†Ø¯\n",
        "                if df_ema['long_term_uptrend'].iloc[i - 1] and not df_ema['long_term_uptrend'].iloc[i]:\n",
        "                    strength += 15\n",
        "                    description += ' - Ø¨Ø§Ø²Ú¯Ø´Øª Ø±ÙˆÙ†Ø¯ Ø¨Ù„Ù†Ø¯Ù…Ø¯Øª Ø¨Ù‡ Ù†Ø²ÙˆÙ„ÛŒ'\n",
        "\n",
        "                bearish_signals.append({\n",
        "                    'index': i,\n",
        "                    'date': df_ema.index[i],\n",
        "                    'price': df_ema['close'].iloc[i],\n",
        "                    'strength': min(100, strength),\n",
        "                    'description': description\n",
        "                })\n",
        "\n",
        "        # ØªØ­Ù„ÛŒÙ„ ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ\n",
        "        current_ema_status = 'Ø®Ù†Ø«ÛŒ'\n",
        "        current_ema_strength = 50\n",
        "\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ Ø±ÙˆÙ†Ø¯ ÙØ¹Ù„ÛŒ\n",
        "        if df_ema['long_term_uptrend'].iloc[-1]:\n",
        "            base_trend = 'ØµØ¹ÙˆØ¯ÛŒ'\n",
        "        else:\n",
        "            base_trend = 'Ù†Ø²ÙˆÙ„ÛŒ'\n",
        "\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ Ù‡Ù…Ø³ÙˆÛŒÛŒ EMAÙ‡Ø§\n",
        "        if df_ema['ema_aligned_bullish'].iloc[-1]:\n",
        "            current_ema_status = f'ØµØ¹ÙˆØ¯ÛŒ Ù‚ÙˆÛŒ (Ø±ÙˆÙ†Ø¯ {base_trend})'\n",
        "            current_ema_strength = 85\n",
        "        elif df_ema['ema_aligned_bearish'].iloc[-1]:\n",
        "            current_ema_status = f'Ù†Ø²ÙˆÙ„ÛŒ Ù‚ÙˆÛŒ (Ø±ÙˆÙ†Ø¯ {base_trend})'\n",
        "            current_ema_strength = 15\n",
        "        elif df_ema['ema_short_above_mid'].iloc[-1]:\n",
        "            if df_ema['long_term_uptrend'].iloc[-1]:\n",
        "                current_ema_status = f'ØµØ¹ÙˆØ¯ÛŒ (Ø±ÙˆÙ†Ø¯ {base_trend})'\n",
        "                current_ema_strength = 70\n",
        "            else:\n",
        "                current_ema_status = f'ØµØ¹ÙˆØ¯ÛŒ Ú©ÙˆØªØ§Ù‡â€ŒÙ…Ø¯Øª Ø¯Ø± Ø±ÙˆÙ†Ø¯ {base_trend}'\n",
        "                current_ema_strength = 60\n",
        "        elif df_ema['ema_short_below_mid'].iloc[-1]:\n",
        "            if not df_ema['long_term_uptrend'].iloc[-1]:\n",
        "                current_ema_status = f'Ù†Ø²ÙˆÙ„ÛŒ (Ø±ÙˆÙ†Ø¯ {base_trend})'\n",
        "                current_ema_strength = 30\n",
        "            else:\n",
        "                current_ema_status = f'Ù†Ø²ÙˆÙ„ÛŒ Ú©ÙˆØªØ§Ù‡â€ŒÙ…Ø¯Øª Ø¯Ø± Ø±ÙˆÙ†Ø¯ {base_trend}'\n",
        "                current_ema_strength = 40\n",
        "\n",
        "        # Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ ÙˆØ±ÙˆØ¯ Ùˆ Ø®Ø±ÙˆØ¬\n",
        "        entry_points = []\n",
        "        exit_points = []\n",
        "\n",
        "        # Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ ÙˆØ±ÙˆØ¯: Ù‚ÛŒÙ…Øª Ø§Ø² Ø²ÛŒØ± EMA Ù…ÛŒØ§Ù†ÛŒ Ø¨Ù‡ Ø¨Ø§Ù„Ø§ÛŒ Ø¢Ù† Ù…ÛŒâ€ŒØ±ÙˆØ¯ Ø¯Ø± Ø±ÙˆÙ†Ø¯ ØµØ¹ÙˆØ¯ÛŒ\n",
        "        for i in range(max(trend_period, mid_period, long_period) + 10, len(df_ema) - 1):\n",
        "            # ÙˆØ±ÙˆØ¯ ØµØ¹ÙˆØ¯ÛŒ\n",
        "            if (df_ema['close'].iloc[i - 1] < df_ema[f'ema_{mid_period}'].iloc[i - 1] and\n",
        "                    df_ema['close'].iloc[i] > df_ema[f'ema_{mid_period}'].iloc[i] and\n",
        "                    df_ema['long_term_uptrend'].iloc[i]):\n",
        "                entry_points.append({\n",
        "                    'index': i,\n",
        "                    'type': 'long',\n",
        "                    'price': df_ema['close'].iloc[i],\n",
        "                    'stop_loss': df_ema[f'ema_{long_period}'].iloc[i],\n",
        "                    'take_profit': df_ema['close'].iloc[i] + (\n",
        "                            df_ema['close'].iloc[i] - df_ema[f'ema_{long_period}'].iloc[i]) * 2\n",
        "                })\n",
        "\n",
        "            # ÙˆØ±ÙˆØ¯ Ù†Ø²ÙˆÙ„ÛŒ\n",
        "            if (df_ema['close'].iloc[i - 1] > df_ema[f'ema_{mid_period}'].iloc[i - 1] and\n",
        "                    df_ema['close'].iloc[i] < df_ema[f'ema_{mid_period}'].iloc[i] and\n",
        "                    not df_ema['long_term_uptrend'].iloc[i]):\n",
        "                entry_points.append({\n",
        "                    'index': i,\n",
        "                    'type': 'short',\n",
        "                    'price': df_ema['close'].iloc[i],\n",
        "                    'stop_loss': df_ema[f'ema_{long_period}'].iloc[i],\n",
        "                    'take_profit': df_ema['close'].iloc[i] - (\n",
        "                            df_ema[f'ema_{long_period}'].iloc[i] - df_ema['close'].iloc[i]) * 2\n",
        "                })\n",
        "\n",
        "            # Ø®Ø±ÙˆØ¬ Ø§Ø² Ù…ÙˆÙ‚Ø¹ÛŒØª ØµØ¹ÙˆØ¯ÛŒ: Ù‚ÛŒÙ…Øª Ø²ÛŒØ± EMA Ú©ÙˆØªØ§Ù‡â€ŒÙ…Ø¯Øª\n",
        "            if (df_ema['close'].iloc[i - 1] > df_ema[f'ema_{short_period}'].iloc[i - 1] and\n",
        "                    df_ema['close'].iloc[i] < df_ema[f'ema_{short_period}'].iloc[i]):\n",
        "                exit_points.append({\n",
        "                    'index': i,\n",
        "                    'type': 'exit_long',\n",
        "                    'price': df_ema['close'].iloc[i]\n",
        "                })\n",
        "\n",
        "            # Ø®Ø±ÙˆØ¬ Ø§Ø² Ù…ÙˆÙ‚Ø¹ÛŒØª Ù†Ø²ÙˆÙ„ÛŒ: Ù‚ÛŒÙ…Øª Ø¨Ø§Ù„Ø§ÛŒ EMA Ú©ÙˆØªØ§Ù‡â€ŒÙ…Ø¯Øª\n",
        "            if (df_ema['close'].iloc[i - 1] < df_ema[f'ema_{short_period}'].iloc[i - 1] and\n",
        "                    df_ema['close'].iloc[i] > df_ema[f'ema_{short_period}'].iloc[i]):\n",
        "                exit_points.append({\n",
        "                    'index': i,\n",
        "                    'type': 'exit_short',\n",
        "                    'price': df_ema['close'].iloc[i]\n",
        "                })\n",
        "\n",
        "        # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø¢Ø®Ø±\n",
        "        latest_signal = None\n",
        "        latest_signal_type = 'Ø®Ù†Ø«ÛŒ'\n",
        "        latest_signal_strength = 50\n",
        "\n",
        "        if bullish_signals and (not bearish_signals or bullish_signals[-1]['index'] > bearish_signals[-1]['index']):\n",
        "            latest_signal = bullish_signals[-1]\n",
        "            latest_signal_type = 'Ø®Ø±ÛŒØ¯'\n",
        "            latest_signal_strength = latest_signal['strength']\n",
        "\n",
        "            # Ø§Ú¯Ø± Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø®Ø±ÛŒØ¯ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ú©Ù†Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ø®ÛŒØ± Ø¨Ø§Ø´Ø¯ØŒ Ù‚Ø¯Ø±Øª Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø±Ø§ Ø§ÙØ²Ø§ÛŒØ´ Ù…ÛŒâ€ŒØ¯Ù‡ÛŒÙ…\n",
        "            if len(df_ema) - latest_signal['index'] <= 3:\n",
        "                latest_signal_strength = min(100, latest_signal_strength + 10)\n",
        "\n",
        "        elif bearish_signals and (not bullish_signals or bearish_signals[-1]['index'] > bullish_signals[-1]['index']):\n",
        "            latest_signal = bearish_signals[-1]\n",
        "            latest_signal_type = 'ÙØ±ÙˆØ´'\n",
        "            latest_signal_strength = latest_signal['strength']\n",
        "\n",
        "            # Ø§Ú¯Ø± Ø³ÛŒÚ¯Ù†Ø§Ù„ ÙØ±ÙˆØ´ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ú©Ù†Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ø®ÛŒØ± Ø¨Ø§Ø´Ø¯ØŒ Ù‚Ø¯Ø±Øª Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø±Ø§ Ø§ÙØ²Ø§ÛŒØ´ Ù…ÛŒâ€ŒØ¯Ù‡ÛŒÙ…\n",
        "            if len(df_ema) - latest_signal['index'] <= 3:\n",
        "                latest_signal_strength = min(100, latest_signal_strength + 10)\n",
        "\n",
        "        # Ù†ØªØ§ÛŒØ¬ Ù†Ù‡Ø§ÛŒÛŒ\n",
        "        result = {\n",
        "            'current_status': current_ema_status,\n",
        "            'current_strength': current_ema_strength,\n",
        "            'latest_signal_type': latest_signal_type,\n",
        "            'latest_signal_strength': latest_signal_strength,\n",
        "            'latest_signal': latest_signal,\n",
        "            'bullish_signals': bullish_signals,\n",
        "            'bearish_signals': bearish_signals,\n",
        "            'entry_points': entry_points,\n",
        "            'exit_points': exit_points,\n",
        "            'dataframe': df_ema\n",
        "        }\n",
        "\n",
        "        return result\n",
        "\n",
        "    def analyze_rsi_strategy(self, df, period=14, overbought=70, oversold=30):\n",
        "        \"\"\"\n",
        "        Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø´Ø§Ø®Øµ Ù‚Ø¯Ø±Øª Ù†Ø³Ø¨ÛŒ (RSI) Ø¨Ø§ ØªØ´Ø®ÛŒØµ Ø¨Ù‡ØªØ±ÛŒÙ† Ù†Ù‚Ø§Ø· ÙˆØ±ÙˆØ¯\n",
        "\n",
        "        Args:\n",
        "            df: Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§\n",
        "            period: Ø¯ÙˆØ±Ù‡ Ù…Ø­Ø§Ø³Ø¨Ù‡ RSI\n",
        "            overbought: Ø³Ø·Ø­ Ø§Ø´Ø¨Ø§Ø¹ Ø®Ø±ÛŒØ¯\n",
        "            oversold: Ø³Ø·Ø­ Ø§Ø´Ø¨Ø§Ø¹ ÙØ±ÙˆØ´\n",
        "\n",
        "        Returns:\n",
        "            Ù†ØªØ§ÛŒØ¬ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ RSI\n",
        "        \"\"\"\n",
        "        # Ù…Ø­Ø§Ø³Ø¨Ù‡ RSI\n",
        "        df_rsi = df.copy()\n",
        "        df_rsi['rsi'] = ta.momentum.rsi(df_rsi['close'], window=period)\n",
        "\n",
        "        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…ØªØ­Ø±Ú© Ø³Ø§Ø¯Ù‡ RSI Ø¨Ø±Ø§ÛŒ ØªØ¹ÛŒÛŒÙ† Ø±ÙˆÙ†Ø¯ RSI\n",
        "        df_rsi['rsi_sma5'] = df_rsi['rsi'].rolling(window=5).mean()\n",
        "\n",
        "        # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù…Ù†Ø§Ø·Ù‚ Ø§Ø´Ø¨Ø§Ø¹ Ø®Ø±ÛŒØ¯ Ùˆ ÙØ±ÙˆØ´\n",
        "        df_rsi['overbought'] = df_rsi['rsi'] > overbought\n",
        "        df_rsi['oversold'] = df_rsi['rsi'] < oversold\n",
        "\n",
        "        # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø®Ø±ÙˆØ¬ Ø§Ø² Ù…Ù†Ø§Ø·Ù‚ Ø§Ø´Ø¨Ø§Ø¹\n",
        "        df_rsi['exit_overbought'] = (df_rsi['rsi'] < overbought) & (df_rsi['rsi'].shift(1) >= overbought)\n",
        "        df_rsi['exit_oversold'] = (df_rsi['rsi'] > oversold) & (df_rsi['rsi'].shift(1) <= oversold)\n",
        "\n",
        "        # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø±ÙˆÙ†Ø¯ Ù‚ÛŒÙ…Øª (Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…ØªØ­Ø±Ú© 50)\n",
        "        df_rsi['sma50'] = df_rsi['close'].rolling(window=50).mean()\n",
        "        df_rsi['price_uptrend'] = df_rsi['close'] > df_rsi['sma50']\n",
        "\n",
        "        # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ ÙˆØ§Ú¯Ø±Ø§ÛŒÛŒâ€ŒÙ‡Ø§ÛŒ Ø³Ø§Ø¯Ù‡\n",
        "        df_rsi['rsi_higher_high'] = (df_rsi['rsi'] > df_rsi['rsi'].shift(1)) & (\n",
        "                df_rsi['rsi'].shift(1) > df_rsi['rsi'].shift(2))\n",
        "        df_rsi['price_higher_high'] = (df_rsi['high'] > df_rsi['high'].shift(1)) & (\n",
        "                df_rsi['high'].shift(1) > df_rsi['high'].shift(2))\n",
        "\n",
        "        df_rsi['rsi_lower_low'] = (df_rsi['rsi'] < df_rsi['rsi'].shift(1)) & (\n",
        "                df_rsi['rsi'].shift(1) < df_rsi['rsi'].shift(2))\n",
        "        df_rsi['price_lower_low'] = (df_rsi['low'] < df_rsi['low'].shift(1)) & (\n",
        "                df_rsi['low'].shift(1) < df_rsi['low'].shift(2))\n",
        "\n",
        "        # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø®Ø±ÛŒØ¯ RSI\n",
        "        bullish_signals = []\n",
        "\n",
        "        for i in range(period + 10, len(df_rsi)):\n",
        "            # Ù†ÙˆØ¹ Ø§ÙˆÙ„: Ø®Ø±ÙˆØ¬ Ø§Ø² Ù…Ù†Ø·Ù‚Ù‡ Ø§Ø´Ø¨Ø§Ø¹ ÙØ±ÙˆØ´\n",
        "            if df_rsi['exit_oversold'].iloc[i]:\n",
        "                strength = 70\n",
        "                description = 'Ø®Ø±ÙˆØ¬ Ø§Ø² Ù…Ù†Ø·Ù‚Ù‡ Ø§Ø´Ø¨Ø§Ø¹ ÙØ±ÙˆØ´'\n",
        "\n",
        "                # ØªÙ‚ÙˆÛŒØª Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø§Ú¯Ø± Ø¯Ø± Ø±ÙˆÙ†Ø¯ ØµØ¹ÙˆØ¯ÛŒ Ù‚ÛŒÙ…Øª Ø¨Ø§Ø´ÛŒÙ…\n",
        "                if df_rsi['price_uptrend'].iloc[i]:\n",
        "                    strength += 15\n",
        "                    description += ' Ø¯Ø± Ø±ÙˆÙ†Ø¯ ØµØ¹ÙˆØ¯ÛŒ Ù‚ÛŒÙ…Øª'\n",
        "\n",
        "                # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø¨Ø§Ø²Ú¯Ø´Øªâ€ŒÙ‡Ø§ÛŒ Ù‚ÙˆÛŒâ€ŒØªØ± Ø§Ø² Ø³Ø·ÙˆØ­ Ø¨Ø³ÛŒØ§Ø± Ù¾Ø§ÛŒÛŒÙ†\n",
        "                if df_rsi['rsi'].iloc[i - 1] < 20:\n",
        "                    strength += 10\n",
        "                    description += ' (RSI Ø¨Ø³ÛŒØ§Ø± Ù¾Ø§ÛŒÛŒÙ†)'\n",
        "\n",
        "                bullish_signals.append({\n",
        "                    'index': i,\n",
        "                    'date': df_rsi.index[i],\n",
        "                    'price': df_rsi['close'].iloc[i],\n",
        "                    'rsi': df_rsi['rsi'].iloc[i],\n",
        "                    'strength': min(100, strength),\n",
        "                    'description': description,\n",
        "                    'type': 'exit_oversold'\n",
        "                })\n",
        "\n",
        "            # Ù†ÙˆØ¹ Ø¯ÙˆÙ…: RSI Ø¯Ø± Ø­Ø§Ù„ ØµØ¹ÙˆØ¯ Ø§Ø² Ù…Ù†Ø·Ù‚Ù‡ Ù…ÛŒØ§Ù†ÛŒ Ùˆ Ù‚ÛŒÙ…Øª Ø¯Ø± Ø±ÙˆÙ†Ø¯ ØµØ¹ÙˆØ¯ÛŒ\n",
        "            if (50 > df_rsi['rsi'].iloc[i - 1] > 45 and df_rsi['rsi'].iloc[i] > 50 and\n",
        "                    df_rsi['rsi'].iloc[i] > df_rsi['rsi'].iloc[i - 1] and df_rsi['price_uptrend'].iloc[i]):\n",
        "                bullish_signals.append({\n",
        "                    'index': i,\n",
        "                    'date': df_rsi.index[i],\n",
        "                    'price': df_rsi['close'].iloc[i],\n",
        "                    'rsi': df_rsi['rsi'].iloc[i],\n",
        "                    'strength': 65,\n",
        "                    'description': 'Ø´Ú©Ø³Øª RSI Ø§Ø² Ø³Ø·Ø­ Ù…ÛŒØ§Ù†ÛŒ Ø¯Ø± Ø±ÙˆÙ†Ø¯ ØµØ¹ÙˆØ¯ÛŒ',\n",
        "                    'type': 'rsi_mid_break'\n",
        "                })\n",
        "\n",
        "        # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ ÙØ±ÙˆØ´ RSI\n",
        "        bearish_signals = []\n",
        "\n",
        "        for i in range(period + 10, len(df_rsi)):\n",
        "            # Ù†ÙˆØ¹ Ø§ÙˆÙ„: Ø®Ø±ÙˆØ¬ Ø§Ø² Ù…Ù†Ø·Ù‚Ù‡ Ø§Ø´Ø¨Ø§Ø¹ Ø®Ø±ÛŒØ¯\n",
        "            if df_rsi['exit_overbought'].iloc[i]:\n",
        "                strength = 70\n",
        "                description = 'Ø®Ø±ÙˆØ¬ Ø§Ø² Ù…Ù†Ø·Ù‚Ù‡ Ø§Ø´Ø¨Ø§Ø¹ Ø®Ø±ÛŒØ¯'\n",
        "\n",
        "                # ØªÙ‚ÙˆÛŒØª Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø§Ú¯Ø± Ø¯Ø± Ø±ÙˆÙ†Ø¯ Ù†Ø²ÙˆÙ„ÛŒ Ù‚ÛŒÙ…Øª Ø¨Ø§Ø´ÛŒÙ…\n",
        "                if not df_rsi['price_uptrend'].iloc[i]:\n",
        "                    strength += 15\n",
        "                    description += ' Ø¯Ø± Ø±ÙˆÙ†Ø¯ Ù†Ø²ÙˆÙ„ÛŒ Ù‚ÛŒÙ…Øª'\n",
        "\n",
        "                # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø¨Ø§Ø²Ú¯Ø´Øªâ€ŒÙ‡Ø§ÛŒ Ù‚ÙˆÛŒâ€ŒØªØ± Ø§Ø² Ø³Ø·ÙˆØ­ Ø¨Ø³ÛŒØ§Ø± Ø¨Ø§Ù„Ø§\n",
        "                if df_rsi['rsi'].iloc[i - 1] > 80:\n",
        "                    strength += 10\n",
        "                    description += ' (RSI Ø¨Ø³ÛŒØ§Ø± Ø¨Ø§Ù„Ø§)'\n",
        "\n",
        "                bearish_signals.append({\n",
        "                    'index': i,\n",
        "                    'date': df_rsi.index[i],\n",
        "                    'price': df_rsi['close'].iloc[i],\n",
        "                    'rsi': df_rsi['rsi'].iloc[i],\n",
        "                    'strength': min(100, strength),\n",
        "                    'description': description,\n",
        "                    'type': 'exit_overbought'\n",
        "                })\n",
        "\n",
        "            # Ù†ÙˆØ¹ Ø¯ÙˆÙ…: RSI Ø¯Ø± Ø­Ø§Ù„ Ù†Ø²ÙˆÙ„ Ø§Ø² Ù…Ù†Ø·Ù‚Ù‡ Ù…ÛŒØ§Ù†ÛŒ Ùˆ Ù‚ÛŒÙ…Øª Ø¯Ø± Ø±ÙˆÙ†Ø¯ Ù†Ø²ÙˆÙ„ÛŒ\n",
        "            if (50 < df_rsi['rsi'].iloc[i - 1] < 55 and df_rsi['rsi'].iloc[i] < 50 and\n",
        "                    df_rsi['rsi'].iloc[i] < df_rsi['rsi'].iloc[i - 1] and not df_rsi['price_uptrend'].iloc[i]):\n",
        "                bearish_signals.append({\n",
        "                    'index': i,\n",
        "                    'date': df_rsi.index[i],\n",
        "                    'price': df_rsi['close'].iloc[i],\n",
        "                    'rsi': df_rsi['rsi'].iloc[i],\n",
        "                    'strength': 65,\n",
        "                    'description': 'Ø´Ú©Ø³Øª RSI Ø§Ø² Ø³Ø·Ø­ Ù…ÛŒØ§Ù†ÛŒ Ø¯Ø± Ø±ÙˆÙ†Ø¯ Ù†Ø²ÙˆÙ„ÛŒ',\n",
        "                    'type': 'rsi_mid_break'\n",
        "                })\n",
        "\n",
        "        # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ ÙˆØ§Ú¯Ø±Ø§ÛŒÛŒâ€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡\n",
        "        bullish_divergences = []\n",
        "        bearish_divergences = []\n",
        "\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ Ø¯ÙˆØ±Ù‡â€ŒÙ‡Ø§ÛŒ Ø²Ù…Ø§Ù†ÛŒ Û³Û° Ú©Ù†Ø¯Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ ÙˆØ§Ú¯Ø±Ø§ÛŒÛŒ\n",
        "        for i in range(period + 30, len(df_rsi)):\n",
        "            window = 30\n",
        "\n",
        "            # ÙˆØ§Ú¯Ø±Ø§ÛŒÛŒ Ù…Ø«Ø¨Øª: Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ÛŒ Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ± Ø§Ù…Ø§ RSI Ø¨Ø§Ù„Ø§ØªØ± (Ù†Ø´Ø§Ù†Ù‡ Ø®Ø±ÛŒØ¯)\n",
        "            if (df_rsi['low'].iloc[i] < df_rsi['low'].iloc[i - window:i].min() and\n",
        "                    df_rsi['rsi'].iloc[i] > df_rsi['rsi'].iloc[i - window:i].min()):\n",
        "\n",
        "                # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒØ²Ø§Ù† ÙˆØ§Ú¯Ø±Ø§ÛŒÛŒ\n",
        "                price_change = (df_rsi['low'].iloc[i] / df_rsi['low'].iloc[i - window:i].min() - 1) * 100\n",
        "                rsi_change = (df_rsi['rsi'].iloc[i] / df_rsi['rsi'].iloc[i - window:i].min() - 1) * 100\n",
        "\n",
        "                # Ø§Ú¯Ø± ÙˆØ§Ú¯Ø±Ø§ÛŒÛŒ Ù…Ø¹Ù†Ø§Ø¯Ø§Ø± Ø¨Ø§Ø´Ø¯ØŒ Ø«Ø¨Øª Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…\n",
        "                if price_change < -1 and rsi_change > 5:\n",
        "                    strength = 75 + min(25, abs(rsi_change - price_change) / 2)\n",
        "\n",
        "                    bullish_divergences.append({\n",
        "                        'index': i,\n",
        "                        'date': df_rsi.index[i],\n",
        "                        'price': df_rsi['close'].iloc[i],\n",
        "                        'rsi': df_rsi['rsi'].iloc[i],\n",
        "                        'strength': min(100, strength),\n",
        "                        'description': f'ÙˆØ§Ú¯Ø±Ø§ÛŒÛŒ Ù…Ø«Ø¨Øª RSI (Ù‚ÛŒÙ…Øª Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ±ØŒ RSI Ø¨Ø§Ù„Ø§ØªØ±)',\n",
        "                        'price_change': price_change,\n",
        "                        'rsi_change': rsi_change\n",
        "                    })\n",
        "\n",
        "            # ÙˆØ§Ú¯Ø±Ø§ÛŒÛŒ Ù…Ù†ÙÛŒ: Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ù„Ø§ØªØ± Ø§Ù…Ø§ RSI Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ± (Ù†Ø´Ø§Ù†Ù‡ ÙØ±ÙˆØ´)\n",
        "            if (df_rsi['high'].iloc[i] > df_rsi['high'].iloc[i - window:i].max() and\n",
        "                    df_rsi['rsi'].iloc[i] < df_rsi['rsi'].iloc[i - window:i].max()):\n",
        "\n",
        "                # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒØ²Ø§Ù† ÙˆØ§Ú¯Ø±Ø§ÛŒÛŒ\n",
        "                price_change = (df_rsi['high'].iloc[i] / df_rsi['high'].iloc[i - window:i].max() - 1) * 100\n",
        "                rsi_change = (df_rsi['rsi'].iloc[i] / df_rsi['rsi'].iloc[i - window:i].max() - 1) * 100\n",
        "\n",
        "                # Ø§Ú¯Ø± ÙˆØ§Ú¯Ø±Ø§ÛŒÛŒ Ù…Ø¹Ù†Ø§Ø¯Ø§Ø± Ø¨Ø§Ø´Ø¯ØŒ Ø«Ø¨Øª Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…\n",
        "                if price_change > 1 and rsi_change < -5:\n",
        "                    strength = 75 + min(25, abs(rsi_change - price_change) / 2)\n",
        "\n",
        "                    bearish_divergences.append({\n",
        "                        'index': i,\n",
        "                        'date': df_rsi.index[i],\n",
        "                        'price': df_rsi['close'].iloc[i],\n",
        "                        'rsi': df_rsi['rsi'].iloc[i],\n",
        "                        'strength': min(100, strength),\n",
        "                        'description': f'ÙˆØ§Ú¯Ø±Ø§ÛŒÛŒ Ù…Ù†ÙÛŒ RSI (Ù‚ÛŒÙ…Øª Ø¨Ø§Ù„Ø§ØªØ±ØŒ RSI Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ±)',\n",
        "                        'price_change': price_change,\n",
        "                        'rsi_change': rsi_change\n",
        "                    })\n",
        "\n",
        "        # ØªØ­Ù„ÛŒÙ„ ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ RSI\n",
        "        current_rsi = df_rsi['rsi'].iloc[-1]\n",
        "        current_rsi_status = 'Ø®Ù†Ø«ÛŒ'\n",
        "        current_signal_type = 'Ø®Ù†Ø«ÛŒ'\n",
        "        current_signal_strength = 50\n",
        "\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø§Ø®ÛŒØ±\n",
        "        if current_rsi > overbought:\n",
        "            current_rsi_status = 'Ø§Ø´Ø¨Ø§Ø¹ Ø®Ø±ÛŒØ¯'\n",
        "            current_signal_type = 'ÙØ±ÙˆØ´'\n",
        "            current_signal_strength = 70\n",
        "\n",
        "            # Ø§Ú¯Ø± RSI Ø¨Ø³ÛŒØ§Ø± Ø¨Ø§Ù„Ø§Ø³ØªØŒ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ù‚ÙˆÛŒâ€ŒØªØ± Ø§Ø³Øª\n",
        "            if current_rsi > 80:\n",
        "                current_signal_strength = 85\n",
        "                current_rsi_status = 'Ø§Ø´Ø¨Ø§Ø¹ Ø®Ø±ÛŒØ¯ Ø´Ø¯ÛŒØ¯'\n",
        "\n",
        "        elif current_rsi < oversold:\n",
        "            current_rsi_status = 'Ø§Ø´Ø¨Ø§Ø¹ ÙØ±ÙˆØ´'\n",
        "            current_signal_type = 'Ø®Ø±ÛŒØ¯'\n",
        "            current_signal_strength = 70\n",
        "\n",
        "            # Ø§Ú¯Ø± RSI Ø¨Ø³ÛŒØ§Ø± Ù¾Ø§ÛŒÛŒÙ† Ø§Ø³ØªØŒ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ù‚ÙˆÛŒâ€ŒØªØ± Ø§Ø³Øª\n",
        "            if current_rsi < 20:\n",
        "                current_signal_strength = 85\n",
        "                current_rsi_status = 'Ø§Ø´Ø¨Ø§Ø¹ ÙØ±ÙˆØ´ Ø´Ø¯ÛŒØ¯'\n",
        "\n",
        "        else:\n",
        "            # Ø¯Ø± Ù…Ù†Ø·Ù‚Ù‡ Ù…ÛŒØ§Ù†ÛŒØŒ Ø¨Ù‡ Ø±ÙˆÙ†Ø¯ RSI Ù†Ú¯Ø§Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…\n",
        "            rsi_trend = df_rsi['rsi'].iloc[-5:].mean() - df_rsi['rsi'].iloc[-10:-5].mean()\n",
        "\n",
        "            if rsi_trend > 3:\n",
        "                current_rsi_status = 'ØµØ¹ÙˆØ¯ÛŒ'\n",
        "                current_signal_type = 'Ø®Ø±ÛŒØ¯'\n",
        "                current_signal_strength = 60\n",
        "            elif rsi_trend < -3:\n",
        "                current_rsi_status = 'Ù†Ø²ÙˆÙ„ÛŒ'\n",
        "                current_signal_type = 'ÙØ±ÙˆØ´'\n",
        "                current_signal_strength = 60\n",
        "\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ø®ÛŒØ±\n",
        "        recent_bullish = [s for s in bullish_signals if len(df_rsi) - s['index'] <= 3]\n",
        "        recent_bearish = [s for s in bearish_signals if len(df_rsi) - s['index'] <= 3]\n",
        "\n",
        "        recent_bull_div = [s for s in bullish_divergences if len(df_rsi) - s['index'] <= 5]\n",
        "        recent_bear_div = [s for s in bearish_divergences if len(df_rsi) - s['index'] <= 5]\n",
        "\n",
        "        if recent_bullish:\n",
        "            current_signal_type = 'Ø®Ø±ÛŒØ¯'\n",
        "            current_signal_strength = max([s['strength'] for s in recent_bullish])\n",
        "        elif recent_bearish:\n",
        "            current_signal_type = 'ÙØ±ÙˆØ´'\n",
        "            current_signal_strength = max([s['strength'] for s in recent_bearish])\n",
        "\n",
        "        # ÙˆØ§Ú¯Ø±Ø§ÛŒÛŒâ€ŒÙ‡Ø§ Ø§ÙˆÙ„ÙˆÛŒØª Ø¨Ø§Ù„Ø§ØªØ±ÛŒ Ø¯Ø§Ø±Ù†Ø¯\n",
        "        if recent_bull_div:\n",
        "            current_signal_type = 'Ø®Ø±ÛŒØ¯'\n",
        "            current_signal_strength = max([s['strength'] for s in recent_bull_div])\n",
        "        elif recent_bear_div:\n",
        "            current_signal_type = 'ÙØ±ÙˆØ´'\n",
        "            current_signal_strength = max([s['strength'] for s in recent_bear_div])\n",
        "\n",
        "        # Ù†ØªØ§ÛŒØ¬ Ù†Ù‡Ø§ÛŒÛŒ\n",
        "        result = {\n",
        "            'current_rsi': current_rsi,\n",
        "            'current_status': current_rsi_status,\n",
        "            'current_signal_type': current_signal_type,\n",
        "            'current_signal_strength': current_signal_strength,\n",
        "            'bullish_signals': bullish_signals,\n",
        "            'bearish_signals': bearish_signals,\n",
        "            'bullish_divergences': bullish_divergences,\n",
        "            'bearish_divergences': bearish_divergences,\n",
        "            'dataframe': df_rsi\n",
        "        }\n",
        "\n",
        "        return result\n",
        "\n",
        "    def detect_divergence(self, df, indicator='rsi', period=14, window_size=20):\n",
        "        \"\"\"\n",
        "        ØªØ´Ø®ÛŒØµ ÙˆØ§Ú¯Ø±Ø§ÛŒÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ø®ÙÛŒ Ùˆ Ø¢Ø´Ú©Ø§Ø± Ø¨ÛŒÙ† Ù‚ÛŒÙ…Øª Ùˆ Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±\n",
        "\n",
        "        Args:\n",
        "            df: Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§\n",
        "            indicator: Ù†ÙˆØ¹ Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ± (rsi, macd, etc.)\n",
        "            period: Ø¯ÙˆØ±Ù‡ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±\n",
        "            window_size: Ø§Ù†Ø¯Ø§Ø²Ù‡ Ù¾Ù†Ø¬Ø±Ù‡ Ø¨Ø±Ø§ÛŒ Ø¬Ø³ØªØ¬ÙˆÛŒ ÙˆØ§Ú¯Ø±Ø§ÛŒÛŒ\n",
        "\n",
        "        Returns:\n",
        "            Ù†ØªØ§ÛŒØ¬ ØªØ´Ø®ÛŒØµ ÙˆØ§Ú¯Ø±Ø§ÛŒÛŒ\n",
        "        \"\"\"\n",
        "        # Ú©Ù¾ÛŒ Ø§Ø² Ø¯ÛŒØªØ§ÙØ±ÛŒÙ…\n",
        "        df_div = df.copy()\n",
        "\n",
        "        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ± Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø±\n",
        "        if indicator == 'rsi':\n",
        "            df_div['indicator'] = ta.momentum.rsi(df_div['close'], window=period)\n",
        "        elif indicator == 'macd':\n",
        "            df_div['indicator'] = ta.trend.macd(df_div['close'], window_slow=26, window_fast=12)\n",
        "        elif indicator == 'stoch':\n",
        "            df_div['indicator'] = ta.momentum.stoch(df_div['high'], df_div['low'], df_div['close'],\n",
        "                                                    window=5, smooth_window=3)\n",
        "        else:\n",
        "            df_div['indicator'] = ta.momentum.rsi(df_div['close'], window=period)\n",
        "\n",
        "        # ÛŒØ§ÙØªÙ† Ù†Ù‚Ø§Ø· Ø§ÙˆØ¬ Ùˆ Ø­Ø¶ÛŒØ¶ Ù…Ø­Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ù‚ÛŒÙ…Øª\n",
        "        df_div['price_high'] = df_div['close'].rolling(window=window_size, center=True).apply(\n",
        "            lambda x: 1 if x.iloc[window_size // 2] == max(x) else 0, raw=False)\n",
        "\n",
        "        df_div['price_low'] = df_div['close'].rolling(window=window_size, center=True).apply(\n",
        "            lambda x: 1 if x.iloc[window_size // 2] == min(x) else 0, raw=False)\n",
        "\n",
        "        # ÛŒØ§ÙØªÙ† Ù†Ù‚Ø§Ø· Ø§ÙˆØ¬ Ùˆ Ø­Ø¶ÛŒØ¶ Ù…Ø­Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±\n",
        "        df_div['ind_high'] = df_div['indicator'].rolling(window=window_size, center=True).apply(\n",
        "            lambda x: 1 if x.iloc[window_size // 2] == max(x) else 0, raw=False)\n",
        "\n",
        "        df_div['ind_low'] = df_div['indicator'].rolling(window=window_size, center=True).apply(\n",
        "            lambda x: 1 if x.iloc[window_size // 2] == min(x) else 0, raw=False)\n",
        "\n",
        "        # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ ÙˆØ§Ú¯Ø±Ø§ÛŒÛŒâ€ŒÙ‡Ø§\n",
        "        regular_bullish = []  # ÙˆØ§Ú¯Ø±Ø§ÛŒÛŒ ØµØ¹ÙˆØ¯ÛŒ Ø¹Ø§Ø¯ÛŒ\n",
        "        regular_bearish = []  # ÙˆØ§Ú¯Ø±Ø§ÛŒÛŒ Ù†Ø²ÙˆÙ„ÛŒ Ø¹Ø§Ø¯ÛŒ\n",
        "        hidden_bullish = []  # ÙˆØ§Ú¯Ø±Ø§ÛŒÛŒ ØµØ¹ÙˆØ¯ÛŒ Ù…Ø®ÙÛŒ\n",
        "        hidden_bearish = []  # ÙˆØ§Ú¯Ø±Ø§ÛŒÛŒ Ù†Ø²ÙˆÙ„ÛŒ Ù…Ø®ÙÛŒ\n",
        "\n",
        "        # Ù„ÛŒØ³Øª Ù†Ù‚Ø§Ø· Ø§ÙˆØ¬ Ùˆ Ø­Ø¶ÛŒØ¶ Ø¨Ø±Ø§ÛŒ Ù‚ÛŒÙ…Øª Ùˆ Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±\n",
        "        price_highs = []\n",
        "        price_lows = []\n",
        "        ind_highs = []\n",
        "        ind_lows = []\n",
        "\n",
        "        for i in range(window_size, len(df_div) - window_size):\n",
        "            if df_div['price_high'].iloc[i] == 1:\n",
        "                price_highs.append((i, df_div['close'].iloc[i]))\n",
        "            if df_div['price_low'].iloc[i] == 1:\n",
        "                price_lows.append((i, df_div['close'].iloc[i]))\n",
        "            if df_div['ind_high'].iloc[i] == 1:\n",
        "                ind_highs.append((i, df_div['indicator'].iloc[i]))\n",
        "            if df_div['ind_low'].iloc[i] == 1:\n",
        "                ind_lows.append((i, df_div['indicator'].iloc[i]))\n",
        "\n",
        "        # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ ÙˆØ§Ú¯Ø±Ø§ÛŒÛŒ ØµØ¹ÙˆØ¯ÛŒ Ø¹Ø§Ø¯ÛŒ (Regular Bullish)\n",
        "        # Ù‚ÛŒÙ…Øª: Ú©Ùâ€ŒÙ‡Ø§ÛŒ Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ±ØŒ Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±: Ú©Ùâ€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ù„Ø§ØªØ±\n",
        "        for i in range(1, len(price_lows)):\n",
        "            for j in range(1, len(ind_lows)):\n",
        "                # Ø§Ú¯Ø± ØªÙØ§ÙˆØª Ø²Ù…Ø§Ù†ÛŒ Ø¨ÛŒÙ† Ø¯Ùˆ Ù†Ù‚Ø·Ù‡ Ú©Ù…ØªØ± Ø§Ø² Ø­Ø¯ Ù…Ø¬Ø§Ø² Ø¨Ø§Ø´Ø¯\n",
        "                if abs(price_lows[i][0] - ind_lows[j][0]) <= window_size // 4:\n",
        "                    # Ú†Ú© Ú©Ø±Ø¯Ù† ÙˆØ§Ú¯Ø±Ø§ÛŒÛŒ ØµØ¹ÙˆØ¯ÛŒ Ø¹Ø§Ø¯ÛŒ\n",
        "                    if (i > 0 and j > 0 and\n",
        "                            price_lows[i][1] < price_lows[i - 1][1] and\n",
        "                            ind_lows[j][1] > ind_lows[j - 1][1]):\n",
        "                        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù‚Ø¯Ø±Øª ÙˆØ§Ú¯Ø±Ø§ÛŒÛŒ Ø¨Ø±Ø§Ø³Ø§Ø³ Ù…ÛŒØ²Ø§Ù† ØªÙØ§ÙˆØª\n",
        "                        price_change = (price_lows[i][1] / price_lows[i - 1][1] - 1) * 100\n",
        "                        ind_change = (ind_lows[j][1] / ind_lows[j - 1][1] - 1) * 100\n",
        "                        strength = min(100, 70 + abs(ind_change - price_change))\n",
        "\n",
        "                        regular_bullish.append({\n",
        "                            'price_idx1': price_lows[i - 1][0],\n",
        "                            'price_idx2': price_lows[i][0],\n",
        "                            'ind_idx1': ind_lows[j - 1][0],\n",
        "                            'ind_idx2': ind_lows[j][0],\n",
        "                            'price1': price_lows[i - 1][1],\n",
        "                            'price2': price_lows[i][1],\n",
        "                            'ind1': ind_lows[j - 1][1],\n",
        "                            'ind2': ind_lows[j][1],\n",
        "                            'strength': strength,\n",
        "                            'description': 'ÙˆØ§Ú¯Ø±Ø§ÛŒÛŒ ØµØ¹ÙˆØ¯ÛŒ Ø¹Ø§Ø¯ÛŒ (Ú©Ùâ€ŒÙ‡Ø§ÛŒ Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ± Ù‚ÛŒÙ…ØªØŒ Ú©Ùâ€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ù„Ø§ØªØ± Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±)'\n",
        "                        })\n",
        "\n",
        "        # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ ÙˆØ§Ú¯Ø±Ø§ÛŒÛŒ Ù†Ø²ÙˆÙ„ÛŒ Ø¹Ø§Ø¯ÛŒ (Regular Bearish)\n",
        "        # Ù‚ÛŒÙ…Øª: Ø³Ù‚Ùâ€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ù„Ø§ØªØ±ØŒ Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±: Ø³Ù‚Ùâ€ŒÙ‡Ø§ÛŒ Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ±\n",
        "        for i in range(1, len(price_highs)):\n",
        "            for j in range(1, len(ind_highs)):\n",
        "                # Ø§Ú¯Ø± ØªÙØ§ÙˆØª Ø²Ù…Ø§Ù†ÛŒ Ø¨ÛŒÙ† Ø¯Ùˆ Ù†Ù‚Ø·Ù‡ Ú©Ù…ØªØ± Ø§Ø² Ø­Ø¯ Ù…Ø¬Ø§Ø² Ø¨Ø§Ø´Ø¯\n",
        "                if abs(price_highs[i][0] - ind_highs[j][0]) <= window_size // 4:\n",
        "                    # Ú†Ú© Ú©Ø±Ø¯Ù† ÙˆØ§Ú¯Ø±Ø§ÛŒÛŒ Ù†Ø²ÙˆÙ„ÛŒ Ø¹Ø§Ø¯ÛŒ\n",
        "                    if (i > 0 and j > 0 and\n",
        "                            price_highs[i][1] > price_highs[i - 1][1] and\n",
        "                            ind_highs[j][1] < ind_highs[j - 1][1]):\n",
        "                        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù‚Ø¯Ø±Øª ÙˆØ§Ú¯Ø±Ø§ÛŒÛŒ Ø¨Ø±Ø§Ø³Ø§Ø³ Ù…ÛŒØ²Ø§Ù† ØªÙØ§ÙˆØª\n",
        "                        price_change = (price_highs[i][1] / price_highs[i - 1][1] - 1) * 100\n",
        "                        ind_change = (ind_highs[j][1] / ind_highs[j - 1][1] - 1) * 100\n",
        "                        strength = min(100, 70 + abs(ind_change - price_change))\n",
        "\n",
        "                        regular_bearish.append({\n",
        "                            'price_idx1': price_highs[i - 1][0],\n",
        "                            'price_idx2': price_highs[i][0],\n",
        "                            'ind_idx1': ind_highs[j - 1][0],\n",
        "                            'ind_idx2': ind_highs[j][0],\n",
        "                            'price1': price_highs[i - 1][1],\n",
        "                            'price2': price_highs[i][1],\n",
        "                            'ind1': ind_highs[j - 1][1],\n",
        "                            'ind2': ind_highs[j][1],\n",
        "                            'strength': strength,\n",
        "                            'description': 'ÙˆØ§Ú¯Ø±Ø§ÛŒÛŒ Ù†Ø²ÙˆÙ„ÛŒ Ø¹Ø§Ø¯ÛŒ (Ø³Ù‚Ùâ€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ù„Ø§ØªØ± Ù‚ÛŒÙ…ØªØŒ Ø³Ù‚Ùâ€ŒÙ‡Ø§ÛŒ Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ± Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±)'\n",
        "                        })\n",
        "\n",
        "        # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ ÙˆØ§Ú¯Ø±Ø§ÛŒÛŒ ØµØ¹ÙˆØ¯ÛŒ Ù…Ø®ÙÛŒ (Hidden Bullish)\n",
        "        # Ù‚ÛŒÙ…Øª: Ú©Ùâ€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ù„Ø§ØªØ±ØŒ Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±: Ú©Ùâ€ŒÙ‡Ø§ÛŒ Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ±\n",
        "        for i in range(1, len(price_lows)):\n",
        "            for j in range(1, len(ind_lows)):\n",
        "                # Ø§Ú¯Ø± ØªÙØ§ÙˆØª Ø²Ù…Ø§Ù†ÛŒ Ø¨ÛŒÙ† Ø¯Ùˆ Ù†Ù‚Ø·Ù‡ Ú©Ù…ØªØ± Ø§Ø² Ø­Ø¯ Ù…Ø¬Ø§Ø² Ø¨Ø§Ø´Ø¯\n",
        "                if abs(price_lows[i][0] - ind_lows[j][0]) <= window_size // 4:\n",
        "                    # Ú†Ú© Ú©Ø±Ø¯Ù† ÙˆØ§Ú¯Ø±Ø§ÛŒÛŒ ØµØ¹ÙˆØ¯ÛŒ Ù…Ø®ÙÛŒ\n",
        "                    if (i > 0 and j > 0 and\n",
        "                            price_lows[i][1] > price_lows[i - 1][1] and\n",
        "                            ind_lows[j][1] < ind_lows[j - 1][1]):\n",
        "                        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù‚Ø¯Ø±Øª ÙˆØ§Ú¯Ø±Ø§ÛŒÛŒ Ø¨Ø±Ø§Ø³Ø§Ø³ Ù…ÛŒØ²Ø§Ù† ØªÙØ§ÙˆØª\n",
        "                        price_change = (price_lows[i][1] / price_lows[i - 1][1] - 1) * 100\n",
        "                        ind_change = (ind_lows[j][1] / ind_lows[j - 1][1] - 1) * 100\n",
        "                        strength = min(100, 70 + abs(ind_change - price_change))\n",
        "\n",
        "                        hidden_bullish.append({\n",
        "                            'price_idx1': price_lows[i - 1][0],\n",
        "                            'price_idx2': price_lows[i][0],\n",
        "                            'ind_idx1': ind_lows[j - 1][0],\n",
        "                            'ind_idx2': ind_lows[j][0],\n",
        "                            'price1': price_lows[i - 1][1],\n",
        "                            'price2': price_lows[i][1],\n",
        "                            'ind1': ind_lows[j - 1][1],\n",
        "                            'ind2': ind_lows[j][1],\n",
        "                            'strength': strength,\n",
        "                            'description': 'ÙˆØ§Ú¯Ø±Ø§ÛŒÛŒ ØµØ¹ÙˆØ¯ÛŒ Ù…Ø®ÙÛŒ (Ú©Ùâ€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ù„Ø§ØªØ± Ù‚ÛŒÙ…ØªØŒ Ú©Ùâ€ŒÙ‡Ø§ÛŒ Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ± Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±)'\n",
        "                        })\n",
        "\n",
        "        # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ ÙˆØ§Ú¯Ø±Ø§ÛŒÛŒ Ù†Ø²ÙˆÙ„ÛŒ Ù…Ø®ÙÛŒ (Hidden Bearish)\n",
        "        # Ù‚ÛŒÙ…Øª: Ø³Ù‚Ùâ€ŒÙ‡Ø§ÛŒ Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ±ØŒ Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±: Ø³Ù‚Ùâ€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ù„Ø§ØªØ±\n",
        "        for i in range(1, len(price_highs)):\n",
        "            for j in range(1, len(ind_highs)):\n",
        "                # Ø§Ú¯Ø± ØªÙØ§ÙˆØª Ø²Ù…Ø§Ù†ÛŒ Ø¨ÛŒÙ† Ø¯Ùˆ Ù†Ù‚Ø·Ù‡ Ú©Ù…ØªØ± Ø§Ø² Ø­Ø¯ Ù…Ø¬Ø§Ø² Ø¨Ø§Ø´Ø¯\n",
        "                if abs(price_highs[i][0] - ind_highs[j][0]) <= window_size // 4:\n",
        "                    # Ú†Ú© Ú©Ø±Ø¯Ù† ÙˆØ§Ú¯Ø±Ø§ÛŒÛŒ Ù†Ø²ÙˆÙ„ÛŒ Ù…Ø®ÙÛŒ\n",
        "                    if (i > 0 and j > 0 and\n",
        "                            price_highs[i][1] < price_highs[i - 1][1] and\n",
        "                            ind_highs[j][1] > ind_highs[j - 1][1]):\n",
        "                        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù‚Ø¯Ø±Øª ÙˆØ§Ú¯Ø±Ø§ÛŒÛŒ Ø¨Ø±Ø§Ø³Ø§Ø³ Ù…ÛŒØ²Ø§Ù† ØªÙØ§ÙˆØª\n",
        "                        price_change = (price_highs[i][1] / price_highs[i - 1][1] - 1) * 100\n",
        "                        ind_change = (ind_highs[j][1] / ind_highs[j - 1][1] - 1) * 100\n",
        "                        strength = min(100, 70 + abs(ind_change - price_change))\n",
        "\n",
        "                        hidden_bearish.append({\n",
        "                            'price_idx1': price_highs[i - 1][0],\n",
        "                            'price_idx2': price_highs[i][0],\n",
        "                            'ind_idx1': ind_highs[j - 1][0],\n",
        "                            'ind_idx2': ind_highs[j][0],\n",
        "                            'price1': price_highs[i - 1][1],\n",
        "                            'price2': price_highs[i][1],\n",
        "                            'ind1': ind_highs[j - 1][1],\n",
        "                            'ind2': ind_highs[j][1],\n",
        "                            'strength': strength,\n",
        "                            'description': 'ÙˆØ§Ú¯Ø±Ø§ÛŒÛŒ Ù†Ø²ÙˆÙ„ÛŒ Ù…Ø®ÙÛŒ (Ø³Ù‚Ùâ€ŒÙ‡Ø§ÛŒ Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ± Ù‚ÛŒÙ…ØªØŒ Ø³Ù‚Ùâ€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ù„Ø§ØªØ± Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±)'\n",
        "                        })\n",
        "\n",
        "        # ØªØ¹ÛŒÛŒÙ† Ù†ÙˆØ¹ ÙˆØ§Ú¯Ø±Ø§ÛŒÛŒ Ø§Ø®ÛŒØ±\n",
        "        current_divergence = 'Ø¨Ø¯ÙˆÙ† ÙˆØ§Ú¯Ø±Ø§ÛŒÛŒ'\n",
        "        current_strength = 0\n",
        "        signal_type = 'Ø®Ù†Ø«ÛŒ'\n",
        "\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ§Ú¯Ø±Ø§ÛŒÛŒâ€ŒÙ‡Ø§ÛŒ Ø§Ø®ÛŒØ± (Ø¯Ø± 10 Ú©Ù†Ø¯Ù„ Ø¢Ø®Ø±)\n",
        "        recent_rb = [d for d in regular_bullish if d['price_idx2'] >= len(df_div) - 10]\n",
        "        recent_hb = [d for d in hidden_bullish if d['price_idx2'] >= len(df_div) - 10]\n",
        "        recent_rs = [d for d in regular_bearish if d['price_idx2'] >= len(df_div) - 10]\n",
        "        recent_hs = [d for d in hidden_bearish if d['price_idx2'] >= len(df_div) - 10]\n",
        "\n",
        "        if recent_rb:\n",
        "            current_divergence = 'ÙˆØ§Ú¯Ø±Ø§ÛŒÛŒ ØµØ¹ÙˆØ¯ÛŒ Ø¹Ø§Ø¯ÛŒ'\n",
        "            current_strength = max([d['strength'] for d in recent_rb])\n",
        "            signal_type = 'Ø®Ø±ÛŒØ¯'\n",
        "        elif recent_hb:\n",
        "            current_divergence = 'ÙˆØ§Ú¯Ø±Ø§ÛŒÛŒ ØµØ¹ÙˆØ¯ÛŒ Ù…Ø®ÙÛŒ'\n",
        "            current_strength = max([d['strength'] for d in recent_hb])\n",
        "            signal_type = 'Ø®Ø±ÛŒØ¯'\n",
        "        elif recent_rs:\n",
        "            current_divergence = 'ÙˆØ§Ú¯Ø±Ø§ÛŒÛŒ Ù†Ø²ÙˆÙ„ÛŒ Ø¹Ø§Ø¯ÛŒ'\n",
        "            current_strength = max([d['strength'] for d in recent_rs])\n",
        "            signal_type = 'ÙØ±ÙˆØ´'\n",
        "        elif recent_hs:\n",
        "            current_divergence = 'ÙˆØ§Ú¯Ø±Ø§ÛŒÛŒ Ù†Ø²ÙˆÙ„ÛŒ Ù…Ø®ÙÛŒ'\n",
        "            current_strength = max([d['strength'] for d in recent_hs])\n",
        "            signal_type = 'ÙØ±ÙˆØ´'\n",
        "\n",
        "        # Ù†ØªØ§ÛŒØ¬ Ù†Ù‡Ø§ÛŒÛŒ\n",
        "        result = {\n",
        "            'current_divergence': current_divergence,\n",
        "            'current_strength': current_strength,\n",
        "            'signal_type': signal_type,\n",
        "            'regular_bullish': regular_bullish,\n",
        "            'regular_bearish': regular_bearish,\n",
        "            'hidden_bullish': hidden_bullish,\n",
        "            'hidden_bearish': hidden_bearish,\n",
        "            'indicator_type': indicator,\n",
        "            'dataframe': df_div\n",
        "        }\n",
        "\n",
        "        return result\n",
        "\n",
        "    def analyze_bbrsi_macd_strategy(self, df):\n",
        "        \"\"\"\n",
        "        Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ ØªØ±Ú©ÛŒØ¨ÛŒ Ø¨Ø§Ù†Ø¯Ù‡Ø§ÛŒ Ø¨ÙˆÙ„ÛŒÙ†Ú¯Ø±ØŒ RSI Ùˆ MACD\n",
        "\n",
        "        Args:\n",
        "            df: Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§\n",
        "\n",
        "        Returns:\n",
        "            Ù†ØªØ§ÛŒØ¬ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ ØªØ±Ú©ÛŒØ¨ÛŒ\n",
        "        \"\"\"\n",
        "        # Ø§ÛŒØ¬Ø§Ø¯ Ú©Ù¾ÛŒ Ø§Ø² Ø¯ÛŒØªØ§ÙØ±ÛŒÙ…\n",
        "        df_combo = df.copy()\n",
        "\n",
        "        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¨Ø§Ù†Ø¯Ù‡Ø§ÛŒ Ø¨ÙˆÙ„ÛŒÙ†Ú¯Ø±\n",
        "        df_combo['bb_upper'] = ta.volatility.bollinger_hband(df_combo['close'], window=20, window_dev=2)\n",
        "        df_combo['bb_middle'] = ta.volatility.bollinger_mavg(df_combo['close'], window=20)\n",
        "        df_combo['bb_lower'] = ta.volatility.bollinger_lband(df_combo['close'], window=20, window_dev=2)\n",
        "\n",
        "        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¨Ø§Ù†Ø¯â€ŒÙ‡Ø§ÛŒ Ø¨ÙˆÙ„ÛŒÙ†Ú¯Ø± Ø¨Ø§ Ø§Ù†Ø­Ø±Ø§Ù Ù…Ø¹ÛŒØ§Ø± Ú©Ù…ØªØ± (1.5) Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ø¯Ù‚ÛŒÙ‚â€ŒØªØ±\n",
        "        df_combo['bb_upper_tight'] = ta.volatility.bollinger_hband(df_combo['close'], window=20, window_dev=1.5)\n",
        "        df_combo['bb_lower_tight'] = ta.volatility.bollinger_lband(df_combo['close'], window=20, window_dev=1.5)\n",
        "\n",
        "        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù¾Ù‡Ù†Ø§ÛŒ Ø¨Ø§Ù†Ø¯Ù‡Ø§ÛŒ Ø¨ÙˆÙ„ÛŒÙ†Ú¯Ø± (Ù†Ø´Ø§Ù†Ú¯Ø± Ù†ÙˆØ³Ø§Ù†)\n",
        "        df_combo['bb_width'] = (df_combo['bb_upper'] - df_combo['bb_lower']) / df_combo['bb_middle']\n",
        "\n",
        "        # Ù…Ø­Ø§Ø³Ø¨Ù‡ RSI\n",
        "        df_combo['rsi'] = ta.momentum.rsi(df_combo['close'], window=14)\n",
        "\n",
        "        # Ù…Ø­Ø§Ø³Ø¨Ù‡ MACD\n",
        "        df_combo['macd'] = ta.trend.macd(df_combo['close'], window_slow=26, window_fast=12)\n",
        "        df_combo['macd_signal'] = ta.trend.macd_signal(df_combo['close'], window_slow=26, window_fast=12, window_sign=9)\n",
        "        df_combo['macd_hist'] = df_combo['macd'] - df_combo['macd_signal']\n",
        "\n",
        "        # ØªØ´Ø®ÛŒØµ Ù‚ÛŒÙ…Øª Ù†Ø³Ø¨Øª Ø¨Ù‡ Ø¨Ø§Ù†Ø¯Ù‡Ø§ÛŒ Ø¨ÙˆÙ„ÛŒÙ†Ú¯Ø±\n",
        "        df_combo['price_above_upper'] = df_combo['close'] > df_combo['bb_upper']\n",
        "        df_combo['price_below_lower'] = df_combo['close'] < df_combo['bb_lower']\n",
        "        df_combo['price_above_upper_tight'] = df_combo['close'] > df_combo['bb_upper_tight']\n",
        "        df_combo['price_below_lower_tight'] = df_combo['close'] < df_combo['bb_lower_tight']\n",
        "\n",
        "        # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ ÙˆØ§Ú©Ù†Ø´ Ù‚ÛŒÙ…Øª Ø¨Ù‡ Ø¨Ø§Ù†Ø¯Ù‡Ø§\n",
        "        df_combo['reaction_lower'] = (df_combo['price_below_lower'].shift(1) & ~df_combo['price_below_lower'])\n",
        "        df_combo['reaction_upper'] = (df_combo['price_above_upper'].shift(1) & ~df_combo['price_above_upper'])\n",
        "\n",
        "        # ØªØ´Ø®ÛŒØµ Ø´Ø±Ø§ÛŒØ· Ø§Ø´Ø¨Ø§Ø¹ Ø®Ø±ÛŒØ¯/ÙØ±ÙˆØ´ RSI\n",
        "        df_combo['rsi_oversold'] = df_combo['rsi'] < 30\n",
        "        df_combo['rsi_overbought'] = df_combo['rsi'] > 70\n",
        "\n",
        "        # ØªØ´Ø®ÛŒØµ Ú©Ø±Ø§Ø³ MACD\n",
        "        df_combo['macd_bullish_cross'] = (df_combo['macd'] > df_combo['macd_signal']) & (\n",
        "                df_combo['macd'].shift(1) <= df_combo['macd_signal'].shift(1))\n",
        "        df_combo['macd_bearish_cross'] = (df_combo['macd'] < df_combo['macd_signal']) & (\n",
        "                df_combo['macd'].shift(1) >= df_combo['macd_signal'].shift(1))\n",
        "\n",
        "        # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù‡Ù…Ú¯Ø±Ø§ÛŒÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§\n",
        "\n",
        "        # Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø®Ø±ÛŒØ¯ Ù‚ÙˆÛŒ:\n",
        "        # 1. Ù‚ÛŒÙ…Øª Ø²ÛŒØ± Ø¨Ø§Ù†Ø¯ Ù¾Ø§ÛŒÛŒÙ† + RSI Ø§Ø´Ø¨Ø§Ø¹ ÙØ±ÙˆØ´ + MACD Ø¯Ø± Ø­Ø§Ù„ Ø§ÙØ²Ø§ÛŒØ´\n",
        "        df_combo['strong_buy'] = (\n",
        "                df_combo['price_below_lower'] &\n",
        "                df_combo['rsi_oversold'] &\n",
        "                (df_combo['macd_hist'] > df_combo['macd_hist'].shift(1))\n",
        "        )\n",
        "\n",
        "        # 2. ÙˆØ§Ú©Ù†Ø´ Ø¨Ù‡ Ø¨Ø§Ù†Ø¯ Ù¾Ø§ÛŒÛŒÙ† + RSI Ø§Ø² Ø§Ø´Ø¨Ø§Ø¹ ÙØ±ÙˆØ´ Ø®Ø§Ø±Ø¬ Ø´Ø¯Ù‡ + MACD Ú©Ø±Ø§Ø³ ØµØ¹ÙˆØ¯ÛŒ\n",
        "        df_combo['strong_buy2'] = (\n",
        "                df_combo['reaction_lower'] &\n",
        "                (df_combo['rsi'] > 30) & (df_combo['rsi'].shift(1) <= 30) &\n",
        "                df_combo['macd_bullish_cross']\n",
        "        )\n",
        "\n",
        "        # Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ ÙØ±ÙˆØ´ Ù‚ÙˆÛŒ:\n",
        "        # 1. Ù‚ÛŒÙ…Øª Ø¨Ø§Ù„Ø§ÛŒ Ø¨Ø§Ù†Ø¯ Ø¨Ø§Ù„Ø§ + RSI Ø§Ø´Ø¨Ø§Ø¹ Ø®Ø±ÛŒØ¯ + MACD Ø¯Ø± Ø­Ø§Ù„ Ú©Ø§Ù‡Ø´\n",
        "        df_combo['strong_sell'] = (\n",
        "                df_combo['price_above_upper'] &\n",
        "                df_combo['rsi_overbought'] &\n",
        "                (df_combo['macd_hist'] < df_combo['macd_hist'].shift(1))\n",
        "        )\n",
        "\n",
        "        # 2. ÙˆØ§Ú©Ù†Ø´ Ø¨Ù‡ Ø¨Ø§Ù†Ø¯ Ø¨Ø§Ù„Ø§ + RSI Ø§Ø² Ø§Ø´Ø¨Ø§Ø¹ Ø®Ø±ÛŒØ¯ Ø®Ø§Ø±Ø¬ Ø´Ø¯Ù‡ + MACD Ú©Ø±Ø§Ø³ Ù†Ø²ÙˆÙ„ÛŒ\n",
        "        df_combo['strong_sell2'] = (\n",
        "                df_combo['reaction_upper'] &\n",
        "                (df_combo['rsi'] < 70) & (df_combo['rsi'].shift(1) >= 70) &\n",
        "                df_combo['macd_bearish_cross']\n",
        "        )\n",
        "\n",
        "        # Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ù…ÛŒØ§Ù†Ù‡:\n",
        "        # Ø®Ø±ÛŒØ¯: Ù‚ÛŒÙ…Øª Ù†Ø²Ø¯ÛŒÚ© Ø¨Ø§Ù†Ø¯ Ù¾Ø§ÛŒÛŒÙ† + RSI Ø²ÛŒØ± 40 + MACD Ú©Ø±Ø§Ø³ ØµØ¹ÙˆØ¯ÛŒ\n",
        "        df_combo['moderate_buy'] = (\n",
        "                (df_combo['close'] < df_combo['bb_lower_tight']) &\n",
        "                (df_combo['rsi'] < 40) &\n",
        "                df_combo['macd_bullish_cross']\n",
        "        )\n",
        "\n",
        "        # ÙØ±ÙˆØ´: Ù‚ÛŒÙ…Øª Ù†Ø²Ø¯ÛŒÚ© Ø¨Ø§Ù†Ø¯ Ø¨Ø§Ù„Ø§ + RSI Ø¨Ø§Ù„Ø§ÛŒ 60 + MACD Ú©Ø±Ø§Ø³ Ù†Ø²ÙˆÙ„ÛŒ\n",
        "        df_combo['moderate_sell'] = (\n",
        "                (df_combo['close'] > df_combo['bb_upper_tight']) &\n",
        "                (df_combo['rsi'] > 60) &\n",
        "                df_combo['macd_bearish_cross']\n",
        "        )\n",
        "\n",
        "        # Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø®Ø±ÛŒØ¯\n",
        "        buy_signals = []\n",
        "        for i in range(50, len(df_combo)):\n",
        "            if df_combo['strong_buy'].iloc[i]:\n",
        "                buy_signals.append({\n",
        "                    'index': i,\n",
        "                    'date': df_combo.index[i],\n",
        "                    'price': df_combo['close'].iloc[i],\n",
        "                    'strength': 90,\n",
        "                    'description': 'Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø®Ø±ÛŒØ¯ Ù‚ÙˆÛŒ: Ù‚ÛŒÙ…Øª Ø²ÛŒØ± Ø¨Ø§Ù†Ø¯ Ù¾Ø§ÛŒÛŒÙ† + RSI Ø§Ø´Ø¨Ø§Ø¹ ÙØ±ÙˆØ´ + MACD Ø¯Ø± Ø­Ø§Ù„ Ø§ÙØ²Ø§ÛŒØ´',\n",
        "                    'type': 'strong_buy'\n",
        "                })\n",
        "            elif df_combo['strong_buy2'].iloc[i]:\n",
        "                buy_signals.append({\n",
        "                    'index': i,\n",
        "                    'date': df_combo.index[i],\n",
        "                    'price': df_combo['close'].iloc[i],\n",
        "                    'strength': 85,\n",
        "                    'description': 'Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø®Ø±ÛŒØ¯ Ù‚ÙˆÛŒ: ÙˆØ§Ú©Ù†Ø´ Ø¨Ù‡ Ø¨Ø§Ù†Ø¯ Ù¾Ø§ÛŒÛŒÙ† + Ø®Ø±ÙˆØ¬ Ø§Ø² Ø§Ø´Ø¨Ø§Ø¹ ÙØ±ÙˆØ´ RSI + Ú©Ø±Ø§Ø³ ØµØ¹ÙˆØ¯ÛŒ MACD',\n",
        "                    'type': 'strong_buy2'\n",
        "                })\n",
        "            elif df_combo['moderate_buy'].iloc[i]:\n",
        "                buy_signals.append({\n",
        "                    'index': i,\n",
        "                    'date': df_combo.index[i],\n",
        "                    'price': df_combo['close'].iloc[i],\n",
        "                    'strength': 75,\n",
        "                    'description': 'Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø®Ø±ÛŒØ¯ Ù…ØªÙˆØ³Ø·: Ù‚ÛŒÙ…Øª Ù†Ø²Ø¯ÛŒÚ© Ø¨Ø§Ù†Ø¯ Ù¾Ø§ÛŒÛŒÙ† + RSI Ø²ÛŒØ± 40 + Ú©Ø±Ø§Ø³ ØµØ¹ÙˆØ¯ÛŒ MACD',\n",
        "                    'type': 'moderate_buy'\n",
        "                })\n",
        "\n",
        "        # Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ ÙØ±ÙˆØ´\n",
        "        sell_signals = []\n",
        "        for i in range(50, len(df_combo)):\n",
        "            if df_combo['strong_sell'].iloc[i]:\n",
        "                sell_signals.append({\n",
        "                    'index': i,\n",
        "                    'date': df_combo.index[i],\n",
        "                    'price': df_combo['close'].iloc[i],\n",
        "                    'strength': 90,\n",
        "                    'description': 'Ø³ÛŒÚ¯Ù†Ø§Ù„ ÙØ±ÙˆØ´ Ù‚ÙˆÛŒ: Ù‚ÛŒÙ…Øª Ø¨Ø§Ù„Ø§ÛŒ Ø¨Ø§Ù†Ø¯ Ø¨Ø§Ù„Ø§ + RSI Ø§Ø´Ø¨Ø§Ø¹ Ø®Ø±ÛŒØ¯ + MACD Ø¯Ø± Ø­Ø§Ù„ Ú©Ø§Ù‡Ø´',\n",
        "                    'type': 'strong_sell'\n",
        "                })\n",
        "            elif df_combo['strong_sell2'].iloc[i]:\n",
        "                sell_signals.append({\n",
        "                    'index': i,\n",
        "                    'date': df_combo.index[i],\n",
        "                    'price': df_combo['close'].iloc[i],\n",
        "                    'strength': 85,\n",
        "                    'description': 'Ø³ÛŒÚ¯Ù†Ø§Ù„ ÙØ±ÙˆØ´ Ù‚ÙˆÛŒ: ÙˆØ§Ú©Ù†Ø´ Ø¨Ù‡ Ø¨Ø§Ù†Ø¯ Ø¨Ø§Ù„Ø§ + Ø®Ø±ÙˆØ¬ Ø§Ø² Ø§Ø´Ø¨Ø§Ø¹ Ø®Ø±ÛŒØ¯ RSI + Ú©Ø±Ø§Ø³ Ù†Ø²ÙˆÙ„ÛŒ MACD',\n",
        "                    'type': 'strong_sell2'\n",
        "                })\n",
        "            elif df_combo['moderate_sell'].iloc[i]:\n",
        "                sell_signals.append({\n",
        "                    'index': i,\n",
        "                    'date': df_combo.index[i],\n",
        "                    'price': df_combo['close'].iloc[i],\n",
        "                    'strength': 75,\n",
        "                    'description': 'Ø³ÛŒÚ¯Ù†Ø§Ù„ ÙØ±ÙˆØ´ Ù…ØªÙˆØ³Ø·: Ù‚ÛŒÙ…Øª Ù†Ø²Ø¯ÛŒÚ© Ø¨Ø§Ù†Ø¯ Ø¨Ø§Ù„Ø§ + RSI Ø¨Ø§Ù„Ø§ÛŒ 60 + Ú©Ø±Ø§Ø³ Ù†Ø²ÙˆÙ„ÛŒ MACD',\n",
        "                    'type': 'moderate_sell'\n",
        "                })\n",
        "\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ Ø´Ø±Ø§ÛŒØ· ÙØ¹Ù„ÛŒ\n",
        "        current_status = 'Ø®Ù†Ø«ÛŒ'\n",
        "        current_signal = 'Ø®Ù†Ø«ÛŒ'\n",
        "        current_strength = 50\n",
        "\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ Ø¢Ø®Ø±ÛŒÙ† ÙˆØ¶Ø¹ÛŒØª Ù†Ø´Ø§Ù†Ú¯Ø±Ù‡Ø§\n",
        "        last_idx = len(df_combo) - 1\n",
        "\n",
        "        # Ø´Ø±Ø§ÛŒØ· ÙØ¹Ù„ÛŒ Ø¨Ø§Ù†Ø¯Ù‡Ø§ÛŒ Ø¨ÙˆÙ„ÛŒÙ†Ú¯Ø±\n",
        "        if df_combo['price_above_upper'].iloc[last_idx]:\n",
        "            bb_status = 'Ø¨Ø§Ù„Ø§ÛŒ Ø¨Ø§Ù†Ø¯ Ø¨Ø§Ù„Ø§ÛŒÛŒ (Ø§Ø­ØªÙ…Ø§Ù„ Ø§Ø´Ø¨Ø§Ø¹ Ø®Ø±ÛŒØ¯)'\n",
        "            bb_signal = 'ÙØ±ÙˆØ´'\n",
        "            bb_strength = 70\n",
        "        elif df_combo['price_below_lower'].iloc[last_idx]:\n",
        "            bb_status = 'Ø²ÛŒØ± Ø¨Ø§Ù†Ø¯ Ù¾Ø§ÛŒÛŒÙ†ÛŒ (Ø§Ø­ØªÙ…Ø§Ù„ Ø§Ø´Ø¨Ø§Ø¹ ÙØ±ÙˆØ´)'\n",
        "            bb_signal = 'Ø®Ø±ÛŒØ¯'\n",
        "            bb_strength = 70\n",
        "        elif df_combo['price_above_upper_tight'].iloc[last_idx]:\n",
        "            bb_status = 'Ù†Ø²Ø¯ÛŒÚ© Ø¨Ù‡ Ø¨Ø§Ù†Ø¯ Ø¨Ø§Ù„Ø§ÛŒÛŒ'\n",
        "            bb_signal = 'ÙØ±ÙˆØ´'\n",
        "            bb_strength = 60\n",
        "        elif df_combo['price_below_lower_tight'].iloc[last_idx]:\n",
        "            bb_status = 'Ù†Ø²Ø¯ÛŒÚ© Ø¨Ù‡ Ø¨Ø§Ù†Ø¯ Ù¾Ø§ÛŒÛŒÙ†ÛŒ'\n",
        "            bb_signal = 'Ø®Ø±ÛŒØ¯'\n",
        "            bb_strength = 60\n",
        "        else:\n",
        "            bb_status = 'Ø¯Ø± Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ù…ÛŒØ§Ù†ÛŒ Ø¨Ø§Ù†Ø¯Ù‡Ø§'\n",
        "            bb_signal = 'Ø®Ù†Ø«ÛŒ'\n",
        "            bb_strength = 50\n",
        "\n",
        "        # Ø´Ø±Ø§ÛŒØ· ÙØ¹Ù„ÛŒ RSI\n",
        "        if df_combo['rsi'].iloc[last_idx] > 70:\n",
        "            rsi_status = 'Ø§Ø´Ø¨Ø§Ø¹ Ø®Ø±ÛŒØ¯'\n",
        "            rsi_signal = 'ÙØ±ÙˆØ´'\n",
        "            rsi_strength = 70\n",
        "        elif df_combo['rsi'].iloc[last_idx] < 30:\n",
        "            rsi_status = 'Ø§Ø´Ø¨Ø§Ø¹ ÙØ±ÙˆØ´'\n",
        "            rsi_signal = 'Ø®Ø±ÛŒØ¯'\n",
        "            rsi_strength = 70\n",
        "        elif df_combo['rsi'].iloc[last_idx] > 60:\n",
        "            rsi_status = 'Ø¨Ø§Ù„Ø§ (Ø§Ø­ØªÙ…Ø§Ù„ Ø±ÙˆÙ†Ø¯ ØµØ¹ÙˆØ¯ÛŒ)'\n",
        "            rsi_signal = 'ÙØ±ÙˆØ´'\n",
        "            rsi_strength = 60\n",
        "        elif df_combo['rsi'].iloc[last_idx] < 40:\n",
        "            rsi_status = 'Ù¾Ø§ÛŒÛŒÙ† (Ø§Ø­ØªÙ…Ø§Ù„ Ø±ÙˆÙ†Ø¯ Ù†Ø²ÙˆÙ„ÛŒ)'\n",
        "            rsi_signal = 'Ø®Ø±ÛŒØ¯'\n",
        "            rsi_strength = 60\n",
        "        else:\n",
        "            rsi_status = 'Ù…Ù†Ø·Ù‚Ù‡ Ù…ÛŒØ§Ù†ÛŒ'\n",
        "            rsi_signal = 'Ø®Ù†Ø«ÛŒ'\n",
        "            rsi_strength = 50\n",
        "\n",
        "        # Ø´Ø±Ø§ÛŒØ· ÙØ¹Ù„ÛŒ MACD\n",
        "        if df_combo['macd_bullish_cross'].iloc[last_idx]:\n",
        "            macd_status = 'Ú©Ø±Ø§Ø³ ØµØ¹ÙˆØ¯ÛŒ'\n",
        "            macd_signal = 'Ø®Ø±ÛŒØ¯'\n",
        "            macd_strength = 70\n",
        "        elif df_combo['macd_bearish_cross'].iloc[last_idx]:\n",
        "            macd_status = 'Ú©Ø±Ø§Ø³ Ù†Ø²ÙˆÙ„ÛŒ'\n",
        "            macd_signal = 'ÙØ±ÙˆØ´'\n",
        "            macd_strength = 70\n",
        "        elif df_combo['macd'].iloc[last_idx] > df_combo['macd_signal'].iloc[last_idx]:\n",
        "            macd_status = 'Ø¨Ø§Ù„Ø§ÛŒ Ø®Ø· Ø³ÛŒÚ¯Ù†Ø§Ù„ (Ø±ÙˆÙ†Ø¯ ØµØ¹ÙˆØ¯ÛŒ)'\n",
        "            macd_signal = 'Ø®Ø±ÛŒØ¯'\n",
        "            macd_strength = 60\n",
        "        else:\n",
        "            macd_status = 'Ø²ÛŒØ± Ø®Ø· Ø³ÛŒÚ¯Ù†Ø§Ù„ (Ø±ÙˆÙ†Ø¯ Ù†Ø²ÙˆÙ„ÛŒ)'\n",
        "            macd_signal = 'ÙØ±ÙˆØ´'\n",
        "            macd_strength = 60\n",
        "\n",
        "        # ØªØ¹ÛŒÛŒÙ† Ø³ÛŒÚ¯Ù†Ø§Ù„ Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ù‡Ù…Ú¯Ø±Ø§ÛŒÛŒ Ù†Ø´Ø§Ù†Ú¯Ø±Ù‡Ø§\n",
        "        if bb_signal == rsi_signal == macd_signal == 'Ø®Ø±ÛŒØ¯':\n",
        "            current_status = 'Ù‡Ù…Ú¯Ø±Ø§ÛŒÛŒ Ú©Ø§Ù…Ù„ Ù†Ø´Ø§Ù†Ú¯Ø±Ù‡Ø§ (Ø®Ø±ÛŒØ¯)'\n",
        "            current_signal = 'Ø®Ø±ÛŒØ¯'\n",
        "            current_strength = (bb_strength + rsi_strength + macd_strength) / 3 + 10\n",
        "        elif bb_signal == rsi_signal == macd_signal == 'ÙØ±ÙˆØ´':\n",
        "            current_status = 'Ù‡Ù…Ú¯Ø±Ø§ÛŒÛŒ Ú©Ø§Ù…Ù„ Ù†Ø´Ø§Ù†Ú¯Ø±Ù‡Ø§ (ÙØ±ÙˆØ´)'\n",
        "            current_signal = 'ÙØ±ÙˆØ´'\n",
        "            current_strength = (bb_strength + rsi_strength + macd_strength) / 3 + 10\n",
        "        elif bb_signal == rsi_signal == 'Ø®Ø±ÛŒØ¯' or bb_signal == macd_signal == 'Ø®Ø±ÛŒØ¯' or rsi_signal == macd_signal == 'Ø®Ø±ÛŒØ¯':\n",
        "            current_status = 'Ù‡Ù…Ú¯Ø±Ø§ÛŒÛŒ Ù†Ø³Ø¨ÛŒ Ù†Ø´Ø§Ù†Ú¯Ø±Ù‡Ø§ (Ø®Ø±ÛŒØ¯)'\n",
        "            current_signal = 'Ø®Ø±ÛŒØ¯'\n",
        "            current_strength = (bb_strength + rsi_strength + macd_strength) / 3 + 5\n",
        "        elif bb_signal == rsi_signal == 'ÙØ±ÙˆØ´' or bb_signal == macd_signal == 'ÙØ±ÙˆØ´' or rsi_signal == macd_signal == 'ÙØ±ÙˆØ´':\n",
        "            current_status = 'Ù‡Ù…Ú¯Ø±Ø§ÛŒÛŒ Ù†Ø³Ø¨ÛŒ Ù†Ø´Ø§Ù†Ú¯Ø±Ù‡Ø§ (ÙØ±ÙˆØ´)'\n",
        "            current_signal = 'ÙØ±ÙˆØ´'\n",
        "            current_strength = (bb_strength + rsi_strength + macd_strength) / 3 + 5\n",
        "\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ø®ÛŒØ±\n",
        "        recent_buy = [s for s in buy_signals if len(df_combo) - s['index'] <= 3]\n",
        "        recent_sell = [s for s in sell_signals if len(df_combo) - s['index'] <= 3]\n",
        "\n",
        "        if recent_buy:\n",
        "            current_signal = 'Ø®Ø±ÛŒØ¯'\n",
        "            current_strength = max([s['strength'] for s in recent_buy])\n",
        "            current_status = 'Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø§Ø®ÛŒØ± Ø®Ø±ÛŒØ¯ - ' + max(recent_buy, key=lambda x: x['strength'])['description']\n",
        "        elif recent_sell:\n",
        "            current_signal = 'ÙØ±ÙˆØ´'\n",
        "            current_strength = max([s['strength'] for s in recent_sell])\n",
        "            current_status = 'Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø§Ø®ÛŒØ± ÙØ±ÙˆØ´ - ' + max(recent_sell, key=lambda x: x['strength'])['description']\n",
        "\n",
        "        # ØªØ¹ÛŒÛŒÙ† Ù†Ù‚Ø§Ø· ÙˆØ±ÙˆØ¯ Ùˆ Ø®Ø±ÙˆØ¬\n",
        "        entry_points = []\n",
        "        exit_points = []\n",
        "\n",
        "        for signal in buy_signals:\n",
        "            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø­Ø¯ Ø¶Ø±Ø± Ùˆ Ø­Ø¯ Ø³ÙˆØ¯ Ø¨Ø±Ø§ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø®Ø±ÛŒØ¯\n",
        "            stop_loss = signal['price'] * 0.97  # 3% Ø²ÛŒØ± Ù‚ÛŒÙ…Øª ÙˆØ±ÙˆØ¯\n",
        "            take_profit = signal['price'] * 1.06  # 6% Ø¨Ø§Ù„Ø§ÛŒ Ù‚ÛŒÙ…Øª ÙˆØ±ÙˆØ¯\n",
        "\n",
        "            entry_points.append({\n",
        "                'index': signal['index'],\n",
        "                'price': signal['price'],\n",
        "                'stop_loss': stop_loss,\n",
        "                'take_profit': take_profit,\n",
        "                'type': 'long',\n",
        "                'strength': signal['strength']\n",
        "            })\n",
        "\n",
        "        for signal in sell_signals:\n",
        "            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø­Ø¯ Ø¶Ø±Ø± Ùˆ Ø­Ø¯ Ø³ÙˆØ¯ Ø¨Ø±Ø§ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ ÙØ±ÙˆØ´\n",
        "            stop_loss = signal['price'] * 1.03  # 3% Ø¨Ø§Ù„Ø§ÛŒ Ù‚ÛŒÙ…Øª ÙˆØ±ÙˆØ¯\n",
        "            take_profit = signal['price'] * 0.94  # 6% Ø²ÛŒØ± Ù‚ÛŒÙ…Øª ÙˆØ±ÙˆØ¯\n",
        "\n",
        "            entry_points.append({\n",
        "                'index': signal['index'],\n",
        "                'price': signal['price'],\n",
        "                'stop_loss': stop_loss,\n",
        "                'take_profit': take_profit,\n",
        "                'type': 'short',\n",
        "                'strength': signal['strength']\n",
        "            })\n",
        "\n",
        "        # Ø®Ø±ÙˆØ¬: ÙˆØ§Ú©Ù†Ø´ Ù‚ÛŒÙ…Øª Ø¨Ù‡ Ø¨Ø§Ù†Ø¯Ù‡Ø§ ÛŒØ§ ØªØºÛŒÛŒØ± ÙˆØ¶Ø¹ÛŒØª MACD\n",
        "        for i in range(50, len(df_combo)):\n",
        "            if df_combo['reaction_upper'].iloc[i] or df_combo['macd_bearish_cross'].iloc[i]:\n",
        "                exit_points.append({\n",
        "                    'index': i,\n",
        "                    'price': df_combo['close'].iloc[i],\n",
        "                    'type': 'exit_long'\n",
        "                })\n",
        "\n",
        "            if df_combo['reaction_lower'].iloc[i] or df_combo['macd_bullish_cross'].iloc[i]:\n",
        "                exit_points.append({\n",
        "                    'index': i,\n",
        "                    'price': df_combo['close'].iloc[i],\n",
        "                    'type': 'exit_short'\n",
        "                })\n",
        "\n",
        "        # Ù†ØªØ§ÛŒØ¬ Ù†Ù‡Ø§ÛŒÛŒ\n",
        "        result = {\n",
        "            'current_status': current_status,\n",
        "            'current_signal': current_signal,\n",
        "            'current_strength': min(100, current_strength),\n",
        "            'indicator_status': {\n",
        "                'bollinger': bb_status,\n",
        "                'rsi': rsi_status,\n",
        "                'macd': macd_status\n",
        "            },\n",
        "            'buy_signals': buy_signals,\n",
        "            'sell_signals': sell_signals,\n",
        "            'entry_points': entry_points,\n",
        "            'exit_points': exit_points,\n",
        "            'dataframe': df_combo\n",
        "        }\n",
        "\n",
        "        return result\n",
        "\n",
        "    def analyze_darvas_box(self, df, lookback_period=20, breakout_threshold=0.02):\n",
        "        \"\"\"\n",
        "        ØªØ­Ù„ÛŒÙ„ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø¬Ø¹Ø¨Ù‡ Ø¯Ø§Ø±ÙˆØ§Ø³ (Darvas Box)\n",
        "\n",
        "        Args:\n",
        "            df: Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§\n",
        "            lookback_period: Ø¯ÙˆØ±Ù‡ Ø¨Ø±Ø±Ø³ÛŒ Ø¨Ø±Ø§ÛŒ ÛŒØ§ÙØªÙ† Ø³Ù‚Ù Ùˆ Ú©Ù\n",
        "            breakout_threshold: Ø¢Ø³ØªØ§Ù†Ù‡ Ø´Ú©Ø³Øª Ù…Ø³ØªØ·ÛŒÙ„ (Ø¯Ø±ØµØ¯)\n",
        "\n",
        "        Returns:\n",
        "            Ù†ØªØ§ÛŒØ¬ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø¬Ø¹Ø¨Ù‡ Ø¯Ø§Ø±ÙˆØ§Ø³\n",
        "        \"\"\"\n",
        "        # Ø§ÛŒØ¬Ø§Ø¯ Ú©Ù¾ÛŒ Ø§Ø² Ø¯ÛŒØªØ§ÙØ±ÛŒÙ…\n",
        "        df_darvas = df.copy()\n",
        "\n",
        "        # Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¬Ø¹Ø¨Ù‡ Ø¯Ø§Ø±ÙˆØ§Ø³\n",
        "        df_darvas['darvas_top'] = np.nan\n",
        "        df_darvas['darvas_bottom'] = np.nan\n",
        "        df_darvas['box_active'] = False\n",
        "        df_darvas['box_breakout_up'] = False\n",
        "        df_darvas['box_breakout_down'] = False\n",
        "\n",
        "        # ÛŒØ§ÙØªÙ† Ø§ÙˆØ¬â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯\n",
        "        df_darvas['new_high'] = df_darvas['high'].rolling(window=lookback_period).max() == df_darvas['high']\n",
        "\n",
        "        # ÛŒØ§ÙØªÙ† Ú©Ùâ€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯\n",
        "        df_darvas['new_low'] = df_darvas['low'].rolling(window=lookback_period).min() == df_darvas['low']\n",
        "\n",
        "        # Ø§ÙØ²ÙˆØ¯Ù† Ø­Ø¬Ù… Ø¨Ù‡ ØªØ­Ù„ÛŒÙ„ (Ù‚ÙˆØª Ø¨ÛŒØ´ØªØ± Ø¨Ù‡ Ø´Ú©Ø³Øªâ€ŒÙ‡Ø§)\n",
        "        df_darvas['volume_sma10'] = df_darvas['volume'].rolling(window=10).mean()\n",
        "        df_darvas['high_volume'] = df_darvas['volume'] > df_darvas['volume_sma10'] * 1.5\n",
        "\n",
        "        # Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¬Ø¹Ø¨Ù‡â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ø±ÙˆØ§Ø³\n",
        "        darvas_boxes = []\n",
        "        active_box = None\n",
        "\n",
        "        # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø¬Ø¹Ø¨Ù‡â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ø±ÙˆØ§Ø³\n",
        "        for i in range(lookback_period, len(df_darvas)):\n",
        "            # Ø§Ú¯Ø± Ø¬Ø¹Ø¨Ù‡ ÙØ¹Ø§Ù„ Ø¯Ø§Ø±ÛŒÙ…\n",
        "            if active_box:\n",
        "                current_price = df_darvas['close'].iloc[i]\n",
        "\n",
        "                # Ø¨Ø±Ø±Ø³ÛŒ Ø´Ú©Ø³Øª Ø§Ø² Ø¨Ø§Ù„Ø§ÛŒ Ø¬Ø¹Ø¨Ù‡\n",
        "                if current_price > active_box['top'] * (1 + breakout_threshold):\n",
        "                    # Ø´Ú©Ø³Øª ØµØ¹ÙˆØ¯ÛŒ\n",
        "                    df_darvas['box_breakout_up'].iloc[i] = True\n",
        "\n",
        "                    # Ø§Ú¯Ø± Ø­Ø¬Ù… Ø¨Ø§Ù„Ø§Ø³ØªØŒ Ø§Ø¹ØªØ¨Ø§Ø± Ø´Ú©Ø³Øª Ø¨ÛŒØ´ØªØ± Ø§Ø³Øª\n",
        "                    breakout_strength = 80\n",
        "                    if df_darvas['high_volume'].iloc[i]:\n",
        "                        breakout_strength = 90\n",
        "\n",
        "                    # Ø§ÙØ²ÙˆØ¯Ù† Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø´Ú©Ø³Øª\n",
        "                    darvas_boxes.append({\n",
        "                        'box_start_idx': active_box['start_idx'],\n",
        "                        'box_end_idx': i,\n",
        "                        'top': active_box['top'],\n",
        "                        'bottom': active_box['bottom'],\n",
        "                        'breakout_idx': i,\n",
        "                        'breakout_price': current_price,\n",
        "                        'breakout_direction': 'up',\n",
        "                        'strength': breakout_strength,\n",
        "                        'entry_price': current_price,\n",
        "                        'stop_loss': active_box['bottom'],\n",
        "                        'take_profit': current_price + (active_box['top'] - active_box['bottom']) * 1.5\n",
        "                    })\n",
        "\n",
        "                    # Ø¬Ø¹Ø¨Ù‡ Ø¬Ø¯ÛŒØ¯ Ø¨Ø§ Ú©Ù Ù‚Ø¨Ù„ÛŒ\n",
        "                    active_box = {\n",
        "                        'start_idx': i,\n",
        "                        'top': current_price,\n",
        "                        'bottom': active_box['bottom'],\n",
        "                        'duration': 0\n",
        "                    }\n",
        "\n",
        "                # Ø¨Ø±Ø±Ø³ÛŒ Ø´Ú©Ø³Øª Ø§Ø² Ù¾Ø§ÛŒÛŒÙ† Ø¬Ø¹Ø¨Ù‡\n",
        "                elif current_price < active_box['bottom'] * (1 - breakout_threshold):\n",
        "                    # Ø´Ú©Ø³Øª Ù†Ø²ÙˆÙ„ÛŒ\n",
        "                    df_darvas['box_breakout_down'].iloc[i] = True\n",
        "\n",
        "                    # Ø§Ú¯Ø± Ø­Ø¬Ù… Ø¨Ø§Ù„Ø§Ø³ØªØŒ Ø§Ø¹ØªØ¨Ø§Ø± Ø´Ú©Ø³Øª Ø¨ÛŒØ´ØªØ± Ø§Ø³Øª\n",
        "                    breakout_strength = 80\n",
        "                    if df_darvas['high_volume'].iloc[i]:\n",
        "                        breakout_strength = 90\n",
        "\n",
        "                    # Ø§ÙØ²ÙˆØ¯Ù† Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø´Ú©Ø³Øª\n",
        "                    darvas_boxes.append({\n",
        "                        'box_start_idx': active_box['start_idx'],\n",
        "                        'box_end_idx': i,\n",
        "                        'top': active_box['top'],\n",
        "                        'bottom': active_box['bottom'],\n",
        "                        'breakout_idx': i,\n",
        "                        'breakout_price': current_price,\n",
        "                        'breakout_direction': 'down',\n",
        "                        'strength': breakout_strength,\n",
        "                        'entry_price': current_price,\n",
        "                        'stop_loss': active_box['top'],\n",
        "                        'take_profit': current_price - (active_box['top'] - active_box['bottom']) * 1.5\n",
        "                    })\n",
        "\n",
        "                    # Ø¬Ø¹Ø¨Ù‡ Ø¬Ø¯ÛŒØ¯ Ø¨Ø§ Ø³Ù‚Ù Ù‚Ø¨Ù„ÛŒ\n",
        "                    active_box = {\n",
        "                        'start_idx': i,\n",
        "                        'top': active_box['top'],\n",
        "                        'bottom': current_price,\n",
        "                        'duration': 0\n",
        "                    }\n",
        "\n",
        "                # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø¬Ø¹Ø¨Ù‡ ÙØ¹Ù„ÛŒ\n",
        "                else:\n",
        "                    active_box['duration'] += 1\n",
        "\n",
        "                    # Ø°Ø®ÛŒØ±Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¬Ø¹Ø¨Ù‡ Ø¯Ø± Ø¯ÛŒØªØ§ÙØ±ÛŒÙ…\n",
        "                    df_darvas['darvas_top'].iloc[i] = active_box['top']\n",
        "                    df_darvas['darvas_bottom'].iloc[i] = active_box['bottom']\n",
        "                    df_darvas['box_active'].iloc[i] = True\n",
        "\n",
        "            # Ø§Ú¯Ø± Ø¬Ø¹Ø¨Ù‡ ÙØ¹Ø§Ù„ Ù†Ø¯Ø§Ø±ÛŒÙ… Ùˆ ÛŒÚ© Ø§ÙˆØ¬ Ø¬Ø¯ÛŒØ¯ Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯ÛŒÙ…\n",
        "            elif df_darvas['new_high'].iloc[i]:\n",
        "                active_box = {\n",
        "                    'start_idx': i,\n",
        "                    'top': df_darvas['high'].iloc[i],\n",
        "                    'bottom': df_darvas['low'].iloc[max(0, i - 5):i + 1].min(),  # Ú©Ù Ø¯Ø± 5 Ú©Ù†Ø¯Ù„ Ø§Ø®ÛŒØ±\n",
        "                    'duration': 0\n",
        "                }\n",
        "\n",
        "                # Ø°Ø®ÛŒØ±Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¬Ø¹Ø¨Ù‡ Ø¯Ø± Ø¯ÛŒØªØ§ÙØ±ÛŒÙ…\n",
        "                df_darvas['darvas_top'].iloc[i] = active_box['top']\n",
        "                df_darvas['darvas_bottom'].iloc[i] = active_box['bottom']\n",
        "                df_darvas['box_active'].iloc[i] = True\n",
        "\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ\n",
        "        current_signal = 'Ø®Ù†Ø«ÛŒ'\n",
        "        current_strength = 50\n",
        "\n",
        "        # Ø§Ú¯Ø± Ø¢Ø®Ø±ÛŒÙ† Ø´Ú©Ø³Øª Ø¯Ø± 5 Ú©Ù†Ø¯Ù„ Ø§Ø®ÛŒØ± Ø¨Ø§Ø´Ø¯ØŒ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø±Ø§ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…\n",
        "        if darvas_boxes:\n",
        "            last_box = darvas_boxes[-1]\n",
        "            if len(df_darvas) - last_box['breakout_idx'] <= 5:\n",
        "                if last_box['breakout_direction'] == 'up':\n",
        "                    current_signal = 'Ø®Ø±ÛŒØ¯'\n",
        "                    current_strength = last_box['strength']\n",
        "                else:\n",
        "                    current_signal = 'ÙØ±ÙˆØ´'\n",
        "                    current_strength = last_box['strength']\n",
        "\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ Ù‚ÛŒÙ…Øª ÙØ¹Ù„ÛŒ Ù†Ø²Ø¯ÛŒÚ© Ù„Ø¨Ù‡ ÛŒÚ© Ø¬Ø¹Ø¨Ù‡ ÙØ¹Ø§Ù„ Ø§Ø³Øª\n",
        "        last_idx = len(df_darvas) - 1\n",
        "        if df_darvas['box_active'].iloc[last_idx]:\n",
        "            top = df_darvas['darvas_top'].iloc[last_idx]\n",
        "            bottom = df_darvas['darvas_bottom'].iloc[last_idx]\n",
        "            current_price = df_darvas['close'].iloc[last_idx]\n",
        "\n",
        "            # Ø§Ú¯Ø± Ù‚ÛŒÙ…Øª Ù†Ø²Ø¯ÛŒÚ© Ø³Ù‚Ù Ø¬Ø¹Ø¨Ù‡ Ø§Ø³Øª (Ø§Ø­ØªÙ…Ø§Ù„ Ø´Ú©Ø³Øª ØµØ¹ÙˆØ¯ÛŒ)\n",
        "            if current_price > top * 0.98:\n",
        "                if current_signal == 'Ø®Ù†Ø«ÛŒ':\n",
        "                    current_signal = 'Ø®Ø±ÛŒØ¯'\n",
        "                    current_strength = 70\n",
        "\n",
        "            # Ø§Ú¯Ø± Ù‚ÛŒÙ…Øª Ù†Ø²Ø¯ÛŒÚ© Ú©Ù Ø¬Ø¹Ø¨Ù‡ Ø§Ø³Øª (Ø§Ø­ØªÙ…Ø§Ù„ Ø´Ú©Ø³Øª Ù†Ø²ÙˆÙ„ÛŒ)\n",
        "            elif current_price < bottom * 1.02:\n",
        "                if current_signal == 'Ø®Ù†Ø«ÛŒ':\n",
        "                    current_signal = 'ÙØ±ÙˆØ´'\n",
        "                    current_strength = 70\n",
        "\n",
        "        # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù†Ù‚Ø§Ø· ÙˆØ±ÙˆØ¯ Ùˆ Ø®Ø±ÙˆØ¬\n",
        "        entry_points = []\n",
        "        for box in darvas_boxes:\n",
        "            entry_type = 'long' if box['breakout_direction'] == 'up' else 'short'\n",
        "            entry_points.append({\n",
        "                'index': box['breakout_idx'],\n",
        "                'price': box['entry_price'],\n",
        "                'stop_loss': box['stop_loss'],\n",
        "                'take_profit': box['take_profit'],\n",
        "                'type': entry_type,\n",
        "                'strength': box['strength']\n",
        "            })\n",
        "\n",
        "        # Ù†ØªØ§ÛŒØ¬ Ù†Ù‡Ø§ÛŒÛŒ\n",
        "        result = {\n",
        "            'current_signal': current_signal,\n",
        "            'current_strength': current_strength,\n",
        "            'darvas_boxes': darvas_boxes,\n",
        "            'entry_points': entry_points,\n",
        "            'dataframe': df_darvas\n",
        "        }\n",
        "\n",
        "        return result\n",
        "\n",
        "    def analyze_ichimoku(self, df):\n",
        "        \"\"\"\n",
        "        Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø§ÛŒÚ†ÛŒÙ…ÙˆÚ©Ùˆ (Ichimoku Kinko Hyo)\n",
        "\n",
        "        Args:\n",
        "            df: Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§\n",
        "\n",
        "        Returns:\n",
        "            Ù†ØªØ§ÛŒØ¬ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø§ÛŒÚ†ÛŒÙ…ÙˆÚ©Ùˆ\n",
        "        \"\"\"\n",
        "        # Ø§ÛŒØ¬Ø§Ø¯ Ú©Ù¾ÛŒ Ø§Ø² Ø¯ÛŒØªØ§ÙØ±ÛŒÙ…\n",
        "        df_ichimoku = df.copy()\n",
        "\n",
        "        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø®Ø·ÙˆØ· Ø§ÛŒÚ†ÛŒÙ…ÙˆÚ©Ùˆ\n",
        "        # ØªÙ†Ú©Ø§Ù†-Ø³Ù† (Tenkan-sen) - Ø®Ø· ØªØ¨Ø¯ÛŒÙ„ - Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø¨Ø§Ù„Ø§ØªØ±ÛŒÙ† Ø¨Ø§Ù„Ø§ Ùˆ Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ±ÛŒÙ† Ù¾Ø§ÛŒÛŒÙ† Ø¯Ø± 9 Ú©Ù†Ø¯Ù„ Ø§Ø®ÛŒØ±\n",
        "        high_9 = df_ichimoku['high'].rolling(window=9).max()\n",
        "        low_9 = df_ichimoku['low'].rolling(window=9).min()\n",
        "        df_ichimoku['tenkan_sen'] = (high_9 + low_9) / 2\n",
        "\n",
        "        # Ú©ÛŒØ¬ÙˆÙ†-Ø³Ù† (Kijun-sen) - Ø®Ø· Ù¾Ø§ÛŒÙ‡ - Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø¨Ø§Ù„Ø§ØªØ±ÛŒÙ† Ø¨Ø§Ù„Ø§ Ùˆ Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ±ÛŒÙ† Ù¾Ø§ÛŒÛŒÙ† Ø¯Ø± 26 Ú©Ù†Ø¯Ù„ Ø§Ø®ÛŒØ±\n",
        "        high_26 = df_ichimoku['high'].rolling(window=26).max()\n",
        "        low_26 = df_ichimoku['low'].rolling(window=26).min()\n",
        "        df_ichimoku['kijun_sen'] = (high_26 + low_26) / 2\n",
        "\n",
        "        # Ø³Ù†Ú©Ùˆ Ø§Ø³Ù¾Ù† A (Senkou Span A) - Ø®Ø· Ø§ÙˆÙ„ Ø§Ø¨Ø± - Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† ØªÙ†Ú©Ø§Ù†-Ø³Ù† Ùˆ Ú©ÛŒØ¬ÙˆÙ†-Ø³Ù†ØŒ Ø±Ø³Ù… Ø´Ø¯Ù‡ 26 Ú©Ù†Ø¯Ù„ Ø¬Ù„ÙˆØªØ±\n",
        "        df_ichimoku['senkou_span_a'] = ((df_ichimoku['tenkan_sen'] + df_ichimoku['kijun_sen']) / 2).shift(26)\n",
        "\n",
        "        # Ø³Ù†Ú©Ùˆ Ø§Ø³Ù¾Ù† B (Senkou Span B) - Ø®Ø· Ø¯ÙˆÙ… Ø§Ø¨Ø± - Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø¨Ø§Ù„Ø§ØªØ±ÛŒÙ† Ø¨Ø§Ù„Ø§ Ùˆ Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ±ÛŒÙ† Ù¾Ø§ÛŒÛŒÙ† Ø¯Ø± 52 Ú©Ù†Ø¯Ù„ Ø§Ø®ÛŒØ±ØŒ Ø±Ø³Ù… Ø´Ø¯Ù‡ 26 Ú©Ù†Ø¯Ù„ Ø¬Ù„ÙˆØªØ±\n",
        "        high_52 = df_ichimoku['high'].rolling(window=52).max()\n",
        "        low_52 = df_ichimoku['low'].rolling(window=52).min()\n",
        "        df_ichimoku['senkou_span_b'] = ((high_52 + low_52) / 2).shift(26)\n",
        "\n",
        "        # Ú†ÛŒÚ©Ùˆ Ø§Ø³Ù¾Ù† (Chikou Span) - Ø®Ø· ØªØ£Ø®ÛŒØ±ÛŒ - Ù‚ÛŒÙ…Øª Ø¨Ø³ØªÙ‡ Ø´Ø¯Ù†ØŒ Ø±Ø³Ù… Ø´Ø¯Ù‡ 26 Ú©Ù†Ø¯Ù„ Ø¹Ù‚Ø¨â€ŒØªØ±\n",
        "        df_ichimoku['chikou_span'] = df_ichimoku['close'].shift(-26)\n",
        "\n",
        "        # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ú©Ø±Ø§Ø³ ØªÙ†Ú©Ø§Ù†-Ø³Ù† Ùˆ Ú©ÛŒØ¬ÙˆÙ†-Ø³Ù† (Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø¹Ø§Ù…Ù„Ù‡)\n",
        "        df_ichimoku['tenkan_cross_above_kijun'] = (\n",
        "                (df_ichimoku['tenkan_sen'] > df_ichimoku['kijun_sen']) &\n",
        "                (df_ichimoku['tenkan_sen'].shift(1) <= df_ichimoku['kijun_sen'].shift(1))\n",
        "        )\n",
        "\n",
        "        df_ichimoku['tenkan_cross_below_kijun'] = (\n",
        "                (df_ichimoku['tenkan_sen'] < df_ichimoku['kijun_sen']) &\n",
        "                (df_ichimoku['tenkan_sen'].shift(1) >= df_ichimoku['kijun_sen'].shift(1))\n",
        "        )\n",
        "\n",
        "        # ØªØ´Ø®ÛŒØµ Ù…ÙˆÙ‚Ø¹ÛŒØª Ù‚ÛŒÙ…Øª Ù†Ø³Ø¨Øª Ø¨Ù‡ Ø§Ø¨Ø±\n",
        "        df_ichimoku['price_above_cloud'] = (\n",
        "                (df_ichimoku['close'] > df_ichimoku['senkou_span_a']) &\n",
        "                (df_ichimoku['close'] > df_ichimoku['senkou_span_b'])\n",
        "        )\n",
        "\n",
        "        df_ichimoku['price_below_cloud'] = (\n",
        "                (df_ichimoku['close'] < df_ichimoku['senkou_span_a']) &\n",
        "                (df_ichimoku['close'] < df_ichimoku['senkou_span_b'])\n",
        "        )\n",
        "\n",
        "        df_ichimoku['price_in_cloud'] = ~(df_ichimoku['price_above_cloud'] | df_ichimoku['price_below_cloud'])\n",
        "\n",
        "        # ØªØ´Ø®ÛŒØµ Ø±Ù†Ú¯ Ø§Ø¨Ø± (Ø§Ø¨Ø± Ø³Ø¨Ø² ÛŒØ§ Ù‚Ø±Ù…Ø²)\n",
        "        df_ichimoku['green_cloud'] = df_ichimoku['senkou_span_a'] > df_ichimoku['senkou_span_b']\n",
        "        df_ichimoku['red_cloud'] = df_ichimoku['senkou_span_a'] < df_ichimoku['senkou_span_b']\n",
        "\n",
        "        # ØªØ´Ø®ÛŒØµ Ù…ÙˆÙ‚Ø¹ÛŒØª Ú†ÛŒÚ©Ùˆ Ø§Ø³Ù¾Ù† Ù†Ø³Ø¨Øª Ø¨Ù‡ Ù‚ÛŒÙ…Øª (Ø³ÛŒÚ¯Ù†Ø§Ù„ ØªØ£ÛŒÛŒØ¯ÛŒ)\n",
        "        df_ichimoku['chikou_above_price'] = df_ichimoku['chikou_span'] > df_ichimoku['close']\n",
        "        df_ichimoku['chikou_below_price'] = df_ichimoku['chikou_span'] < df_ichimoku['close']\n",
        "\n",
        "        # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø®Ø±ÛŒØ¯ Ù‚ÙˆÛŒ\n",
        "        df_ichimoku['strong_buy_signal'] = (\n",
        "                df_ichimoku['tenkan_cross_above_kijun'] &\n",
        "                df_ichimoku['price_above_cloud'] &\n",
        "                df_ichimoku['green_cloud']\n",
        "        )\n",
        "\n",
        "        # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ ÙØ±ÙˆØ´ Ù‚ÙˆÛŒ\n",
        "        df_ichimoku['strong_sell_signal'] = (\n",
        "                df_ichimoku['tenkan_cross_below_kijun'] &\n",
        "                df_ichimoku['price_below_cloud'] &\n",
        "                df_ichimoku['red_cloud']\n",
        "        )\n",
        "\n",
        "        # Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø®Ø±ÛŒØ¯\n",
        "        buy_signals = []\n",
        "        for i in range(52, len(df_ichimoku)):\n",
        "            if df_ichimoku['strong_buy_signal'].iloc[i]:\n",
        "                # Ø¨Ø±Ø±Ø³ÛŒ Ù…ÙˆÙ‚Ø¹ÛŒØª Ú†ÛŒÚ©Ùˆ Ø§Ø³Ù¾Ù† Ø¨Ø±Ø§ÛŒ ØªØ£ÛŒÛŒØ¯ Ø¨ÛŒØ´ØªØ±\n",
        "                chikou_confirmation = False\n",
        "                if i >= 26 and df_ichimoku['chikou_above_price'].iloc[i - 26]:\n",
        "                    chikou_confirmation = True\n",
        "\n",
        "                strength = 85\n",
        "                if chikou_confirmation:\n",
        "                    strength = 95\n",
        "\n",
        "                description = 'Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø®Ø±ÛŒØ¯ Ù‚ÙˆÛŒ Ø§ÛŒÚ†ÛŒÙ…ÙˆÚ©Ùˆ: Ú©Ø±Ø§Ø³ ØµØ¹ÙˆØ¯ÛŒ ØªÙ†Ú©Ø§Ù†-Ø³Ù† Ø¨Ø§Ù„Ø§ÛŒ Ú©ÛŒØ¬ÙˆÙ†-Ø³Ù† + Ù‚ÛŒÙ…Øª Ø¨Ø§Ù„Ø§ÛŒ Ø§Ø¨Ø± Ø³Ø¨Ø²'\n",
        "                if chikou_confirmation:\n",
        "                    description += ' + ØªØ£ÛŒÛŒØ¯ Ú†ÛŒÚ©Ùˆ Ø§Ø³Ù¾Ù†'\n",
        "\n",
        "                buy_signals.append({\n",
        "                    'index': i,\n",
        "                    'date': df_ichimoku.index[i],\n",
        "                    'price': df_ichimoku['close'].iloc[i],\n",
        "                    'strength': strength,\n",
        "                    'description': description\n",
        "                })\n",
        "\n",
        "            # Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø®Ø±ÛŒØ¯ Ù…ØªÙˆØ³Ø·: Ú©Ø±Ø§Ø³ ØµØ¹ÙˆØ¯ÛŒ ØªÙ†Ú©Ø§Ù†-Ø³Ù† Ø¨Ø§Ù„Ø§ÛŒ Ú©ÛŒØ¬ÙˆÙ†-Ø³Ù† + Ù‚ÛŒÙ…Øª Ø¯Ø± Ø­Ø§Ù„ Ø®Ø±ÙˆØ¬ Ø§Ø² Ø§Ø¨Ø±\n",
        "            elif (df_ichimoku['tenkan_cross_above_kijun'].iloc[i] and\n",
        "                  df_ichimoku['price_in_cloud'].iloc[i] and\n",
        "                  df_ichimoku['close'].iloc[i] > df_ichimoku['senkou_span_a'].iloc[i]):\n",
        "\n",
        "                buy_signals.append({\n",
        "                    'index': i,\n",
        "                    'date': df_ichimoku.index[i],\n",
        "                    'price': df_ichimoku['close'].iloc[i],\n",
        "                    'strength': 75,\n",
        "                    'description': 'Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø®Ø±ÛŒØ¯ Ù…ØªÙˆØ³Ø· Ø§ÛŒÚ†ÛŒÙ…ÙˆÚ©Ùˆ: Ú©Ø±Ø§Ø³ ØµØ¹ÙˆØ¯ÛŒ ØªÙ†Ú©Ø§Ù†-Ø³Ù† Ø¨Ø§Ù„Ø§ÛŒ Ú©ÛŒØ¬ÙˆÙ†-Ø³Ù† + Ù‚ÛŒÙ…Øª Ø¯Ø± Ø­Ø§Ù„ Ø®Ø±ÙˆØ¬ Ø§Ø² Ø§Ø¨Ø±'\n",
        "                })\n",
        "\n",
        "        # Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ ÙØ±ÙˆØ´\n",
        "        sell_signals = []\n",
        "        for i in range(52, len(df_ichimoku)):\n",
        "            if df_ichimoku['strong_sell_signal'].iloc[i]:\n",
        "                # Ø¨Ø±Ø±Ø³ÛŒ Ù…ÙˆÙ‚Ø¹ÛŒØª Ú†ÛŒÚ©Ùˆ Ø§Ø³Ù¾Ù† Ø¨Ø±Ø§ÛŒ ØªØ£ÛŒÛŒØ¯ Ø¨ÛŒØ´ØªØ±\n",
        "                chikou_confirmation = False\n",
        "                if i >= 26 and df_ichimoku['chikou_below_price'].iloc[i - 26]:\n",
        "                    chikou_confirmation = True\n",
        "\n",
        "                strength = 85\n",
        "                if chikou_confirmation:\n",
        "                    strength = 95\n",
        "\n",
        "                description = 'Ø³ÛŒÚ¯Ù†Ø§Ù„ ÙØ±ÙˆØ´ Ù‚ÙˆÛŒ Ø§ÛŒÚ†ÛŒÙ…ÙˆÚ©Ùˆ: Ú©Ø±Ø§Ø³ Ù†Ø²ÙˆÙ„ÛŒ ØªÙ†Ú©Ø§Ù†-Ø³Ù† Ø²ÛŒØ± Ú©ÛŒØ¬ÙˆÙ†-Ø³Ù† + Ù‚ÛŒÙ…Øª Ø²ÛŒØ± Ø§Ø¨Ø± Ù‚Ø±Ù…Ø²'\n",
        "                if chikou_confirmation:\n",
        "                    description += ' + ØªØ£ÛŒÛŒØ¯ Ú†ÛŒÚ©Ùˆ Ø§Ø³Ù¾Ù†'\n",
        "\n",
        "                sell_signals.append({\n",
        "                    'index': i,\n",
        "                    'date': df_ichimoku.index[i],\n",
        "                    'price': df_ichimoku['close'].iloc[i],\n",
        "                    'strength': strength,\n",
        "                    'description': description\n",
        "                })\n",
        "\n",
        "            # Ø³ÛŒÚ¯Ù†Ø§Ù„ ÙØ±ÙˆØ´ Ù…ØªÙˆØ³Ø·: Ú©Ø±Ø§Ø³ Ù†Ø²ÙˆÙ„ÛŒ ØªÙ†Ú©Ø§Ù†-Ø³Ù† Ø²ÛŒØ± Ú©ÛŒØ¬ÙˆÙ†-Ø³Ù† + Ù‚ÛŒÙ…Øª Ø¯Ø± Ø­Ø§Ù„ Ø®Ø±ÙˆØ¬ Ø§Ø² Ø§Ø¨Ø±\n",
        "            elif (df_ichimoku['tenkan_cross_below_kijun'].iloc[i] and\n",
        "                  df_ichimoku['price_in_cloud'].iloc[i] and\n",
        "                  df_ichimoku['close'].iloc[i] < df_ichimoku['senkou_span_a'].iloc[i]):\n",
        "\n",
        "                sell_signals.append({\n",
        "                    'index': i,\n",
        "                    'date': df_ichimoku.index[i],\n",
        "                    'price': df_ichimoku['close'].iloc[i],\n",
        "                    'strength': 75,\n",
        "                    'description': 'Ø³ÛŒÚ¯Ù†Ø§Ù„ ÙØ±ÙˆØ´ Ù…ØªÙˆØ³Ø· Ø§ÛŒÚ†ÛŒÙ…ÙˆÚ©Ùˆ: Ú©Ø±Ø§Ø³ Ù†Ø²ÙˆÙ„ÛŒ ØªÙ†Ú©Ø§Ù†-Ø³Ù† Ø²ÛŒØ± Ú©ÛŒØ¬ÙˆÙ†-Ø³Ù† + Ù‚ÛŒÙ…Øª Ø¯Ø± Ø­Ø§Ù„ Ø®Ø±ÙˆØ¬ Ø§Ø² Ø§Ø¨Ø±'\n",
        "                })\n",
        "\n",
        "        # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù†Ù‚Ø§Ø· ÙˆØ±ÙˆØ¯ Ùˆ Ø®Ø±ÙˆØ¬\n",
        "        entry_points = []\n",
        "\n",
        "        for signal in buy_signals:\n",
        "            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø­Ø¯ Ø¶Ø±Ø± Ùˆ Ø­Ø¯ Ø³ÙˆØ¯ Ø¨Ø±Ø§ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø®Ø±ÛŒØ¯\n",
        "            # Ø­Ø¯ Ø¶Ø±Ø±: Ú©ÛŒØ¬ÙˆÙ†-Ø³Ù† ÛŒØ§ Ú©Ù Ø§Ø¨Ø± (Ù‡Ø±Ú©Ø¯Ø§Ù… Ú©Ù‡ Ù†Ø²Ø¯ÛŒÚ©ØªØ± Ø§Ø³Øª)\n",
        "            kijun = df_ichimoku['kijun_sen'].iloc[signal['index']]\n",
        "            cloud_bottom = min(\n",
        "                df_ichimoku['senkou_span_a'].iloc[signal['index']],\n",
        "                df_ichimoku['senkou_span_b'].iloc[signal['index']]\n",
        "            )\n",
        "\n",
        "            stop_loss = max(kijun, cloud_bottom)\n",
        "            if stop_loss > signal['price'] * 0.97:\n",
        "                stop_loss = signal['price'] * 0.97  # Ø­Ø¯Ø§Ú©Ø«Ø± 3% Ø²ÛŒØ§Ù†\n",
        "\n",
        "            # Ø­Ø¯ Ø³ÙˆØ¯: 2 Ø¨Ø±Ø§Ø¨Ø± ÙØ§ØµÙ„Ù‡ ØªØ§ Ø­Ø¯ Ø¶Ø±Ø±\n",
        "            risk = signal['price'] - stop_loss\n",
        "            take_profit = signal['price'] + risk * 2\n",
        "\n",
        "            entry_points.append({\n",
        "                'index': signal['index'],\n",
        "                'price': signal['price'],\n",
        "                'stop_loss': stop_loss,\n",
        "                'take_profit': take_profit,\n",
        "                'type': 'long',\n",
        "                'strength': signal['strength']\n",
        "            })\n",
        "\n",
        "        for signal in sell_signals:\n",
        "            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø­Ø¯ Ø¶Ø±Ø± Ùˆ Ø­Ø¯ Ø³ÙˆØ¯ Ø¨Ø±Ø§ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ ÙØ±ÙˆØ´\n",
        "            # Ø­Ø¯ Ø¶Ø±Ø±: Ú©ÛŒØ¬ÙˆÙ†-Ø³Ù† ÛŒØ§ Ø³Ù‚Ù Ø§Ø¨Ø± (Ù‡Ø±Ú©Ø¯Ø§Ù… Ú©Ù‡ Ù†Ø²Ø¯ÛŒÚ©ØªØ± Ø§Ø³Øª)\n",
        "            kijun = df_ichimoku['kijun_sen'].iloc[signal['index']]\n",
        "            cloud_top = max(\n",
        "                df_ichimoku['senkou_span_a'].iloc[signal['index']],\n",
        "                df_ichimoku['senkou_span_b'].iloc[signal['index']]\n",
        "            )\n",
        "\n",
        "            stop_loss = min(kijun, cloud_top)\n",
        "            if stop_loss < signal['price'] * 1.03:\n",
        "                stop_loss = signal['price'] * 1.03  # Ø­Ø¯Ø§Ú©Ø«Ø± 3% Ø²ÛŒØ§Ù†\n",
        "\n",
        "            # Ø­Ø¯ Ø³ÙˆØ¯: 2 Ø¨Ø±Ø§Ø¨Ø± ÙØ§ØµÙ„Ù‡ ØªØ§ Ø­Ø¯ Ø¶Ø±Ø±\n",
        "            risk = stop_loss - signal['price']\n",
        "            take_profit = signal['price'] - risk * 2\n",
        "\n",
        "            entry_points.append({\n",
        "                'index': signal['index'],\n",
        "                'price': signal['price'],\n",
        "                'stop_loss': stop_loss,\n",
        "                'take_profit': take_profit,\n",
        "                'type': 'short',\n",
        "                'strength': signal['strength']\n",
        "            })\n",
        "\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ\n",
        "        current_signal = 'Ø®Ù†Ø«ÛŒ'\n",
        "        current_strength = 50\n",
        "\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ Ø¢Ø®Ø±ÛŒÙ† ÙˆØ¶Ø¹ÛŒØª Ø§ÛŒÚ†ÛŒÙ…ÙˆÚ©Ùˆ\n",
        "        last_idx = len(df_ichimoku) - 1\n",
        "\n",
        "        # Ù…ÙˆÙ‚Ø¹ÛŒØª Ù‚ÛŒÙ…Øª Ù†Ø³Ø¨Øª Ø¨Ù‡ Ø§Ø¨Ø±\n",
        "        if df_ichimoku['price_above_cloud'].iloc[last_idx]:\n",
        "            if df_ichimoku['green_cloud'].iloc[last_idx]:\n",
        "                current_signal = 'Ø®Ø±ÛŒØ¯'\n",
        "                current_strength = 70\n",
        "                current_status = 'Ù‚ÛŒÙ…Øª Ø¨Ø§Ù„Ø§ÛŒ Ø§Ø¨Ø± Ø³Ø¨Ø² (Ø±ÙˆÙ†Ø¯ ØµØ¹ÙˆØ¯ÛŒ Ù‚ÙˆÛŒ)'\n",
        "            else:\n",
        "                current_signal = 'Ø®Ø±ÛŒØ¯'\n",
        "                current_strength = 60\n",
        "                current_status = 'Ù‚ÛŒÙ…Øª Ø¨Ø§Ù„Ø§ÛŒ Ø§Ø¨Ø± Ù‚Ø±Ù…Ø² (Ø§Ø­ØªÙ…Ø§Ù„ ØªØºÛŒÛŒØ± Ø±ÙˆÙ†Ø¯ Ø¨Ù‡ ØµØ¹ÙˆØ¯ÛŒ)'\n",
        "\n",
        "        elif df_ichimoku['price_below_cloud'].iloc[last_idx]:\n",
        "            if df_ichimoku['red_cloud'].iloc[last_idx]:\n",
        "                current_signal = 'ÙØ±ÙˆØ´'\n",
        "                current_strength = 70\n",
        "                current_status = 'Ù‚ÛŒÙ…Øª Ø²ÛŒØ± Ø§Ø¨Ø± Ù‚Ø±Ù…Ø² (Ø±ÙˆÙ†Ø¯ Ù†Ø²ÙˆÙ„ÛŒ Ù‚ÙˆÛŒ)'\n",
        "            else:\n",
        "                current_signal = 'ÙØ±ÙˆØ´'\n",
        "                current_strength = 60\n",
        "                current_status = 'Ù‚ÛŒÙ…Øª Ø²ÛŒØ± Ø§Ø¨Ø± Ø³Ø¨Ø² (Ø§Ø­ØªÙ…Ø§Ù„ ØªØºÛŒÛŒØ± Ø±ÙˆÙ†Ø¯ Ø¨Ù‡ Ù†Ø²ÙˆÙ„ÛŒ)'\n",
        "\n",
        "        else:\n",
        "            current_status = 'Ù‚ÛŒÙ…Øª Ø¯Ø±ÙˆÙ† Ø§Ø¨Ø± (Ø¹Ø¯Ù… Ù‚Ø·Ø¹ÛŒØª Ø±ÙˆÙ†Ø¯)'\n",
        "\n",
        "        # Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ú©Ø±Ø§Ø³ Ø§Ø®ÛŒØ±\n",
        "        if df_ichimoku['tenkan_cross_above_kijun'].iloc[last_idx - 3:last_idx + 1].any():\n",
        "            current_signal = 'Ø®Ø±ÛŒØ¯'\n",
        "            current_strength = 75\n",
        "            current_status = 'Ú©Ø±Ø§Ø³ ØµØ¹ÙˆØ¯ÛŒ Ø§Ø®ÛŒØ± ØªÙ†Ú©Ø§Ù†-Ø³Ù† Ø¨Ø§Ù„Ø§ÛŒ Ú©ÛŒØ¬ÙˆÙ†-Ø³Ù†'\n",
        "\n",
        "        elif df_ichimoku['tenkan_cross_below_kijun'].iloc[last_idx - 3:last_idx + 1].any():\n",
        "            current_signal = 'ÙØ±ÙˆØ´'\n",
        "            current_strength = 75\n",
        "            current_status = 'Ú©Ø±Ø§Ø³ Ù†Ø²ÙˆÙ„ÛŒ Ø§Ø®ÛŒØ± ØªÙ†Ú©Ø§Ù†-Ø³Ù† Ø²ÛŒØ± Ú©ÛŒØ¬ÙˆÙ†-Ø³Ù†'\n",
        "\n",
        "        # Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ø®ÛŒØ±\n",
        "        recent_buy = [s for s in buy_signals if last_idx - s['index'] <= 3]\n",
        "        recent_sell = [s for s in sell_signals if last_idx - s['index'] <= 3]\n",
        "\n",
        "        if recent_buy:\n",
        "            current_signal = 'Ø®Ø±ÛŒØ¯'\n",
        "            current_strength = max([s['strength'] for s in recent_buy])\n",
        "            current_status = max(recent_buy, key=lambda x: x['strength'])['description']\n",
        "\n",
        "        elif recent_sell:\n",
        "            current_signal = 'ÙØ±ÙˆØ´'\n",
        "            current_strength = max([s['strength'] for s in recent_sell])\n",
        "            current_status = max(recent_sell, key=lambda x: x['strength'])['description']\n",
        "\n",
        "        # Ù†ØªØ§ÛŒØ¬ Ù†Ù‡Ø§ÛŒÛŒ\n",
        "        result = {\n",
        "            'current_signal': current_signal,\n",
        "            'current_strength': current_strength,\n",
        "            'current_status': current_status,\n",
        "            'buy_signals': buy_signals,\n",
        "            'sell_signals': sell_signals,\n",
        "            'entry_points': entry_points,\n",
        "            'dataframe': df_ichimoku\n",
        "        }\n",
        "\n",
        "        return result\n",
        "\n",
        "    def analyze_fibonacci(self, df, period=120, use_atr=True):\n",
        "        \"\"\"\n",
        "        Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ Ø¨Ø§ Ø¨Ù‡ØªØ±ÛŒÙ† ØªØ±Ú©ÛŒØ¨\n",
        "\n",
        "        Args:\n",
        "            df: Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§\n",
        "            period: Ø¯ÙˆØ±Ù‡ Ø¨Ø±Ø±Ø³ÛŒ Ø¨Ø±Ø§ÛŒ ÛŒØ§ÙØªÙ† Ø§ÙˆØ¬â€ŒÙ‡Ø§ Ùˆ Ø­Ø¶ÛŒØ¶â€ŒÙ‡Ø§\n",
        "            use_atr: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ATR Ø¨Ø±Ø§ÛŒ ØªÙ†Ø¸ÛŒÙ… Ø­Ø¯ Ø¶Ø±Ø± Ùˆ Ø­Ø¯ Ø³ÙˆØ¯\n",
        "\n",
        "        Returns:\n",
        "            Ù†ØªØ§ÛŒØ¬ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ\n",
        "        \"\"\"\n",
        "        # Ø§ÛŒØ¬Ø§Ø¯ Ú©Ù¾ÛŒ Ø§Ø² Ø¯ÛŒØªØ§ÙØ±ÛŒÙ…\n",
        "        df_fib = df.copy()\n",
        "\n",
        "        # Ù…Ø­Ø§Ø³Ø¨Ù‡ ATR\n",
        "        if use_atr:\n",
        "            df_fib['atr'] = ta.volatility.average_true_range(df_fib['high'], df_fib['low'], df_fib['close'], window=14)\n",
        "\n",
        "        # ÛŒØ§ÙØªÙ† Ø§ÙˆØ¬â€ŒÙ‡Ø§ Ùˆ Ø­Ø¶ÛŒØ¶â€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù… Ø¯Ø± Ø¯ÙˆØ±Ù‡ Ù…Ø´Ø®Øµ Ø´Ø¯Ù‡\n",
        "        df_fib['swing_high'] = df_fib['high'].rolling(window=period, center=True).apply(\n",
        "            lambda x: 1 if x.iloc[period // 2] == max(x) else 0, raw=False)\n",
        "\n",
        "        df_fib['swing_low'] = df_fib['low'].rolling(window=period, center=True).apply(\n",
        "            lambda x: 1 if x.iloc[period // 2] == min(x) else 0, raw=False)\n",
        "\n",
        "        # Ù„ÛŒØ³Øª Ø§ÙˆØ¬â€ŒÙ‡Ø§ Ùˆ Ø­Ø¶ÛŒØ¶â€ŒÙ‡Ø§\n",
        "        swing_highs = []\n",
        "        swing_lows = []\n",
        "\n",
        "        for i in range(period, len(df_fib) - period):\n",
        "            if df_fib['swing_high'].iloc[i] == 1:\n",
        "                swing_highs.append((i, df_fib['high'].iloc[i]))\n",
        "            if df_fib['swing_low'].iloc[i] == 1:\n",
        "                swing_lows.append((i, df_fib['low'].iloc[i]))\n",
        "\n",
        "        # Ø³Ø·ÙˆØ­ ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ Ù…Ø¹Ù…ÙˆÙ„\n",
        "        fib_levels = [0, 0.236, 0.382, 0.5, 0.618, 0.786, 1]\n",
        "\n",
        "        # Ù„ÛŒØ³Øª Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬ ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ\n",
        "        fibonacci_retracements = []\n",
        "        fibonacci_extensions = []\n",
        "\n",
        "        # Ø³Ø·ÙˆØ­ Ø­Ù…Ø§ÛŒØª Ùˆ Ù…Ù‚Ø§ÙˆÙ…Øª Ù…Ù‡Ù… ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ\n",
        "        current_support_levels = []\n",
        "        current_resistance_levels = []\n",
        "\n",
        "        # Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø¬ÙØª Ø§Ø² Ø§ÙˆØ¬ Ùˆ Ø­Ø¶ÛŒØ¶ Ù…Ø¬Ø§ÙˆØ±\n",
        "        # Ø§Ø¨ØªØ¯Ø§ ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ Ø¨Ø§Ø²Ú¯Ø´ØªÛŒ (retracement) Ø±Ø§ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…\n",
        "        for i in range(1, min(len(swing_highs), len(swing_lows))):\n",
        "            # Ø¨Ø§Ø²Ú¯Ø´Øª Ø§Ø² Ø§ÙˆØ¬ Ø¨Ù‡ Ø­Ø¶ÛŒØ¶ (Ø±ÙˆÙ†Ø¯ Ù†Ø²ÙˆÙ„ÛŒ)\n",
        "            if swing_highs[i - 1][0] < swing_lows[i][0]:\n",
        "                high_val = swing_highs[i - 1][1]\n",
        "                low_val = swing_lows[i][1]\n",
        "                price_range = high_val - low_val\n",
        "\n",
        "                # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø³Ø·ÙˆØ­ ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ\n",
        "                levels = {}\n",
        "                for fib in fib_levels:\n",
        "                    levels[fib] = high_val - price_range * fib\n",
        "\n",
        "                fibonacci_retracements.append({\n",
        "                    'type': 'bearish',\n",
        "                    'high_idx': swing_highs[i - 1][0],\n",
        "                    'low_idx': swing_lows[i][0],\n",
        "                    'high_val': high_val,\n",
        "                    'low_val': low_val,\n",
        "                    'levels': levels\n",
        "                })\n",
        "\n",
        "                # Ø¨Ø±Ø±Ø³ÛŒ Ø³Ø·ÙˆØ­ Ù…Ù‚Ø§ÙˆÙ…Øª ÙØ¹Ù„ÛŒ (Ø¯Ø± Ø±ÙˆÙ†Ø¯ Ù†Ø²ÙˆÙ„ÛŒ)\n",
        "                current_price = df_fib['close'].iloc[-1]\n",
        "                for fib, level in levels.items():\n",
        "                    if level > current_price:\n",
        "                        current_resistance_levels.append((fib, level))\n",
        "                    elif level < current_price:\n",
        "                        current_support_levels.append((fib, level))\n",
        "\n",
        "            # Ø¨Ø§Ø²Ú¯Ø´Øª Ø§Ø² Ø­Ø¶ÛŒØ¶ Ø¨Ù‡ Ø§ÙˆØ¬ (Ø±ÙˆÙ†Ø¯ ØµØ¹ÙˆØ¯ÛŒ)\n",
        "            elif swing_lows[i - 1][0] < swing_highs[i][0]:\n",
        "                high_val = swing_highs[i][1]\n",
        "                low_val = swing_lows[i - 1][1]\n",
        "                price_range = high_val - low_val\n",
        "\n",
        "                # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø³Ø·ÙˆØ­ ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ\n",
        "                levels = {}\n",
        "                for fib in fib_levels:\n",
        "                    levels[fib] = low_val + price_range * fib\n",
        "\n",
        "                fibonacci_retracements.append({\n",
        "                    'type': 'bullish',\n",
        "                    'high_idx': swing_highs[i][0],\n",
        "                    'low_idx': swing_lows[i - 1][0],\n",
        "                    'high_val': high_val,\n",
        "                    'low_val': low_val,\n",
        "                    'levels': levels\n",
        "                })\n",
        "\n",
        "                # Ø¨Ø±Ø±Ø³ÛŒ Ø³Ø·ÙˆØ­ Ø­Ù…Ø§ÛŒØª ÙØ¹Ù„ÛŒ (Ø¯Ø± Ø±ÙˆÙ†Ø¯ ØµØ¹ÙˆØ¯ÛŒ)\n",
        "                current_price = df_fib['close'].iloc[-1]\n",
        "                for fib, level in levels.items():\n",
        "                    if level < current_price:\n",
        "                        current_support_levels.append((fib, level))\n",
        "                    elif level > current_price:\n",
        "                        current_resistance_levels.append((fib, level))\n",
        "\n",
        "        # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø³Ø·ÙˆØ­ Ø­Ù…Ø§ÛŒØª Ùˆ Ù…Ù‚Ø§ÙˆÙ…Øª\n",
        "        current_support_levels.sort(key=lambda x: x[1], reverse=True)\n",
        "        current_resistance_levels.sort(key=lambda x: x[1])\n",
        "\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ§Ú©Ù†Ø´ Ù‚ÛŒÙ…Øª Ø¨Ù‡ Ø³Ø·ÙˆØ­ ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ\n",
        "        price_reactions = []\n",
        "\n",
        "        # Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø³Ø·ÙˆØ­ ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ Ù†Ø²Ø¯ÛŒÚ©\n",
        "        df_fib['nearest_fib_level'] = np.nan\n",
        "        df_fib['nearest_fib_value'] = np.nan\n",
        "        df_fib['fib_reaction'] = False\n",
        "\n",
        "        for i in range(period, len(df_fib)):\n",
        "            # Ø¨Ø±Ø±Ø³ÛŒ Ù‡Ù…Ù‡ Ø³Ø·ÙˆØ­ ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¯Ù‡\n",
        "            for fib_obj in fibonacci_retracements:\n",
        "                # Ø§Ú¯Ø± Ø§ÛŒÙ† Ú©Ù†Ø¯Ù„ Ø¨Ø¹Ø¯ Ø§Ø² Ù…Ø­Ø§Ø³Ø¨Ù‡ ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ Ø§Ø³Øª\n",
        "                if i > max(fib_obj['high_idx'], fib_obj['low_idx']):\n",
        "                    levels = fib_obj['levels']\n",
        "\n",
        "                    # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ§Ú©Ù†Ø´ Ù‚ÛŒÙ…Øª Ø¨Ù‡ Ù‡Ø± Ø³Ø·Ø­\n",
        "                    for fib, level in levels.items():\n",
        "                        # Ø§Ú¯Ø± Ù‚ÛŒÙ…Øª Ú©Ù†Ø¯Ù„ Ø¨Ù‡ Ø§ÛŒÙ† Ø³Ø·Ø­ Ø±Ø³ÛŒØ¯Ù‡ Ø§Ø³Øª\n",
        "                        if (df_fib['low'].iloc[i] <= level <= df_fib['high'].iloc[i]):\n",
        "                            # Ø§Ú¯Ø± Ú©Ù†Ø¯Ù„ ØµØ¹ÙˆØ¯ÛŒ Ø§Ø³Øª Ùˆ Ø§Ø² Ø³Ø·Ø­ Ø­Ù…Ø§ÛŒØª Ø¨Ø§Ù„Ø§ Ø±ÙØªÙ‡ Ø§Ø³Øª\n",
        "                            if df_fib['close'].iloc[i] > df_fib['open'].iloc[i] and df_fib['low'].iloc[i] <= level:\n",
        "                                df_fib['nearest_fib_level'].iloc[i] = fib\n",
        "                                df_fib['nearest_fib_value'].iloc[i] = level\n",
        "                                df_fib['fib_reaction'].iloc[i] = True\n",
        "\n",
        "                                # Ø§ÙØ²ÙˆØ¯Ù† Ø¨Ù‡ Ù„ÛŒØ³Øª ÙˆØ§Ú©Ù†Ø´â€ŒÙ‡Ø§\n",
        "                                reaction_strength = 70\n",
        "                                if fib in [0.382, 0.618]:  # Ø³Ø·ÙˆØ­ Ù‚ÙˆÛŒâ€ŒØªØ±\n",
        "                                    reaction_strength = 85\n",
        "\n",
        "                                price_reactions.append({\n",
        "                                    'index': i,\n",
        "                                    'date': df_fib.index[i],\n",
        "                                    'price': df_fib['close'].iloc[i],\n",
        "                                    'fib_level': fib,\n",
        "                                    'fib_value': level,\n",
        "                                    'reaction_type': 'support' if fib_obj['type'] == 'bullish' else 'resistance',\n",
        "                                    'strength': reaction_strength\n",
        "                                })\n",
        "\n",
        "                            # Ø§Ú¯Ø± Ú©Ù†Ø¯Ù„ Ù†Ø²ÙˆÙ„ÛŒ Ø§Ø³Øª Ùˆ Ø§Ø² Ø³Ø·Ø­ Ù…Ù‚Ø§ÙˆÙ…Øª Ù¾Ø§ÛŒÛŒÙ† Ø±ÙØªÙ‡ Ø§Ø³Øª\n",
        "                            elif df_fib['close'].iloc[i] < df_fib['open'].iloc[i] and df_fib['high'].iloc[i] >= level:\n",
        "                                df_fib['nearest_fib_level'].iloc[i] = fib\n",
        "                                df_fib['nearest_fib_value'].iloc[i] = level\n",
        "                                df_fib['fib_reaction'].iloc[i] = True\n",
        "\n",
        "                                # Ø§ÙØ²ÙˆØ¯Ù† Ø¨Ù‡ Ù„ÛŒØ³Øª ÙˆØ§Ú©Ù†Ø´â€ŒÙ‡Ø§\n",
        "                                reaction_strength = 70\n",
        "                                if fib in [0.382, 0.618]:  # Ø³Ø·ÙˆØ­ Ù‚ÙˆÛŒâ€ŒØªØ±\n",
        "                                    reaction_strength = 85\n",
        "\n",
        "                                price_reactions.append({\n",
        "                                    'index': i,\n",
        "                                    'date': df_fib.index[i],\n",
        "                                    'price': df_fib['close'].iloc[i],\n",
        "                                    'fib_level': fib,\n",
        "                                    'fib_value': level,\n",
        "                                    'reaction_type': 'resistance' if fib_obj['type'] == 'bullish' else 'support',\n",
        "                                    'strength': reaction_strength\n",
        "                                })\n",
        "\n",
        "        # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ ÙˆØ§Ú©Ù†Ø´ Ù‚ÛŒÙ…Øª\n",
        "        buy_signals = []\n",
        "        sell_signals = []\n",
        "\n",
        "        for i in range(1, len(price_reactions)):\n",
        "            reaction = price_reactions[i]\n",
        "\n",
        "            # Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø®Ø±ÛŒØ¯: ÙˆØ§Ú©Ù†Ø´ Ù…Ø«Ø¨Øª Ø¨Ù‡ Ø³Ø·Ø­ Ø­Ù…Ø§ÛŒØª ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ\n",
        "            if reaction['reaction_type'] == 'support':\n",
        "                # Ø§Ú¯Ø± Ù‚ÛŒÙ…Øª Ø§Ø² Ø³Ø·Ø­ Ø­Ù…Ø§ÛŒØª Ø¨Ø§Ù„Ø§ Ø±ÙØªÙ‡ Ø§Ø³Øª\n",
        "                candle_idx = reaction['index']\n",
        "                if (df_fib['close'].iloc[candle_idx] > df_fib['open'].iloc[candle_idx] and\n",
        "                        df_fib['close'].iloc[candle_idx] > reaction['fib_value']):\n",
        "\n",
        "                    # Ø¨Ø±Ø±Ø³ÛŒ Ø­Ø¬Ù… Ø¨Ø±Ø§ÛŒ ØªØ£ÛŒÛŒØ¯ Ø¨ÛŒØ´ØªØ±\n",
        "                    volume_confirmation = df_fib['volume'].iloc[candle_idx] > df_fib['volume'].iloc[\n",
        "                                                                              candle_idx - 5:candle_idx].mean()\n",
        "                    strength = reaction['strength']\n",
        "\n",
        "                    if volume_confirmation:\n",
        "                        strength += 10\n",
        "\n",
        "                    description = f\"Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø®Ø±ÛŒØ¯ ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ: ÙˆØ§Ú©Ù†Ø´ Ù…Ø«Ø¨Øª Ø¨Ù‡ Ø³Ø·Ø­ Ø­Ù…Ø§ÛŒØª {reaction['fib_level']}\"\n",
        "                    if volume_confirmation:\n",
        "                        description += \" Ø¨Ø§ ØªØ£ÛŒÛŒØ¯ Ø­Ø¬Ù…\"\n",
        "\n",
        "                    # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø­Ø¯ Ø¶Ø±Ø± Ùˆ Ø­Ø¯ Ø³ÙˆØ¯\n",
        "                    if use_atr:\n",
        "                        atr = df_fib['atr'].iloc[candle_idx]\n",
        "                        stop_loss = reaction['fib_value'] - 1.5 * atr\n",
        "                        take_profit = reaction['price'] + 3 * atr\n",
        "                    else:\n",
        "                        # Ø­Ø¯ Ø¶Ø±Ø±: Ø³Ø·Ø­ ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ Ù‚Ø¨Ù„ÛŒ\n",
        "                        if reaction['fib_level'] == 0:\n",
        "                            stop_loss = reaction['fib_value'] * 0.97\n",
        "                        else:\n",
        "                            prev_level = max([fib for fib in fib_levels if fib < reaction['fib_level']], default=0)\n",
        "                            fib_range = fibonacci_retracements[-1]['high_val'] - fibonacci_retracements[-1]['low_val']\n",
        "                            stop_loss = reaction['fib_value'] - fib_range * 0.1\n",
        "\n",
        "                        # Ø­Ø¯ Ø³ÙˆØ¯: Ø³Ø·Ø­ ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ Ø¨Ø¹Ø¯ÛŒ\n",
        "                        next_level = min([fib for fib in fib_levels if fib > reaction['fib_level']], default=1)\n",
        "                        take_profit = fibonacci_retracements[-1]['low_val'] + fibonacci_retracements[-1]['high_val'] - \\\n",
        "                                      fibonacci_retracements[-1]['low_val'] * next_level\n",
        "\n",
        "                    buy_signals.append({\n",
        "                        'index': candle_idx,\n",
        "                        'date': df_fib.index[candle_idx],\n",
        "                        'price': df_fib['close'].iloc[candle_idx],\n",
        "                        'stop_loss': stop_loss,\n",
        "                        'take_profit': take_profit,\n",
        "                        'strength': min(100, strength),\n",
        "                        'description': description\n",
        "                    })\n",
        "\n",
        "            # Ø³ÛŒÚ¯Ù†Ø§Ù„ ÙØ±ÙˆØ´: ÙˆØ§Ú©Ù†Ø´ Ù…Ù†ÙÛŒ Ø¨Ù‡ Ø³Ø·Ø­ Ù…Ù‚Ø§ÙˆÙ…Øª ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ\n",
        "            elif reaction['reaction_type'] == 'resistance':\n",
        "                # Ø§Ú¯Ø± Ù‚ÛŒÙ…Øª Ø§Ø² Ø³Ø·Ø­ Ù…Ù‚Ø§ÙˆÙ…Øª Ù¾Ø§ÛŒÛŒÙ† Ø±ÙØªÙ‡ Ø§Ø³Øª\n",
        "                candle_idx = reaction['index']\n",
        "                if (df_fib['close'].iloc[candle_idx] < df_fib['open'].iloc[candle_idx] and\n",
        "                        df_fib['close'].iloc[candle_idx] < reaction['fib_value']):\n",
        "\n",
        "                    # Ø¨Ø±Ø±Ø³ÛŒ Ø­Ø¬Ù… Ø¨Ø±Ø§ÛŒ ØªØ£ÛŒÛŒØ¯ Ø¨ÛŒØ´ØªØ±\n",
        "                    volume_confirmation = df_fib['volume'].iloc[candle_idx] > df_fib['volume'].iloc[\n",
        "                                                                              candle_idx - 5:candle_idx].mean()\n",
        "                    strength = reaction['strength']\n",
        "\n",
        "                    if volume_confirmation:\n",
        "                        strength += 10\n",
        "\n",
        "                    description = f\"Ø³ÛŒÚ¯Ù†Ø§Ù„ ÙØ±ÙˆØ´ ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ: ÙˆØ§Ú©Ù†Ø´ Ù…Ù†ÙÛŒ Ø¨Ù‡ Ø³Ø·Ø­ Ù…Ù‚Ø§ÙˆÙ…Øª {reaction['fib_level']}\"\n",
        "                    if volume_confirmation:\n",
        "                        description += \" Ø¨Ø§ ØªØ£ÛŒÛŒØ¯ Ø­Ø¬Ù…\"\n",
        "\n",
        "                    # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø­Ø¯ Ø¶Ø±Ø± Ùˆ Ø­Ø¯ Ø³ÙˆØ¯\n",
        "                    if use_atr:\n",
        "                        atr = df_fib['atr'].iloc[candle_idx]\n",
        "                        stop_loss = reaction['fib_value'] + 1.5 * atr\n",
        "                        take_profit = reaction['price'] - 3 * atr\n",
        "                    else:\n",
        "                        # Ø­Ø¯ Ø¶Ø±Ø±: Ø³Ø·Ø­ ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ Ø¨Ø¹Ø¯ÛŒ\n",
        "                        if reaction['fib_level'] == 1:\n",
        "                            stop_loss = reaction['fib_value'] * 1.03\n",
        "                        else:\n",
        "                            next_level = min([fib for fib in fib_levels if fib > reaction['fib_level']], default=1)\n",
        "                            fib_range = fibonacci_retracements[-1]['high_val'] - fibonacci_retracements[-1]['low_val']\n",
        "                            stop_loss = reaction['fib_value'] + fib_range * 0.1\n",
        "\n",
        "                        # Ø­Ø¯ Ø³ÙˆØ¯: Ø³Ø·Ø­ ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ Ù‚Ø¨Ù„ÛŒ\n",
        "                        prev_level = max([fib for fib in fib_levels if fib < reaction['fib_level']], default=0)\n",
        "                        take_profit = fibonacci_retracements[-1]['low_val'] + fibonacci_retracements[-1]['high_val'] - \\\n",
        "                                      fibonacci_retracements[-1]['low_val'] * prev_level\n",
        "\n",
        "                    sell_signals.append({\n",
        "                        'index': candle_idx,\n",
        "                        'date': df_fib.index[candle_idx],\n",
        "                        'price': df_fib['close'].iloc[candle_idx],\n",
        "                        'stop_loss': stop_loss,\n",
        "                        'take_profit': take_profit,\n",
        "                        'strength': min(100, strength),\n",
        "                        'description': description\n",
        "                    })\n",
        "\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ Ù†Ø³Ø¨Øª Ø¨Ù‡ Ø³Ø·ÙˆØ­ ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ\n",
        "        current_signal = 'Ø®Ù†Ø«ÛŒ'\n",
        "        current_strength = 50\n",
        "\n",
        "        # ÛŒØ§ÙØªÙ† Ù†Ø²Ø¯ÛŒÚ©ØªØ±ÛŒÙ† Ø³Ø·Ø­ Ø­Ù…Ø§ÛŒØª Ùˆ Ù…Ù‚Ø§ÙˆÙ…Øª ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ\n",
        "        current_price = df_fib['close'].iloc[-1]\n",
        "        nearest_support = None\n",
        "        nearest_resistance = None\n",
        "\n",
        "        if current_support_levels:\n",
        "            nearest_support = current_support_levels[0]\n",
        "\n",
        "        if current_resistance_levels:\n",
        "            nearest_resistance = current_resistance_levels[0]\n",
        "\n",
        "        # Ø§Ú¯Ø± Ù‚ÛŒÙ…Øª Ù†Ø²Ø¯ÛŒÚ© ÛŒÚ© Ø³Ø·Ø­ ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ Ø§Ø³Øª\n",
        "        last_idx = len(df_fib) - 1\n",
        "        if df_fib['fib_reaction'].iloc[last_idx - 3:last_idx + 1].any():\n",
        "            # ÛŒØ§ÙØªÙ† Ø¢Ø®Ø±ÛŒÙ† ÙˆØ§Ú©Ù†Ø´\n",
        "            for i in range(last_idx, max(0, last_idx - 3), -1):\n",
        "                if df_fib['fib_reaction'].iloc[i]:\n",
        "                    fib_level = df_fib['nearest_fib_level'].iloc[i]\n",
        "                    fib_value = df_fib['nearest_fib_value'].iloc[i]\n",
        "\n",
        "                    # Ø§Ú¯Ø± ÙˆØ§Ú©Ù†Ø´ Ø¨Ù‡ Ø³Ø·Ø­ Ø­Ù…Ø§ÛŒØª Ø¨ÙˆØ¯\n",
        "                    if current_price > fib_value:\n",
        "                        current_signal = 'Ø®Ø±ÛŒØ¯'\n",
        "                        current_strength = 70\n",
        "                        if fib_level in [0.382, 0.618]:\n",
        "                            current_strength = 80\n",
        "\n",
        "                    # Ø§Ú¯Ø± ÙˆØ§Ú©Ù†Ø´ Ø¨Ù‡ Ø³Ø·Ø­ Ù…Ù‚Ø§ÙˆÙ…Øª Ø¨ÙˆØ¯\n",
        "                    else:\n",
        "                        current_signal = 'ÙØ±ÙˆØ´'\n",
        "                        current_strength = 70\n",
        "                        if fib_level in [0.382, 0.618]:\n",
        "                            current_strength = 80\n",
        "\n",
        "                    break\n",
        "\n",
        "        # Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ø®ÛŒØ±\n",
        "        recent_buy = [s for s in buy_signals if last_idx - s['index'] <= 5]\n",
        "        recent_sell = [s for s in sell_signals if last_idx - s['index'] <= 5]\n",
        "\n",
        "        if recent_buy:\n",
        "            current_signal = 'Ø®Ø±ÛŒØ¯'\n",
        "            current_strength = max([s['strength'] for s in recent_buy])\n",
        "\n",
        "        elif recent_sell:\n",
        "            current_signal = 'ÙØ±ÙˆØ´'\n",
        "            current_strength = max([s['strength'] for s in recent_sell])\n",
        "\n",
        "        # Ù†ØªØ§ÛŒØ¬ Ù†Ù‡Ø§ÛŒÛŒ\n",
        "        result = {\n",
        "            'current_signal': current_signal,\n",
        "            'current_strength': current_strength,\n",
        "            'nearest_support': nearest_support,\n",
        "            'nearest_resistance': nearest_resistance,\n",
        "            'fibonacci_retracements': fibonacci_retracements,\n",
        "            'price_reactions': price_reactions,\n",
        "            'buy_signals': buy_signals,\n",
        "            'sell_signals': sell_signals,\n",
        "            'dataframe': df_fib\n",
        "        }\n",
        "\n",
        "        return result\n",
        "\n",
        "    def golden_strategy(self, df):\n",
        "        \"\"\"\n",
        "        Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø·Ù„Ø§ÛŒÛŒ: ØªØ±Ú©ÛŒØ¨ Ø¨Ù‡ØªØ±ÛŒÙ† Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø¯Ø³ØªÛŒØ§Ø¨ÛŒ Ø¨Ù‡ Ø¨Ù‡ØªØ±ÛŒÙ† Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¨Ø§ Ù…Ø­Ø§Ø³Ø¨Ù‡ ÙˆØ§Ù‚Ø¹ÛŒâ€ŒØªØ± Ø¯Ù‚Øª\n",
        "\n",
        "        Args:\n",
        "            df: Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§\n",
        "\n",
        "        Returns:\n",
        "            Ù†ØªØ§ÛŒØ¬ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø·Ù„Ø§ÛŒÛŒ\n",
        "        \"\"\"\n",
        "        # Ø§Ø¬Ø±Ø§ÛŒ ØªÙ…Ø§Ù… Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ\n",
        "        market_structure_result = self.analyze_market_structure(df, fib_factor=0.273)\n",
        "        pressure_result = self.analyze_buying_selling_pressure(df)\n",
        "        whale_result = self.detect_whale_activity(df)\n",
        "        ema_result = self.analyze_ema_strategy(df)\n",
        "        rsi_result = self.analyze_rsi_strategy(df)\n",
        "        divergence_result = self.detect_divergence(df)\n",
        "        bbrsi_macd_result = self.analyze_bbrsi_macd_strategy(df)\n",
        "        ichimoku_result = self.analyze_ichimoku(df)\n",
        "        fibonacci_result = self.analyze_fibonacci(df)\n",
        "        special_result = self.special_strategy(df)\n",
        "\n",
        "        # ÙˆØ²Ù†â€ŒØ¯Ù‡ÛŒ Ø¨Ù‡ Ù‡Ø± Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø¨Ø§ Ø¨Ø§Ø²Ù†Ú¯Ø±ÛŒ\n",
        "        strategy_weights = {\n",
        "            'market_structure': 0.22,  # ÙˆØ²Ù† Ø¨ÛŒØ´ØªØ± Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ø§Ù‡Ù…ÛŒØª Ø³Ø§Ø®ØªØ§Ø± Ø¨Ø§Ø²Ø§Ø±\n",
        "            'pressure': 0.12,  # ÙØ´Ø§Ø± Ø®Ø±ÛŒØ¯/ÙØ±ÙˆØ´\n",
        "            'whale': 0.08,  # ÙØ¹Ø§Ù„ÛŒØª Ù†Ù‡Ù†Ú¯â€ŒÙ‡Ø§\n",
        "            'ema': 0.15,  # Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ EMA\n",
        "            'rsi': 0.10,  # Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ RSI\n",
        "            'divergence': 0.10,  # ÙˆØ§Ú¯Ø±Ø§ÛŒÛŒ\n",
        "            'bbrsi_macd': 0.09,  # ØªØ±Ú©ÛŒØ¨ Ø¨Ø§Ù†Ø¯ Ø¨ÙˆÙ„ÛŒÙ†Ú¯Ø±ØŒ RSI Ùˆ MACD\n",
        "            'ichimoku': 0.08,  # Ø§ÛŒÚ†ÛŒÙ…ÙˆÚ©Ùˆ\n",
        "            'fibonacci': 0.06  # ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ (ÙˆØ²Ù† Ú©Ù…ØªØ± Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ù†ÙˆØ³Ø§Ù† Ø¨ÛŒØ´ØªØ±)\n",
        "        }\n",
        "\n",
        "        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ Ùˆ Ù‚Ø¯Ø±Øª Ø¢Ù†â€ŒÙ‡Ø§ Ø§Ø² Ù‡Ø± Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ\n",
        "        signals = {\n",
        "            'market_structure': {\n",
        "                'type': 'ØµØ¹ÙˆØ¯ÛŒ' if market_structure_result['market_structure']['trend_score'] > 0 else 'Ù†Ø²ÙˆÙ„ÛŒ',\n",
        "                'strength': abs(market_structure_result['market_structure']['strength']),\n",
        "                'historical_accuracy': 0.78  # Ø¯Ù‚Øª ØªØ§Ø±ÛŒØ®ÛŒ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø¨Ø±Ø§Ø³Ø§Ø³ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ú¯Ø°Ø´ØªÙ‡\n",
        "            },\n",
        "            'pressure': {\n",
        "                'type': pressure_result['pressure_status'],\n",
        "                'strength': pressure_result['pressure_strength'],\n",
        "                'historical_accuracy': 0.65\n",
        "            },\n",
        "            'whale': {\n",
        "                'type': whale_result['whale_signal'],\n",
        "                'strength': whale_result['whale_strength'],\n",
        "                'historical_accuracy': 0.62\n",
        "            },\n",
        "            'ema': {\n",
        "                'type': ema_result['latest_signal_type'],\n",
        "                'strength': ema_result['latest_signal_strength'],\n",
        "                'historical_accuracy': 0.75\n",
        "            },\n",
        "            'rsi': {\n",
        "                'type': rsi_result['current_signal_type'],\n",
        "                'strength': rsi_result['current_signal_strength'],\n",
        "                'historical_accuracy': 0.72\n",
        "            },\n",
        "            'divergence': {\n",
        "                'type': divergence_result['signal_type'],\n",
        "                'strength': divergence_result['current_strength'],\n",
        "                'historical_accuracy': 0.70\n",
        "            },\n",
        "            'bbrsi_macd': {\n",
        "                'type': bbrsi_macd_result['current_signal'],\n",
        "                'strength': bbrsi_macd_result['current_strength'],\n",
        "                'historical_accuracy': 0.68\n",
        "            },\n",
        "            'ichimoku': {\n",
        "                'type': ichimoku_result['current_signal'],\n",
        "                'strength': ichimoku_result['current_strength'],\n",
        "                'historical_accuracy': 0.66\n",
        "            },\n",
        "            'fibonacci': {\n",
        "                'type': fibonacci_result['current_signal'],\n",
        "                'strength': fibonacci_result['current_strength'],\n",
        "                'historical_accuracy': 0.60\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² Ø¨Ø±Ø§ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø®Ø±ÛŒØ¯ Ùˆ ÙØ±ÙˆØ´\n",
        "        buy_score = 0\n",
        "        sell_score = 0\n",
        "        buy_weights_sum = 0\n",
        "        sell_weights_sum = 0\n",
        "\n",
        "        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¯Ù‚Øª ØªØ±Ú©ÛŒØ¨ÛŒ Ø¨Ø§ Ø¯Ø± Ù†Ø¸Ø± Ú¯Ø±ÙØªÙ† ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ø¯Ù‚Øª Ùˆ ÙˆØ²Ù†â€ŒØ¯Ù‡ÛŒ\n",
        "        for strategy, signal in signals.items():\n",
        "            weight = strategy_weights[strategy]\n",
        "            accuracy = signal['historical_accuracy']\n",
        "\n",
        "            # ØªØ¹Ø¯ÛŒÙ„ Ù‚Ø¯Ø±Øª Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ø¯Ù‚Øª ØªØ§Ø±ÛŒØ®ÛŒ\n",
        "            adjusted_strength = signal['strength'] * accuracy\n",
        "\n",
        "            if signal['type'] in ['Ø®Ø±ÛŒØ¯', 'ØµØ¹ÙˆØ¯ÛŒ', 'BUY', 'LONG']:\n",
        "                buy_score += adjusted_strength * weight\n",
        "                buy_weights_sum += weight\n",
        "            elif signal['type'] in ['ÙØ±ÙˆØ´', 'Ù†Ø²ÙˆÙ„ÛŒ', 'SELL', 'SHORT']:\n",
        "                sell_score += adjusted_strength * weight\n",
        "                sell_weights_sum += weight\n",
        "\n",
        "        # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø§Ù…ØªÛŒØ§Ø²Ù‡Ø§\n",
        "        if buy_weights_sum > 0:\n",
        "            buy_score = buy_score / buy_weights_sum\n",
        "        if sell_weights_sum > 0:\n",
        "            sell_score = sell_score / sell_weights_sum\n",
        "\n",
        "        # ÙØ§Ú©ØªÙˆØ± ÙˆØ§Ù‚Ø¹â€ŒÚ¯Ø±Ø§ÛŒÛŒ: Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ù†ÙˆØ³Ø§Ù†Ø§Øª Ø·Ø¨ÛŒØ¹ÛŒ Ø¨Ø§Ø²Ø§Ø±ØŒ ÛŒÚ© Ø¶Ø±ÛŒØ¨ Ú©Ø§Ù‡Ø´ÛŒ Ø§Ø¹Ù…Ø§Ù„ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…\n",
        "        realism_factor = 0.85  # Ú©Ø§Ù‡Ø´ 15% Ø¯Ø± Ø¯Ù‚Øª Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ø±Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒâ€ŒØªØ± Ø¨ÙˆØ¯Ù†\n",
        "\n",
        "        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø±Ø§ÛŒØ· ÙØ¹Ù„ÛŒ Ø¨Ø§Ø²Ø§Ø± (Ù†ÙˆØ³Ø§Ù†ØŒ Ø­Ø¬Ù… Ùˆ Ø±ÙˆÙ†Ø¯)\n",
        "        market_volatility = df['volatility'].iloc[-10:].mean() if 'volatility' in df.columns else 0\n",
        "        if market_volatility > 5:  # Ù†ÙˆØ³Ø§Ù† Ø¨Ø§Ù„Ø§\n",
        "            realism_factor *= 0.92  # Ú©Ø§Ù‡Ø´ Ø¨ÛŒØ´ØªØ± Ø¯Ù‚Øª Ø¯Ø± Ø´Ø±Ø§ÛŒØ· Ù¾Ø±Ù†ÙˆØ³Ø§Ù†\n",
        "\n",
        "        # ØªØ¹ÛŒÛŒÙ† Ø³ÛŒÚ¯Ù†Ø§Ù„ Ù†Ù‡Ø§ÛŒÛŒ\n",
        "        final_signal = 'Ø®Ù†Ø«ÛŒ'\n",
        "        final_strength = 50\n",
        "        confidence_factor = 0\n",
        "\n",
        "        if buy_score > sell_score and buy_score >= 65:\n",
        "            final_signal = 'Ø®Ø±ÛŒØ¯'\n",
        "            final_strength = buy_score * realism_factor\n",
        "            confidence_factor = (buy_score - sell_score) / 10  # Ø§Ø®ØªÙ„Ø§Ù Ø§Ù…ØªÛŒØ§Ø²Ù‡Ø§ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† ÙØ§Ú©ØªÙˆØ± Ø§Ø·Ù…ÛŒÙ†Ø§Ù†\n",
        "        elif sell_score > buy_score and sell_score >= 65:\n",
        "            final_signal = 'ÙØ±ÙˆØ´'\n",
        "            final_strength = sell_score * realism_factor\n",
        "            confidence_factor = (sell_score - buy_score) / 10\n",
        "        else:\n",
        "            # Ø¯Ø± Ø­Ø§Ù„Øª Ø®Ù†Ø«ÛŒØŒ Ù‚Ø¯Ø±Øª Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø¨Ù‡ Ù…ÛŒØ²Ø§Ù† Ø¹Ø¯Ù… Ù‚Ø·Ø¹ÛŒØª Ø¨Ø³ØªÚ¯ÛŒ Ø¯Ø§Ø±Ø¯\n",
        "            final_strength = 50 - abs(buy_score - sell_score) / 2\n",
        "            final_strength *= realism_factor  # Ø§Ø¹Ù…Ø§Ù„ ÙØ§Ú©ØªÙˆØ± ÙˆØ§Ù‚Ø¹â€ŒÚ¯Ø±Ø§ÛŒÛŒ\n",
        "\n",
        "        # ØªØ¹Ø¯ÛŒÙ„ Ù†Ù‡Ø§ÛŒÛŒ Ù‚Ø¯Ø±Øª Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ¹Ø¯Ø§Ø¯ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§ÛŒ Ù‡Ù…Ø³Ùˆ\n",
        "        buy_strategies_count = sum(1 for s in signals.values() if s['type'] in ['Ø®Ø±ÛŒØ¯', 'ØµØ¹ÙˆØ¯ÛŒ', 'BUY', 'LONG'])\n",
        "        sell_strategies_count = sum(1 for s in signals.values() if s['type'] in ['ÙØ±ÙˆØ´', 'Ù†Ø²ÙˆÙ„ÛŒ', 'SELL', 'SHORT'])\n",
        "\n",
        "        # Ø§Ú¯Ø± Ø¨ÛŒØ´ Ø§Ø² 80% Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§ Ù‡Ù…Ø³Ùˆ Ù‡Ø³ØªÙ†Ø¯ØŒ Ø¯Ù‚Øª Ø±Ø§ Ø§ÙØ²Ø§ÛŒØ´ Ù…ÛŒâ€ŒØ¯Ù‡ÛŒÙ…\n",
        "        total_strategies = len(signals)\n",
        "        if final_signal == 'Ø®Ø±ÛŒØ¯' and buy_strategies_count >= 0.8 * total_strategies:\n",
        "            final_strength += 5\n",
        "        elif final_signal == 'ÙØ±ÙˆØ´' and sell_strategies_count >= 0.8 * total_strategies:\n",
        "            final_strength += 5\n",
        "\n",
        "        # Ø§ÙØ²Ø§ÛŒØ´ ÛŒØ§ Ú©Ø§Ù‡Ø´ Ù‚Ø¯Ø±Øª Ø¨Ø±Ø§Ø³Ø§Ø³ Ù…ÛŒØ²Ø§Ù† Ø§Ø·Ù…ÛŒÙ†Ø§Ù†\n",
        "        final_strength += confidence_factor\n",
        "\n",
        "        # Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† Ù‚Ø¯Ø±Øª Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ù‡ Ù…Ø­Ø¯ÙˆØ¯Ù‡ 1-100\n",
        "        final_strength = max(1, min(100, final_strength))\n",
        "\n",
        "        # ØªØ¹ÛŒÛŒÙ† Ù†Ù‚Ø§Ø· ÙˆØ±ÙˆØ¯ØŒ Ø­Ø¯ Ø¶Ø±Ø± Ùˆ Ø­Ø¯ Ø³ÙˆØ¯\n",
        "        entry_price = df['close'].iloc[-1]\n",
        "        stop_loss = 0\n",
        "        take_profit = 0\n",
        "\n",
        "        # ØªØ±Ú©ÛŒØ¨ Ø­Ø¯ Ø¶Ø±Ø± Ùˆ Ø­Ø¯ Ø³ÙˆØ¯ Ø§Ø² Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù\n",
        "        if final_signal == 'Ø®Ø±ÛŒØ¯':\n",
        "            # Ø¨Ø±Ø§ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø®Ø±ÛŒØ¯\n",
        "            stop_losses = []\n",
        "            take_profits = []\n",
        "\n",
        "            # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø³Ø§Ø®ØªØ§Ø± Ø¨Ø§Ø²Ø§Ø±\n",
        "            if 'orderblock_bearish' in market_structure_result and market_structure_result['orderblock_bearish']:\n",
        "                latest_block = market_structure_result['orderblock_bearish'][-1]\n",
        "                stop_losses.append(latest_block['low'] * 0.98)\n",
        "\n",
        "            # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø­Ø¯ Ø¶Ø±Ø± Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ EMA\n",
        "            if ema_result['entry_points'] and ema_result['entry_points'][-1]['type'] == 'long':\n",
        "                stop_losses.append(ema_result['entry_points'][-1]['stop_loss'])\n",
        "                take_profits.append(ema_result['entry_points'][-1]['take_profit'])\n",
        "\n",
        "            # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø­Ø¯ Ø¶Ø±Ø± Ø§ÛŒÚ†ÛŒÙ…ÙˆÚ©Ùˆ\n",
        "            if ichimoku_result['entry_points'] and ichimoku_result['entry_points'][-1]['type'] == 'long':\n",
        "                stop_losses.append(ichimoku_result['entry_points'][-1]['stop_loss'])\n",
        "                take_profits.append(ichimoku_result['entry_points'][-1]['take_profit'])\n",
        "\n",
        "            # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø³Ø·ÙˆØ­ ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ\n",
        "            if fibonacci_result['nearest_support'] and fibonacci_result['nearest_support'][1] < entry_price:\n",
        "                stop_losses.append(fibonacci_result['nearest_support'][1] * 0.98)\n",
        "\n",
        "            # Ø§Ú¯Ø± Ù‡ÛŒÚ† Ø­Ø¯ Ø¶Ø±Ø±ÛŒ Ø§Ø² Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§ Ù†ÛŒØ³ØªØŒ Ø§Ø² ATR Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…\n",
        "            if not stop_losses:\n",
        "                atr = ta.volatility.average_true_range(df['high'], df['low'], df['close'], window=14).iloc[-1]\n",
        "                stop_losses.append(entry_price - atr * 2)\n",
        "                take_profits.append(entry_price + atr * 4)\n",
        "\n",
        "            # Ø§Ù†ØªØ®Ø§Ø¨ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø­Ø¯ Ø¶Ø±Ø± Ùˆ Ø­Ø¯ Ø³ÙˆØ¯\n",
        "            stop_loss = sum(stop_losses) / len(stop_losses)\n",
        "\n",
        "            # Ø§Ú¯Ø± Ø­Ø¯ Ø³ÙˆØ¯ Ø§Ø² Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§ ØªØ¹ÛŒÛŒÙ† Ù†Ø´Ø¯Ù‡ØŒ 2 Ø¨Ø±Ø§Ø¨Ø± Ø±ÛŒØ³Ú© Ø¯Ø± Ù†Ø¸Ø± Ù…ÛŒâ€ŒÚ¯ÛŒØ±ÛŒÙ…\n",
        "            if take_profits:\n",
        "                take_profit = sum(take_profits) / len(take_profits)\n",
        "            else:\n",
        "                take_profit = entry_price + (entry_price - stop_loss) * 2\n",
        "\n",
        "        elif final_signal == 'ÙØ±ÙˆØ´':\n",
        "            # Ø¨Ø±Ø§ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„ ÙØ±ÙˆØ´ (Ú©Ø¯ Ù…Ø´Ø§Ø¨Ù‡ Ø´Ø±Ø· Ø¨Ø§Ù„Ø§)\n",
        "            stop_losses = []\n",
        "            take_profits = []\n",
        "\n",
        "            # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø³Ø§Ø®ØªØ§Ø± Ø¨Ø§Ø²Ø§Ø±\n",
        "            if 'orderblock_bullish' in market_structure_result and market_structure_result['orderblock_bullish']:\n",
        "                latest_block = market_structure_result['orderblock_bullish'][-1]\n",
        "                stop_losses.append(latest_block['high'] * 1.02)\n",
        "\n",
        "            # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø­Ø¯ Ø¶Ø±Ø± Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ EMA\n",
        "            if ema_result['entry_points'] and ema_result['entry_points'][-1]['type'] == 'short':\n",
        "                stop_losses.append(ema_result['entry_points'][-1]['stop_loss'])\n",
        "                take_profits.append(ema_result['entry_points'][-1]['take_profit'])\n",
        "\n",
        "            # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø­Ø¯ Ø¶Ø±Ø± Ø§ÛŒÚ†ÛŒÙ…ÙˆÚ©Ùˆ\n",
        "            if ichimoku_result['entry_points'] and ichimoku_result['entry_points'][-1]['type'] == 'short':\n",
        "                stop_losses.append(ichimoku_result['entry_points'][-1]['stop_loss'])\n",
        "                take_profits.append(ichimoku_result['entry_points'][-1]['take_profit'])\n",
        "\n",
        "            # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø³Ø·ÙˆØ­ ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ\n",
        "            if fibonacci_result['nearest_resistance'] and fibonacci_result['nearest_resistance'][1] > entry_price:\n",
        "                stop_losses.append(fibonacci_result['nearest_resistance'][1] * 1.02)\n",
        "\n",
        "            # Ø§Ú¯Ø± Ù‡ÛŒÚ† Ø­Ø¯ Ø¶Ø±Ø±ÛŒ Ø§Ø² Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§ Ù†ÛŒØ³ØªØŒ Ø§Ø² ATR Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…\n",
        "            if not stop_losses:\n",
        "                atr = ta.volatility.average_true_range(df['high'], df['low'], df['close'], window=14).iloc[-1]\n",
        "                stop_losses.append(entry_price + atr * 2)\n",
        "                take_profits.append(entry_price - atr * 4)\n",
        "\n",
        "            # Ø§Ù†ØªØ®Ø§Ø¨ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø­Ø¯ Ø¶Ø±Ø± Ùˆ Ø­Ø¯ Ø³ÙˆØ¯\n",
        "            stop_loss = sum(stop_losses) / len(stop_losses)\n",
        "\n",
        "            # Ø§Ú¯Ø± Ø­Ø¯ Ø³ÙˆØ¯ Ø§Ø² Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§ ØªØ¹ÛŒÛŒÙ† Ù†Ø´Ø¯Ù‡ØŒ 2 Ø¨Ø±Ø§Ø¨Ø± Ø±ÛŒØ³Ú© Ø¯Ø± Ù†Ø¸Ø± Ù…ÛŒâ€ŒÚ¯ÛŒØ±ÛŒÙ…\n",
        "            if take_profits:\n",
        "                take_profit = sum(take_profits) / len(take_profits)\n",
        "            else:\n",
        "                take_profit = entry_price - (stop_loss - entry_price) * 2\n",
        "\n",
        "        # ØªÙˆØ¶ÛŒØ­Ø§Øª Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ§ÙÙ‚\n",
        "        supporting_strategies = {}\n",
        "        strategy_descriptions = []\n",
        "\n",
        "        for strategy, info in signals.items():\n",
        "            if (final_signal == 'Ø®Ø±ÛŒØ¯' and info['type'] in ['Ø®Ø±ÛŒØ¯', 'ØµØ¹ÙˆØ¯ÛŒ', 'BUY', 'LONG'] and info[\n",
        "                'strength'] >= 60) or \\\n",
        "                    (final_signal == 'ÙØ±ÙˆØ´' and info['type'] in ['ÙØ±ÙˆØ´', 'Ù†Ø²ÙˆÙ„ÛŒ', 'SELL', 'SHORT'] and info[\n",
        "                        'strength'] >= 60):\n",
        "\n",
        "                strategy_name = {\n",
        "                    'market_structure': 'Ø³Ø§Ø®ØªØ§Ø± Ø¨Ø§Ø²Ø§Ø±',\n",
        "                    'pressure': 'ÙØ´Ø§Ø± Ø®Ø±ÛŒØ¯/ÙØ±ÙˆØ´',\n",
        "                    'whale': 'ÙØ¹Ø§Ù„ÛŒØª Ù†Ù‡Ù†Ú¯â€ŒÙ‡Ø§',\n",
        "                    'ema': 'Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…ØªØ­Ø±Ú© Ù†Ù…Ø§ÛŒÛŒ',\n",
        "                    'rsi': 'Ø´Ø§Ø®Øµ Ù‚Ø¯Ø±Øª Ù†Ø³Ø¨ÛŒ',\n",
        "                    'divergence': 'ÙˆØ§Ú¯Ø±Ø§ÛŒÛŒ',\n",
        "                    'bbrsi_macd': 'Ø¨Ø§Ù†Ø¯ Ø¨ÙˆÙ„ÛŒÙ†Ú¯Ø±/RSI/MACD',\n",
        "                    'ichimoku': 'Ø§ÛŒÚ†ÛŒÙ…ÙˆÚ©Ùˆ',\n",
        "                    'fibonacci': 'ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ'\n",
        "                }\n",
        "\n",
        "                # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù‚Ø¯Ø±Øª ÙˆØ§Ù‚Ø¹ÛŒ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø¨Ø§ Ø§Ø¹Ù…Ø§Ù„ Ø¯Ù‚Øª ØªØ§Ø±ÛŒØ®ÛŒ\n",
        "                adjusted_strength = info['strength'] * info['historical_accuracy']\n",
        "                supporting_strategies[strategy_name[strategy]] = min(100, adjusted_strength)\n",
        "\n",
        "                # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ØªÙˆØ¶ÛŒØ­Ø§Øª Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ\n",
        "                if strategy == 'market_structure' and final_signal == 'Ø®Ø±ÛŒØ¯':\n",
        "                    strategy_descriptions.append(f\"Ø³Ø§Ø®ØªØ§Ø± Ø¨Ø§Ø²Ø§Ø± ØµØ¹ÙˆØ¯ÛŒ Ø¨Ø§ Ø´Ú©Ø³Øª Ø³Ø§Ø®ØªØ§Ø±ÛŒ Ùˆ Ø¨Ù„ÙˆÚ© Ø³ÙØ§Ø±Ø´\")\n",
        "                elif strategy == 'market_structure' and final_signal == 'ÙØ±ÙˆØ´':\n",
        "                    strategy_descriptions.append(f\"Ø³Ø§Ø®ØªØ§Ø± Ø¨Ø§Ø²Ø§Ø± Ù†Ø²ÙˆÙ„ÛŒ Ø¨Ø§ Ø´Ú©Ø³Øª Ø³Ø§Ø®ØªØ§Ø±ÛŒ Ùˆ Ø¨Ù„ÙˆÚ© Ø³ÙØ§Ø±Ø´\")\n",
        "                elif strategy == 'ema':\n",
        "                    strategy_descriptions.append(f\"Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ EMA: {ema_result['current_status']}\")\n",
        "                elif strategy == 'rsi' and 'current_status' in rsi_result:\n",
        "                    strategy_descriptions.append(f\"RSI Ø¯Ø± ÙˆØ¶Ø¹ÛŒØª {rsi_result['current_status']}\")\n",
        "                elif strategy == 'ichimoku' and 'current_status' in ichimoku_result:\n",
        "                    strategy_descriptions.append(f\"Ø§ÛŒÚ†ÛŒÙ…ÙˆÚ©Ùˆ: {ichimoku_result['current_status']}\")\n",
        "\n",
        "        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ØªÙˆØ¶ÛŒØ­ ÙˆØ§Ù‚Ø¹â€ŒÚ¯Ø±Ø§ÛŒÛŒ\n",
        "        strategy_descriptions.append(f\"Ø¯Ù‚Øª Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ø´Ø±Ø§ÛŒØ· Ø¨Ø§Ø²Ø§Ø± Ùˆ ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¯Ù‡ Ø§Ø³Øª\")\n",
        "        if market_volatility > 5:\n",
        "            strategy_descriptions.append(f\"Ù†ÙˆØ³Ø§Ù† Ø¨Ø§Ø²Ø§Ø± Ø¨Ø§Ù„Ø§Ø³Øª - Ø¯Ù‚Øª Ø³ÛŒÚ¯Ù†Ø§Ù„ Ú©Ø§Ù‡Ø´ ÛŒØ§ÙØªÙ‡\")\n",
        "\n",
        "        # Ù†ØªØ§ÛŒØ¬ Ù†Ù‡Ø§ÛŒÛŒ\n",
        "        result = {\n",
        "            'signal': final_signal,\n",
        "            'strength': round(final_strength, 1),  # Ú¯Ø±Ø¯ Ú©Ø±Ø¯Ù† Ø¨Ù‡ ÛŒÚ© Ø±Ù‚Ù… Ø§Ø¹Ø´Ø§Ø± Ø¨Ø±Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒâ€ŒØªØ± Ø¨ÙˆØ¯Ù†\n",
        "            'entry_price': entry_price,\n",
        "            'stop_loss': stop_loss,\n",
        "            'take_profit': take_profit,\n",
        "            'supporting_strategies': supporting_strategies,\n",
        "            'strategy_descriptions': strategy_descriptions,\n",
        "            'risk_reward_ratio': abs(\n",
        "                (take_profit - entry_price) / (entry_price - stop_loss)) if stop_loss != entry_price else 0,\n",
        "            'buy_score': buy_score,\n",
        "            'sell_score': sell_score,\n",
        "            'signals': signals,\n",
        "            'market_conditions': {\n",
        "                'volatility': market_volatility,\n",
        "                'confidence_factor': confidence_factor,\n",
        "                'realism_factor': realism_factor\n",
        "            }\n",
        "        }\n",
        "\n",
        "        return result\n",
        "\n",
        "    def special_strategy(self, df):\n",
        "        \"\"\"\n",
        "        Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ ÙˆÛŒÚ˜Ù‡: ØªØ±Ú©ÛŒØ¨ Ú†Ù†Ø¯ÛŒÙ† Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ± Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¨Ø±Ø§ÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø¨Ù‡ØªØ±ÛŒÙ† ÙØ±ØµØªâ€ŒÙ‡Ø§ÛŒ Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ\n",
        "\n",
        "        Args:\n",
        "            df: Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§\n",
        "\n",
        "        Returns:\n",
        "            Ù†ØªØ§ÛŒØ¬ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ ÙˆÛŒÚ˜Ù‡\n",
        "        \"\"\"\n",
        "        # Ø§ÛŒØ¬Ø§Ø¯ Ú©Ù¾ÛŒ Ø§Ø² Ø¯ÛŒØªØ§ÙØ±ÛŒÙ…\n",
        "        df_special = df.copy()\n",
        "\n",
        "        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡\n",
        "        # 1. Super Trend\n",
        "        atr_period = 10\n",
        "        atr_multiplier = 3.0\n",
        "\n",
        "        # Ù…Ø­Ø§Ø³Ø¨Ù‡ ATR\n",
        "        df_special['atr'] = ta.volatility.average_true_range(df_special['high'], df_special['low'], df_special['close'],\n",
        "                                                             window=atr_period)\n",
        "\n",
        "        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¨Ø§Ù†Ø¯â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ù„Ø§ Ùˆ Ù¾Ø§ÛŒÛŒÙ†\n",
        "        df_special['upperband'] = ((df_special['high'] + df_special['low']) / 2) + (atr_multiplier * df_special['atr'])\n",
        "        df_special['lowerband'] = ((df_special['high'] + df_special['low']) / 2) - (atr_multiplier * df_special['atr'])\n",
        "\n",
        "        # ØªØ¹ÛŒÛŒÙ† Ø±ÙˆÙ†Ø¯ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Super Trend\n",
        "        df_special['in_uptrend'] = True\n",
        "        for i in range(1, len(df_special)):\n",
        "            current_close = df_special['close'].iloc[i]\n",
        "            prev_close = df_special['close'].iloc[i - 1]\n",
        "\n",
        "            prev_upperband = df_special['upperband'].iloc[i - 1]\n",
        "            prev_lowerband = df_special['lowerband'].iloc[i - 1]\n",
        "\n",
        "            current_upperband = df_special['upperband'].iloc[i]\n",
        "            current_lowerband = df_special['lowerband'].iloc[i]\n",
        "\n",
        "            prev_in_uptrend = df_special['in_uptrend'].iloc[i - 1]\n",
        "\n",
        "            if prev_in_uptrend:\n",
        "                # Ø§Ú¯Ø± Ù‚Ø¨Ù„Ø§Ù‹ Ø¯Ø± Ø±ÙˆÙ†Ø¯ ØµØ¹ÙˆØ¯ÛŒ Ø¨ÙˆØ¯ÛŒÙ…\n",
        "                if current_close < current_lowerband:\n",
        "                    df_special.loc[df_special.index[i], 'in_uptrend'] = False\n",
        "                else:\n",
        "                    df_special.loc[df_special.index[i], 'in_uptrend'] = True\n",
        "            else:\n",
        "                # Ø§Ú¯Ø± Ù‚Ø¨Ù„Ø§Ù‹ Ø¯Ø± Ø±ÙˆÙ†Ø¯ Ù†Ø²ÙˆÙ„ÛŒ Ø¨ÙˆØ¯ÛŒÙ…\n",
        "                if current_close > current_upperband:\n",
        "                    df_special.loc[df_special.index[i], 'in_uptrend'] = True\n",
        "                else:\n",
        "                    df_special.loc[df_special.index[i], 'in_uptrend'] = False\n",
        "\n",
        "        # 2. Williams Vix Fix - Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ ØªØ±Ø³ Ùˆ Ø·Ù…Ø¹ Ø¨Ø§Ø²Ø§Ø±\n",
        "        period = 22\n",
        "        stddev = 2.0\n",
        "\n",
        "        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ±ÛŒÙ† Ú©Ù Ø¯Ø± Ø¯ÙˆØ±Ù‡\n",
        "        df_special['lowest_low'] = df_special['low'].rolling(window=period).min()\n",
        "\n",
        "        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¨Ø§Ù„Ø§ØªØ±ÛŒÙ† Ø¨Ø§Ù„Ø§ Ø¯Ø± Ø¯ÙˆØ±Ù‡\n",
        "        df_special['highest_high'] = df_special['high'].rolling(window=period).max()\n",
        "\n",
        "        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Williams Vix Fix\n",
        "        df_special['williams_vix'] = ((df_special['highest_high'] - df_special['close']) /\n",
        "                                      (df_special['highest_high'] - df_special['lowest_low'])) * 100\n",
        "\n",
        "        # Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…ØªØ­Ø±Ú© Williams Vix Fix\n",
        "        df_special['williams_vix_ma'] = df_special['williams_vix'].rolling(window=9).mean()\n",
        "\n",
        "        # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù†Ù‚Ø§Ø· Ø§ÙˆØ¬ Ùˆ Ø­Ø¶ÛŒØ¶ Williams Vix Fix\n",
        "        df_special['williams_vix_high'] = df_special['williams_vix'].rolling(window=10, center=True).max()\n",
        "        df_special['williams_vix_low'] = df_special['williams_vix'].rolling(window=10, center=True).min()\n",
        "\n",
        "        # 3. TTM Squeeze - Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ ÙØ´Ø±Ø¯Ú¯ÛŒ Ù†ÙˆØ³Ø§Ù† Ùˆ Ø§Ù†ÙØ¬Ø§Ø± Ù‚ÛŒÙ…Øª\n",
        "        len_bb = 20\n",
        "        len_kc = 20\n",
        "        mult_bb = 2.0\n",
        "        mult_kc = 1.5\n",
        "\n",
        "        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¨Ø§Ù†Ø¯ Ø¨ÙˆÙ„ÛŒÙ†Ú¯Ø±\n",
        "        df_special['bb_upper'] = ta.volatility.bollinger_hband(df_special['close'], window=len_bb, window_dev=mult_bb)\n",
        "        df_special['bb_middle'] = ta.volatility.bollinger_mavg(df_special['close'], window=len_bb)\n",
        "        df_special['bb_lower'] = ta.volatility.bollinger_lband(df_special['close'], window=len_bb, window_dev=mult_bb)\n",
        "\n",
        "        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ú©Ø§Ù†Ø§Ù„ Ú©Ù„ØªÙ†Ø±\n",
        "        df_special['kc_middle'] = df_special['close'].rolling(window=len_kc).mean()\n",
        "        df_special['kc_range'] = (df_special['high'] - df_special['low']).rolling(window=len_kc).mean()\n",
        "        df_special['kc_upper'] = df_special['kc_middle'] + mult_kc * df_special['kc_range']\n",
        "        df_special['kc_lower'] = df_special['kc_middle'] - mult_kc * df_special['kc_range']\n",
        "\n",
        "        # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ ÙØ´Ø±Ø¯Ú¯ÛŒ (Squeeze)\n",
        "        df_special['squeeze_on'] = ((df_special['bb_lower'] > df_special['kc_lower']) &\n",
        "                                    (df_special['bb_upper'] < df_special['kc_upper']))\n",
        "\n",
        "        # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø§Ù†ÙØ¬Ø§Ø± (Firing)\n",
        "        df_special['squeeze_off'] = ((df_special['squeeze_on'].shift(1) == True) &\n",
        "                                     (df_special['squeeze_on'] == False))\n",
        "\n",
        "        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÙˆÙ…Ù†ØªÙˆÙ… Ø¨Ø±Ø§ÛŒ ØªØ¹ÛŒÛŒÙ† Ø¬Ù‡Øª Ù¾Ø³ Ø§Ø² Ø§Ù†ÙØ¬Ø§Ø±\n",
        "        df_special['momentum'] = df_special['close'] - df_special['close'].rolling(window=len_bb).mean()\n",
        "        df_special['momentum_ma'] = df_special['momentum'].rolling(window=9).mean()\n",
        "\n",
        "        # ØªØ±Ú©ÛŒØ¨ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ù‚ÙˆÛŒ\n",
        "\n",
        "        # Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø®Ø±ÛŒØ¯ Ù‚ÙˆÛŒ:\n",
        "        # 1. Super Trend ØªØºÛŒÛŒØ± Ø¨Ù‡ Ø±ÙˆÙ†Ø¯ ØµØ¹ÙˆØ¯ÛŒ + TTM Squeeze Ù¾Ø§ÛŒØ§Ù† ÙØ´Ø±Ø¯Ú¯ÛŒ + Williams Vix Fix Ø¯Ø± Ù†Ù‚Ø·Ù‡ Ø§ÙˆØ¬\n",
        "        df_special['strong_buy'] = (\n",
        "                (df_special['in_uptrend'] == True) &\n",
        "                (df_special['in_uptrend'].shift(1) == False) &\n",
        "                (df_special['squeeze_off'] == True) &\n",
        "                (df_special['momentum'] > 0) &\n",
        "                (df_special['williams_vix'] > 80)\n",
        "        )\n",
        "\n",
        "        # 2. Super Trend Ø¯Ø± Ø±ÙˆÙ†Ø¯ ØµØ¹ÙˆØ¯ÛŒ + TTM Squeeze Ø¯Ø± Ø­Ø§Ù„ ÙØ´Ø±Ø¯Ú¯ÛŒ + Ù†Ø²Ø¯ÛŒÚ© Ø´Ø¯Ù† Ø¨Ù‡ Ú©Ù Williams Vix Fix\n",
        "        df_special['moderate_buy'] = (\n",
        "                (df_special['in_uptrend'] == True) &\n",
        "                (df_special['squeeze_on'] == True) &\n",
        "                (df_special['williams_vix'] < 30) &\n",
        "                (df_special['williams_vix'] < df_special['williams_vix'].shift(1))\n",
        "        )\n",
        "\n",
        "        # Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ ÙØ±ÙˆØ´ Ù‚ÙˆÛŒ:\n",
        "        # 1. Super Trend ØªØºÛŒÛŒØ± Ø¨Ù‡ Ø±ÙˆÙ†Ø¯ Ù†Ø²ÙˆÙ„ÛŒ + TTM Squeeze Ù¾Ø§ÛŒØ§Ù† ÙØ´Ø±Ø¯Ú¯ÛŒ + Williams Vix Fix Ø¯Ø± Ù†Ù‚Ø·Ù‡ Ø­Ø¶ÛŒØ¶\n",
        "        df_special['strong_sell'] = (\n",
        "                (df_special['in_uptrend'] == False) &\n",
        "                (df_special['in_uptrend'].shift(1) == True) &\n",
        "                (df_special['squeeze_off'] == True) &\n",
        "                (df_special['momentum'] < 0) &\n",
        "                (df_special['williams_vix'] < 20)\n",
        "        )\n",
        "\n",
        "        # 2. Super Trend Ø¯Ø± Ø±ÙˆÙ†Ø¯ Ù†Ø²ÙˆÙ„ÛŒ + TTM Squeeze Ø¯Ø± Ø­Ø§Ù„ ÙØ´Ø±Ø¯Ú¯ÛŒ + Ù†Ø²Ø¯ÛŒÚ© Ø´Ø¯Ù† Ø¨Ù‡ Ø§ÙˆØ¬ Williams Vix Fix\n",
        "        df_special['moderate_sell'] = (\n",
        "                (df_special['in_uptrend'] == False) &\n",
        "                (df_special['squeeze_on'] == True) &\n",
        "                (df_special['williams_vix'] > 70) &\n",
        "                (df_special['williams_vix'] > df_special['williams_vix'].shift(1))\n",
        "        )\n",
        "\n",
        "        # Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§\n",
        "        buy_signals = []\n",
        "        sell_signals = []\n",
        "\n",
        "        for i in range(max(len_bb, len_kc, period) + 10, len(df_special)):\n",
        "            # Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø®Ø±ÛŒØ¯\n",
        "            if df_special['strong_buy'].iloc[i]:\n",
        "                buy_signals.append({\n",
        "                    'index': i,\n",
        "                    'date': df_special.index[i],\n",
        "                    'price': df_special['close'].iloc[i],\n",
        "                    'strength': 90,\n",
        "                    'description': 'Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø®Ø±ÛŒØ¯ Ù‚ÙˆÛŒ: Super Trend ØµØ¹ÙˆØ¯ÛŒ + TTM Squeeze Ù¾Ø§ÛŒØ§Ù† ÙØ´Ø±Ø¯Ú¯ÛŒ + Williams Vix Fix Ø¯Ø± Ù†Ù‚Ø·Ù‡ Ø§ÙˆØ¬',\n",
        "                    'type': 'strong_buy'\n",
        "                })\n",
        "            elif df_special['moderate_buy'].iloc[i]:\n",
        "                buy_signals.append({\n",
        "                    'index': i,\n",
        "                    'date': df_special.index[i],\n",
        "                    'price': df_special['close'].iloc[i],\n",
        "                    'strength': 75,\n",
        "                    'description': 'Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø®Ø±ÛŒØ¯ Ù…ØªÙˆØ³Ø·: Super Trend ØµØ¹ÙˆØ¯ÛŒ + TTM Squeeze Ø¯Ø± Ø­Ø§Ù„ ÙØ´Ø±Ø¯Ú¯ÛŒ + Ú©Ø§Ù‡Ø´ Williams Vix Fix',\n",
        "                    'type': 'moderate_buy'\n",
        "                })\n",
        "\n",
        "            # Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ ÙØ±ÙˆØ´\n",
        "            if df_special['strong_sell'].iloc[i]:\n",
        "                sell_signals.append({\n",
        "                    'index': i,\n",
        "                    'date': df_special.index[i],\n",
        "                    'price': df_special['close'].iloc[i],\n",
        "                    'strength': 90,\n",
        "                    'description': 'Ø³ÛŒÚ¯Ù†Ø§Ù„ ÙØ±ÙˆØ´ Ù‚ÙˆÛŒ: Super Trend Ù†Ø²ÙˆÙ„ÛŒ + TTM Squeeze Ù¾Ø§ÛŒØ§Ù† ÙØ´Ø±Ø¯Ú¯ÛŒ + Williams Vix Fix Ø¯Ø± Ù†Ù‚Ø·Ù‡ Ø­Ø¶ÛŒØ¶',\n",
        "                    'type': 'strong_sell'\n",
        "                })\n",
        "            elif df_special['moderate_sell'].iloc[i]:\n",
        "                sell_signals.append({\n",
        "                    'index': i,\n",
        "                    'date': df_special.index[i],\n",
        "                    'price': df_special['close'].iloc[i],\n",
        "                    'strength': 75,\n",
        "                    'description': 'Ø³ÛŒÚ¯Ù†Ø§Ù„ ÙØ±ÙˆØ´ Ù…ØªÙˆØ³Ø·: Super Trend Ù†Ø²ÙˆÙ„ÛŒ + TTM Squeeze Ø¯Ø± Ø­Ø§Ù„ ÙØ´Ø±Ø¯Ú¯ÛŒ + Ø§ÙØ²Ø§ÛŒØ´ Williams Vix Fix',\n",
        "                    'type': 'moderate_sell'\n",
        "                })\n",
        "\n",
        "        # ØªØ¹ÛŒÛŒÙ† Ù†Ù‚Ø§Ø· ÙˆØ±ÙˆØ¯ Ùˆ Ø®Ø±ÙˆØ¬\n",
        "        entry_points = []\n",
        "\n",
        "        for signal in buy_signals:\n",
        "            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø­Ø¯ Ø¶Ø±Ø± Ùˆ Ø­Ø¯ Ø³ÙˆØ¯ Ø¨Ø±Ø§ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø®Ø±ÛŒØ¯\n",
        "            i = signal['index']\n",
        "            price = signal['price']\n",
        "\n",
        "            # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Super Trend Ø¨Ø±Ø§ÛŒ Ø­Ø¯ Ø¶Ø±Ø±\n",
        "            stop_loss = df_special['lowerband'].iloc[i]\n",
        "\n",
        "            # Ø­Ø¯ Ø³ÙˆØ¯: Ù†Ø³Ø¨Øª Ø±ÛŒØ³Ú© Ø¨Ù‡ Ø±ÛŒÙˆØ§Ø±Ø¯ 1:2\n",
        "            risk = price - stop_loss\n",
        "            take_profit = price + (risk * 2)\n",
        "\n",
        "            entry_points.append({\n",
        "                'index': i,\n",
        "                'price': price,\n",
        "                'stop_loss': stop_loss,\n",
        "                'take_profit': take_profit,\n",
        "                'type': 'long',\n",
        "                'strength': signal['strength']\n",
        "            })\n",
        "\n",
        "        for signal in sell_signals:\n",
        "            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø­Ø¯ Ø¶Ø±Ø± Ùˆ Ø­Ø¯ Ø³ÙˆØ¯ Ø¨Ø±Ø§ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ ÙØ±ÙˆØ´\n",
        "            i = signal['index']\n",
        "            price = signal['price']\n",
        "\n",
        "            # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Super Trend Ø¨Ø±Ø§ÛŒ Ø­Ø¯ Ø¶Ø±Ø±\n",
        "            stop_loss = df_special['upperband'].iloc[i]\n",
        "\n",
        "            # Ø­Ø¯ Ø³ÙˆØ¯: Ù†Ø³Ø¨Øª Ø±ÛŒØ³Ú© Ø¨Ù‡ Ø±ÛŒÙˆØ§Ø±Ø¯ 1:2\n",
        "            risk = stop_loss - price\n",
        "            take_profit = price - (risk * 2)\n",
        "\n",
        "            entry_points.append({\n",
        "                'index': i,\n",
        "                'price': price,\n",
        "                'stop_loss': stop_loss,\n",
        "                'take_profit': take_profit,\n",
        "                'type': 'short',\n",
        "                'strength': signal['strength']\n",
        "            })\n",
        "\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ\n",
        "        current_signal = 'Ø®Ù†Ø«ÛŒ'\n",
        "        current_strength = 50\n",
        "        last_idx = len(df_special) - 1\n",
        "\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ Ø±ÙˆÙ†Ø¯ ÙØ¹Ù„ÛŒ Super Trend\n",
        "        if df_special['in_uptrend'].iloc[last_idx]:\n",
        "            if df_special['in_uptrend'].iloc[last_idx - 1] == False:\n",
        "                # ØªØºÛŒÛŒØ± Ø±ÙˆÙ†Ø¯ Ø¨Ù‡ ØµØ¹ÙˆØ¯ÛŒ\n",
        "                current_signal = 'Ø®Ø±ÛŒØ¯'\n",
        "                current_strength = 80\n",
        "            else:\n",
        "                # Ø§Ø¯Ø§Ù…Ù‡ Ø±ÙˆÙ†Ø¯ ØµØ¹ÙˆØ¯ÛŒ\n",
        "                current_signal = 'Ø®Ø±ÛŒØ¯'\n",
        "                current_strength = 60\n",
        "        else:\n",
        "            if df_special['in_uptrend'].iloc[last_idx - 1] == True:\n",
        "                # ØªØºÛŒÛŒØ± Ø±ÙˆÙ†Ø¯ Ø¨Ù‡ Ù†Ø²ÙˆÙ„ÛŒ\n",
        "                current_signal = 'ÙØ±ÙˆØ´'\n",
        "                current_strength = 80\n",
        "            else:\n",
        "                # Ø§Ø¯Ø§Ù…Ù‡ Ø±ÙˆÙ†Ø¯ Ù†Ø²ÙˆÙ„ÛŒ\n",
        "                current_signal = 'ÙØ±ÙˆØ´'\n",
        "                current_strength = 60\n",
        "\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ TTM Squeeze\n",
        "        if df_special['squeeze_off'].iloc[last_idx]:\n",
        "            # ÙØ´Ø±Ø¯Ú¯ÛŒ Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯Ù‡ Ùˆ Ù‚ÛŒÙ…Øª Ø¯Ø± Ø­Ø§Ù„ Ø­Ø±Ú©Øª Ø§Ø³Øª\n",
        "            if df_special['momentum'].iloc[last_idx] > 0:\n",
        "                current_signal = 'Ø®Ø±ÛŒØ¯'\n",
        "                current_strength += 15\n",
        "            else:\n",
        "                current_signal = 'ÙØ±ÙˆØ´'\n",
        "                current_strength += 15\n",
        "        elif df_special['squeeze_on'].iloc[last_idx]:\n",
        "            # Ø¯Ø± Ø­Ø§Ù„ ÙØ´Ø±Ø¯Ú¯ÛŒ Ù‡Ø³ØªÛŒÙ… - Ù‚ÛŒÙ…Øª Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ Ø¯Ø± Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ Ø§Ø³Øª\n",
        "            current_strength -= 10\n",
        "\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ Williams Vix Fix\n",
        "        williams_vix_current = df_special['williams_vix'].iloc[last_idx]\n",
        "        if williams_vix_current > 80:\n",
        "            # Ø³Ø·Ø­ Ø¨Ø§Ù„Ø§ÛŒ ØªØ±Ø³ - Ø§Ø­ØªÙ…Ø§Ù„ Ø¨Ø±Ú¯Ø´Øª ØµØ¹ÙˆØ¯ÛŒ\n",
        "            if current_signal == 'Ø®Ø±ÛŒØ¯':\n",
        "                current_strength += 10\n",
        "        elif williams_vix_current < 20:\n",
        "            # Ø³Ø·Ø­ Ù¾Ø§ÛŒÛŒÙ† ØªØ±Ø³ - Ø§Ø­ØªÙ…Ø§Ù„ Ø¨Ø±Ú¯Ø´Øª Ù†Ø²ÙˆÙ„ÛŒ\n",
        "            if current_signal == 'ÙØ±ÙˆØ´':\n",
        "                current_strength += 10\n",
        "\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ø®ÛŒØ±\n",
        "        recent_buy = [s for s in buy_signals if last_idx - s['index'] <= 3]\n",
        "        recent_sell = [s for s in sell_signals if last_idx - s['index'] <= 3]\n",
        "\n",
        "        if recent_buy:\n",
        "            current_signal = 'Ø®Ø±ÛŒØ¯'\n",
        "            current_strength = max([s['strength'] for s in recent_buy])\n",
        "        elif recent_sell:\n",
        "            current_signal = 'ÙØ±ÙˆØ´'\n",
        "            current_strength = max([s['strength'] for s in recent_sell])\n",
        "\n",
        "        # ØªÙˆØ¶ÛŒØ­Ø§Øª Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ\n",
        "        strategy_description = \"\"\n",
        "\n",
        "        if current_signal == 'Ø®Ø±ÛŒØ¯':\n",
        "            if df_special['in_uptrend'].iloc[last_idx] and df_special['in_uptrend'].iloc[last_idx - 1] == False:\n",
        "                strategy_description += \"ØªØºÛŒÛŒØ± Super Trend Ø¨Ù‡ Ø±ÙˆÙ†Ø¯ ØµØ¹ÙˆØ¯ÛŒ. \"\n",
        "\n",
        "            if df_special['squeeze_off'].iloc[last_idx] and df_special['momentum'].iloc[last_idx] > 0:\n",
        "                strategy_description += \"TTM Squeeze: Ù¾Ø§ÛŒØ§Ù† ÙØ´Ø±Ø¯Ú¯ÛŒ Ø¨Ø§ Ù…ÙˆÙ…Ù†ØªÙˆÙ… Ù…Ø«Ø¨Øª. \"\n",
        "\n",
        "            if df_special['williams_vix'].iloc[last_idx] > 80:\n",
        "                strategy_description += \"Williams Vix Fix Ø¯Ø± Ø³Ø·Ø­ Ø¨Ø§Ù„Ø§ - Ø§Ø­ØªÙ…Ø§Ù„ Ø¨Ø±Ú¯Ø´Øª ØµØ¹ÙˆØ¯ÛŒ. \"\n",
        "\n",
        "        elif current_signal == 'ÙØ±ÙˆØ´':\n",
        "            if df_special['in_uptrend'].iloc[last_idx] == False and df_special['in_uptrend'].iloc[last_idx - 1]:\n",
        "                strategy_description += \"ØªØºÛŒÛŒØ± Super Trend Ø¨Ù‡ Ø±ÙˆÙ†Ø¯ Ù†Ø²ÙˆÙ„ÛŒ. \"\n",
        "\n",
        "            if df_special['squeeze_off'].iloc[last_idx] and df_special['momentum'].iloc[last_idx] < 0:\n",
        "                strategy_description += \"TTM Squeeze: Ù¾Ø§ÛŒØ§Ù† ÙØ´Ø±Ø¯Ú¯ÛŒ Ø¨Ø§ Ù…ÙˆÙ…Ù†ØªÙˆÙ… Ù…Ù†ÙÛŒ. \"\n",
        "\n",
        "            if df_special['williams_vix'].iloc[last_idx] < 20:\n",
        "                strategy_description += \"Williams Vix Fix Ø¯Ø± Ø³Ø·Ø­ Ù¾Ø§ÛŒÛŒÙ† - Ø§Ø­ØªÙ…Ø§Ù„ Ø¨Ø±Ú¯Ø´Øª Ù†Ø²ÙˆÙ„ÛŒ. \"\n",
        "\n",
        "        # Ù†ØªØ§ÛŒØ¬ Ù†Ù‡Ø§ÛŒÛŒ\n",
        "        result = {\n",
        "            'current_signal': current_signal,\n",
        "            'current_strength': min(100, current_strength),\n",
        "            'strategy_description': strategy_description,\n",
        "            'buy_signals': buy_signals,\n",
        "            'sell_signals': sell_signals,\n",
        "            'entry_points': entry_points,\n",
        "            'dataframe': df_special\n",
        "        }\n",
        "\n",
        "        return result\n",
        "\n",
        "    def run_analysis(self, symbol, timeframes=None):\n",
        "        \"\"\"\n",
        "        Ø§Ø¬Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¨Ø± Ø±ÙˆÛŒ ÛŒÚ© Ø§Ø±Ø² Ùˆ ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…â€ŒÙ‡Ø§ÛŒ Ù…Ø´Ø®Øµ Ø¨Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø´Ø±Ø·ÛŒ\n",
        "\n",
        "        Args:\n",
        "            symbol: Ù†Ù…Ø§Ø¯ Ø§Ø±Ø²\n",
        "            timeframes: Ù„ÛŒØ³Øª ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…â€ŒÙ‡Ø§ (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)\n",
        "\n",
        "        Returns:\n",
        "            Ù†ØªØ§ÛŒØ¬ ØªØ­Ù„ÛŒÙ„\n",
        "        \"\"\"\n",
        "        if timeframes is None:\n",
        "            timeframes = ['15m', '1h', '4h', '1d']\n",
        "\n",
        "        results = {}\n",
        "\n",
        "        for timeframe in timeframes:\n",
        "            logger.info(f\"ğŸ” Ø¯Ø± Ø­Ø§Ù„ ØªØ­Ù„ÛŒÙ„ {symbol} Ø¯Ø± ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ… {timeframe}...\")\n",
        "\n",
        "            # Ø¨Ø±Ø±Ø³ÛŒ Ø²Ù…Ø§Ù† Ø¢Ø®Ø±ÛŒÙ† ØªØ­Ù„ÛŒÙ„\n",
        "            last_time = get_last_analysis_time(symbol, timeframe)\n",
        "            current_time = time.time()\n",
        "\n",
        "            # Ø§Ú¯Ø± Ø§Ø®ÛŒØ±Ø§Ù‹ Ø§ÛŒÙ† Ø§Ø±Ø² Ø±Ø§ ØªØ­Ù„ÛŒÙ„ Ú©Ø±Ø¯Ù‡â€ŒØ§ÛŒÙ…ØŒ Ø§Ø² Ú©Ø´ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…\n",
        "            if last_time and current_time - last_time < 1800:  # 30 Ø¯Ù‚ÛŒÙ‚Ù‡\n",
        "                logger.info(f\"ğŸ•‘ {symbol} Ø¯Ø± ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ… {timeframe} Ø§Ø®ÛŒØ±Ø§Ù‹ ØªØ­Ù„ÛŒÙ„ Ø´Ø¯Ù‡ Ø§Ø³Øª. Ø§Ø² Ù†ØªØ§ÛŒØ¬ Ù‚Ø¨Ù„ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.\")\n",
        "                continue\n",
        "\n",
        "            # Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§\n",
        "            df = force_latest_data(symbol, timeframe)\n",
        "            if df is None:\n",
        "                logger.warning(f\"Ø¯Ø±ÛŒØ§ÙØª Ø§Ø¬Ø¨Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ {symbol}/{timeframe} Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯ - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø±ÙˆØ´ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ†\")\n",
        "                df = fetch_data(symbol, timeframe, limit=1000, max_retries=5, force_fresh=True)\n",
        "\n",
        "            if df is None or len(df) < 100:\n",
        "                logger.error(f\"âŒ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ {symbol} Ø¯Ø± ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ… {timeframe} Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯\")\n",
        "                continue\n",
        "\n",
        "            # Ø§Ø¬Ø±Ø§ÛŒ ØªÙ…Ø§Ù… Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§\n",
        "            try:\n",
        "                # ØªØ­Ù„ÛŒÙ„ Ø³Ø§Ø®ØªØ§Ø± Ø¨Ø§Ø²Ø§Ø± Ùˆ Ø¨Ù„ÙˆÚ©â€ŒÙ‡Ø§ÛŒ Ø³ÙØ§Ø±Ø´\n",
        "                market_structure_result = self.analyze_market_structure(df, fib_factor=0.273)\n",
        "\n",
        "                # ØªØ­Ù„ÛŒÙ„ ÙØ´Ø§Ø± Ø®Ø±ÛŒØ¯/ÙØ±ÙˆØ´\n",
        "                pressure_result = self.analyze_buying_selling_pressure(df)\n",
        "\n",
        "                # ØªØ­Ù„ÛŒÙ„ ÙØ¹Ø§Ù„ÛŒØª Ù†Ù‡Ù†Ú¯â€ŒÙ‡Ø§\n",
        "                whale_result = self.detect_whale_activity(df)\n",
        "\n",
        "                # ØªØ­Ù„ÛŒÙ„ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ EMA\n",
        "                ema_result = self.analyze_ema_strategy(df)\n",
        "\n",
        "                # ØªØ­Ù„ÛŒÙ„ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ RSI\n",
        "                rsi_result = self.analyze_rsi_strategy(df)\n",
        "\n",
        "                # ØªØ­Ù„ÛŒÙ„ ÙˆØ§Ú¯Ø±Ø§ÛŒÛŒ\n",
        "                divergence_result = self.detect_divergence(df)\n",
        "\n",
        "                # ØªØ­Ù„ÛŒÙ„ ØªØ±Ú©ÛŒØ¨ÛŒ Ø¨Ø§Ù†Ø¯ Ø¨ÙˆÙ„ÛŒÙ†Ú¯Ø±ØŒ RSI Ùˆ MACD\n",
        "                bbrsi_macd_result = self.analyze_bbrsi_macd_strategy(df)\n",
        "\n",
        "                # ØªØ­Ù„ÛŒÙ„ Ø¬Ø¹Ø¨Ù‡ Ø¯Ø§Ø±ÙˆØ§Ø³\n",
        "                darvas_result = self.analyze_darvas_box(df)\n",
        "\n",
        "                # ØªØ­Ù„ÛŒÙ„ Ø§ÛŒÚ†ÛŒÙ…ÙˆÚ©Ùˆ\n",
        "                ichimoku_result = self.analyze_ichimoku(df)\n",
        "\n",
        "                # ØªØ­Ù„ÛŒÙ„ ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ\n",
        "                fibonacci_result = self.analyze_fibonacci(df)\n",
        "\n",
        "                # Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø·Ù„Ø§ÛŒÛŒ\n",
        "                golden_result = self.golden_strategy(df)\n",
        "\n",
        "                # Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ ÙˆÛŒÚ˜Ù‡\n",
        "                special_result = self.special_strategy(df)\n",
        "\n",
        "                # Ø«Ø¨Øª Ø²Ù…Ø§Ù† ØªØ­Ù„ÛŒÙ„\n",
        "                track_last_analysis_time(symbol, timeframe)\n",
        "\n",
        "                # ======= Ø¨Ø±Ø±Ø³ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø´Ø±Ø·ÛŒ Ø¨Ø±Ø§Ø³Ø§Ø³ Ø³Ø§Ø®ØªØ§Ø± Ø¨Ø§Ø²Ø§Ø± =======\n",
        "                if 'entry_points' in market_structure_result and market_structure_result['entry_points']:\n",
        "                    for entry_point in market_structure_result['entry_points']:\n",
        "                        # ØªØ¹ÛŒÛŒÙ† Ù†ÙˆØ¹ Ø³ÛŒÚ¯Ù†Ø§Ù„\n",
        "                        signal_type = \"Ø®Ø±ÛŒØ¯\" if entry_point['type'].startswith('conditional_long') else \"ÙØ±ÙˆØ´\"\n",
        "\n",
        "                        # Ø¢Ù…Ø§Ø¯Ù‡ Ú©Ø±Ø¯Ù† Ø­Ø¯Ù‡Ø§ÛŒ Ø³ÙˆØ¯ Ø¨Ù‡ ØµÙˆØ±Øª Ù„ÛŒØ³Øª\n",
        "                        take_profit_levels = [\n",
        "                            entry_point['take_profit1'],\n",
        "                            entry_point['take_profit2'],\n",
        "                            entry_point['take_profit3']\n",
        "                        ]\n",
        "\n",
        "                        # ØªØ±Ú©ÛŒØ¨ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§ÛŒ ØªØ£ÛŒÛŒØ¯Ú©Ù†Ù†Ø¯Ù‡ Ø¨Ø±Ø§Ø³Ø§Ø³ ØªØ·Ø§Ø¨Ù‚ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù\n",
        "                        supporting_strategies = {\n",
        "                            \"Ø³Ø§Ø®ØªØ§Ø± Ø¨Ø§Ø²Ø§Ø±\": entry_point['strength']\n",
        "                        }\n",
        "\n",
        "                        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¯ÛŒÚ¯Ø± Ø¯Ø± ØµÙˆØ±Øª ØªØ·Ø§Ø¨Ù‚ Ø³ÛŒÚ¯Ù†Ø§Ù„\n",
        "                        if signal_type == \"Ø®Ø±ÛŒØ¯\":\n",
        "                            if pressure_result['pressure_status'] in ['Ø®Ø±ÛŒØ¯', 'BUY']:\n",
        "                                supporting_strategies[\"ÙØ´Ø§Ø± Ø®Ø±ÛŒØ¯/ÙØ±ÙˆØ´\"] = pressure_result['pressure_strength']\n",
        "\n",
        "                            if whale_result['whale_signal'] in ['Ø®Ø±ÛŒØ¯', 'BUY']:\n",
        "                                supporting_strategies[\"ÙØ¹Ø§Ù„ÛŒØª Ù†Ù‡Ù†Ú¯â€ŒÙ‡Ø§\"] = whale_result['whale_strength']\n",
        "\n",
        "                            if ema_result['latest_signal_type'] in ['Ø®Ø±ÛŒØ¯', 'ØµØ¹ÙˆØ¯ÛŒ']:\n",
        "                                supporting_strategies[\"Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…ØªØ­Ø±Ú© Ù†Ù…Ø§ÛŒÛŒ\"] = ema_result['latest_signal_strength']\n",
        "\n",
        "                            if rsi_result['current_signal_type'] in ['Ø®Ø±ÛŒØ¯', 'ØµØ¹ÙˆØ¯ÛŒ']:\n",
        "                                supporting_strategies[\"Ø´Ø§Ø®Øµ Ù‚Ø¯Ø±Øª Ù†Ø³Ø¨ÛŒ\"] = rsi_result['current_signal_strength']\n",
        "\n",
        "                            if divergence_result['signal_type'] in ['Ø®Ø±ÛŒØ¯', 'ØµØ¹ÙˆØ¯ÛŒ']:\n",
        "                                supporting_strategies[\"ÙˆØ§Ú¯Ø±Ø§ÛŒÛŒ\"] = divergence_result['current_strength']\n",
        "\n",
        "                            if bbrsi_macd_result['current_signal'] in ['Ø®Ø±ÛŒØ¯', 'ØµØ¹ÙˆØ¯ÛŒ']:\n",
        "                                supporting_strategies[\"ØªØ±Ú©ÛŒØ¨ÛŒ BB/RSI/MACD\"] = bbrsi_macd_result['current_strength']\n",
        "\n",
        "                        elif signal_type == \"ÙØ±ÙˆØ´\":\n",
        "                            if pressure_result['pressure_status'] in ['ÙØ±ÙˆØ´', 'SELL']:\n",
        "                                supporting_strategies[\"ÙØ´Ø§Ø± Ø®Ø±ÛŒØ¯/ÙØ±ÙˆØ´\"] = pressure_result['pressure_strength']\n",
        "\n",
        "                            if whale_result['whale_signal'] in ['ÙØ±ÙˆØ´', 'SELL']:\n",
        "                                supporting_strategies[\"ÙØ¹Ø§Ù„ÛŒØª Ù†Ù‡Ù†Ú¯â€ŒÙ‡Ø§\"] = whale_result['whale_strength']\n",
        "\n",
        "                            if ema_result['latest_signal_type'] in ['ÙØ±ÙˆØ´', 'Ù†Ø²ÙˆÙ„ÛŒ']:\n",
        "                                supporting_strategies[\"Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…ØªØ­Ø±Ú© Ù†Ù…Ø§ÛŒÛŒ\"] = ema_result['latest_signal_strength']\n",
        "\n",
        "                            if rsi_result['current_signal_type'] in ['ÙØ±ÙˆØ´', 'Ù†Ø²ÙˆÙ„ÛŒ']:\n",
        "                                supporting_strategies[\"Ø´Ø§Ø®Øµ Ù‚Ø¯Ø±Øª Ù†Ø³Ø¨ÛŒ\"] = rsi_result['current_signal_strength']\n",
        "\n",
        "                            if divergence_result['signal_type'] in ['ÙØ±ÙˆØ´', 'Ù†Ø²ÙˆÙ„ÛŒ']:\n",
        "                                supporting_strategies[\"ÙˆØ§Ú¯Ø±Ø§ÛŒÛŒ\"] = divergence_result['current_strength']\n",
        "\n",
        "                            if bbrsi_macd_result['current_signal'] in ['ÙØ±ÙˆØ´', 'Ù†Ø²ÙˆÙ„ÛŒ']:\n",
        "                                supporting_strategies[\"ØªØ±Ú©ÛŒØ¨ÛŒ BB/RSI/MACD\"] = bbrsi_macd_result['current_strength']\n",
        "\n",
        "                        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†Ø³Ø¨Øª Ø±ÛŒØ³Ú© Ø¨Ù‡ Ø±ÛŒÙˆØ§Ø±Ø¯\n",
        "                        if signal_type == \"Ø®Ø±ÛŒØ¯\":\n",
        "                            risk = entry_point['price'] - entry_point['stop_loss']\n",
        "                            reward = entry_point['take_profit2'] - entry_point['price']\n",
        "                            risk_reward_ratio = reward / risk if risk > 0 else 0\n",
        "                        else:  # ÙØ±ÙˆØ´\n",
        "                            risk = entry_point['stop_loss'] - entry_point['price']\n",
        "                            reward = entry_point['price'] - entry_point['take_profit2']\n",
        "                            risk_reward_ratio = reward / risk if risk > 0 else 0\n",
        "\n",
        "                        # Ø³Ø§Ø®Øª ØªÙˆØ¶ÛŒØ­Ø§Øª Ù…ÙØµÙ„\n",
        "                        description = f\"Ø³ÛŒÚ¯Ù†Ø§Ù„ {signal_type} Ø¨Ø±Ø§Ø³Ø§Ø³ ØªØ­Ù„ÛŒÙ„ Ø³Ø§Ø®ØªØ§Ø± Ø¨Ø§Ø²Ø§Ø± Ùˆ Ø¨Ù„ÙˆÚ©â€ŒÙ‡Ø§ÛŒ Ø³ÙØ§Ø±Ø´\\n\\n\"\n",
        "\n",
        "                        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¬Ø²Ø¦ÛŒØ§Øª Ø¨ÛŒØ´ØªØ± Ø¨Ø±Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ Ø³ÛŒÚ¯Ù†Ø§Ù„\n",
        "                        if signal_type == \"Ø®Ø±ÛŒØ¯\":\n",
        "                            description += f\"â€¢ Ù…Ø¹Ø§Ù…Ù„Ù‡ Ø¯Ø± Ù†Ø§Ø­ÛŒÙ‡ Ø¨Ù„ÙˆÚ© Ø³ÙØ§Ø±Ø´ ØµØ¹ÙˆØ¯ÛŒ\\n\"\n",
        "                            description += f\"â€¢ Ù†Ø³Ø¨Øª Ø±ÛŒØ³Ú© Ø¨Ù‡ Ø±ÛŒÙˆØ§Ø±Ø¯: {risk_reward_ratio:.2f}\\n\"\n",
        "                            description += f\"â€¢ ÙˆØ¶Ø¹ÛŒØª Ø³Ø§Ø®ØªØ§Ø± Ø¨Ø§Ø²Ø§Ø±: {market_structure_result['market_structure']['status']}\\n\"\n",
        "\n",
        "                            # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø±ÙˆÙ†Ø¯ Ù‚ÛŒÙ…Øª ÙØ¹Ù„ÛŒ Ù†Ø³Ø¨Øª Ø¨Ù‡ EMA\n",
        "                            if 'current_status' in ema_result:\n",
        "                                description += f\"â€¢ Ø±ÙˆÙ†Ø¯ EMA: {ema_result['current_status']}\\n\"\n",
        "\n",
        "                            # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ÙˆØ¶Ø¹ÛŒØª RSI\n",
        "                            if 'current_status' in rsi_result:\n",
        "                                description += f\"â€¢ ÙˆØ¶Ø¹ÛŒØª RSI: {rsi_result['current_status']}\\n\"\n",
        "\n",
        "                            # Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ù…Ø¯ÛŒØ±ÛŒØª Ø³Ø±Ù…Ø§ÛŒÙ‡ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ\n",
        "                            description += f\"\\nØ§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ:\\n\"\n",
        "                            description += f\"â€¢ ÙˆØ±ÙˆØ¯: Ø²Ù…Ø§Ù†ÛŒ Ú©Ù‡ Ù‚ÛŒÙ…Øª Ø¨Ù‡ Ù†Ø§Ø­ÛŒÙ‡ {entry_point['price']:.6f} Ø¨Ø±Ø³Ø¯\\n\"\n",
        "                            description += f\"â€¢ Ø­Ø¯ Ø¶Ø±Ø±: {entry_point['stop_loss']:.6f} ({(entry_point['stop_loss'] / entry_point['price'] - 1) * 100:.2f}%)\\n\"\n",
        "                            description += f\"â€¢ Ø®Ø±ÙˆØ¬ Ø§ÙˆÙ„: {entry_point['take_profit1']:.6f} ({(entry_point['take_profit1'] / entry_point['price'] - 1) * 100:.2f}%)\\n\"\n",
        "                            description += f\"â€¢ Ø®Ø±ÙˆØ¬ Ø¯ÙˆÙ…: {entry_point['take_profit2']:.6f} ({(entry_point['take_profit2'] / entry_point['price'] - 1) * 100:.2f}%)\\n\"\n",
        "                            description += f\"â€¢ Ø®Ø±ÙˆØ¬ Ø³ÙˆÙ…: {entry_point['take_profit3']:.6f} ({(entry_point['take_profit3'] / entry_point['price'] - 1) * 100:.2f}%)\\n\"\n",
        "\n",
        "                        else:  # ÙØ±ÙˆØ´\n",
        "                            description += f\"â€¢ Ù…Ø¹Ø§Ù…Ù„Ù‡ Ø¯Ø± Ù†Ø§Ø­ÛŒÙ‡ Ø¨Ù„ÙˆÚ© Ø³ÙØ§Ø±Ø´ Ù†Ø²ÙˆÙ„ÛŒ\\n\"\n",
        "                            description += f\"â€¢ Ù†Ø³Ø¨Øª Ø±ÛŒØ³Ú© Ø¨Ù‡ Ø±ÛŒÙˆØ§Ø±Ø¯: {risk_reward_ratio:.2f}\\n\"\n",
        "                            description += f\"â€¢ ÙˆØ¶Ø¹ÛŒØª Ø³Ø§Ø®ØªØ§Ø± Ø¨Ø§Ø²Ø§Ø±: {market_structure_result['market_structure']['status']}\\n\"\n",
        "\n",
        "                            # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø±ÙˆÙ†Ø¯ Ù‚ÛŒÙ…Øª ÙØ¹Ù„ÛŒ Ù†Ø³Ø¨Øª Ø¨Ù‡ EMA\n",
        "                            if 'current_status' in ema_result:\n",
        "                                description += f\"â€¢ Ø±ÙˆÙ†Ø¯ EMA: {ema_result['current_status']}\\n\"\n",
        "\n",
        "                            # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ÙˆØ¶Ø¹ÛŒØª RSI\n",
        "                            if 'current_status' in rsi_result:\n",
        "                                description += f\"â€¢ ÙˆØ¶Ø¹ÛŒØª RSI: {rsi_result['current_status']}\\n\"\n",
        "\n",
        "                            # Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ù…Ø¯ÛŒØ±ÛŒØª Ø³Ø±Ù…Ø§ÛŒÙ‡ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ\n",
        "                            description += f\"\\nØ§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ:\\n\"\n",
        "                            description += f\"â€¢ ÙˆØ±ÙˆØ¯: Ø²Ù…Ø§Ù†ÛŒ Ú©Ù‡ Ù‚ÛŒÙ…Øª Ø¨Ù‡ Ù†Ø§Ø­ÛŒÙ‡ {entry_point['price']:.6f} Ø¨Ø±Ø³Ø¯\\n\"\n",
        "                            description += f\"â€¢ Ø­Ø¯ Ø¶Ø±Ø±: {entry_point['stop_loss']:.6f} ({(entry_point['stop_loss'] / entry_point['price'] - 1) * 100:.2f}%)\\n\"\n",
        "                            description += f\"â€¢ Ø®Ø±ÙˆØ¬ Ø§ÙˆÙ„: {entry_point['take_profit1']:.6f} ({(entry_point['take_profit1'] / entry_point['price'] - 1) * 100:.2f}%)\\n\"\n",
        "                            description += f\"â€¢ Ø®Ø±ÙˆØ¬ Ø¯ÙˆÙ…: {entry_point['take_profit2']:.6f} ({(entry_point['take_profit2'] / entry_point['price'] - 1) * 100:.2f}%)\\n\"\n",
        "                            description += f\"â€¢ Ø®Ø±ÙˆØ¬ Ø³ÙˆÙ…: {entry_point['take_profit3']:.6f} ({(entry_point['take_profit3'] / entry_point['price'] - 1) * 100:.2f}%)\\n\"\n",
        "\n",
        "                        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ú©Ù„ÛŒ Ø¨Ø±Ø§Ø³Ø§Ø³ ØªØ¹Ø¯Ø§Ø¯ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§ÛŒ ØªØ£ÛŒÛŒØ¯Ú©Ù†Ù†Ø¯Ù‡\n",
        "                        total_confidence = sum(supporting_strategies.values()) / len(supporting_strategies)\n",
        "\n",
        "                        # Ø±Ø³Ù… Ù†Ù…ÙˆØ¯Ø§Ø± Ø¨Ø§ ØªÙ…Ø§Ù… Ø¬Ø²Ø¦ÛŒØ§Øª Ùˆ Ù†Ù…Ø§ÛŒØ´ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ\n",
        "                        chart_path = self.create_candlestick_chart(\n",
        "                            df, symbol, timeframe,\n",
        "                            strategies=supporting_strategies,\n",
        "                            indicators={\n",
        "                                'ema': True,  # Ù†Ù…Ø§ÛŒØ´ EMA\n",
        "                                'rsi': True,  # Ù†Ù…Ø§ÛŒØ´ RSI\n",
        "                                'macd': True,  # Ù†Ù…Ø§ÛŒØ´ MACD\n",
        "                                'bollinger': 'ØªØ±Ú©ÛŒØ¨ÛŒ BB/RSI/MACD' in supporting_strategies,\n",
        "                                'ichimoku': 'Ø§ÛŒÚ†ÛŒÙ…ÙˆÚ©Ùˆ' in supporting_strategies,\n",
        "                                'fibonacci': 'ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ' in supporting_strategies\n",
        "                            },\n",
        "                            patterns={\n",
        "                                'market_structure_break_bullish': market_structure_result.get('msb_bullish', []),\n",
        "                                'market_structure_break_bearish': market_structure_result.get('msb_bearish', []),\n",
        "                                'order_block_bullish': market_structure_result.get('orderblock_bullish', []),\n",
        "                                'order_block_bearish': market_structure_result.get('orderblock_bearish', [])\n",
        "                            },\n",
        "                            entry_exit={\n",
        "                                'entries': [\n",
        "                                    {'index': entry_point.get('index', len(df) - 1), 'price': entry_point['price']}],\n",
        "                                'stop_loss': entry_point['stop_loss'],\n",
        "                                'take_profit': take_profit_levels\n",
        "                            },\n",
        "                            title=f\"{symbol} - {timeframe} - Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø´Ø±Ø·ÛŒ {signal_type} ({int(total_confidence)}% Ø§Ø·Ù…ÛŒÙ†Ø§Ù†)\"\n",
        "                        )\n",
        "\n",
        "                        # Ø§Ø±Ø³Ø§Ù„ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø´Ø±Ø·ÛŒ\n",
        "                        self.send_conditional_signal(\n",
        "                            symbol=symbol,\n",
        "                            timeframe=timeframe,\n",
        "                            signal_type=signal_type,\n",
        "                            entry_condition=entry_point.get('condition', f\"Ù‚ÛŒÙ…Øª Ø¨Ù‡ {entry_point['price']:.6f} Ø¨Ø±Ø³Ø¯\"),\n",
        "                            entry_price=entry_point['price'],\n",
        "                            stop_loss=entry_point['stop_loss'],\n",
        "                            take_profit_levels=take_profit_levels,\n",
        "                            strategies=supporting_strategies,\n",
        "                            confidence=total_confidence,\n",
        "                            description=description,\n",
        "                            chart_path=chart_path\n",
        "                        )\n",
        "                # ======= Ø¨Ø±Ø±Ø³ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø·Ù„Ø§ÛŒÛŒ Ùˆ Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… ØªØ£ÛŒÛŒØ¯ÛŒÙ‡ =======\n",
        "                if golden_result['signal'] in ['Ø®Ø±ÛŒØ¯', 'ÙØ±ÙˆØ´'] and golden_result['strength'] >= BOT_SETTINGS[\n",
        "                    'signal_confidence_threshold']:\n",
        "                    # Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§ÛŒ ØªØ£ÛŒÛŒØ¯Ú©Ù†Ù†Ø¯Ù‡\n",
        "                    gold_strategies = golden_result['supporting_strategies']\n",
        "\n",
        "                    # Ø§ÛŒØ¬Ø§Ø¯ Ù†Ù…ÙˆØ¯Ø§Ø±\n",
        "                    gold_chart_path = self.create_candlestick_chart(\n",
        "                        df, symbol, timeframe,\n",
        "                        strategies=gold_strategies,\n",
        "                        indicators={\n",
        "                            'ema': True,\n",
        "                            'rsi': True,\n",
        "                            'macd': True,\n",
        "                            'bollinger': True,\n",
        "                            'ichimoku': ('Ø§ÛŒÚ†ÛŒÙ…ÙˆÚ©Ùˆ' in gold_strategies),\n",
        "                            'fibonacci': ('ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ' in gold_strategies)\n",
        "                        },\n",
        "                        patterns={\n",
        "                            'market_structure_break_bullish': market_structure_result.get('msb_bullish', []),\n",
        "                            'market_structure_break_bearish': market_structure_result.get('msb_bearish', []),\n",
        "                            'order_block_bullish': market_structure_result.get('orderblock_bullish', []),\n",
        "                            'order_block_bearish': market_structure_result.get('orderblock_bearish', [])\n",
        "                        },\n",
        "                        entry_exit={\n",
        "                            'entries': [{'index': len(df) - 1, 'price': golden_result['entry_price']}],\n",
        "                            'stop_loss': golden_result['stop_loss'],\n",
        "                            'take_profit': golden_result['take_profit']\n",
        "                        },\n",
        "                        title=f\"{symbol} - {timeframe} - â­ï¸ ØªØ£ÛŒÛŒØ¯ÛŒÙ‡ Ù†Ù‡Ø§ÛŒÛŒ Ø±Ø¨Ø§Øª â­ï¸ {golden_result['signal']} ({int(golden_result['strength'])}% Ø§Ø·Ù…ÛŒÙ†Ø§Ù†)\"\n",
        "                    )\n",
        "\n",
        "                    # Ø³Ø§Ø®Øª Ù¾ÛŒØ§Ù… ØªØ£ÛŒÛŒØ¯ÛŒÙ‡\n",
        "                    confirmation_message = f\"â­ï¸ <b>ØªØ£ÛŒÛŒØ¯ÛŒÙ‡ Ù†Ù‡Ø§ÛŒÛŒ Ø±Ø¨Ø§Øª | {symbol} | {timeframe}</b> â­ï¸\\n\\n\"\n",
        "                    confirmation_message += f\"ğŸ¤– <b>ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø±Ø¨Ø§Øª:</b> Ø³ÛŒÚ¯Ù†Ø§Ù„ {golden_result['signal']} ØªØ£ÛŒÛŒØ¯ Ù…ÛŒâ€ŒØ´ÙˆØ¯\\n\"\n",
        "                    confirmation_message += f\"âš¡ï¸ <b>Ø¯Ø±ØµØ¯ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†:</b> {golden_result['strength']:.1f}%\\n\"\n",
        "                    confirmation_message += f\"ğŸ’µ <b>Ù‚ÛŒÙ…Øª ÙˆØ±ÙˆØ¯:</b> {golden_result['entry_price']:.6f}\\n\"\n",
        "                    confirmation_message += f\"ğŸ›‘ <b>Ø­Ø¯ Ø¶Ø±Ø±:</b> {golden_result['stop_loss']:.6f}\\n\"\n",
        "                    confirmation_message += f\"ğŸ¯ <b>Ø­Ø¯ Ø³ÙˆØ¯:</b> {golden_result['take_profit']:.6f}\\n\\n\"\n",
        "\n",
        "                    confirmation_message += \"<b>Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§ÛŒ ØªØ£ÛŒÛŒØ¯Ú©Ù†Ù†Ø¯Ù‡:</b>\\n\"\n",
        "                    for strategy, conf in gold_strategies.items():\n",
        "                        emoji = \"âœ…\" if conf >= 80 else \"âš ï¸\"\n",
        "                        confirmation_message += f\"{emoji} {strategy}: {conf}%\\n\"\n",
        "\n",
        "                    if golden_result['strategy_descriptions']:\n",
        "                        confirmation_message += f\"\\n<b>ØªÙˆØ¶ÛŒØ­Ø§Øª:</b>\\n\"\n",
        "                        for desc in golden_result['strategy_descriptions']:\n",
        "                            confirmation_message += f\"â€¢ {desc}\\n\"\n",
        "\n",
        "                    confirmation_message += f\"\\nâš ï¸ <b>ØªÙˆØ¬Ù‡:</b> Ø§ÛŒÙ† Ù¾ÛŒØ§Ù… ØªØ£ÛŒÛŒØ¯ÛŒÙ‡ Ù†Ù‡Ø§ÛŒÛŒ Ø±Ø¨Ø§Øª Ø§Ø³Øª. Ø³Ø§ÛŒØ± Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ ØµØ±ÙØ§Ù‹ Ø¬Ù‡Øª Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒÛŒ Ø§Ø±Ø³Ø§Ù„ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯.\\n\"\n",
        "                    confirmation_message += f\"â—ï¸ <i>Ø§ÛŒÙ† Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ ØµØ±ÙØ§Ù‹ Ø¬Ù†Ø¨Ù‡ Ø¢Ù…ÙˆØ²Ø´ÛŒ Ø¯Ø§Ø´ØªÙ‡ Ùˆ ØªÙˆØµÛŒÙ‡ Ø³Ø±Ù…Ø§ÛŒÙ‡â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ù†ÛŒØ³Øª.</i>\"\n",
        "\n",
        "                    # Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… ØªØ£ÛŒÛŒØ¯ÛŒÙ‡\n",
        "                    self.send_telegram_message(confirmation_message, gold_chart_path)\n",
        "\n",
        "                # ======= Ø¨Ø±Ø±Ø³ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø·Ù„Ø§ÛŒÛŒ =======\n",
        "                if golden_result['signal'] in ['Ø®Ø±ÛŒØ¯', 'ÙØ±ÙˆØ´'] and golden_result['strength'] >= BOT_SETTINGS[\n",
        "                    'signal_confidence_threshold']:\n",
        "                    # Ø³Ø§Ø®Øª Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§ÛŒ ØªØ£ÛŒÛŒØ¯Ú©Ù†Ù†Ø¯Ù‡\n",
        "                    gold_strategies = {}\n",
        "                    for strategy in golden_result['supporting_strategies']:\n",
        "                        gold_strategies[strategy['name']] = strategy['strength']\n",
        "\n",
        "                    # Ø§ÛŒØ¬Ø§Ø¯ Ù†Ù…ÙˆØ¯Ø§Ø±\n",
        "                    gold_chart_path = self.create_candlestick_chart(\n",
        "                        df, symbol, timeframe,\n",
        "                        strategies=gold_strategies,\n",
        "                        indicators={\n",
        "                            'ema': True,\n",
        "                            'rsi': True,\n",
        "                            'macd': True,\n",
        "                            'bollinger': True,\n",
        "                            'ichimoku': ('Ø§ÛŒÚ†ÛŒÙ…ÙˆÚ©Ùˆ' in [s['name'] for s in golden_result['supporting_strategies']]),\n",
        "                            'fibonacci': ('ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ' in [s['name'] for s in golden_result['supporting_strategies']])\n",
        "                        },\n",
        "                        patterns={\n",
        "                            'market_structure_break_bullish': market_structure_result.get('msb_bullish', []),\n",
        "                            'market_structure_break_bearish': market_structure_result.get('msb_bearish', []),\n",
        "                            'order_block_bullish': market_structure_result.get('orderblock_bullish', []),\n",
        "                            'order_block_bearish': market_structure_result.get('orderblock_bearish', [])\n",
        "                        },\n",
        "                        entry_exit={\n",
        "                            'entries': [{'index': len(df) - 1, 'price': golden_result['entry_price']}],\n",
        "                            'stop_loss': golden_result['stop_loss'],\n",
        "                            'take_profit': golden_result['take_profit']\n",
        "                        },\n",
        "                        title=f\"{symbol} - {timeframe} - Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø·Ù„Ø§ÛŒÛŒ ({int(golden_result['strength'])}% Ø§Ø·Ù…ÛŒÙ†Ø§Ù†)\"\n",
        "                    )\n",
        "\n",
        "                    # Ø§Ø±Ø³Ø§Ù„ Ø³ÛŒÚ¯Ù†Ø§Ù„\n",
        "                    self.send_signal(\n",
        "                        symbol, timeframe, golden_result['signal'], golden_result['entry_price'],\n",
        "                        golden_result['stop_loss'], golden_result['take_profit'],\n",
        "                        gold_strategies, golden_result['strength'],\n",
        "                        \"\\n\".join(golden_result['strategy_descriptions']),\n",
        "                        gold_chart_path\n",
        "                    )\n",
        "\n",
        "                # ======= Ø¨Ø±Ø±Ø³ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø¯Ø§Ø±ÙˆØ§Ø³ =======\n",
        "                if 'current_signal' in darvas_result and darvas_result['current_signal'] in ['Ø®Ø±ÛŒØ¯', 'ÙØ±ÙˆØ´'] and \\\n",
        "                        darvas_result['current_strength'] >= BOT_SETTINGS['signal_confidence_threshold']:\n",
        "                    # Ø³Ø§Ø®Øª Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§ÛŒ ØªØ£ÛŒÛŒØ¯Ú©Ù†Ù†Ø¯Ù‡\n",
        "                    darvas_strategies = {\n",
        "                        \"Ø¬Ø¹Ø¨Ù‡ Ø¯Ø§Ø±ÙˆØ§Ø³\": darvas_result['current_strength']\n",
        "                    }\n",
        "\n",
        "                    # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§ÛŒ Ù‡Ù…Ø³Ùˆ\n",
        "                    if darvas_result['current_signal'] == 'Ø®Ø±ÛŒØ¯':\n",
        "                        if ema_result['latest_signal_type'] in ['Ø®Ø±ÛŒØ¯', 'ØµØ¹ÙˆØ¯ÛŒ']:\n",
        "                            darvas_strategies[\"Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…ØªØ­Ø±Ú© Ù†Ù…Ø§ÛŒÛŒ\"] = ema_result['latest_signal_strength']\n",
        "                        if rsi_result['current_signal_type'] in ['Ø®Ø±ÛŒØ¯', 'ØµØ¹ÙˆØ¯ÛŒ']:\n",
        "                            darvas_strategies[\"Ø´Ø§Ø®Øµ Ù‚Ø¯Ø±Øª Ù†Ø³Ø¨ÛŒ\"] = rsi_result['current_signal_strength']\n",
        "                        if bbrsi_macd_result['current_signal'] in ['Ø®Ø±ÛŒØ¯', 'ØµØ¹ÙˆØ¯ÛŒ']:\n",
        "                            darvas_strategies[\"ØªØ±Ú©ÛŒØ¨ÛŒ BB/RSI/MACD\"] = bbrsi_macd_result['current_strength']\n",
        "                    elif darvas_result['current_signal'] == 'ÙØ±ÙˆØ´':\n",
        "                        if ema_result['latest_signal_type'] in ['ÙØ±ÙˆØ´', 'Ù†Ø²ÙˆÙ„ÛŒ']:\n",
        "                            darvas_strategies[\"Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…ØªØ­Ø±Ú© Ù†Ù…Ø§ÛŒÛŒ\"] = ema_result['latest_signal_strength']\n",
        "                        if rsi_result['current_signal_type'] in ['ÙØ±ÙˆØ´', 'Ù†Ø²ÙˆÙ„ÛŒ']:\n",
        "                            darvas_strategies[\"Ø´Ø§Ø®Øµ Ù‚Ø¯Ø±Øª Ù†Ø³Ø¨ÛŒ\"] = rsi_result['current_signal_strength']\n",
        "                        if bbrsi_macd_result['current_signal'] in ['ÙØ±ÙˆØ´', 'Ù†Ø²ÙˆÙ„ÛŒ']:\n",
        "                            darvas_strategies[\"ØªØ±Ú©ÛŒØ¨ÛŒ BB/RSI/MACD\"] = bbrsi_macd_result['current_strength']\n",
        "\n",
        "                    # ØªØ¹ÛŒÛŒÙ† Ù‚ÛŒÙ…Øª ÙˆØ±ÙˆØ¯ØŒ Ø­Ø¯ Ø¶Ø±Ø± Ùˆ Ø­Ø¯ Ø³ÙˆØ¯\n",
        "                    entry_price = df['close'].iloc[-1]\n",
        "\n",
        "                    # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù†Ù‚Ø§Ø· ÙˆØ±ÙˆØ¯ Ø¯Ø§Ø±ÙˆØ§Ø³ Ø§Ú¯Ø± Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ø´Ù†Ø¯\n",
        "                    stop_loss = entry_price * 0.95  # Ù¾ÛŒØ´â€ŒÙØ±Ø¶: 5% Ø²ÛŒØ± Ù‚ÛŒÙ…Øª ÙˆØ±ÙˆØ¯\n",
        "                    take_profit = entry_price * 1.10  # Ù¾ÛŒØ´â€ŒÙØ±Ø¶: 10% Ø¨Ø§Ù„Ø§ÛŒ Ù‚ÛŒÙ…Øª ÙˆØ±ÙˆØ¯\n",
        "\n",
        "                    if 'entry_points' in darvas_result and darvas_result['entry_points'] and len(\n",
        "                            darvas_result['entry_points']) > 0:\n",
        "                        latest_entry = darvas_result['entry_points'][-1]\n",
        "                        if latest_entry['type'] == 'long' and darvas_result['current_signal'] == 'Ø®Ø±ÛŒØ¯':\n",
        "                            entry_price = latest_entry['price']\n",
        "                            stop_loss = latest_entry['stop_loss']\n",
        "                            take_profit = latest_entry['take_profit']\n",
        "                        elif latest_entry['type'] == 'short' and darvas_result['current_signal'] == 'ÙØ±ÙˆØ´':\n",
        "                            entry_price = latest_entry['price']\n",
        "                            stop_loss = latest_entry['stop_loss']\n",
        "                            take_profit = latest_entry['take_profit']\n",
        "\n",
        "                    # Ø§ÛŒØ¬Ø§Ø¯ ØªÙˆØ¶ÛŒØ­Ø§Øª\n",
        "                    description = f\"Ø³ÛŒÚ¯Ù†Ø§Ù„ {darvas_result['current_signal']} Ø¨Ø±Ø§Ø³Ø§Ø³ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø¬Ø¹Ø¨Ù‡ Ø¯Ø§Ø±ÙˆØ§Ø³\\n\\n\"\n",
        "\n",
        "                    if 'darvas_boxes' in darvas_result and darvas_result['darvas_boxes']:\n",
        "                        latest_box = darvas_result['darvas_boxes'][-1]\n",
        "                        description += f\"â€¢ Ø¬Ø¹Ø¨Ù‡ Ø¯Ø§Ø±ÙˆØ§Ø³ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯Ù‡ Ø¯Ø± Ù‚ÛŒÙ…Øª {latest_box.get('breakout_price', entry_price):.6f}\\n\"\n",
        "                        description += f\"â€¢ Ø¬Ù‡Øª Ø´Ú©Ø³Øª: {latest_box.get('breakout_direction', 'Ù†Ø§Ù…Ø´Ø®Øµ')}\\n\"\n",
        "\n",
        "                    description += f\"â€¢ Ø³Ø·Ø­ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†: {darvas_result['current_strength']}%\\n\"\n",
        "                    description += f\"\\nØ§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ:\\n\"\n",
        "                    description += f\"â€¢ ÙˆØ±ÙˆØ¯: {entry_price:.6f}\\n\"\n",
        "                    description += f\"â€¢ Ø­Ø¯ Ø¶Ø±Ø±: {stop_loss:.6f}\\n\"\n",
        "                    description += f\"â€¢ Ø­Ø¯ Ø³ÙˆØ¯: {take_profit:.6f}\\n\"\n",
        "\n",
        "                    # Ø§ÛŒØ¬Ø§Ø¯ Ù†Ù…ÙˆØ¯Ø§Ø±\n",
        "                    darvas_chart_path = self.create_candlestick_chart(\n",
        "                        df, symbol, timeframe,\n",
        "                        strategies=darvas_strategies,\n",
        "                        indicators={\n",
        "                            'ema': True,\n",
        "                            'rsi': True,\n",
        "                            'macd': True,\n",
        "                            'bollinger': True\n",
        "                        },\n",
        "                        patterns={\n",
        "                            'market_structure_break_bullish': market_structure_result.get('msb_bullish', []),\n",
        "                            'market_structure_break_bearish': market_structure_result.get('msb_bearish', []),\n",
        "                            'order_block_bullish': market_structure_result.get('orderblock_bullish', []),\n",
        "                            'order_block_bearish': market_structure_result.get('orderblock_bearish', [])\n",
        "                        },\n",
        "                        entry_exit={\n",
        "                            'entries': [{'index': len(df) - 1, 'price': entry_price}],\n",
        "                            'stop_loss': stop_loss,\n",
        "                            'take_profit': take_profit\n",
        "                        },\n",
        "                        title=f\"{symbol} - {timeframe} - Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø¯Ø§Ø±ÙˆØ§Ø³ ({int(darvas_result['current_strength'])}% Ø§Ø·Ù…ÛŒÙ†Ø§Ù†)\"\n",
        "                    )\n",
        "\n",
        "                    # Ø§Ø±Ø³Ø§Ù„ Ø³ÛŒÚ¯Ù†Ø§Ù„\n",
        "                    self.send_signal(\n",
        "                        symbol, timeframe, darvas_result['current_signal'], entry_price,\n",
        "                        stop_loss, take_profit,\n",
        "                        darvas_strategies, darvas_result['current_strength'],\n",
        "                        description,\n",
        "                        darvas_chart_path\n",
        "                    )\n",
        "\n",
        "                # ======= Ø¨Ø±Ø±Ø³ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ ÙˆÛŒÚ˜Ù‡ =======\n",
        "                if 'current_signal' in special_result and special_result['current_signal'] in ['Ø®Ø±ÛŒØ¯', 'ÙØ±ÙˆØ´'] and \\\n",
        "                        special_result['current_strength'] >= BOT_SETTINGS['signal_confidence_threshold']:\n",
        "                    # Ø³Ø§Ø®Øª Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§ÛŒ ØªØ£ÛŒÛŒØ¯Ú©Ù†Ù†Ø¯Ù‡\n",
        "                    special_strategies = {\n",
        "                        \"Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ ÙˆÛŒÚ˜Ù‡\": special_result['current_strength']\n",
        "                    }\n",
        "\n",
        "                    # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§ÛŒ Ù‡Ù…Ø³Ùˆ Ø§Ú¯Ø± Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ø´Ù†Ø¯\n",
        "                    if special_result['current_signal'] == 'Ø®Ø±ÛŒØ¯':\n",
        "                        if ema_result['latest_signal_type'] in ['Ø®Ø±ÛŒØ¯', 'ØµØ¹ÙˆØ¯ÛŒ']:\n",
        "                            special_strategies[\"Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…ØªØ­Ø±Ú© Ù†Ù…Ø§ÛŒÛŒ\"] = ema_result['latest_signal_strength']\n",
        "                        if rsi_result['current_signal_type'] in ['Ø®Ø±ÛŒØ¯', 'ØµØ¹ÙˆØ¯ÛŒ']:\n",
        "                            special_strategies[\"Ø´Ø§Ø®Øµ Ù‚Ø¯Ø±Øª Ù†Ø³Ø¨ÛŒ\"] = rsi_result['current_signal_strength']\n",
        "                    elif special_result['current_signal'] == 'ÙØ±ÙˆØ´':\n",
        "                        if ema_result['latest_signal_type'] in ['ÙØ±ÙˆØ´', 'Ù†Ø²ÙˆÙ„ÛŒ']:\n",
        "                            special_strategies[\"Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…ØªØ­Ø±Ú© Ù†Ù…Ø§ÛŒÛŒ\"] = ema_result['latest_signal_strength']\n",
        "                        if rsi_result['current_signal_type'] in ['ÙØ±ÙˆØ´', 'Ù†Ø²ÙˆÙ„ÛŒ']:\n",
        "                            special_strategies[\"Ø´Ø§Ø®Øµ Ù‚Ø¯Ø±Øª Ù†Ø³Ø¨ÛŒ\"] = rsi_result['current_signal_strength']\n",
        "\n",
        "                    # ØªØ¹ÛŒÛŒÙ† Ù‚ÛŒÙ…Øª ÙˆØ±ÙˆØ¯ØŒ Ø­Ø¯ Ø¶Ø±Ø± Ùˆ Ø­Ø¯ Ø³ÙˆØ¯\n",
        "                    entry_price = df['close'].iloc[-1]\n",
        "\n",
        "                    # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù†Ù‚Ø§Ø· ÙˆØ±ÙˆØ¯ Ø§Ú¯Ø± Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ø´Ù†Ø¯\n",
        "                    stop_loss = entry_price * 0.95  # Ù¾ÛŒØ´â€ŒÙØ±Ø¶: 5% Ø²ÛŒØ± Ù‚ÛŒÙ…Øª ÙˆØ±ÙˆØ¯\n",
        "                    take_profit = entry_price * 1.10  # Ù¾ÛŒØ´â€ŒÙØ±Ø¶: 10% Ø¨Ø§Ù„Ø§ÛŒ Ù‚ÛŒÙ…Øª ÙˆØ±ÙˆØ¯\n",
        "\n",
        "                    if 'entry_points' in special_result and special_result['entry_points'] and len(\n",
        "                            special_result['entry_points']) > 0:\n",
        "                        latest_entry = special_result['entry_points'][-1]\n",
        "                        if latest_entry['type'] == 'long' and special_result['current_signal'] == 'Ø®Ø±ÛŒØ¯':\n",
        "                            stop_loss = latest_entry['stop_loss']\n",
        "                            take_profit = latest_entry['take_profit']\n",
        "                        elif latest_entry['type'] == 'short' and special_result['current_signal'] == 'ÙØ±ÙˆØ´':\n",
        "                            stop_loss = latest_entry['stop_loss']\n",
        "                            take_profit = latest_entry['take_profit']\n",
        "\n",
        "                    # Ø§ÛŒØ¬Ø§Ø¯ ØªÙˆØ¶ÛŒØ­Ø§Øª\n",
        "                    description = f\"Ø³ÛŒÚ¯Ù†Ø§Ù„ {special_result['current_signal']} Ø¨Ø±Ø§Ø³Ø§Ø³ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ ÙˆÛŒÚ˜Ù‡\\n\\n\"\n",
        "\n",
        "                    if 'strategy_description' in special_result and special_result['strategy_description']:\n",
        "                        description += f\"â€¢ {special_result['strategy_description']}\\n\"\n",
        "\n",
        "                    description += f\"â€¢ Ø³Ø·Ø­ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†: {special_result['current_strength']}%\\n\"\n",
        "                    description += f\"\\nØ§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ:\\n\"\n",
        "                    description += f\"â€¢ ÙˆØ±ÙˆØ¯: {entry_price:.6f}\\n\"\n",
        "                    description += f\"â€¢ Ø­Ø¯ Ø¶Ø±Ø±: {stop_loss:.6f}\\n\"\n",
        "                    description += f\"â€¢ Ø­Ø¯ Ø³ÙˆØ¯: {take_profit:.6f}\\n\"\n",
        "\n",
        "                    # Ø§ÛŒØ¬Ø§Ø¯ Ù†Ù…ÙˆØ¯Ø§Ø±\n",
        "                    special_chart_path = self.create_candlestick_chart(\n",
        "                        df, symbol, timeframe,\n",
        "                        strategies=special_strategies,\n",
        "                        indicators={\n",
        "                            'ema': True,\n",
        "                            'rsi': True,\n",
        "                            'macd': True,\n",
        "                            'bollinger': True\n",
        "                        },\n",
        "                        patterns={\n",
        "                            'market_structure_break_bullish': market_structure_result.get('msb_bullish', []),\n",
        "                            'market_structure_break_bearish': market_structure_result.get('msb_bearish', []),\n",
        "                            'order_block_bullish': market_structure_result.get('orderblock_bullish', []),\n",
        "                            'order_block_bearish': market_structure_result.get('orderblock_bearish', [])\n",
        "                        },\n",
        "                        entry_exit={\n",
        "                            'entries': [{'index': len(df) - 1, 'price': entry_price}],\n",
        "                            'stop_loss': stop_loss,\n",
        "                            'take_profit': take_profit\n",
        "                        },\n",
        "                        title=f\"{symbol} - {timeframe} - Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ ÙˆÛŒÚ˜Ù‡ ({int(special_result['current_strength'])}% Ø§Ø·Ù…ÛŒÙ†Ø§Ù†)\"\n",
        "                    )\n",
        "\n",
        "                    # Ø§Ø±Ø³Ø§Ù„ Ø³ÛŒÚ¯Ù†Ø§Ù„\n",
        "                    self.send_signal(\n",
        "                        symbol, timeframe, special_result['current_signal'], entry_price,\n",
        "                        stop_loss, take_profit,\n",
        "                        special_strategies, special_result['current_strength'],\n",
        "                        description,\n",
        "                        special_chart_path\n",
        "                    )\n",
        "\n",
        "                # ======= Ø¨Ø±Ø±Ø³ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø§ÛŒÚ†ÛŒÙ…ÙˆÚ©Ùˆ =======\n",
        "                if 'current_signal' in ichimoku_result and ichimoku_result['current_signal'] in ['Ø®Ø±ÛŒØ¯', 'ÙØ±ÙˆØ´'] and \\\n",
        "                        ichimoku_result['current_strength'] >= BOT_SETTINGS['signal_confidence_threshold']:\n",
        "                    # Ø³Ø§Ø®Øª Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§ÛŒ ØªØ£ÛŒÛŒØ¯Ú©Ù†Ù†Ø¯Ù‡\n",
        "                    ichimoku_strategies = {\n",
        "                        \"Ø§ÛŒÚ†ÛŒÙ…ÙˆÚ©Ùˆ\": ichimoku_result['current_strength']\n",
        "                    }\n",
        "\n",
        "                    # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§ÛŒ Ù‡Ù…Ø³Ùˆ\n",
        "                    if ichimoku_result['current_signal'] == 'Ø®Ø±ÛŒØ¯':\n",
        "                        if ema_result['latest_signal_type'] in ['Ø®Ø±ÛŒØ¯', 'ØµØ¹ÙˆØ¯ÛŒ']:\n",
        "                            ichimoku_strategies[\"Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…ØªØ­Ø±Ú© Ù†Ù…Ø§ÛŒÛŒ\"] = ema_result['latest_signal_strength']\n",
        "                        if rsi_result['current_signal_type'] in ['Ø®Ø±ÛŒØ¯', 'ØµØ¹ÙˆØ¯ÛŒ']:\n",
        "                            ichimoku_strategies[\"Ø´Ø§Ø®Øµ Ù‚Ø¯Ø±Øª Ù†Ø³Ø¨ÛŒ\"] = rsi_result['current_signal_strength']\n",
        "                    elif ichimoku_result['current_signal'] == 'ÙØ±ÙˆØ´':\n",
        "                        if ema_result['latest_signal_type'] in ['ÙØ±ÙˆØ´', 'Ù†Ø²ÙˆÙ„ÛŒ']:\n",
        "                            ichimoku_strategies[\"Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…ØªØ­Ø±Ú© Ù†Ù…Ø§ÛŒÛŒ\"] = ema_result['latest_signal_strength']\n",
        "                        if rsi_result['current_signal_type'] in ['ÙØ±ÙˆØ´', 'Ù†Ø²ÙˆÙ„ÛŒ']:\n",
        "                            ichimoku_strategies[\"Ø´Ø§Ø®Øµ Ù‚Ø¯Ø±Øª Ù†Ø³Ø¨ÛŒ\"] = rsi_result['current_signal_strength']\n",
        "\n",
        "                    # ØªØ¹ÛŒÛŒÙ† Ù‚ÛŒÙ…Øª ÙˆØ±ÙˆØ¯ØŒ Ø­Ø¯ Ø¶Ø±Ø± Ùˆ Ø­Ø¯ Ø³ÙˆØ¯\n",
        "                    entry_price = df['close'].iloc[-1]\n",
        "\n",
        "                    # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù†Ù‚Ø§Ø· ÙˆØ±ÙˆØ¯ Ø§ÛŒÚ†ÛŒÙ…ÙˆÚ©Ùˆ Ø§Ú¯Ø± Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ø´Ù†Ø¯\n",
        "                    stop_loss = entry_price * 0.95  # Ù¾ÛŒØ´â€ŒÙØ±Ø¶: 5% Ø²ÛŒØ± Ù‚ÛŒÙ…Øª ÙˆØ±ÙˆØ¯\n",
        "                    take_profit = entry_price * 1.10  # Ù¾ÛŒØ´â€ŒÙØ±Ø¶: 10% Ø¨Ø§Ù„Ø§ÛŒ Ù‚ÛŒÙ…Øª ÙˆØ±ÙˆØ¯\n",
        "\n",
        "                    if 'entry_points' in ichimoku_result and ichimoku_result['entry_points'] and len(\n",
        "                            ichimoku_result['entry_points']) > 0:\n",
        "                        latest_entry = ichimoku_result['entry_points'][-1]\n",
        "                        if latest_entry['type'] == 'long' and ichimoku_result['current_signal'] == 'Ø®Ø±ÛŒØ¯':\n",
        "                            entry_price = latest_entry['price']\n",
        "                            stop_loss = latest_entry['stop_loss']\n",
        "                            take_profit = latest_entry['take_profit']\n",
        "                        elif latest_entry['type'] == 'short' and ichimoku_result['current_signal'] == 'ÙØ±ÙˆØ´':\n",
        "                            entry_price = latest_entry['price']\n",
        "                            stop_loss = latest_entry['stop_loss']\n",
        "                            take_profit = latest_entry['take_profit']\n",
        "\n",
        "                    # Ø§ÛŒØ¬Ø§Ø¯ ØªÙˆØ¶ÛŒØ­Ø§Øª\n",
        "                    description = f\"Ø³ÛŒÚ¯Ù†Ø§Ù„ {ichimoku_result['current_signal']} Ø¨Ø±Ø§Ø³Ø§Ø³ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø§ÛŒÚ†ÛŒÙ…ÙˆÚ©Ùˆ\\n\\n\"\n",
        "\n",
        "                    if 'current_status' in ichimoku_result:\n",
        "                        description += f\"â€¢ {ichimoku_result['current_status']}\\n\"\n",
        "\n",
        "                    description += f\"â€¢ Ø³Ø·Ø­ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†: {ichimoku_result['current_strength']}%\\n\"\n",
        "                    description += f\"\\nØ§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ:\\n\"\n",
        "                    description += f\"â€¢ ÙˆØ±ÙˆØ¯: {entry_price:.6f}\\n\"\n",
        "                    description += f\"â€¢ Ø­Ø¯ Ø¶Ø±Ø±: {stop_loss:.6f}\\n\"\n",
        "                    description += f\"â€¢ Ø­Ø¯ Ø³ÙˆØ¯: {take_profit:.6f}\\n\"\n",
        "\n",
        "                    # Ø§ÛŒØ¬Ø§Ø¯ Ù†Ù…ÙˆØ¯Ø§Ø±\n",
        "                    ichimoku_chart_path = self.create_candlestick_chart(\n",
        "                        df, symbol, timeframe,\n",
        "                        strategies=ichimoku_strategies,\n",
        "                        indicators={\n",
        "                            'ema': True,\n",
        "                            'rsi': True,\n",
        "                            'macd': True,\n",
        "                            'ichimoku': True\n",
        "                        },\n",
        "                        patterns={\n",
        "                            'market_structure_break_bullish': market_structure_result.get('msb_bullish', []),\n",
        "                            'market_structure_break_bearish': market_structure_result.get('msb_bearish', []),\n",
        "                            'order_block_bullish': market_structure_result.get('orderblock_bullish', []),\n",
        "                            'order_block_bearish': market_structure_result.get('orderblock_bearish', [])\n",
        "                        },\n",
        "                        entry_exit={\n",
        "                            'entries': [{'index': len(df) - 1, 'price': entry_price}],\n",
        "                            'stop_loss': stop_loss,\n",
        "                            'take_profit': take_profit\n",
        "                        },\n",
        "                        title=f\"{symbol} - {timeframe} - Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø§ÛŒÚ†ÛŒÙ…ÙˆÚ©Ùˆ ({int(ichimoku_result['current_strength'])}% Ø§Ø·Ù…ÛŒÙ†Ø§Ù†)\"\n",
        "                    )\n",
        "\n",
        "                    # Ø§Ø±Ø³Ø§Ù„ Ø³ÛŒÚ¯Ù†Ø§Ù„\n",
        "                    self.send_signal(\n",
        "                        symbol, timeframe, ichimoku_result['current_signal'], entry_price,\n",
        "                        stop_loss, take_profit,\n",
        "                        ichimoku_strategies, ichimoku_result['current_strength'],\n",
        "                        description,\n",
        "                        ichimoku_chart_path\n",
        "                    )\n",
        "\n",
        "                # ======= Ø¨Ø±Ø±Ø³ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ =======\n",
        "                if 'current_signal' in fibonacci_result and fibonacci_result['current_signal'] in ['Ø®Ø±ÛŒØ¯', 'ÙØ±ÙˆØ´'] and \\\n",
        "                        fibonacci_result['current_strength'] >= BOT_SETTINGS['signal_confidence_threshold']:\n",
        "                    # Ø³Ø§Ø®Øª Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§ÛŒ ØªØ£ÛŒÛŒØ¯Ú©Ù†Ù†Ø¯Ù‡\n",
        "                    fib_strategies = {\n",
        "                        \"ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ\": fibonacci_result['current_strength']\n",
        "                    }\n",
        "\n",
        "                    # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§ÛŒ Ù‡Ù…Ø³Ùˆ\n",
        "                    if fibonacci_result['current_signal'] == 'Ø®Ø±ÛŒØ¯':\n",
        "                        if ema_result['latest_signal_type'] in ['Ø®Ø±ÛŒØ¯', 'ØµØ¹ÙˆØ¯ÛŒ']:\n",
        "                            fib_strategies[\"Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…ØªØ­Ø±Ú© Ù†Ù…Ø§ÛŒÛŒ\"] = ema_result['latest_signal_strength']\n",
        "                        if rsi_result['current_signal_type'] in ['Ø®Ø±ÛŒØ¯', 'ØµØ¹ÙˆØ¯ÛŒ']:\n",
        "                            fib_strategies[\"Ø´Ø§Ø®Øµ Ù‚Ø¯Ø±Øª Ù†Ø³Ø¨ÛŒ\"] = rsi_result['current_signal_strength']\n",
        "                    elif fibonacci_result['current_signal'] == 'ÙØ±ÙˆØ´':\n",
        "                        if ema_result['latest_signal_type'] in ['ÙØ±ÙˆØ´', 'Ù†Ø²ÙˆÙ„ÛŒ']:\n",
        "                            fib_strategies[\"Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…ØªØ­Ø±Ú© Ù†Ù…Ø§ÛŒÛŒ\"] = ema_result['latest_signal_strength']\n",
        "                        if rsi_result['current_signal_type'] in ['ÙØ±ÙˆØ´', 'Ù†Ø²ÙˆÙ„ÛŒ']:\n",
        "                            fib_strategies[\"Ø´Ø§Ø®Øµ Ù‚Ø¯Ø±Øª Ù†Ø³Ø¨ÛŒ\"] = rsi_result['current_signal_strength']\n",
        "\n",
        "                    # ØªØ¹ÛŒÛŒÙ† Ù‚ÛŒÙ…Øª ÙˆØ±ÙˆØ¯ØŒ Ø­Ø¯ Ø¶Ø±Ø± Ùˆ Ø­Ø¯ Ø³ÙˆØ¯\n",
        "                    entry_price = df['close'].iloc[-1]\n",
        "\n",
        "                    # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù†Ù‚Ø§Ø· ÙˆØ±ÙˆØ¯ ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ Ø§Ú¯Ø± Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ø´Ù†Ø¯\n",
        "                    stop_loss = entry_price * 0.95  # Ù¾ÛŒØ´â€ŒÙØ±Ø¶: 5% Ø²ÛŒØ± Ù‚ÛŒÙ…Øª ÙˆØ±ÙˆØ¯\n",
        "                    take_profit = entry_price * 1.10  # Ù¾ÛŒØ´â€ŒÙØ±Ø¶: 10% Ø¨Ø§Ù„Ø§ÛŒ Ù‚ÛŒÙ…Øª ÙˆØ±ÙˆØ¯\n",
        "\n",
        "                    if fibonacci_result['current_signal'] == 'Ø®Ø±ÛŒØ¯' and 'buy_signals' in fibonacci_result and \\\n",
        "                            fibonacci_result['buy_signals'] and len(fibonacci_result['buy_signals']) > 0:\n",
        "                        latest_entry = fibonacci_result['buy_signals'][-1]\n",
        "                        stop_loss = latest_entry.get('stop_loss', stop_loss)\n",
        "                        take_profit = latest_entry.get('take_profit', take_profit)\n",
        "                    elif fibonacci_result['current_signal'] == 'ÙØ±ÙˆØ´' and 'sell_signals' in fibonacci_result and \\\n",
        "                            fibonacci_result['sell_signals'] and len(fibonacci_result['sell_signals']) > 0:\n",
        "                        latest_entry = fibonacci_result['sell_signals'][-1]\n",
        "                        stop_loss = latest_entry.get('stop_loss', stop_loss)\n",
        "                        take_profit = latest_entry.get('take_profit', take_profit)\n",
        "\n",
        "                    # Ø§ÛŒØ¬Ø§Ø¯ ØªÙˆØ¶ÛŒØ­Ø§Øª\n",
        "                    description = f\"Ø³ÛŒÚ¯Ù†Ø§Ù„ {fibonacci_result['current_signal']} Ø¨Ø±Ø§Ø³Ø§Ø³ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ\\n\\n\"\n",
        "\n",
        "                    # Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø³Ø·ÙˆØ­ ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ\n",
        "                    if fibonacci_result['current_signal'] == 'Ø®Ø±ÛŒØ¯' and fibonacci_result.get('nearest_support'):\n",
        "                        fib_level, fib_value = fibonacci_result.get('nearest_support')\n",
        "                        description += f\"â€¢ ÙˆØ§Ú©Ù†Ø´ Ø¨Ù‡ Ø³Ø·Ø­ ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ {fib_level} Ø¯Ø± Ù‚ÛŒÙ…Øª {fib_value:.6f}\\n\"\n",
        "                    elif fibonacci_result['current_signal'] == 'ÙØ±ÙˆØ´' and fibonacci_result.get('nearest_resistance'):\n",
        "                        fib_level, fib_value = fibonacci_result.get('nearest_resistance')\n",
        "                        description += f\"â€¢ ÙˆØ§Ú©Ù†Ø´ Ø¨Ù‡ Ø³Ø·Ø­ ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ {fib_level} Ø¯Ø± Ù‚ÛŒÙ…Øª {fib_value:.6f}\\n\"\n",
        "\n",
        "                    description += f\"â€¢ Ø³Ø·Ø­ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†: {fibonacci_result['current_strength']}%\\n\"\n",
        "                    description += f\"\\nØ§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ:\\n\"\n",
        "                    description += f\"â€¢ ÙˆØ±ÙˆØ¯: {entry_price:.6f}\\n\"\n",
        "                    description += f\"â€¢ Ø­Ø¯ Ø¶Ø±Ø±: {stop_loss:.6f}\\n\"\n",
        "                    description += f\"â€¢ Ø­Ø¯ Ø³ÙˆØ¯: {take_profit:.6f}\\n\"\n",
        "\n",
        "                    # Ø§ÛŒØ¬Ø§Ø¯ Ù†Ù…ÙˆØ¯Ø§Ø±\n",
        "                    fib_chart_path = self.create_candlestick_chart(\n",
        "                        df, symbol, timeframe,\n",
        "                        strategies=fib_strategies,\n",
        "                        indicators={\n",
        "                            'ema': True,\n",
        "                            'rsi': True,\n",
        "                            'macd': True,\n",
        "                            'fibonacci': True\n",
        "                        },\n",
        "                        patterns={\n",
        "                            'market_structure_break_bullish': market_structure_result.get('msb_bullish', []),\n",
        "                            'market_structure_break_bearish': market_structure_result.get('msb_bearish', []),\n",
        "                            'order_block_bullish': market_structure_result.get('orderblock_bullish', []),\n",
        "                            'order_block_bearish': market_structure_result.get('orderblock_bearish', [])\n",
        "                        },\n",
        "                        entry_exit={\n",
        "                            'entries': [{'index': len(df) - 1, 'price': entry_price}],\n",
        "                            'stop_loss': stop_loss,\n",
        "                            'take_profit': take_profit\n",
        "                        },\n",
        "                        title=f\"{symbol} - {timeframe} - Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ ({int(fibonacci_result['current_strength'])}% Ø§Ø·Ù…ÛŒÙ†Ø§Ù†)\"\n",
        "                    )\n",
        "\n",
        "                    # Ø§Ø±Ø³Ø§Ù„ Ø³ÛŒÚ¯Ù†Ø§Ù„\n",
        "                    self.send_signal(\n",
        "                        symbol, timeframe, fibonacci_result['current_signal'], entry_price,\n",
        "                        stop_loss, take_profit,\n",
        "                        fib_strategies, fibonacci_result['current_strength'],\n",
        "                        description,\n",
        "                        fib_chart_path\n",
        "                    )\n",
        "\n",
        "                # ======= Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬ =======\n",
        "                results[timeframe] = {\n",
        "                    'market_structure': market_structure_result,\n",
        "                    'pressure': pressure_result,\n",
        "                    'whale': whale_result,\n",
        "                    'ema': ema_result,\n",
        "                    'rsi': rsi_result,\n",
        "                    'divergence': divergence_result,\n",
        "                    'bbrsi_macd': bbrsi_macd_result,\n",
        "                    'darvas': darvas_result,\n",
        "                    'ichimoku': ichimoku_result,\n",
        "                    'fibonacci': fibonacci_result,\n",
        "                    'golden': golden_result,\n",
        "                    'special': special_result\n",
        "                }\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.error(f\"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ {symbol} Ø¯Ø± ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ… {timeframe}: {str(e)}\")\n",
        "                logger.error(traceback.format_exc())\n",
        "\n",
        "        return results\n",
        "\n",
        "    def run(self):\n",
        "        \"\"\"Ø§Ø¬Ø±Ø§ÛŒ Ø±Ø¨Ø§Øª ØªØ­Ù„ÛŒÙ„Ú¯Ø± Ø¨Ø§ Ù‚Ø§Ø¨Ù„ÛŒØª Ù…Ù‚Ø§ÙˆÙ…Øª Ø¯Ø± Ø¨Ø±Ø§Ø¨Ø± Ù‚Ø·Ø¹ Ø§ØªØµØ§Ù„ Ùˆ Ù…Ø¯ÛŒØ±ÛŒØª Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø­Ø§ÙØ¸Ù‡\"\"\"\n",
        "        logger.info(\"ğŸš€ Ø±Ø¨Ø§Øª ØªØ­Ù„ÛŒÙ„Ú¯Ø± Ø§Ø±Ø² Ø¯ÛŒØ¬ÛŒØªØ§Ù„ Ø´Ø±ÙˆØ¹ Ø¨Ù‡ Ú©Ø§Ø± Ú©Ø±Ø¯\")\n",
        "\n",
        "        # Ø§ÙØ²ÙˆØ¯Ù† Ù…Ú©Ø§Ù†ÛŒØ³Ù…â€ŒÙ‡Ø§ÛŒ Ø¨Ù‚Ø§ Ø¯Ø± Ù…Ø­ÛŒØ· Ú©ÙˆÙ„Ø¨\n",
        "        self.add_colab_survival_mechanisms()\n",
        "\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø§ØªØµØ§Ù„ Ùˆ Ø´Ù…Ø§Ø±Ù†Ø¯Ù‡â€ŒÙ‡Ø§\n",
        "        self.diagnose_signals()\n",
        "\n",
        "        # Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ Ú©Ø´ Ø¯ÛŒØ³Ú© Ø¯Ø± Ø´Ø±ÙˆØ¹ Ø¨Ø±Ù†Ø§Ù…Ù‡\n",
        "        cleanup_old_disk_cache()\n",
        "\n",
        "        # Ù…Ú©Ø§Ù†ÛŒØ³Ù… Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§\n",
        "        max_errors = 5\n",
        "        consecutive_errors = 0\n",
        "\n",
        "        # Ø´Ù…Ø§Ø±Ù†Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù¾Ø§ÛŒØ´ Ù…Ø¯Ø§ÙˆÙ… Ù…Ù†Ø§Ø¨Ø¹\n",
        "        resource_check_counter = 0\n",
        "\n",
        "        while True:\n",
        "            try:\n",
        "                # Ù¾Ø§ÛŒØ´ Ù…Ù†Ø§Ø¨Ø¹ Ø¯Ø± Ù‡Ø± Ú†Ø±Ø®Ù‡\n",
        "                resource_check_counter += 1\n",
        "                if resource_check_counter >= 5:  # Ù‡Ø± 5 Ú†Ø±Ø®Ù‡ ÛŒÚ© Ø¨Ø§Ø± Ù¾Ø§ÛŒØ´ Ú©Ø§Ù…Ù„ Ù…Ù†Ø§Ø¨Ø¹\n",
        "                    system_status = monitor_resources(critical_threshold=90, warning_threshold=75)\n",
        "                    logger.info(f\"ÙˆØ¶Ø¹ÛŒØª Ø³ÛŒØ³ØªÙ…: RAM {system_status.get('memory_percent', 0):.1f}%, \"\n",
        "                                f\"CPU {system_status.get('cpu_percent', 0):.1f}%, \"\n",
        "                                f\"Ú©Ø´ {system_status.get('cache_items', 0)} Ø¢ÛŒØªÙ…\")\n",
        "                    resource_check_counter = 0\n",
        "                else:\n",
        "                    # Ù¾Ø§ÛŒØ´ Ø³Ø±ÛŒØ¹ Ø¯Ø± Ù‡Ø± Ú†Ø±Ø®Ù‡ Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ø¹Ø¯Ù… Ú©Ù…Ø¨ÙˆØ¯ Ø­Ø§ÙØ¸Ù‡\n",
        "                    try:\n",
        "                        import psutil\n",
        "                        memory_percent = psutil.virtual_memory().percent\n",
        "                        if memory_percent > 85:  # Ø§Ú¯Ø± Ø­Ø§ÙØ¸Ù‡ Ø¨ÛŒØ´ Ø§Ø² 85% Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ù‡ØŒ Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ¯Ù‡ÛŒÙ…\n",
        "                            logger.warning(f\"Ù…ØµØ±Ù Ø­Ø§ÙØ¸Ù‡ Ø¨Ø§Ù„Ø§: {memory_percent:.1f}% - Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ\")\n",
        "                            clean_memory_cache(force_cleanup=True)\n",
        "                    except:\n",
        "                        pass\n",
        "\n",
        "                # Ù…Ú©Ø§Ù†ÛŒØ³Ù… Ø§Ø¬Ø±Ø§ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒØ¯Ù‡ÛŒ Ø¨Ø§ ØªÙˆØ²ÛŒØ¹ Ø¨Ø§Ø±\n",
        "                symbols_batch_size = 5  # Ú©Ø§Ù‡Ø´ ØªØ¹Ø¯Ø§Ø¯ Ø§Ø±Ø²Ù‡Ø§ÛŒ Ù‚Ø§Ø¨Ù„ Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ø± Ù‡Ø± Ø¨Ø§Ø± Ø¨Ø±Ø§ÛŒ Ú©Ø§Ù‡Ø´ Ù…ØµØ±Ù Ø­Ø§ÙØ¸Ù‡\n",
        "\n",
        "                # ØªÙ‚Ø³ÛŒÙ… Ù„ÛŒØ³Øª Ø§Ø±Ø²Ù‡Ø§ Ø¨Ù‡ Ú¯Ø±ÙˆÙ‡â€ŒÙ‡Ø§ÛŒ Ú©ÙˆÚ†Ú©ØªØ±\n",
        "                for i in range(0, len(symbols), symbols_batch_size):\n",
        "                    batch = symbols[i:i + symbols_batch_size]\n",
        "                    logger.info(\n",
        "                        f\"ğŸ“Š Ø¨Ø±Ø±Ø³ÛŒ Ú¯Ø±ÙˆÙ‡ Ø§Ø±Ø²Ù‡Ø§: {i // symbols_batch_size + 1}/{math.ceil(len(symbols) / symbols_batch_size)}\")\n",
        "\n",
        "                    for symbol in batch:\n",
        "                        self.run_analysis(symbol, timeframes)\n",
        "\n",
        "                        # Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ ØµØ±ÛŒØ­ Ø­Ø§ÙØ¸Ù‡ Ø¨Ø¹Ø¯ Ø§Ø² Ù‡Ø± Ø§Ø±Ø²\n",
        "                        gc.collect()\n",
        "\n",
        "                        # Ù…Ú©Ø« Ú©ÙˆØªØ§Ù‡ Ø¨ÛŒÙ† Ù‡Ø± Ø§Ø±Ø² Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø²ÛŒØ§Ø¯ Ù…Ù†Ø§Ø¨Ø¹\n",
        "                        time.sleep(2)\n",
        "\n",
        "                    # Ù¾Ø§ÛŒØ´ Ù…Ù†Ø§Ø¨Ø¹ Ø¨Ø¹Ø¯ Ø§Ø² Ù‡Ø± Ú¯Ø±ÙˆÙ‡\n",
        "                    try:\n",
        "                        import psutil\n",
        "                        memory_percent = psutil.virtual_memory().percent\n",
        "                        if memory_percent > 80:  # Ø§Ú¯Ø± Ø­Ø§ÙØ¸Ù‡ Ø¨ÛŒØ´ Ø§Ø² 80% Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ù‡ØŒ Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ¯Ù‡ÛŒÙ…\n",
        "                            logger.warning(f\"Ù…ØµØ±Ù Ø­Ø§ÙØ¸Ù‡ Ø¨Ø§Ù„Ø§ Ø¨Ø¹Ø¯ Ø§Ø² Ú¯Ø±ÙˆÙ‡: {memory_percent:.1f}% - Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ\")\n",
        "                            clean_memory_cache(force_cleanup=True)\n",
        "                    except:\n",
        "                        # Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ù…Ø­ØªØ§Ø·Ø§Ù†Ù‡ Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§\n",
        "                        clean_memory_cache(force_cleanup=True)\n",
        "\n",
        "                    # Ø°Ø®ÛŒØ±Ù‡ ÙˆØ¶Ø¹ÛŒØª Ù¾Ø³ Ø§Ø² Ù‡Ø± Ú¯Ø±ÙˆÙ‡\n",
        "                    self.save_state()\n",
        "\n",
        "                    # Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ú©Ø´ Ø­Ø§ÙØ¸Ù‡ Ø¨Ø¹Ø¯ Ø§Ø² Ù‡Ø± Ú¯Ø±ÙˆÙ‡\n",
        "                    clean_memory_cache()\n",
        "\n",
        "                    # Ù…Ú©Ø« Ø¨ÛŒÙ† Ú¯Ø±ÙˆÙ‡â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ ØªÙˆØ²ÛŒØ¹ Ø¨Ø§Ø±\n",
        "                    time.sleep(15)\n",
        "\n",
        "                # ØªØ­Ù„ÛŒÙ„ Ø¹Ù…Ù„Ú©Ø±Ø¯ ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§\n",
        "                analyze_exchange_performance()\n",
        "\n",
        "                # Ø°Ø®ÛŒØ±Ù‡ ÙˆØ¶Ø¹ÛŒØª\n",
        "                self.save_state()\n",
        "\n",
        "                # Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ú©Ø´ Ù‚Ø¯ÛŒÙ…ÛŒ\n",
        "                cleanup_old_disk_cache()\n",
        "\n",
        "                # Ø±ÛŒØ³Øª Ø´Ù…Ø§Ø±Ù†Ø¯Ù‡ Ø®Ø·Ø§Ù‡Ø§\n",
        "                consecutive_errors = 0\n",
        "\n",
        "                # Ù…Ú©Ø§Ù†ÛŒØ³Ù… Ø®ÙˆØ§Ø¨ Ù‡ÙˆØ´Ù…Ù†Ø¯: Ø¯Ø± Ø³Ø§Ø¹Ø§Øª Ú©Ù… Ù…Ø¹Ø§Ù…Ù„Ù‡ØŒ Ø²Ù…Ø§Ù† Ø·ÙˆÙ„Ø§Ù†ÛŒâ€ŒØªØ±ÛŒ Ù…ÛŒâ€ŒØ®ÙˆØ§Ø¨ÛŒÙ…\n",
        "                current_hour = datetime.datetime.now().hour\n",
        "                if 2 <= current_hour <= 5:  # Ø³Ø§Ø¹Ø§Øª Ú©Ù… ÙØ¹Ø§Ù„ÛŒØª Ø¨Ø§Ø²Ø§Ø± (2 ØªØ§ 5 ØµØ¨Ø­)\n",
        "                    logger.info(\"ğŸ’¤ Ø³Ø§Ø¹Ø§Øª Ú©Ù… ÙØ¹Ø§Ù„ÛŒØª Ø¨Ø§Ø²Ø§Ø± - Ø§Ø¬Ø±Ø§ÛŒ Ø¨Ø§ ØªØ§Ø®ÛŒØ± Ø¨ÛŒØ´ØªØ±...\")\n",
        "                    sleep_time = 600  # 10 Ø¯Ù‚ÛŒÙ‚Ù‡ Ø¯Ø± Ø³Ø§Ø¹Ø§Øª Ú©Ù… ÙØ¹Ø§Ù„ÛŒØª\n",
        "                else:\n",
        "                    sleep_time = 180  # 3 Ø¯Ù‚ÛŒÙ‚Ù‡ Ø¯Ø± Ø³Ø§Ø¹Ø§Øª Ù…Ø¹Ù…ÙˆÙ„\n",
        "\n",
        "                # Ø¢Ø²Ø§Ø¯Ø³Ø§Ø²ÛŒ ØµØ±ÛŒØ­ Ø­Ø§ÙØ¸Ù‡ Ø¯Ø± Ù¾Ø§ÛŒØ§Ù† Ù‡Ø± Ú†Ø±Ø®Ù‡\n",
        "                gc.collect()\n",
        "\n",
        "                # Ø§Ù†ØªØ¸Ø§Ø± Ù‚Ø¨Ù„ Ø§Ø² Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø¬Ø¯Ø¯ Ø¨Ø§ Ù†Ù…Ø§ÛŒØ´ Ø´Ù…Ø§Ø±Ù†Ø¯Ù‡ Ù…Ø¹Ú©ÙˆØ³\n",
        "                for remaining in range(sleep_time, 0, -15):\n",
        "                    print(f\"\\râ³ Ø¨Ø±Ø±Ø³ÛŒ Ø¨Ø¹Ø¯ÛŒ Ø¯Ø± {remaining} Ø«Ø§Ù†ÛŒÙ‡ Ø¯ÛŒÚ¯Ø±...     \", end=\"\")\n",
        "\n",
        "                    # Ù¾Ø§ÛŒØ´ Ù…Ù†Ø§Ø¨Ø¹ Ø­ØªÛŒ Ø¯Ø± Ø­Ø§Ù„Øª Ø§Ù†ØªØ¸Ø§Ø±\n",
        "                    if remaining % 60 == 0:  # Ù‡Ø± 60 Ø«Ø§Ù†ÛŒÙ‡\n",
        "                        try:\n",
        "                            import psutil\n",
        "                            memory_percent = psutil.virtual_memory().percent\n",
        "                            if memory_percent > 90:  # Ø§Ú¯Ø± Ø­Ø§ÙØ¸Ù‡ Ø¨ÛŒØ´ Ø§Ø² 90% Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ù‡ØŒ Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø§Ø¶Ø·Ø±Ø§Ø±ÛŒ Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ¯Ù‡ÛŒÙ…\n",
        "                                logger.warning(\n",
        "                                    f\"Ù…ØµØ±Ù Ø­Ø§ÙØ¸Ù‡ Ø¨Ø­Ø±Ø§Ù†ÛŒ Ø¯Ø± Ø­Ø§Ù„Øª Ø§Ù†ØªØ¸Ø§Ø±: {memory_percent:.1f}% - Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø§Ø¶Ø·Ø±Ø§Ø±ÛŒ\")\n",
        "                                memory_cache.clear()\n",
        "                                memory_cache_access_time.clear()\n",
        "                                gc.collect()\n",
        "                        except:\n",
        "                            pass\n",
        "\n",
        "                    time.sleep(15)\n",
        "                print(\"\\r                                              \", end=\"\")\n",
        "\n",
        "            except KeyboardInterrupt:\n",
        "                # Ø°Ø®ÛŒØ±Ù‡ Ù†Ù‡Ø§ÛŒÛŒ ÙˆØ¶Ø¹ÛŒØª\n",
        "                self.save_state()\n",
        "                logger.info(\"ğŸ‘‹ Ø±Ø¨Ø§Øª Ù…ØªÙˆÙ‚Ù Ø´Ø¯ - ÙˆØ¶Ø¹ÛŒØª Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯\")\n",
        "                break\n",
        "\n",
        "            except Exception as e:\n",
        "                # Ø§ÙØ²Ø§ÛŒØ´ Ø´Ù…Ø§Ø±Ù†Ø¯Ù‡ Ø®Ø·Ø§Ù‡Ø§ÛŒ Ù¾ÛŒ Ø¯Ø± Ù¾ÛŒ\n",
        "                consecutive_errors += 1\n",
        "\n",
        "                logger.error(f\"âŒ Ø®Ø·Ø§ÛŒ Ú©Ù„ÛŒ ({consecutive_errors}/{max_errors}): {str(e)}\")\n",
        "                logger.error(traceback.format_exc())\n",
        "\n",
        "                # Ø°Ø®ÛŒØ±Ù‡ ÙˆØ¶Ø¹ÛŒØª Ø­ØªÛŒ Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§\n",
        "                self.save_state()\n",
        "\n",
        "                # Ø¢Ø²Ø§Ø¯Ø³Ø§Ø²ÛŒ ØµØ±ÛŒØ­ Ø­Ø§ÙØ¸Ù‡ Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§ Ùˆ Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø§Ø¶Ø·Ø±Ø§Ø±ÛŒ\n",
        "                memory_cache.clear()\n",
        "                memory_cache_access_time.clear()\n",
        "                gc.collect()\n",
        "\n",
        "                # Ø§Ú¯Ø± ØªØ¹Ø¯Ø§Ø¯ Ø®Ø·Ø§Ù‡Ø§ÛŒ Ù¾ÛŒ Ø¯Ø± Ù¾ÛŒ Ø§Ø² Ø­Ø¯ Ù…Ø¬Ø§Ø² Ø¨ÛŒØ´ØªØ± Ø´Ø¯ØŒ Ú©Ù…ÛŒ Ø¨ÛŒØ´ØªØ± ØµØ¨Ø± Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…\n",
        "                if consecutive_errors >= max_errors:\n",
        "                    logger.warning(f\"âš ï¸ ØªØ¹Ø¯Ø§Ø¯ Ø®Ø·Ø§Ù‡Ø§ÛŒ Ù¾ÛŒ Ø¯Ø± Ù¾ÛŒ Ø¨Ù‡ Ø­Ø¯ Ù…Ø¬Ø§Ø² Ø±Ø³ÛŒØ¯. Ø§Ù†ØªØ¸Ø§Ø± Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ...\")\n",
        "                    time.sleep(300)  # 5 Ø¯Ù‚ÛŒÙ‚Ù‡ Ø§Ù†ØªØ¸Ø§Ø± Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ\n",
        "                    consecutive_errors = 0\n",
        "                else:\n",
        "                    time.sleep(60)  # 1 Ø¯Ù‚ÛŒÙ‚Ù‡ Ø§Ù†ØªØ¸Ø§Ø± Ù‚Ø¨Ù„ Ø§Ø² ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯\n",
        "\n",
        "    # Ø§Ø¬Ø±Ø§ÛŒ Ø§ØµÙ„ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡\n",
        "if __name__ == \"__main__\":\n",
        "    # ØªÙ†Ø¸ÛŒÙ… ØªÙˆÚ©Ù† Ø±Ø¨Ø§Øª ØªÙ„Ú¯Ø±Ø§Ù… Ùˆ Ø¢ÛŒØ¯ÛŒ Ú©Ø§Ù†Ø§Ù„\n",
        "    TELEGRAM_BOT_TOKEN = \"7307185304:AAF9zG3vM0Pc74WkiIDVEnRxu41OJYdyql8\"\n",
        "    TELEGRAM_CHANNEL_ID = \"@hosseinbtb2\"  # Ù…Ø«Ø§Ù„: \"@your_channel_name\"\n",
        "\n",
        "    # Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ù„Ø§Ø²Ù…\n",
        "    for path in [f\"{BASE_DIR}/cache/ohlcv\", f\"{BASE_DIR}/charts\", f\"{BASE_DIR}/logs\"]:\n",
        "        os.makedirs(path, exist_ok=True)\n",
        "\n",
        "    # Ø§ÛŒØ¬Ø§Ø¯ Ù†Ù…ÙˆÙ†Ù‡ ØªØ­Ù„ÛŒÙ„Ú¯Ø±\n",
        "    analyzer = CryptoAnalyzer(TELEGRAM_BOT_TOKEN, TELEGRAM_CHANNEL_ID)\n",
        "\n",
        "    # Ø§Ø¬Ø±Ø§ÛŒ Ø±Ø¨Ø§Øª\n",
        "    analyzer.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AnrmaSaljgxr",
        "outputId": "ef9bb9d8-4fd4-4165-a412-ee2795e31fa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸŒŸ Ù…Ø­ÛŒØ· Ú¯ÙˆÚ¯Ù„ Ú©ÙˆÙ„Ø¨ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯ - ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù¾Ø§ÛŒØ¯Ø§Ø±...\n",
            "ğŸ“¡ Ø±Ø¨Ø§Øª ÙØ¹Ø§Ù„ - Ø¢Ø®Ø±ÛŒÙ† Ø°Ø®ÛŒØ±Ù‡: 06:59:25 - Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§: 680Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "                function ClickConnect(){\n",
              "                    console.log(\"Ú©Ù„ÛŒÚ© Ø§ØªÙˆÙ…Ø§ØªÛŒÚ©\"); \n",
              "                    document.querySelector(\"colab-toolbar-button#connect\").click() \n",
              "                }\n",
              "                setInterval(ClickConnect, 60000)\n",
              "\n",
              "                // Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ ÙØ¹Ø§Ù„ÛŒØª Ú©Ø§Ø±Ø¨Ø± Ø¨Ø§ Ø§Ø³Ú©Ø±ÙˆÙ„ Ú©Ø±Ø¯Ù† ØµÙØ­Ù‡\n",
              "                function keepAlive() {\n",
              "                    document.body.dispatchEvent(new KeyboardEvent('keydown', {key: 'ArrowUp'}));\n",
              "                    setTimeout(function() {\n",
              "                        document.body.dispatchEvent(new KeyboardEvent('keydown', {key: 'ArrowDown'}));\n",
              "                    }, 500);\n",
              "                }\n",
              "                setInterval(keepAlive, 30000);\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-05-07 07:04:08,684 - ERROR - âŒ Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ø±Ø¨Ø§Øª ØªÙ„Ú¯Ø±Ø§Ù… Ø¨Ø±Ù‚Ø±Ø§Ø± Ù†ÛŒØ³Øª\n",
            "2025-05-07 07:04:08,684 - ERROR - âŒ Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ø±Ø¨Ø§Øª ØªÙ„Ú¯Ø±Ø§Ù… Ø¨Ø±Ù‚Ø±Ø§Ø± Ù†ÛŒØ³Øª\n",
            "2025-05-07 07:04:08,684 - ERROR - âŒ Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ø±Ø¨Ø§Øª ØªÙ„Ú¯Ø±Ø§Ù… Ø¨Ø±Ù‚Ø±Ø§Ø± Ù†ÛŒØ³Øª\n",
            "2025-05-07 07:04:08,684 - ERROR - âŒ Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ø±Ø¨Ø§Øª ØªÙ„Ú¯Ø±Ø§Ù… Ø¨Ø±Ù‚Ø±Ø§Ø± Ù†ÛŒØ³Øª\n",
            "2025-05-07 07:04:08,684 - ERROR - âŒ Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ø±Ø¨Ø§Øª ØªÙ„Ú¯Ø±Ø§Ù… Ø¨Ø±Ù‚Ø±Ø§Ø± Ù†ÛŒØ³Øª\n",
            "2025-05-07 07:04:08,684 - ERROR - âŒ Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ø±Ø¨Ø§Øª ØªÙ„Ú¯Ø±Ø§Ù… Ø¨Ø±Ù‚Ø±Ø§Ø± Ù†ÛŒØ³Øª\n",
            "ERROR:__main__:âŒ Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ø±Ø¨Ø§Øª ØªÙ„Ú¯Ø±Ø§Ù… Ø¨Ø±Ù‚Ø±Ø§Ø± Ù†ÛŒØ³Øª\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“¡ Ø±Ø¨Ø§Øª ÙØ¹Ø§Ù„ - Ø¢Ø®Ø±ÛŒÙ† Ø°Ø®ÛŒØ±Ù‡: 07:52:21 - Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§: 685"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-05-07 07:52:47,692 - WARNING - Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ OMG/USDT/15m\n",
            "2025-05-07 07:52:47,692 - WARNING - Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ OMG/USDT/15m\n",
            "2025-05-07 07:52:47,692 - WARNING - Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ OMG/USDT/15m\n",
            "2025-05-07 07:52:47,692 - WARNING - Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ OMG/USDT/15m\n",
            "2025-05-07 07:52:47,692 - WARNING - Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ OMG/USDT/15m\n",
            "2025-05-07 07:52:47,692 - WARNING - Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ OMG/USDT/15m\n",
            "WARNING:__main__:Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ OMG/USDT/15m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“¡ Ø±Ø¨Ø§Øª ÙØ¹Ø§Ù„ - Ø¢Ø®Ø±ÛŒÙ† Ø°Ø®ÛŒØ±Ù‡: 07:50:24 - Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§: 840"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-05-07 07:53:09,105 - WARNING - Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ OMG/USDT/1h\n",
            "2025-05-07 07:53:09,105 - WARNING - Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ OMG/USDT/1h\n",
            "2025-05-07 07:53:09,105 - WARNING - Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ OMG/USDT/1h\n",
            "2025-05-07 07:53:09,105 - WARNING - Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ OMG/USDT/1h\n",
            "2025-05-07 07:53:09,105 - WARNING - Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ OMG/USDT/1h\n",
            "2025-05-07 07:53:09,105 - WARNING - Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ OMG/USDT/1h\n",
            "WARNING:__main__:Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ OMG/USDT/1h\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“¡ Ø±Ø¨Ø§Øª ÙØ¹Ø§Ù„ - Ø¢Ø®Ø±ÛŒÙ† Ø°Ø®ÛŒØ±Ù‡: 07:50:24 - Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§: 680"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-05-07 07:53:29,319 - WARNING - Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ OMG/USDT/4h\n",
            "2025-05-07 07:53:29,319 - WARNING - Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ OMG/USDT/4h\n",
            "2025-05-07 07:53:29,319 - WARNING - Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ OMG/USDT/4h\n",
            "2025-05-07 07:53:29,319 - WARNING - Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ OMG/USDT/4h\n",
            "2025-05-07 07:53:29,319 - WARNING - Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ OMG/USDT/4h\n",
            "2025-05-07 07:53:29,319 - WARNING - Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ OMG/USDT/4h\n",
            "WARNING:__main__:Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ OMG/USDT/4h\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\rğŸ“¡ Ø±Ø¨Ø§Øª ÙØ¹Ø§Ù„ - Ø¢Ø®Ø±ÛŒÙ† Ø°Ø®ÛŒØ±Ù‡: 07:50:24 - Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§: 840\rğŸ“¡ Ø±Ø¨Ø§Øª ÙØ¹Ø§Ù„ - Ø¢Ø®Ø±ÛŒÙ† Ø°Ø®ÛŒØ±Ù‡: 07:50:24 - Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§: 680\rğŸ“¡ Ø±Ø¨Ø§Øª ÙØ¹Ø§Ù„ - Ø¢Ø®Ø±ÛŒÙ† Ø°Ø®ÛŒØ±Ù‡: 07:50:54 - Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§: 692\rğŸ“¡ Ø±Ø¨Ø§Øª ÙØ¹Ø§Ù„ - Ø¢Ø®Ø±ÛŒÙ† Ø°Ø®ÛŒØ±Ù‡: 07:51:49 - Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§: 694\rğŸ“¡ Ø±Ø¨Ø§Øª ÙØ¹Ø§Ù„ - Ø¢Ø®Ø±ÛŒÙ† Ø°Ø®ÛŒØ±Ù‡: 07:52:21 - Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§: 685\rğŸ“¡ Ø±Ø¨Ø§Øª ÙØ¹Ø§Ù„ - Ø¢Ø®Ø±ÛŒÙ† Ø°Ø®ÛŒØ±Ù‡: 07:49:53 - Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§: 689"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-05-07 07:53:42,532 - WARNING - Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ OMG/USDT/1d\n",
            "2025-05-07 07:53:42,532 - WARNING - Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ OMG/USDT/1d\n",
            "2025-05-07 07:53:42,532 - WARNING - Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ OMG/USDT/1d\n",
            "2025-05-07 07:53:42,532 - WARNING - Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ OMG/USDT/1d\n",
            "2025-05-07 07:53:42,532 - WARNING - Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ OMG/USDT/1d\n",
            "2025-05-07 07:53:42,532 - WARNING - Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ OMG/USDT/1d\n",
            "WARNING:__main__:Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ OMG/USDT/1d\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“¡ Ø±Ø¨Ø§Øª ÙØ¹Ø§Ù„ - Ø¢Ø®Ø±ÛŒÙ† Ø°Ø®ÛŒØ±Ù‡: 07:50:24 - Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§: 680"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-05-07 07:54:27,162 - WARNING - Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ SRM/USDT/15m\n",
            "2025-05-07 07:54:27,162 - WARNING - Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ SRM/USDT/15m\n",
            "2025-05-07 07:54:27,162 - WARNING - Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ SRM/USDT/15m\n",
            "2025-05-07 07:54:27,162 - WARNING - Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ SRM/USDT/15m\n",
            "2025-05-07 07:54:27,162 - WARNING - Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ SRM/USDT/15m\n",
            "2025-05-07 07:54:27,162 - WARNING - Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ SRM/USDT/15m\n",
            "WARNING:__main__:Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ SRM/USDT/15m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“¡ Ø±Ø¨Ø§Øª ÙØ¹Ø§Ù„ - Ø¢Ø®Ø±ÛŒÙ† Ø°Ø®ÛŒØ±Ù‡: 07:51:49 - Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§: 694"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-05-07 07:55:14,752 - WARNING - Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ SRM/USDT/1h\n",
            "2025-05-07 07:55:14,752 - WARNING - Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ SRM/USDT/1h\n",
            "2025-05-07 07:55:14,752 - WARNING - Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ SRM/USDT/1h\n",
            "2025-05-07 07:55:14,752 - WARNING - Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ SRM/USDT/1h\n",
            "2025-05-07 07:55:14,752 - WARNING - Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ SRM/USDT/1h\n",
            "2025-05-07 07:55:14,752 - WARNING - Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ SRM/USDT/1h\n",
            "WARNING:__main__:Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ SRM/USDT/1h\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“¡ Ø±Ø¨Ø§Øª ÙØ¹Ø§Ù„ - Ø¢Ø®Ø±ÛŒÙ† Ø°Ø®ÛŒØ±Ù‡: 07:55:33 - Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§: 680"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-05-07 07:55:58,911 - WARNING - Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ SRM/USDT/4h\n",
            "2025-05-07 07:55:58,911 - WARNING - Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ SRM/USDT/4h\n",
            "2025-05-07 07:55:58,911 - WARNING - Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ SRM/USDT/4h\n",
            "2025-05-07 07:55:58,911 - WARNING - Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ SRM/USDT/4h\n",
            "2025-05-07 07:55:58,911 - WARNING - Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ SRM/USDT/4h\n",
            "2025-05-07 07:55:58,911 - WARNING - Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ SRM/USDT/4h\n",
            "WARNING:__main__:Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ SRM/USDT/4h\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“¡ Ø±Ø¨Ø§Øª ÙØ¹Ø§Ù„ - Ø¢Ø®Ø±ÛŒÙ† Ø°Ø®ÛŒØ±Ù‡: 07:52:21 - Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§: 685"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-05-07 07:56:37,671 - WARNING - Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ SRM/USDT/1d\n",
            "2025-05-07 07:56:37,671 - WARNING - Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ SRM/USDT/1d\n",
            "2025-05-07 07:56:37,671 - WARNING - Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ SRM/USDT/1d\n",
            "2025-05-07 07:56:37,671 - WARNING - Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ SRM/USDT/1d\n",
            "2025-05-07 07:56:37,671 - WARNING - Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ SRM/USDT/1d\n",
            "2025-05-07 07:56:37,671 - WARNING - Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ SRM/USDT/1d\n",
            "WARNING:__main__:Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² binance Ø¨Ø±Ø§ÛŒ SRM/USDT/1d\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“¡ Ø±Ø¨Ø§Øª ÙØ¹Ø§Ù„ - Ø¢Ø®Ø±ÛŒÙ† Ø°Ø®ÛŒØ±Ù‡: 08:06:20 - Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§: 692\n",
            "=== Ú¯Ø²Ø§Ø±Ø´ Ø¹Ù…Ù„Ú©Ø±Ø¯ ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§ ===\n",
            "kucoin: Ù†Ø±Ø® Ù…ÙˆÙÙ‚ÛŒØª 99.4%, ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ø¯Ø±Ø®ÙˆØ§Ø³Øª: 538, Ø¯ÙØ¹Ø§Øª Ù…Ø­Ø¯ÙˆØ¯ÛŒØª: 0\n",
            "gate: Ù†Ø±Ø® Ù…ÙˆÙÙ‚ÛŒØª 98.5%, ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ø¯Ø±Ø®ÙˆØ§Ø³Øª: 591, Ø¯ÙØ¹Ø§Øª Ù…Ø­Ø¯ÙˆØ¯ÛŒØª: 0\n",
            "mexc: Ù†Ø±Ø® Ù…ÙˆÙÙ‚ÛŒØª 99.3%, ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ø¯Ø±Ø®ÙˆØ§Ø³Øª: 1085, Ø¯ÙØ¹Ø§Øª Ù…Ø­Ø¯ÙˆØ¯ÛŒØª: 0\n",
            "ğŸ“¡ Ø±Ø¨Ø§Øª ÙØ¹Ø§Ù„ - Ø¢Ø®Ø±ÛŒÙ† Ø°Ø®ÛŒØ±Ù‡: 08:44:31 - Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§: 694"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-05-07 08:47:50,453 - WARNING - Ù…ØµØ±Ù Ø­Ø§ÙØ¸Ù‡ Ø¨Ø§Ù„Ø§ Ø¨Ø¹Ø¯ Ø§Ø² Ú¯Ø±ÙˆÙ‡: 82.0% - Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ\n",
            "2025-05-07 08:47:50,453 - WARNING - Ù…ØµØ±Ù Ø­Ø§ÙØ¸Ù‡ Ø¨Ø§Ù„Ø§ Ø¨Ø¹Ø¯ Ø§Ø² Ú¯Ø±ÙˆÙ‡: 82.0% - Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ\n",
            "2025-05-07 08:47:50,453 - WARNING - Ù…ØµØ±Ù Ø­Ø§ÙØ¸Ù‡ Ø¨Ø§Ù„Ø§ Ø¨Ø¹Ø¯ Ø§Ø² Ú¯Ø±ÙˆÙ‡: 82.0% - Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ\n",
            "2025-05-07 08:47:50,453 - WARNING - Ù…ØµØ±Ù Ø­Ø§ÙØ¸Ù‡ Ø¨Ø§Ù„Ø§ Ø¨Ø¹Ø¯ Ø§Ø² Ú¯Ø±ÙˆÙ‡: 82.0% - Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ\n",
            "2025-05-07 08:47:50,453 - WARNING - Ù…ØµØ±Ù Ø­Ø§ÙØ¸Ù‡ Ø¨Ø§Ù„Ø§ Ø¨Ø¹Ø¯ Ø§Ø² Ú¯Ø±ÙˆÙ‡: 82.0% - Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ\n",
            "2025-05-07 08:47:50,453 - WARNING - Ù…ØµØ±Ù Ø­Ø§ÙØ¸Ù‡ Ø¨Ø§Ù„Ø§ Ø¨Ø¹Ø¯ Ø§Ø² Ú¯Ø±ÙˆÙ‡: 82.0% - Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ\n",
            "WARNING:__main__:Ù…ØµØ±Ù Ø­Ø§ÙØ¸Ù‡ Ø¨Ø§Ù„Ø§ Ø¨Ø¹Ø¯ Ø§Ø² Ú¯Ø±ÙˆÙ‡: 82.0% - Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“¡ Ø±Ø¨Ø§Øª ÙØ¹Ø§Ù„ - Ø¢Ø®Ø±ÛŒÙ† Ø°Ø®ÛŒØ±Ù‡: 08:44:31 - Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§: 694"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPlYZ8ejfJKVlAsUEey6koW",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}