{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNL73NeHMB2wZt5mD5JjNNn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hosseinmiripy/rezume/blob/main/%D9%BE%DB%8C%D8%AF%D8%A7%20%DA%A9%D8%B1%D8%AF%D9%86%20%D8%AA%D8%B1%D9%86%D8%AF%20%D9%87%D8%A7%DB%8C%20%D8%A7%DB%8C%D8%B1%D8%A7%D9%86.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Ø³ÛŒØ³ØªÙ… ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø§Ø± Ø§ÛŒØ±Ø§Ù† - Market Analysis System for Iran\n",
        "Ø·Ø±Ø§Ø­ÛŒ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§ÛŒ Ø±ÙˆØ²Ø§Ù†Ù‡ Ø¯Ø± Google Colab\n",
        "\"\"\"\n",
        "import os\n",
        "os.environ['NUMPY_EXPERIMENTAL_ARRAY_FUNCTION'] = '0'\n",
        "import sys\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# Ø¨Ø®Ø´ 1: Ù†ØµØ¨ Ø§ÛŒÙ…Ù† Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§\n",
        "# ===============================\n",
        "\n",
        "class SafePackageInstaller:\n",
        "    \"\"\"Ù…Ø¯ÛŒØ±ÛŒØª Ù†ØµØ¨ Ø§ÛŒÙ…Ù† Ùˆ Ù…Ù‚Ø§ÙˆÙ… Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.installed_packages = []\n",
        "        self.failed_packages = []\n",
        "\n",
        "    def safe_install(self, package_name, pip_name=None, version=None):\n",
        "        \"\"\"Ù†ØµØ¨ Ø§ÛŒÙ…Ù† Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ Ø¨Ø§ Ù…Ø¯ÛŒØ±ÛŒØª Ø®Ø·Ø§\"\"\"\n",
        "        if pip_name is None:\n",
        "            pip_name = package_name\n",
        "\n",
        "        try:\n",
        "            # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡\n",
        "            __import__(package_name)\n",
        "            print(f\"âœ… {package_name} Ø¯Ø± Ø­Ø§Ù„ Ø­Ø§Ø¶Ø± Ù†ØµØ¨ Ø§Ø³Øª\")\n",
        "            self.installed_packages.append(package_name)\n",
        "            return True\n",
        "        except ImportError:\n",
        "            try:\n",
        "                # Ù†ØµØ¨ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡\n",
        "                install_cmd = f\"{pip_name}\"\n",
        "                if version:\n",
        "                    install_cmd += f\"=={version}\"\n",
        "\n",
        "                print(f\"ğŸ“¦ Ù†ØµØ¨ {package_name}...\")\n",
        "\n",
        "                # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† --no-cache-dir Ùˆ --force-reinstall Ø¨Ø±Ø§ÛŒ Ø­Ù„ Ù…Ø´Ú©Ù„ numpy\n",
        "                result = os.system(f\"pip install --quiet --no-cache-dir --force-reinstall {install_cmd}\")\n",
        "\n",
        "                if result != 0:\n",
        "                    print(f\"âš ï¸ ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯ Ø¨Ø±Ø§ÛŒ Ù†ØµØ¨ {package_name}...\")\n",
        "                    os.system(f\"pip install --quiet --upgrade --no-deps {install_cmd}\")\n",
        "\n",
        "                # ØªØ³Øª Ù†ØµØ¨\n",
        "                __import__(package_name)\n",
        "                print(f\"âœ… {package_name} Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ù†ØµØ¨ Ø´Ø¯\")\n",
        "                self.installed_packages.append(package_name)\n",
        "                return True\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù†ØµØ¨ {package_name}: {str(e)}\")\n",
        "                self.failed_packages.append(package_name)\n",
        "                return False\n",
        "\n",
        "    def install_all_packages(self):\n",
        "        \"\"\"Ù†ØµØ¨ ØªÙ…Ø§Ù… Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²\"\"\"\n",
        "        packages = [\n",
        "            ('pandas', 'pandas'),\n",
        "            ('numpy', 'numpy'),\n",
        "            ('requests', 'requests'),\n",
        "            ('bs4', 'beautifulsoup4'),  # Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡\n",
        "            ('matplotlib', 'matplotlib'),\n",
        "            ('seaborn', 'seaborn'),\n",
        "            ('plotly', 'plotly'),\n",
        "            ('sklearn', 'scikit-learn'),  # Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡\n",
        "            ('textblob', 'textblob'),\n",
        "            ('googletrans', 'googletrans==4.0.0rc1'),\n",
        "            ('persiantools', 'persiantools'),\n",
        "            ('khayyam', 'khayyam'),\n",
        "            ('pytrends', 'pytrends'),\n",
        "            ('telebot', 'pyTelegramBotAPI'),\n",
        "            ('wordcloud', 'wordcloud')\n",
        "            # hazm Ø­Ø°Ù Ø´Ø¯Ù‡ ØªØ§ Ù…Ø´Ú©Ù„ numpy Ø­Ù„ Ø´ÙˆØ¯\n",
        "        ]\n",
        "\n",
        "        print(\"ğŸš€ Ø´Ø±ÙˆØ¹ Ù†ØµØ¨ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§...\")\n",
        "\n",
        "        # Ø§Ø¨ØªØ¯Ø§ numpy Ø±Ø§ Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ú©Ù†ÛŒÙ…\n",
        "        print(\"ğŸ”§ Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ numpy...\")\n",
        "        os.system(\"pip install --quiet --upgrade numpy\")\n",
        "\n",
        "        for package_name, pip_name in packages:\n",
        "            self.safe_install(package_name, pip_name)\n",
        "\n",
        "        print(f\"\\nğŸ“Š Ø®Ù„Ø§ØµÙ‡ Ù†ØµØ¨:\")\n",
        "        print(f\"âœ… Ù†ØµØ¨ Ø´Ø¯Ù‡: {len(self.installed_packages)}\")\n",
        "        print(f\"âŒ Ù†Ø§Ù…ÙˆÙÙ‚: {len(self.failed_packages)}\")\n",
        "\n",
        "        if self.failed_packages:\n",
        "            print(f\"âš ï¸ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ù…ÙˆÙÙ‚: {', '.join(self.failed_packages)}\")\n",
        "\n",
        "# Ù†ØµØ¨ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§\n",
        "installer = SafePackageInstaller()\n",
        "installer.install_all_packages()\n",
        "\n",
        "# ===============================\n",
        "# Ø¨Ø®Ø´ 2: Import Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§\n",
        "# ===============================\n",
        "\n",
        "# Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø§ÛŒÙ‡\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import datetime\n",
        "from datetime import datetime, timedelta\n",
        "import time\n",
        "import random\n",
        "import re\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "# Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡\n",
        "try:\n",
        "    from sklearn.cluster import KMeans\n",
        "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "    SKLEARN_AVAILABLE = True\n",
        "except ImportError:\n",
        "    SKLEARN_AVAILABLE = False\n",
        "    print(\"âš ï¸ scikit-learn Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª - ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ ØºÛŒØ±ÙØ¹Ø§Ù„ Ø´Ø¯\")\n",
        "\n",
        "# Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ±Ø³ÛŒÙ… Ù†Ù…ÙˆØ¯Ø§Ø±\n",
        "# Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ±Ø³ÛŒÙ… Ù†Ù…ÙˆØ¯Ø§Ø±\n",
        "try:\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "\n",
        "    plt.style.use('default')\n",
        "    MATPLOTLIB_AVAILABLE = True\n",
        "except ImportError:\n",
        "    MATPLOTLIB_AVAILABLE = False\n",
        "    print(\"âš ï¸ matplotlib Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª - Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§ ØºÛŒØ±ÙØ¹Ø§Ù„ Ø´Ø¯\")\n",
        "\n",
        "# Ø§ØµÙ„Ø§Ø­ import plotly\n",
        "try:\n",
        "    # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ import Ù‚Ø¯ÛŒÙ…ÛŒ\n",
        "    import plotly.graph_objects as go\n",
        "\n",
        "    # Ø¯Ø± ØµÙˆØ±Øª Ù…Ø´Ú©Ù„ Ø¨Ø§ plotly.expressØŒ Ø§Ø² Ø±ÙˆØ´ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒÙ…\n",
        "    try:\n",
        "        import plotly.express as px\n",
        "    except RuntimeError:\n",
        "        print(\"âš ï¸ Ù…Ø´Ú©Ù„ Ø¯Ø± plotly.express - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² graph_objects\")\n",
        "        px = None\n",
        "\n",
        "    PLOTLY_AVAILABLE = True\n",
        "except ImportError:\n",
        "    PLOTLY_AVAILABLE = False\n",
        "    px = None\n",
        "    go = None\n",
        "    print(\"âš ï¸ plotly Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª - Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§ÛŒ ØªØ¹Ø§Ù…Ù„ÛŒ ØºÛŒØ±ÙØ¹Ø§Ù„ Ø´Ø¯\")\n",
        "except RuntimeError as e:\n",
        "    print(f\"âš ï¸ Ù…Ø´Ú©Ù„ plotly: {str(e)} - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…Ø­Ø¯ÙˆØ¯\")\n",
        "    PLOTLY_AVAILABLE = False\n",
        "    px = None\n",
        "    go = None\n",
        "\n",
        "# Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡\n",
        "import requests\n",
        "\n",
        "try:\n",
        "    from bs4 import BeautifulSoup\n",
        "\n",
        "    BS4_AVAILABLE = True\n",
        "except ImportError:\n",
        "    BS4_AVAILABLE = False\n",
        "    print(\"âš ï¸ BeautifulSoup Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª - Ú©Ø±Ø§ÙˆÙ„ÛŒÙ†Ú¯ ÙˆØ¨ ØºÛŒØ±ÙØ¹Ø§Ù„ Ø´Ø¯\")\n",
        "\n",
        "try:\n",
        "    from pytrends.request import TrendReq\n",
        "\n",
        "    PYTRENDS_AVAILABLE = True\n",
        "except ImportError:\n",
        "    PYTRENDS_AVAILABLE = False\n",
        "    print(\"âš ï¸ pytrends Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª - Google Trends ØºÛŒØ±ÙØ¹Ø§Ù„ Ø´Ø¯\")\n",
        "\n",
        "# Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ØªÙ† ÙØ§Ø±Ø³ÛŒ\n",
        "try:\n",
        "    from textblob import TextBlob\n",
        "    from googletrans import Translator\n",
        "\n",
        "    TEXT_PROCESSING_AVAILABLE = True\n",
        "except ImportError:\n",
        "    TEXT_PROCESSING_AVAILABLE = False\n",
        "    print(\"âš ï¸ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ØªÙ† Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª\")\n",
        "\n",
        "try:\n",
        "    import telebot\n",
        "\n",
        "    TELEGRAM_AVAILABLE = True\n",
        "except ImportError:\n",
        "    TELEGRAM_AVAILABLE = False\n",
        "    print(\"âš ï¸ telegram bot Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª - Ø§Ø±Ø³Ø§Ù„ Ú¯Ø²Ø§Ø±Ø´ ØºÛŒØ±ÙØ¹Ø§Ù„ Ø´Ø¯\")\n",
        "\n",
        "# Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ§Ø±ÛŒØ® ÙØ§Ø±Ø³ÛŒ\n",
        "try:\n",
        "    import khayyam\n",
        "\n",
        "    PERSIAN_DATE_AVAILABLE = True\n",
        "except ImportError:\n",
        "    PERSIAN_DATE_AVAILABLE = False\n",
        "    print(\"âš ï¸ ØªØ§Ø±ÛŒØ® ÙØ§Ø±Ø³ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª - Ø§Ø² ØªØ§Ø±ÛŒØ® Ù…ÛŒÙ„Ø§Ø¯ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯\")\n",
        "\n",
        "\n",
        "class PersianTextProcessor:\n",
        "    \"\"\"Ù¾Ø±Ø¯Ø§Ø²Ø´â€ŒÚ©Ù†Ù†Ø¯Ù‡ Ø³Ø§Ø¯Ù‡ Ù…ØªÙ† ÙØ§Ø±Ø³ÛŒ (Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† hazm)\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def clean_persian_text(text):\n",
        "        \"\"\"Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ Ø³Ø§Ø¯Ù‡ Ù…ØªÙ† ÙØ§Ø±Ø³ÛŒ\"\"\"\n",
        "        if not text:\n",
        "            return text\n",
        "\n",
        "        # Ø­Ø°Ù Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ\n",
        "        text = re.sub(r'[^\\u0600-\\u06FF\\u0750-\\u077F\\u08A0-\\u08FF\\uFB50-\\uFDFF\\uFE70-\\uFEFF\\s\\d\\w]', '', text)\n",
        "\n",
        "        # ÛŒÚ©ÛŒ Ú©Ø±Ø¯Ù† ÙØ§ØµÙ„Ù‡â€ŒÙ‡Ø§\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "\n",
        "        return text.strip()\n",
        "\n",
        "    @staticmethod\n",
        "    def extract_keywords(text, max_keywords=10):\n",
        "        \"\"\"Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡â€ŒÙ‡Ø§ÛŒ Ø³Ø§Ø¯Ù‡\"\"\"\n",
        "        if not text:\n",
        "            return []\n",
        "\n",
        "        # ØªÙ‚Ø³ÛŒÙ… Ø¨Ù‡ Ú©Ù„Ù…Ø§Øª\n",
        "        words = text.split()\n",
        "\n",
        "        # ÙÛŒÙ„ØªØ± Ú©Ù„Ù…Ø§Øª (Ø­Ø¯Ø§Ù‚Ù„ 3 Ú©Ø§Ø±Ø§Ú©ØªØ±)\n",
        "        words = [w for w in words if len(w) >= 3]\n",
        "\n",
        "        # Ø´Ù…Ø§Ø±Ø´ ÙØ±Ø§ÙˆØ§Ù†ÛŒ\n",
        "        word_count = Counter(words)\n",
        "\n",
        "        # Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù† Ù¾Ø±ØªÚ©Ø±Ø§Ø±ØªØ±ÛŒÙ† Ú©Ù„Ù…Ø§Øª\n",
        "        return [word for word, count in word_count.most_common(max_keywords)]\n",
        "# ===============================\n",
        "# Ø¨Ø®Ø´ 3: ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ØµÙ„ÛŒ\n",
        "# ===============================\n",
        "\n",
        "class Config:\n",
        "    \"\"\"ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø³ÛŒØ³ØªÙ…\"\"\"\n",
        "\n",
        "    # ØªÙ†Ø¸ÛŒÙ…Ø§Øª ØªÙ„Ú¯Ø±Ø§Ù… (Ø¨Ø§ÛŒØ¯ ØªÙˆØ³Ø· Ú©Ø§Ø±Ø¨Ø± ØªÚ©Ù…ÛŒÙ„ Ø´ÙˆØ¯)\n",
        "    TELEGRAM_BOT_TOKEN = \"7962358346:AAHxMMHpgKfNZ8eUnvwKALDnct5eoXxqr6s\"  # ØªÙˆÚ©Ù† Ø±Ø¨Ø§Øª ØªÙ„Ú¯Ø±Ø§Ù…\n",
        "    TELEGRAM_CHAT_ID = \"@andisharia_backup\"  # Ø´Ù†Ø§Ø³Ù‡ Ú†Øª\n",
        "\n",
        "    # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¹Ù…ÙˆÙ…ÛŒ\n",
        "    MAX_RETRIES = 3\n",
        "    REQUEST_DELAY = 2  # ØªØ§Ø®ÛŒØ± Ø¨ÛŒÙ† Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§ (Ø«Ø§Ù†ÛŒÙ‡)\n",
        "\n",
        "    # Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø§ÛŒÙ‡ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø§Ø± Ø§ÛŒØ±Ø§Ù†\n",
        "    IRAN_KEYWORDS = [\n",
        "        'Ù…ÙˆØ¨Ø§ÛŒÙ„', 'Ú¯ÙˆØ´ÛŒ', 'Ù„Ù¾ ØªØ§Ù¾', 'Ú©Ø§Ù…Ù¾ÛŒÙˆØªØ±', 'ØªØ¨Ù„Øª',\n",
        "        'Ù„Ø¨Ø§Ø³', 'Ú©ÙØ´', 'Ú©ÛŒÙ', 'Ø³Ø§Ø¹Øª', 'Ø¹Ø·Ø±',\n",
        "        'Ú©ØªØ§Ø¨', 'ÙÛŒÙ„Ù…', 'Ø¨Ø§Ø²ÛŒ', 'Ù…ÙˆØ³ÛŒÙ‚ÛŒ',\n",
        "        'ØºØ°Ø§', 'Ø±Ø³ØªÙˆØ±Ø§Ù†', 'Ø¢Ø´Ù¾Ø²ÛŒ', 'Ù†Ø§Ù†',\n",
        "        'Ø®Ø§Ù†Ù‡', 'Ø§Ø«Ø§Ø«ÛŒÙ‡', 'Ø¯Ú©ÙˆØ±Ø§Ø³ÛŒÙˆÙ†', 'Ø¢Ø´Ù¾Ø²Ø®Ø§Ù†Ù‡',\n",
        "        'Ù…Ø§Ø´ÛŒÙ†', 'Ø®ÙˆØ¯Ø±Ùˆ', 'Ù…ÙˆØªÙˆØ±', 'Ø¯ÙˆÚ†Ø±Ø®Ù‡',\n",
        "        'Ø³Ù„Ø§Ù…Øª', 'Ø¯Ø§Ø±Ùˆ', 'ÙˆØ±Ø²Ø´', 'ØªÙ†Ø§Ø³Ø¨ Ø§Ù†Ø¯Ø§Ù…',\n",
        "        'Ø¢Ø±Ø§ÛŒØ´', 'Ø²ÛŒØ¨Ø§ÛŒÛŒ', 'Ù…Ø±Ø§Ù‚Ø¨Øª Ù¾ÙˆØ³Øª',\n",
        "        'Ø³ÙØ±', 'Ú¯Ø±Ø¯Ø´Ú¯Ø±ÛŒ', 'Ù‡ØªÙ„', 'Ø¨Ù„ÛŒØ·',\n",
        "        'ØªØ­ØµÛŒÙ„', 'Ú©ÙˆØ±Ø³', 'Ø²Ø¨Ø§Ù†', 'Ù…Ù‡Ø§Ø±Øª'\n",
        "    ]\n",
        "\n",
        "    # Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ\n",
        "    CATEGORIES = {\n",
        "        'ØªÚ©Ù†ÙˆÙ„ÙˆÚ˜ÛŒ': ['Ù…ÙˆØ¨Ø§ÛŒÙ„', 'Ú¯ÙˆØ´ÛŒ', 'Ù„Ù¾ ØªØ§Ù¾', 'Ú©Ø§Ù…Ù¾ÛŒÙˆØªØ±', 'ØªØ¨Ù„Øª', 'Ù‡Ø¯ÙÙˆÙ†'],\n",
        "        'Ù¾ÙˆØ´Ø§Ú©': ['Ù„Ø¨Ø§Ø³', 'Ú©ÙØ´', 'Ú©ÛŒÙ', 'Ø³Ø§Ø¹Øª'],\n",
        "        'Ø²ÛŒØ¨Ø§ÛŒÛŒ': ['Ø¢Ø±Ø§ÛŒØ´', 'Ø¹Ø·Ø±', 'Ù…Ø±Ø§Ù‚Ø¨Øª Ù¾ÙˆØ³Øª', 'Ø²ÛŒØ¨Ø§ÛŒÛŒ'],\n",
        "        'Ø®Ø§Ù†Ù‡': ['Ø§Ø«Ø§Ø«ÛŒÙ‡', 'Ø¯Ú©ÙˆØ±Ø§Ø³ÛŒÙˆÙ†', 'Ø¢Ø´Ù¾Ø²Ø®Ø§Ù†Ù‡', 'Ø®Ø§Ù†Ù‡'],\n",
        "        'Ø®ÙˆØ¯Ø±Ùˆ': ['Ù…Ø§Ø´ÛŒÙ†', 'Ø®ÙˆØ¯Ø±Ùˆ', 'Ù…ÙˆØªÙˆØ±', 'Ø¯ÙˆÚ†Ø±Ø®Ù‡'],\n",
        "        'Ø³Ù„Ø§Ù…Øª': ['Ø³Ù„Ø§Ù…Øª', 'Ø¯Ø§Ø±Ùˆ', 'ÙˆØ±Ø²Ø´', 'ØªÙ†Ø§Ø³Ø¨ Ø§Ù†Ø¯Ø§Ù…'],\n",
        "        'Ø³Ø±Ú¯Ø±Ù…ÛŒ': ['Ú©ØªØ§Ø¨', 'ÙÛŒÙ„Ù…', 'Ø¨Ø§Ø²ÛŒ', 'Ù…ÙˆØ³ÛŒÙ‚ÛŒ'],\n",
        "        'ØºØ°Ø§': ['ØºØ°Ø§', 'Ø±Ø³ØªÙˆØ±Ø§Ù†', 'Ø¢Ø´Ù¾Ø²ÛŒ'],\n",
        "        'Ø³ÙØ±': ['Ø³ÙØ±', 'Ú¯Ø±Ø¯Ø´Ú¯Ø±ÛŒ', 'Ù‡ØªÙ„'],\n",
        "        'Ø¢Ù…ÙˆØ²Ø´': ['ØªØ­ØµÛŒÙ„', 'Ú©ÙˆØ±Ø³', 'Ø²Ø¨Ø§Ù†', 'Ù…Ù‡Ø§Ø±Øª']\n",
        "    }\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# Ø¨Ø®Ø´ 4: Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ Ø³ÛŒØ³ØªÙ…\n",
        "# ===============================\n",
        "\n",
        "class PersianDateHelper:\n",
        "    \"\"\"Ú©Ù…Ú©â€ŒÚ©Ù†Ù†Ø¯Ù‡ ØªØ§Ø±ÛŒØ® ÙØ§Ø±Ø³ÛŒ\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def get_persian_date():\n",
        "        \"\"\"Ø¯Ø±ÛŒØ§ÙØª ØªØ§Ø±ÛŒØ® ÙØ§Ø±Ø³ÛŒ\"\"\"\n",
        "        if PERSIAN_DATE_AVAILABLE:\n",
        "            return khayyam.JalaliDatetime.now().strftime('%Y/%m/%d')\n",
        "        else:\n",
        "            return datetime.now().strftime('%Y/%m/%d')\n",
        "\n",
        "    @staticmethod\n",
        "    def get_persian_datetime():\n",
        "        \"\"\"Ø¯Ø±ÛŒØ§ÙØª ØªØ§Ø±ÛŒØ® Ùˆ Ø²Ù…Ø§Ù† ÙØ§Ø±Ø³ÛŒ\"\"\"\n",
        "        if PERSIAN_DATE_AVAILABLE:\n",
        "            return khayyam.JalaliDatetime.now().strftime('%Y/%m/%d - %H:%M')\n",
        "        else:\n",
        "            return datetime.now().strftime('%Y/%m/%d - %H:%M')\n",
        "\n",
        "\n",
        "class DataIngestion:\n",
        "    \"\"\"Ø¯Ø±ÛŒØ§ÙØª Ùˆ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.trends_data = {}\n",
        "        self.products_data = []\n",
        "        self.session = requests.Session()\n",
        "\n",
        "        # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Google Trends\n",
        "        if PYTRENDS_AVAILABLE:\n",
        "            try:\n",
        "                self.pytrends = TrendReq(hl='fa-IR', tz=210)\n",
        "            except:\n",
        "                self.pytrends = None\n",
        "                print(\"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø§ØªØµØ§Ù„ Ø¨Ù‡ Google Trends\")\n",
        "        else:\n",
        "            self.pytrends = None\n",
        "\n",
        "    def get_google_trends(self, keywords, timeframe='today 7-d'):\n",
        "        \"\"\"Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Google Trends\"\"\"\n",
        "        if not self.pytrends or not keywords:\n",
        "            return {}\n",
        "\n",
        "        trends_data = {}\n",
        "\n",
        "        try:\n",
        "            # ØªÙ‚Ø³ÛŒÙ… Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡â€ŒÙ‡Ø§ Ø¨Ù‡ Ú¯Ø±ÙˆÙ‡â€ŒÙ‡Ø§ÛŒ 5 ØªØ§ÛŒÛŒ (Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Google)\n",
        "            for i in range(0, len(keywords), 5):\n",
        "                keyword_batch = keywords[i:i + 5]\n",
        "\n",
        "                try:\n",
        "                    self.pytrends.build_payload(\n",
        "                        keyword_batch,\n",
        "                        cat=0,\n",
        "                        timeframe=timeframe,\n",
        "                        geo='IR'  # Ø§ÛŒØ±Ø§Ù†\n",
        "                    )\n",
        "\n",
        "                    # Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ±Ù†Ø¯\n",
        "                    interest_over_time = self.pytrends.interest_over_time()\n",
        "\n",
        "                    if not interest_over_time.empty:\n",
        "                        for keyword in keyword_batch:\n",
        "                            if keyword in interest_over_time.columns:\n",
        "                                trends_data[keyword] = {\n",
        "                                    'current_score': interest_over_time[keyword].iloc[-1],\n",
        "                                    'avg_score': interest_over_time[keyword].mean(),\n",
        "                                    'trend_direction': self._calculate_trend_direction(interest_over_time[keyword]),\n",
        "                                    'data': interest_over_time[keyword].tolist()\n",
        "                                }\n",
        "\n",
        "                    time.sleep(Config.REQUEST_DELAY)  # ØªØ§Ø®ÛŒØ± Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ù…Ø­Ø¯ÙˆØ¯ÛŒØª\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ØªØ±Ù†Ø¯ Ø¨Ø±Ø§ÛŒ {keyword_batch}: {str(e)}\")\n",
        "                    continue\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Ø®Ø·Ø§ÛŒ Ú©Ù„ÛŒ Ø¯Ø± Google Trends: {str(e)}\")\n",
        "\n",
        "        return trends_data\n",
        "\n",
        "    def _calculate_trend_direction(self, data_series):\n",
        "        \"\"\"Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¬Ù‡Øª ØªØ±Ù†Ø¯ (ØµØ¹ÙˆØ¯ÛŒØŒ Ù†Ø²ÙˆÙ„ÛŒØŒ Ø«Ø§Ø¨Øª)\"\"\"\n",
        "        if len(data_series) < 2:\n",
        "            return 'Ø«Ø§Ø¨Øª'\n",
        "\n",
        "        recent_avg = data_series.tail(3).mean()\n",
        "        older_avg = data_series.head(3).mean()\n",
        "\n",
        "        if recent_avg > older_avg * 1.2:\n",
        "            return 'ØµØ¹ÙˆØ¯ÛŒ'\n",
        "        elif recent_avg < older_avg * 0.8:\n",
        "            return 'Ù†Ø²ÙˆÙ„ÛŒ'\n",
        "        else:\n",
        "            return 'Ø«Ø§Ø¨Øª'\n",
        "\n",
        "    def simulate_digikala_data(self):\n",
        "        \"\"\"Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¯ÛŒØ¬ÛŒâ€ŒÚ©Ø§Ù„Ø§ (ØªØ§ Ø²Ù…Ø§Ù† Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ API ÙˆØ§Ù‚Ø¹ÛŒ)\"\"\"\n",
        "        categories = list(Config.CATEGORIES.keys())\n",
        "        products = []\n",
        "\n",
        "        for category in categories:\n",
        "            for i in range(5):  # 5 Ù…Ø­ØµÙˆÙ„ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø¯Ø³ØªÙ‡\n",
        "                product = {\n",
        "                    'name': f\"Ù…Ø­ØµÙˆÙ„ {i + 1} {category}\",\n",
        "                    'category': category,\n",
        "                    'price': random.randint(100000, 5000000),\n",
        "                    'rating': round(random.uniform(3.0, 5.0), 1),\n",
        "                    'sales_count': random.randint(100, 10000),\n",
        "                    'trend_score': random.randint(50, 100)\n",
        "                }\n",
        "                products.append(product)\n",
        "\n",
        "        return products\n",
        "\n",
        "    def collect_all_data(self):\n",
        "        \"\"\"Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ ØªÙ…Ø§Ù… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§\"\"\"\n",
        "        print(\"ğŸ“Š Ø´Ø±ÙˆØ¹ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§...\")\n",
        "\n",
        "        # Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Google Trends\n",
        "        print(\"ğŸ” Ø¯Ø±ÛŒØ§ÙØª Google Trends...\")\n",
        "        self.trends_data = self.get_google_trends(Config.IRAN_KEYWORDS)\n",
        "\n",
        "        # Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª\n",
        "        print(\"ğŸ›’ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª...\")\n",
        "        self.products_data = self.simulate_digikala_data()\n",
        "\n",
        "        print(f\"âœ… Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯:\")\n",
        "        print(f\"   - {len(self.trends_data)} Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡ ØªØ±Ù†Ø¯\")\n",
        "        print(f\"   - {len(self.products_data)} Ù…Ø­ØµÙˆÙ„\")\n",
        "\n",
        "        return {\n",
        "            'trends': self.trends_data,\n",
        "            'products': self.products_data,\n",
        "            'timestamp': datetime.now()\n",
        "        }\n",
        "\n",
        "\n",
        "class MarketAnalyzer:\n",
        "    \"\"\"ØªØ­Ù„ÛŒÙ„â€ŒÚ¯Ø± Ø¨Ø§Ø²Ø§Ø±\"\"\"\n",
        "\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "        self.analysis_results = {}\n",
        "\n",
        "    def analyze_trends(self):\n",
        "        \"\"\"ØªØ­Ù„ÛŒÙ„ ØªØ±Ù†Ø¯Ù‡Ø§\"\"\"\n",
        "        trends = self.data.get('trends', {})\n",
        "\n",
        "        # Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ ØªØ±Ù†Ø¯Ù‡Ø§\n",
        "        hot_trends = []  # ØªØ±Ù†Ø¯Ù‡Ø§ÛŒ Ø¯Ø§Øº\n",
        "        rising_trends = []  # ØªØ±Ù†Ø¯Ù‡Ø§ÛŒ ØµØ¹ÙˆØ¯ÛŒ\n",
        "        falling_trends = []  # ØªØ±Ù†Ø¯Ù‡Ø§ÛŒ Ù†Ø²ÙˆÙ„ÛŒ\n",
        "\n",
        "        for keyword, trend_data in trends.items():\n",
        "            score = trend_data.get('current_score', 0)\n",
        "            direction = trend_data.get('trend_direction', 'Ø«Ø§Ø¨Øª')\n",
        "\n",
        "            if score > 80:\n",
        "                hot_trends.append((keyword, score))\n",
        "\n",
        "            if direction == 'ØµØ¹ÙˆØ¯ÛŒ':\n",
        "                rising_trends.append((keyword, score))\n",
        "            elif direction == 'Ù†Ø²ÙˆÙ„ÛŒ':\n",
        "                falling_trends.append((keyword, score))\n",
        "\n",
        "        # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ù…ØªÛŒØ§Ø²\n",
        "        hot_trends = sorted(hot_trends, key=lambda x: x[1], reverse=True)[:10]\n",
        "        rising_trends = sorted(rising_trends, key=lambda x: x[1], reverse=True)[:10]\n",
        "        falling_trends = sorted(falling_trends, key=lambda x: x[1], reverse=True)[:10]\n",
        "\n",
        "        return {\n",
        "            'hot_trends': hot_trends,\n",
        "            'rising_trends': rising_trends,\n",
        "            'falling_trends': falling_trends,\n",
        "            'total_keywords': len(trends)\n",
        "        }\n",
        "\n",
        "    def analyze_categories(self):\n",
        "        \"\"\"ØªØ­Ù„ÛŒÙ„ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§\"\"\"\n",
        "        trends = self.data.get('trends', {})\n",
        "        products = self.data.get('products', [])\n",
        "\n",
        "        category_analysis = {}\n",
        "\n",
        "        for category, keywords in Config.CATEGORIES.items():\n",
        "            # ØªØ­Ù„ÛŒÙ„ ØªØ±Ù†Ø¯ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ\n",
        "            category_trends = []\n",
        "            for keyword in keywords:\n",
        "                if keyword in trends:\n",
        "                    category_trends.append(trends[keyword]['current_score'])\n",
        "\n",
        "            # ØªØ­Ù„ÛŒÙ„ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ\n",
        "            category_products = [p for p in products if p['category'] == category]\n",
        "\n",
        "            avg_trend_score = np.mean(category_trends) if category_trends else 0\n",
        "            avg_product_rating = np.mean([p['rating'] for p in category_products]) if category_products else 0\n",
        "            total_sales = sum([p['sales_count'] for p in category_products])\n",
        "\n",
        "            category_analysis[category] = {\n",
        "                'trend_score': round(avg_trend_score, 2),\n",
        "                'product_rating': round(avg_product_rating, 2),\n",
        "                'total_sales': total_sales,\n",
        "                'product_count': len(category_products),\n",
        "                'status': self._get_category_status(avg_trend_score)\n",
        "            }\n",
        "\n",
        "        return category_analysis\n",
        "\n",
        "    def _get_category_status(self, score):\n",
        "        \"\"\"ØªØ¹ÛŒÛŒÙ† ÙˆØ¶Ø¹ÛŒØª Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ\"\"\"\n",
        "        if score > 70:\n",
        "            return 'Ø¹Ø§Ù„ÛŒ'\n",
        "        elif score > 50:\n",
        "            return 'Ø®ÙˆØ¨'\n",
        "        elif score > 30:\n",
        "            return 'Ù…ØªÙˆØ³Ø·'\n",
        "        else:\n",
        "            return 'Ø¶Ø¹ÛŒÙ'\n",
        "\n",
        "    def predict_opportunities(self):\n",
        "        \"\"\"Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ ÙØ±ØµØªâ€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø²Ø§Ø±\"\"\"\n",
        "        trends_analysis = self.analyze_trends()\n",
        "        category_analysis = self.analyze_categories()\n",
        "\n",
        "        opportunities = []\n",
        "\n",
        "        # ÙØ±ØµØªâ€ŒÙ‡Ø§ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ±Ù†Ø¯Ù‡Ø§ÛŒ ØµØ¹ÙˆØ¯ÛŒ\n",
        "        for keyword, score in trends_analysis['rising_trends'][:5]:\n",
        "            opportunities.append({\n",
        "                'type': 'ØªØ±Ù†Ø¯ ØµØ¹ÙˆØ¯ÛŒ',\n",
        "                'keyword': keyword,\n",
        "                'score': score,\n",
        "                'recommendation': f'Ø³Ø±Ù…Ø§ÛŒÙ‡â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ø±ÙˆÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª Ù…Ø±ØªØ¨Ø· Ø¨Ø§ \"{keyword}\" ØªÙˆØµÛŒÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯'\n",
        "            })\n",
        "\n",
        "        # ÙØ±ØµØªâ€ŒÙ‡Ø§ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù‚ÙˆÛŒ\n",
        "        strong_categories = [(cat, data) for cat, data in category_analysis.items()\n",
        "                             if data['trend_score'] > 60 and data['status'] in ['Ø¹Ø§Ù„ÛŒ', 'Ø®ÙˆØ¨']]\n",
        "\n",
        "        for category, data in strong_categories[:3]:\n",
        "            opportunities.append({\n",
        "                'type': 'Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ù‚ÙˆÛŒ',\n",
        "                'keyword': category,\n",
        "                'score': data['trend_score'],\n",
        "                'recommendation': f'ØªÙˆØ³Ø¹Ù‡ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¯Ø± Ø¯Ø³ØªÙ‡ \"{category}\" Ø¨Ø§Ø²Ø§Ø± Ù…Ù†Ø§Ø³Ø¨ÛŒ Ø¯Ø§Ø±Ø¯'\n",
        "            })\n",
        "\n",
        "        return opportunities\n",
        "\n",
        "    def run_full_analysis(self):\n",
        "        \"\"\"Ø§Ø¬Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„\"\"\"\n",
        "        print(\"ğŸ§  Ø´Ø±ÙˆØ¹ ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø§Ø±...\")\n",
        "\n",
        "        self.analysis_results = {\n",
        "            'trends_analysis': self.analyze_trends(),\n",
        "            'category_analysis': self.analyze_categories(),\n",
        "            'opportunities': self.predict_opportunities(),\n",
        "            'analysis_timestamp': datetime.now()\n",
        "        }\n",
        "\n",
        "        print(\"âœ… ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø§Ø± ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯\")\n",
        "        return self.analysis_results\n",
        "\n",
        "\n",
        "class ReportGenerator:\n",
        "    \"\"\"ØªÙˆÙ„ÛŒØ¯Ú©Ù†Ù†Ø¯Ù‡ Ú¯Ø²Ø§Ø±Ø´\"\"\"\n",
        "\n",
        "    def __init__(self, analysis_results):\n",
        "        self.analysis = analysis_results\n",
        "        self.persian_date = PersianDateHelper.get_persian_datetime()\n",
        "\n",
        "    def generate_daily_report(self):\n",
        "        \"\"\"ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ Ø±ÙˆØ²Ø§Ù†Ù‡\"\"\"\n",
        "        trends = self.analysis.get('trends_analysis', {})\n",
        "        categories = self.analysis.get('category_analysis', {})\n",
        "        opportunities = self.analysis.get('opportunities', [])\n",
        "\n",
        "        report = f\"\"\"\n",
        "ğŸ”¥ Ú¯Ø²Ø§Ø±Ø´ Ø±ÙˆØ²Ø§Ù†Ù‡ Ø¨Ø§Ø²Ø§Ø± Ø§ÛŒØ±Ø§Ù†\n",
        "ğŸ“… ØªØ§Ø±ÛŒØ®: {self.persian_date}\n",
        "\n",
        "ğŸ“ˆ ØªØ±Ù†Ø¯Ù‡Ø§ÛŒ Ø¯Ø§Øº Ø§Ù…Ø±ÙˆØ²:\n",
        "\"\"\"\n",
        "\n",
        "        # ØªØ±Ù†Ø¯Ù‡Ø§ÛŒ Ø¯Ø§Øº\n",
        "        hot_trends = trends.get('hot_trends', [])[:5]\n",
        "        for i, (keyword, score) in enumerate(hot_trends, 1):\n",
        "            report += f\"{i}. {keyword} (Ø§Ù…ØªÛŒØ§Ø²: {score})\\n\"\n",
        "\n",
        "        report += f\"\\nğŸš€ ØªØ±Ù†Ø¯Ù‡Ø§ÛŒ Ø¯Ø± Ø­Ø§Ù„ Ø±Ø´Ø¯:\\n\"\n",
        "\n",
        "        # ØªØ±Ù†Ø¯Ù‡Ø§ÛŒ ØµØ¹ÙˆØ¯ÛŒ\n",
        "        rising_trends = trends.get('rising_trends', [])[:5]\n",
        "        for i, (keyword, score) in enumerate(rising_trends, 1):\n",
        "            report += f\"{i}. {keyword} (Ø§Ù…ØªÛŒØ§Ø²: {score})\\n\"\n",
        "\n",
        "        report += f\"\\nğŸ“Š ÙˆØ¶Ø¹ÛŒØª Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§:\\n\"\n",
        "\n",
        "        # Ø¨Ù‡ØªØ±ÛŒÙ† Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§\n",
        "        sorted_categories = sorted(categories.items(),\n",
        "                                   key=lambda x: x[1]['trend_score'], reverse=True)[:5]\n",
        "\n",
        "        for category, data in sorted_categories:\n",
        "            status_emoji = 'ğŸŸ¢' if data['status'] == 'Ø¹Ø§Ù„ÛŒ' else 'ğŸŸ¡' if data['status'] == 'Ø®ÙˆØ¨' else 'ğŸŸ '\n",
        "            report += f\"{status_emoji} {category}: {data['trend_score']} ({data['status']})\\n\"\n",
        "\n",
        "        report += f\"\\nğŸ’¡ ÙØ±ØµØªâ€ŒÙ‡Ø§ÛŒ Ø§Ù…Ø±ÙˆØ²:\\n\"\n",
        "\n",
        "        # ÙØ±ØµØªâ€ŒÙ‡Ø§\n",
        "        for i, opp in enumerate(opportunities[:3], 1):\n",
        "            report += f\"{i}. {opp['recommendation']}\\n\"\n",
        "\n",
        "        report += f\"\\nğŸ“‹ Ø®Ù„Ø§ØµÙ‡ Ø¢Ù…Ø§Ø±:\\n\"\n",
        "        report += f\"â€¢ ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ Ø´Ø¯Ù‡: {trends.get('total_keywords', 0)}\\n\"\n",
        "        report += f\"â€¢ ØªØ¹Ø¯Ø§Ø¯ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ÛŒ ÙØ¹Ø§Ù„: {len([c for c in categories.values() if c['trend_score'] > 30])}\\n\"\n",
        "        report += f\"â€¢ ØªØ¹Ø¯Ø§Ø¯ ÙØ±ØµØªâ€ŒÙ‡Ø§ÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯Ù‡: {len(opportunities)}\\n\"\n",
        "\n",
        "        return report\n",
        "\n",
        "    def generate_weekly_report(self):\n",
        "        \"\"\"ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ Ù‡ÙØªÚ¯ÛŒ\"\"\"\n",
        "        # Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø¯Ú¯ÛŒØŒ Ø§Ø² Ú¯Ø²Ø§Ø±Ø´ Ø±ÙˆØ²Ø§Ù†Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…\n",
        "        # Ø¯Ø± Ù†Ø³Ø®Ù‡ Ú©Ø§Ù…Ù„ØŒ Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø®ÙˆØ§Ù‡Ø¯ Ø´Ø¯\n",
        "        daily_report = self.generate_daily_report()\n",
        "\n",
        "        weekly_report = daily_report.replace('Ú¯Ø²Ø§Ø±Ø´ Ø±ÙˆØ²Ø§Ù†Ù‡', 'Ú¯Ø²Ø§Ø±Ø´ Ù‡ÙØªÚ¯ÛŒ')\n",
        "        weekly_report += f\"\\n\\nğŸ“ˆ Ø±ÙˆÙ†Ø¯ Ù‡ÙØªÚ¯ÛŒ:\\n\"\n",
        "        weekly_report += \"â€¢ Ø§ÛŒÙ† Ú¯Ø²Ø§Ø±Ø´ Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ¬Ù…ÛŒØ¹ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ ØªÙ‡ÛŒÙ‡ Ø´Ø¯Ù‡ Ø§Ø³Øª\\n\"\n",
        "        weekly_report += \"â€¢ Ø¨Ø±Ø§ÛŒ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¯Ù‚ÛŒÙ‚â€ŒØªØ±ØŒ Ø³ÛŒØ³ØªÙ… Ø¨Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨ÛŒØ´ØªØ±ÛŒ Ù†ÛŒØ§Ø² Ø¯Ø§Ø±Ø¯\\n\"\n",
        "\n",
        "        return weekly_report\n",
        "\n",
        "    def generate_monthly_report(self):\n",
        "        \"\"\"ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ Ù…Ø§Ù‡Ø§Ù†Ù‡\"\"\"\n",
        "        daily_report = self.generate_daily_report()\n",
        "\n",
        "        monthly_report = daily_report.replace('Ú¯Ø²Ø§Ø±Ø´ Ø±ÙˆØ²Ø§Ù†Ù‡', 'Ú¯Ø²Ø§Ø±Ø´ Ù…Ø§Ù‡Ø§Ù†Ù‡')\n",
        "        monthly_report += f\"\\n\\nğŸ“Š ØªØ­Ù„ÛŒÙ„ Ù…Ø§Ù‡Ø§Ù†Ù‡:\\n\"\n",
        "        monthly_report += \"â€¢ Ø§ÛŒÙ† Ú¯Ø²Ø§Ø±Ø´ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø±ÙˆÙ†Ø¯Ù‡Ø§ÛŒ Ù…Ø§Ù‡ Ø¬Ø§Ø±ÛŒ ØªÙ‡ÛŒÙ‡ Ø´Ø¯Ù‡ Ø§Ø³Øª\\n\"\n",
        "        monthly_report += \"â€¢ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¯Ù‚ÛŒÙ‚â€ŒØªØ± Ù…Ø§Ù‡Ø§Ù†Ù‡ØŒ Ø³ÛŒØ³ØªÙ… Ø¨Ù‡ 30 Ø±ÙˆØ² Ø¯Ø§Ø¯Ù‡ Ù†ÛŒØ§Ø² Ø¯Ø§Ø±Ø¯\\n\"\n",
        "\n",
        "        return monthly_report\n",
        "\n",
        "    def create_chart(self):\n",
        "        \"\"\"Ø§ÛŒØ¬Ø§Ø¯ Ù†Ù…ÙˆØ¯Ø§Ø± (Ø¯Ø± ØµÙˆØ±Øª Ø§Ù…Ú©Ø§Ù†)\"\"\"\n",
        "        if not MATPLOTLIB_AVAILABLE:\n",
        "            print(\"âš ï¸ matplotlib Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª - Ù†Ù…ÙˆØ¯Ø§Ø± Ø§ÛŒØ¬Ø§Ø¯ Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯\")\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            categories = self.analysis.get('category_analysis', {})\n",
        "\n",
        "            if not categories:\n",
        "                print(\"âš ï¸ Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…ÙˆØ¯Ø§Ø± Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª\")\n",
        "                return None\n",
        "\n",
        "            # Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ù…ÙˆØ¯Ø§Ø±\n",
        "            cat_names = list(categories.keys())\n",
        "            scores = [categories[cat]['trend_score'] for cat in cat_names]\n",
        "\n",
        "            # Ø§ÛŒØ¬Ø§Ø¯ Ù†Ù…ÙˆØ¯Ø§Ø± Ø¨Ø§ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¨Ù‡ØªØ±\n",
        "            plt.figure(figsize=(12, 6))\n",
        "\n",
        "            # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² font Ú©Ù‡ Ø¯Ø± colab Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø³Øª\n",
        "            plt.rcParams.update({'font.size': 10})\n",
        "\n",
        "            bars = plt.bar(cat_names, scores, color='skyblue', alpha=0.7)\n",
        "\n",
        "            # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù†Ù…ÙˆØ¯Ø§Ø±\n",
        "            plt.title('Market Categories Analysis - Iran', fontsize=14, pad=20)\n",
        "            plt.ylabel('Trend Score')\n",
        "            plt.xticks(rotation=45, ha='right')\n",
        "            plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "            # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù…Ù‚Ø§Ø¯ÛŒØ± Ø±ÙˆÛŒ Ù…ÛŒÙ„Ù‡â€ŒÙ‡Ø§\n",
        "            for bar, score in zip(bars, scores):\n",
        "                plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 1,\n",
        "                         f'{score:.1f}', ha='center', va='bottom')\n",
        "\n",
        "            plt.tight_layout()\n",
        "\n",
        "            # Ø°Ø®ÛŒØ±Ù‡ Ù†Ù…ÙˆØ¯Ø§Ø±\n",
        "            chart_path = '/content/market_chart.png'\n",
        "            plt.savefig(chart_path, dpi=300, bbox_inches='tight')\n",
        "            plt.close()  # Ø¨Ø³ØªÙ† figure Ø¨Ø±Ø§ÛŒ Ø¢Ø²Ø§Ø¯Ø³Ø§Ø²ÛŒ Ø­Ø§ÙØ¸Ù‡\n",
        "\n",
        "            print(\"âœ… Ù†Ù…ÙˆØ¯Ø§Ø± Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯\")\n",
        "            return chart_path\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ Ù†Ù…ÙˆØ¯Ø§Ø±: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "# !/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Ø³ÛŒØ³ØªÙ… ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø§Ø± Ø§ÛŒØ±Ø§Ù† - Ø¨Ø®Ø´ Ø¯ÙˆÙ…\n",
        "Ø§Ø¯Ø§Ù…Ù‡ Ú©Ù„Ø§Ø³ TelegramSender Ùˆ Ø³ÛŒØ³ØªÙ… Ø§ØµÙ„ÛŒ\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class TelegramSender:\n",
        "    \"\"\"Ø§Ø±Ø³Ø§Ù„â€ŒÚ©Ù†Ù†Ø¯Ù‡ ØªÙ„Ú¯Ø±Ø§Ù…\"\"\"\n",
        "\n",
        "    def __init__(self, token, chat_id):\n",
        "        self.token = token\n",
        "        self.chat_id = chat_id\n",
        "        self.bot = None\n",
        "\n",
        "        if TELEGRAM_AVAILABLE and token != \"YOUR_BOT_TOKEN_HERE\":\n",
        "            try:\n",
        "                self.bot = telebot.TeleBot(token)\n",
        "                print(\"âœ… Ø§ØªØµØ§Ù„ Ø¨Ù‡ ØªÙ„Ú¯Ø±Ø§Ù… Ø¨Ø±Ù‚Ø±Ø§Ø± Ø´Ø¯\")\n",
        "            except Exception as e:\n",
        "                print(f\"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§ØªØµØ§Ù„ Ø¨Ù‡ ØªÙ„Ú¯Ø±Ø§Ù…: {str(e)}\")\n",
        "\n",
        "    def send_report(self, report_text, chart_path=None):\n",
        "        \"\"\"Ø§Ø±Ø³Ø§Ù„ Ú¯Ø²Ø§Ø±Ø´ Ø¨Ù‡ ØªÙ„Ú¯Ø±Ø§Ù…\"\"\"\n",
        "        if not self.bot:\n",
        "            print(\"âš ï¸ Ø±Ø¨Ø§Øª ØªÙ„Ú¯Ø±Ø§Ù… ØªÙ†Ø¸ÛŒÙ… Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª\")\n",
        "            print(\"ğŸ“ Ú¯Ø²Ø§Ø±Ø´:\")\n",
        "            print(report_text)\n",
        "            return False\n",
        "\n",
        "        try:\n",
        "            # ØªÙ‚Ø³ÛŒÙ… Ù…ØªÙ† Ø¨Ù‡ Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ Ú©ÙˆÚ†Ú©ØªØ± (Ù…Ø­Ø¯ÙˆØ¯ÛŒØª ØªÙ„Ú¯Ø±Ø§Ù…: 4096 Ú©Ø§Ø±Ø§Ú©ØªØ±)\n",
        "            max_length = 4000\n",
        "            text_parts = []\n",
        "\n",
        "            if len(report_text) > max_length:\n",
        "                # ØªÙ‚Ø³ÛŒÙ… Ù…ØªÙ†\n",
        "                lines = report_text.split('\\n')\n",
        "                current_part = \"\"\n",
        "\n",
        "                for line in lines:\n",
        "                    if len(current_part + line + '\\n') > max_length:\n",
        "                        if current_part:\n",
        "                            text_parts.append(current_part.strip())\n",
        "                        current_part = line + '\\n'\n",
        "                    else:\n",
        "                        current_part += line + '\\n'\n",
        "\n",
        "                if current_part:\n",
        "                    text_parts.append(current_part.strip())\n",
        "            else:\n",
        "                text_parts = [report_text]\n",
        "\n",
        "            # Ø§Ø±Ø³Ø§Ù„ Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ Ù…ØªÙ†\n",
        "            for i, part in enumerate(text_parts):\n",
        "                if i == 0:\n",
        "                    sent_message = self.bot.send_message(\n",
        "                        chat_id=self.chat_id,\n",
        "                        text=part\n",
        "                    )\n",
        "                else:\n",
        "                    sent_message = self.bot.send_message(\n",
        "                        chat_id=self.chat_id,\n",
        "                        text=f\"ğŸ“„ Ø§Ø¯Ø§Ù…Ù‡ Ú¯Ø²Ø§Ø±Ø´ ({i + 1}):\\n\\n{part}\"\n",
        "                    )\n",
        "\n",
        "                time.sleep(1)  # ØªØ§Ø®ÛŒØ± Ú©ÙˆØªØ§Ù‡ Ø¨ÛŒÙ† Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§\n",
        "\n",
        "            # Ø§Ø±Ø³Ø§Ù„ Ù†Ù…ÙˆØ¯Ø§Ø± (Ø¯Ø± ØµÙˆØ±Øª ÙˆØ¬ÙˆØ¯)\n",
        "            if chart_path and os.path.exists(chart_path):\n",
        "                try:\n",
        "                    with open(chart_path, 'rb') as photo:\n",
        "                        self.bot.send_photo(\n",
        "                            chat_id=self.chat_id,\n",
        "                            photo=photo,\n",
        "                            caption=\"ğŸ“Š Ù†Ù…ÙˆØ¯Ø§Ø± ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø§Ø± Ø§ÛŒØ±Ø§Ù†\"\n",
        "                        )\n",
        "                    print(\"âœ… Ù†Ù…ÙˆØ¯Ø§Ø± Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯\")\n",
        "                except Exception as e:\n",
        "                    print(f\"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ù†Ù…ÙˆØ¯Ø§Ø±: {str(e)}\")\n",
        "\n",
        "            print(\"âœ… Ú¯Ø²Ø§Ø±Ø´ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ú¯Ø²Ø§Ø±Ø´: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def test_connection(self):\n",
        "        \"\"\"ØªØ³Øª Ø§ØªØµØ§Ù„ Ø¨Ù‡ ØªÙ„Ú¯Ø±Ø§Ù…\"\"\"\n",
        "        if not self.bot:\n",
        "            return False\n",
        "\n",
        "        try:\n",
        "            me = self.bot.get_me()\n",
        "            print(f\"âœ… Ø§ØªØµØ§Ù„ Ù…ÙˆÙÙ‚ - Ù†Ø§Ù… Ø±Ø¨Ø§Øª: {me.first_name}\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªØ³Øª Ø§ØªØµØ§Ù„: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "\n",
        "class MarketAnalysisSystem:\n",
        "    \"\"\"Ø³ÛŒØ³ØªÙ… Ø§ØµÙ„ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø§Ø± Ø§ÛŒØ±Ø§Ù†\"\"\"\n",
        "\n",
        "    def __init__(self, telegram_token=None, telegram_chat_id=None):\n",
        "        \"\"\"Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø³ÛŒØ³ØªÙ…\"\"\"\n",
        "        print(\"ğŸš€ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø³ÛŒØ³ØªÙ… ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø§Ø± Ø§ÛŒØ±Ø§Ù†...\")\n",
        "\n",
        "        # ØªÙ†Ø¸ÛŒÙ…Ø§Øª ØªÙ„Ú¯Ø±Ø§Ù…\n",
        "        self.telegram_token = telegram_token or Config.TELEGRAM_BOT_TOKEN\n",
        "        self.telegram_chat_id = telegram_chat_id or Config.TELEGRAM_CHAT_ID\n",
        "\n",
        "        # Ø§Ø¬Ø²Ø§ÛŒ Ø³ÛŒØ³ØªÙ…\n",
        "        self.data_ingester = DataIngestion()\n",
        "        self.telegram_sender = TelegramSender(self.telegram_token, self.telegram_chat_id)\n",
        "\n",
        "        # Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ø¯Ø§Ø®Ù„ÛŒ\n",
        "        self.raw_data = None\n",
        "        self.analysis_results = None\n",
        "        self.reports = {}\n",
        "\n",
        "        print(\"âœ… Ø³ÛŒØ³ØªÙ… Ø¢Ù…Ø§Ø¯Ù‡ Ø§Ø³Øª\")\n",
        "\n",
        "    def check_system_status(self):\n",
        "        \"\"\"Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø³ÛŒØ³ØªÙ…\"\"\"\n",
        "        print(\"\\nğŸ” Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø³ÛŒØ³ØªÙ…:\")\n",
        "\n",
        "        status = {\n",
        "            'google_trends': PYTRENDS_AVAILABLE,\n",
        "            'text_processing': TEXT_PROCESSING_AVAILABLE,\n",
        "            'charts': MATPLOTLIB_AVAILABLE,\n",
        "            'machine_learning': SKLEARN_AVAILABLE,\n",
        "            'telegram': TELEGRAM_AVAILABLE and self.telegram_token != \"YOUR_BOT_TOKEN_HERE\",\n",
        "            'web_scraping': BS4_AVAILABLE\n",
        "        }\n",
        "\n",
        "        for component, available in status.items():\n",
        "            status_emoji = \"âœ…\" if available else \"âŒ\"\n",
        "            print(f\"   {status_emoji} {component}\")\n",
        "\n",
        "        # Ù‡Ø´Ø¯Ø§Ø±Ù‡Ø§ÛŒ Ù…Ù‡Ù…\n",
        "        if not status['telegram']:\n",
        "            print(\"\\nâš ï¸ Ù‡Ø´Ø¯Ø§Ø±: ØªÙ„Ú¯Ø±Ø§Ù… ØªÙ†Ø¸ÛŒÙ… Ù†Ø´Ø¯Ù‡ - Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§ Ø¯Ø± Ú©Ù†Ø³ÙˆÙ„ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯\")\n",
        "\n",
        "        if not status['google_trends']:\n",
        "            print(\"\\nâš ï¸ Ù‡Ø´Ø¯Ø§Ø±: Google Trends Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª - Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯\")\n",
        "\n",
        "        return status\n",
        "\n",
        "    def collect_data(self):\n",
        "        \"\"\"Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§\"\"\"\n",
        "        print(\"\\nğŸ“Š Ù…Ø±Ø­Ù„Ù‡ 1: Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§\")\n",
        "        self.raw_data = self.data_ingester.collect_all_data()\n",
        "        return self.raw_data\n",
        "\n",
        "    def analyze_market(self):\n",
        "        \"\"\"ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø§Ø±\"\"\"\n",
        "        if not self.raw_data:\n",
        "            print(\"âŒ Ø§Ø¨ØªØ¯Ø§ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø±Ø§ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ú©Ù†ÛŒØ¯\")\n",
        "            return None\n",
        "\n",
        "        print(\"\\nğŸ§  Ù…Ø±Ø­Ù„Ù‡ 2: ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø§Ø±\")\n",
        "        analyzer = MarketAnalyzer(self.raw_data)\n",
        "        self.analysis_results = analyzer.run_full_analysis()\n",
        "        return self.analysis_results\n",
        "\n",
        "    def generate_reports(self):\n",
        "        \"\"\"ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§\"\"\"\n",
        "        if not self.analysis_results:\n",
        "            print(\"âŒ Ø§Ø¨ØªØ¯Ø§ ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø§Ø± Ø±Ø§ Ø§Ù†Ø¬Ø§Ù… Ø¯Ù‡ÛŒØ¯\")\n",
        "            return None\n",
        "\n",
        "        print(\"\\nğŸ“ Ù…Ø±Ø­Ù„Ù‡ 3: ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§\")\n",
        "\n",
        "        report_generator = ReportGenerator(self.analysis_results)\n",
        "\n",
        "        # ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù\n",
        "        self.reports = {\n",
        "            'daily': report_generator.generate_daily_report(),\n",
        "            'weekly': report_generator.generate_weekly_report(),\n",
        "            'monthly': report_generator.generate_monthly_report()\n",
        "        }\n",
        "\n",
        "        # Ø§ÛŒØ¬Ø§Ø¯ Ù†Ù…ÙˆØ¯Ø§Ø±\n",
        "        chart_path = report_generator.create_chart()\n",
        "        self.reports['chart_path'] = chart_path\n",
        "\n",
        "        print(\"âœ… Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù†Ø¯\")\n",
        "        return self.reports\n",
        "\n",
        "    def send_reports(self, report_type='daily'):\n",
        "        \"\"\"Ø§Ø±Ø³Ø§Ù„ Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§\"\"\"\n",
        "        if not self.reports:\n",
        "            print(\"âŒ Ø§Ø¨ØªØ¯Ø§ Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§ Ø±Ø§ ØªÙˆÙ„ÛŒØ¯ Ú©Ù†ÛŒØ¯\")\n",
        "            return False\n",
        "\n",
        "        print(f\"\\nğŸ“¤ Ù…Ø±Ø­Ù„Ù‡ 4: Ø§Ø±Ø³Ø§Ù„ Ú¯Ø²Ø§Ø±Ø´ {report_type}\")\n",
        "\n",
        "        if report_type not in self.reports:\n",
        "            print(f\"âŒ Ù†ÙˆØ¹ Ú¯Ø²Ø§Ø±Ø´ '{report_type}' Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª\")\n",
        "            return False\n",
        "\n",
        "        success = self.telegram_sender.send_report(\n",
        "            self.reports[report_type],\n",
        "            self.reports.get('chart_path')\n",
        "        )\n",
        "\n",
        "        return success\n",
        "\n",
        "    def run_daily_analysis(self):\n",
        "        \"\"\"Ø§Ø¬Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø±ÙˆØ²Ø§Ù†Ù‡ Ú©Ø§Ù…Ù„\"\"\"\n",
        "        print(\"=\" * 50)\n",
        "        print(\"ğŸ‡®ğŸ‡· Ø³ÛŒØ³ØªÙ… ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø§Ø± Ø§ÛŒØ±Ø§Ù† - Ø§Ø¬Ø±Ø§ÛŒ Ø±ÙˆØ²Ø§Ù†Ù‡\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø³ÛŒØ³ØªÙ…\n",
        "        system_status = self.check_system_status()\n",
        "\n",
        "        try:\n",
        "            # Ù…Ø±Ø§Ø­Ù„ ØªØ­Ù„ÛŒÙ„\n",
        "            self.collect_data()\n",
        "            self.analyze_market()\n",
        "            self.generate_reports()\n",
        "\n",
        "            # Ø§Ø±Ø³Ø§Ù„ Ú¯Ø²Ø§Ø±Ø´ Ø±ÙˆØ²Ø§Ù†Ù‡\n",
        "            success = self.send_reports('daily')\n",
        "\n",
        "            if success:\n",
        "                print(\"\\nğŸ‰ ØªØ­Ù„ÛŒÙ„ Ø±ÙˆØ²Ø§Ù†Ù‡ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯!\")\n",
        "            else:\n",
        "                print(\"\\nâš ï¸ ØªØ­Ù„ÛŒÙ„ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯ Ø§Ù…Ø§ Ø§Ø±Ø³Ø§Ù„ Ú¯Ø²Ø§Ø±Ø´ Ø¨Ø§ Ù…Ø´Ú©Ù„ Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯\")\n",
        "\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\nâŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø¬Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def run_weekly_analysis(self):\n",
        "        \"\"\"Ø§Ø¬Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ù‡ÙØªÚ¯ÛŒ\"\"\"\n",
        "        print(\"=\" * 50)\n",
        "        print(\"ğŸ‡®ğŸ‡· Ø³ÛŒØ³ØªÙ… ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø§Ø± Ø§ÛŒØ±Ø§Ù† - Ø§Ø¬Ø±Ø§ÛŒ Ù‡ÙØªÚ¯ÛŒ\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        try:\n",
        "            self.collect_data()\n",
        "            self.analyze_market()\n",
        "            self.generate_reports()\n",
        "\n",
        "            success = self.send_reports('weekly')\n",
        "\n",
        "            if success:\n",
        "                print(\"\\nğŸ‰ ØªØ­Ù„ÛŒÙ„ Ù‡ÙØªÚ¯ÛŒ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯!\")\n",
        "\n",
        "            return success\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\nâŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø¬Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ù‡ÙØªÚ¯ÛŒ: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def run_monthly_analysis(self):\n",
        "        \"\"\"Ø§Ø¬Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ù…Ø§Ù‡Ø§Ù†Ù‡\"\"\"\n",
        "        print(\"=\" * 50)\n",
        "        print(\"ğŸ‡®ğŸ‡· Ø³ÛŒØ³ØªÙ… ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø§Ø± Ø§ÛŒØ±Ø§Ù† - Ø§Ø¬Ø±Ø§ÛŒ Ù…Ø§Ù‡Ø§Ù†Ù‡\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        try:\n",
        "            self.collect_data()\n",
        "            self.analyze_market()\n",
        "            self.generate_reports()\n",
        "\n",
        "            success = self.send_reports('monthly')\n",
        "\n",
        "            if success:\n",
        "                print(\"\\nğŸ‰ ØªØ­Ù„ÛŒÙ„ Ù…Ø§Ù‡Ø§Ù†Ù‡ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯!\")\n",
        "\n",
        "            return success\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\nâŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø¬Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ù…Ø§Ù‡Ø§Ù†Ù‡: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def interactive_menu(self):\n",
        "        \"\"\"Ù…Ù†ÙˆÛŒ ØªØ¹Ø§Ù…Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±\"\"\"\n",
        "        while True:\n",
        "            print(\"\\n\" + \"=\" * 40)\n",
        "            print(\"ğŸ‡®ğŸ‡· Ø³ÛŒØ³ØªÙ… ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø§Ø± Ø§ÛŒØ±Ø§Ù†\")\n",
        "            print(\"=\" * 40)\n",
        "            print(\"1ï¸âƒ£ ØªØ­Ù„ÛŒÙ„ Ø±ÙˆØ²Ø§Ù†Ù‡\")\n",
        "            print(\"2ï¸âƒ£ ØªØ­Ù„ÛŒÙ„ Ù‡ÙØªÚ¯ÛŒ\")\n",
        "            print(\"3ï¸âƒ£ ØªØ­Ù„ÛŒÙ„ Ù…Ø§Ù‡Ø§Ù†Ù‡\")\n",
        "            print(\"4ï¸âƒ£ Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø³ÛŒØ³ØªÙ…\")\n",
        "            print(\"5ï¸âƒ£ ØªØ³Øª Ø§ØªØµØ§Ù„ ØªÙ„Ú¯Ø±Ø§Ù…\")\n",
        "            print(\"6ï¸âƒ£ Ù†Ù…Ø§ÛŒØ´ Ú¯Ø²Ø§Ø±Ø´ Ø¯Ø± Ú©Ù†Ø³ÙˆÙ„\")\n",
        "            print(\"0ï¸âƒ£ Ø®Ø±ÙˆØ¬\")\n",
        "            print(\"-\" * 40)\n",
        "\n",
        "            try:\n",
        "                choice = input(\"Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ù…Ø§: \").strip()\n",
        "\n",
        "                if choice == '1':\n",
        "                    self.run_daily_analysis()\n",
        "                elif choice == '2':\n",
        "                    self.run_weekly_analysis()\n",
        "                elif choice == '3':\n",
        "                    self.run_monthly_analysis()\n",
        "                elif choice == '4':\n",
        "                    self.check_system_status()\n",
        "                elif choice == '5':\n",
        "                    self.telegram_sender.test_connection()\n",
        "                elif choice == '6':\n",
        "                    self.show_console_report()\n",
        "                elif choice == '0':\n",
        "                    print(\"ğŸ‘‹ Ø®Ø¯Ø§Ø­Ø§ÙØ¸!\")\n",
        "                    break\n",
        "                else:\n",
        "                    print(\"âŒ Ø§Ù†ØªØ®Ø§Ø¨ Ù†Ø§Ù…Ø¹ØªØ¨Ø±\")\n",
        "\n",
        "            except KeyboardInterrupt:\n",
        "                print(\"\\nğŸ‘‹ Ø®Ø¯Ø§Ø­Ø§ÙØ¸!\")\n",
        "                break\n",
        "            except Exception as e:\n",
        "                print(f\"âŒ Ø®Ø·Ø§: {str(e)}\")\n",
        "\n",
        "    def show_console_report(self):\n",
        "        \"\"\"Ù†Ù…Ø§ÛŒØ´ Ú¯Ø²Ø§Ø±Ø´ Ø¯Ø± Ú©Ù†Ø³ÙˆÙ„\"\"\"\n",
        "        if not self.reports:\n",
        "            print(\"âš ï¸ Ø§Ø¨ØªØ¯Ø§ ÛŒÚ©ÛŒ Ø§Ø² ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ Ø±Ø§ Ø§Ø¬Ø±Ø§ Ú©Ù†ÛŒØ¯\")\n",
        "            return\n",
        "\n",
        "        print(\"\\nğŸ“Š Ú©Ø¯Ø§Ù… Ú¯Ø²Ø§Ø±Ø´ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ø´ÙˆØ¯ØŸ\")\n",
        "        print(\"1. Ø±ÙˆØ²Ø§Ù†Ù‡\")\n",
        "        print(\"2. Ù‡ÙØªÚ¯ÛŒ\")\n",
        "        print(\"3. Ù…Ø§Ù‡Ø§Ù†Ù‡\")\n",
        "\n",
        "        choice = input(\"Ø§Ù†ØªØ®Ø§Ø¨: \").strip()\n",
        "\n",
        "        if choice == '1' and 'daily' in self.reports:\n",
        "            print(\"\\n\" + \"=\" * 50)\n",
        "            print(self.reports['daily'])\n",
        "            print(\"=\" * 50)\n",
        "        elif choice == '2' and 'weekly' in self.reports:\n",
        "            print(\"\\n\" + \"=\" * 50)\n",
        "            print(self.reports['weekly'])\n",
        "            print(\"=\" * 50)\n",
        "        elif choice == '3' and 'monthly' in self.reports:\n",
        "            print(\"\\n\" + \"=\" * 50)\n",
        "            print(self.reports['monthly'])\n",
        "            print(\"=\" * 50)\n",
        "        else:\n",
        "            print(\"âŒ Ú¯Ø²Ø§Ø±Ø´ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª\")\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# Ø¨Ø®Ø´ 5: ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ú©Ø§Ø±Ø¨Ø± Ùˆ Ø§Ø¬Ø±Ø§\n",
        "# ===============================\n",
        "\n",
        "def setup_telegram_credentials():\n",
        "    \"\"\"ØªÙ†Ø¸ÛŒÙ… Ø§Ø·Ù„Ø§Ø¹Ø§Øª ØªÙ„Ú¯Ø±Ø§Ù…\"\"\"\n",
        "    print(\"\\nğŸ”§ ØªÙ†Ø¸ÛŒÙ… Ø§Ø·Ù„Ø§Ø¹Ø§Øª ØªÙ„Ú¯Ø±Ø§Ù…:\")\n",
        "    print(\"Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§ Ø¯Ø± ØªÙ„Ú¯Ø±Ø§Ù…ØŒ Ù„Ø·ÙØ§Ù‹ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø²ÛŒØ± Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯:\")\n",
        "    print(\"(Ø¯Ø± ØµÙˆØ±Øª Ø¹Ø¯Ù… ØªÙ…Ø§ÛŒÙ„ØŒ Enter Ø¨Ø²Ù†ÛŒØ¯)\")\n",
        "\n",
        "    token = input(\"Bot Token: \").strip()\n",
        "    chat_id = input(\"Chat ID: \").strip()\n",
        "\n",
        "    if token and chat_id:\n",
        "        return token, chat_id\n",
        "    else:\n",
        "        print(\"âš ï¸ Ø§Ø·Ù„Ø§Ø¹Ø§Øª ØªÙ„Ú¯Ø±Ø§Ù… ÙˆØ§Ø±Ø¯ Ù†Ø´Ø¯ - Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§ Ø¯Ø± Ú©Ù†Ø³ÙˆÙ„ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯\")\n",
        "        return None, None\n",
        "\n",
        "\n",
        "def quick_demo():\n",
        "    \"\"\"Ù†Ù…Ø§ÛŒØ´ Ø³Ø±ÛŒØ¹ Ø³ÛŒØ³ØªÙ…\"\"\"\n",
        "    print(\"\\nğŸ¬ Ø§Ø¬Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ÛŒ Ø³ÛŒØ³ØªÙ…...\")\n",
        "\n",
        "    # Ø§ÛŒØ¬Ø§Ø¯ Ø³ÛŒØ³ØªÙ… Ø¨Ø§ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶\n",
        "    system = MarketAnalysisSystem()\n",
        "\n",
        "    # Ø§Ø¬Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø±ÙˆØ²Ø§Ù†Ù‡\n",
        "    success = system.run_daily_analysis()\n",
        "\n",
        "    if success:\n",
        "        print(\"\\nâœ… Ù†Ù…Ø§ÛŒØ´ ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯!\")\n",
        "\n",
        "        # Ù†Ù…Ø§ÛŒØ´ Ø®Ù„Ø§ØµÙ‡ Ú¯Ø²Ø§Ø±Ø´ Ø¯Ø± Ú©Ù†Ø³ÙˆÙ„\n",
        "        if system.reports and 'daily' in system.reports:\n",
        "            print(\"\\nğŸ“Š Ø®Ù„Ø§ØµÙ‡ Ú¯Ø²Ø§Ø±Ø´ Ø±ÙˆØ²Ø§Ù†Ù‡:\")\n",
        "            print(\"-\" * 30)\n",
        "\n",
        "            # Ù†Ù…Ø§ÛŒØ´ 10 Ø®Ø· Ø§ÙˆÙ„ Ú¯Ø²Ø§Ø±Ø´\n",
        "            report_lines = system.reports['daily'].split('\\n')[:10]\n",
        "            for line in report_lines:\n",
        "                print(line)\n",
        "\n",
        "            print(\"...\")\n",
        "            print(f\"(Ù†Ù…Ø§ÛŒØ´ {len(report_lines)} Ø®Ø· Ø§Ø² {len(system.reports['daily'].split(chr(10)))} Ø®Ø· Ú©Ù„)\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ\"\"\"\n",
        "    print(\"ğŸ‡®ğŸ‡· Ø®ÙˆØ´ Ø¢Ù…Ø¯ÛŒØ¯ Ø¨Ù‡ Ø³ÛŒØ³ØªÙ… ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø§Ø± Ø§ÛŒØ±Ø§Ù†!\")\n",
        "    print(\"\\nØ¢ÛŒØ§ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯:\")\n",
        "    print(\"1ï¸âƒ£ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ú©Ø§Ù…Ù„ Ùˆ Ø§Ø¬Ø±Ø§ÛŒ ØªØ¹Ø§Ù…Ù„ÛŒ\")\n",
        "    print(\"2ï¸âƒ£ Ø§Ø¬Ø±Ø§ÛŒ Ø³Ø±ÛŒØ¹ Ù†Ù…Ø§ÛŒØ´ÛŒ\")\n",
        "    print(\"3ï¸âƒ£ ÙÙ‚Ø· ØªØ­Ù„ÛŒÙ„ Ø±ÙˆØ²Ø§Ù†Ù‡\")\n",
        "\n",
        "    choice = input(\"\\nØ§Ù†ØªØ®Ø§Ø¨ Ø´Ù…Ø§: \").strip()\n",
        "\n",
        "    if choice == '1':\n",
        "        # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ú©Ø§Ù…Ù„\n",
        "        token, chat_id = setup_telegram_credentials()\n",
        "        system = MarketAnalysisSystem(token, chat_id)\n",
        "        system.interactive_menu()\n",
        "\n",
        "    elif choice == '2':\n",
        "        # Ù†Ù…Ø§ÛŒØ´ Ø³Ø±ÛŒØ¹\n",
        "        quick_demo()\n",
        "\n",
        "    elif choice == '3':\n",
        "        # ÙÙ‚Ø· ØªØ­Ù„ÛŒÙ„ Ø±ÙˆØ²Ø§Ù†Ù‡\n",
        "        token, chat_id = setup_telegram_credentials()\n",
        "        system = MarketAnalysisSystem(token, chat_id)\n",
        "        system.run_daily_analysis()\n",
        "\n",
        "    else:\n",
        "        print(\"âŒ Ø§Ù†ØªØ®Ø§Ø¨ Ù†Ø§Ù…Ø¹ØªØ¨Ø±\")\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# Ø§Ø¬Ø±Ø§ÛŒ Ø³ÛŒØ³ØªÙ…\n",
        "# ===============================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        main()\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nğŸ‘‹ Ø®Ø¯Ø§Ø­Ø§ÙØ¸!\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nâŒ Ø®Ø·Ø§ÛŒ Ú©Ù„ÛŒ: {str(e)}\")\n",
        "        print(\"ğŸ”„ Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯\")\n",
        "\n",
        "# ===============================\n",
        "# Ù†Ù…ÙˆÙ†Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø³Ø±ÛŒØ¹\n",
        "# ===============================\n",
        "\n",
        "# Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§ÛŒ Ø³Ø±ÛŒØ¹ØŒ Ø®Ø·ÙˆØ· Ø²ÛŒØ± Ø±Ø§ ØºÛŒØ±ÙØ¹Ø§Ù„ Ú©Ù†ÛŒØ¯:\n",
        "\"\"\"\n",
        "# Ø§ÛŒØ¬Ø§Ø¯ Ø³ÛŒØ³ØªÙ…\n",
        "system = MarketAnalysisSystem(\n",
        "    telegram_token=\"YOUR_BOT_TOKEN\",  # ØªÙˆÚ©Ù† Ø±Ø¨Ø§Øª Ø®ÙˆØ¯ Ø±Ø§ Ø§ÛŒÙ†Ø¬Ø§ Ù‚Ø±Ø§Ø± Ø¯Ù‡ÛŒØ¯\n",
        "    telegram_chat_id=\"YOUR_CHAT_ID\"  # Ø´Ù†Ø§Ø³Ù‡ Ú†Øª Ø®ÙˆØ¯ Ø±Ø§ Ø§ÛŒÙ†Ø¬Ø§ Ù‚Ø±Ø§Ø± Ø¯Ù‡ÛŒØ¯\n",
        ")\n",
        "\n",
        "# Ø§Ø¬Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø±ÙˆØ²Ø§Ù†Ù‡\n",
        "system.run_daily_analysis()\n",
        "\"\"\"\n",
        "\n",
        "print(\"âœ… Ø³ÛŒØ³ØªÙ… ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø§Ø± Ø§ÛŒØ±Ø§Ù† Ø¢Ù…Ø§Ø¯Ù‡ Ø§Ø³Øª!\")\n",
        "print(\"ğŸ“– Ø¨Ø±Ø§ÛŒ Ø´Ø±ÙˆØ¹ØŒ ØªØ§Ø¨Ø¹ main() Ø±Ø§ Ø§Ø¬Ø±Ø§ Ú©Ù†ÛŒØ¯\")"
      ],
      "metadata": {
        "id": "YhfDfW_1270b",
        "outputId": "edbe9d41-22b0-4db3-bf0e-03eb372997a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ Ø´Ø±ÙˆØ¹ Ù†ØµØ¨ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§...\n",
            "ğŸ”§ Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ numpy...\n",
            "âœ… pandas Ø¯Ø± Ø­Ø§Ù„ Ø­Ø§Ø¶Ø± Ù†ØµØ¨ Ø§Ø³Øª\n",
            "âœ… numpy Ø¯Ø± Ø­Ø§Ù„ Ø­Ø§Ø¶Ø± Ù†ØµØ¨ Ø§Ø³Øª\n",
            "âœ… requests Ø¯Ø± Ø­Ø§Ù„ Ø­Ø§Ø¶Ø± Ù†ØµØ¨ Ø§Ø³Øª\n",
            "âœ… bs4 Ø¯Ø± Ø­Ø§Ù„ Ø­Ø§Ø¶Ø± Ù†ØµØ¨ Ø§Ø³Øª\n",
            "âœ… matplotlib Ø¯Ø± Ø­Ø§Ù„ Ø­Ø§Ø¶Ø± Ù†ØµØ¨ Ø§Ø³Øª\n",
            "âœ… seaborn Ø¯Ø± Ø­Ø§Ù„ Ø­Ø§Ø¶Ø± Ù†ØµØ¨ Ø§Ø³Øª\n",
            "âœ… plotly Ø¯Ø± Ø­Ø§Ù„ Ø­Ø§Ø¶Ø± Ù†ØµØ¨ Ø§Ø³Øª\n",
            "âœ… sklearn Ø¯Ø± Ø­Ø§Ù„ Ø­Ø§Ø¶Ø± Ù†ØµØ¨ Ø§Ø³Øª\n",
            "âœ… textblob Ø¯Ø± Ø­Ø§Ù„ Ø­Ø§Ø¶Ø± Ù†ØµØ¨ Ø§Ø³Øª\n",
            "âœ… googletrans Ø¯Ø± Ø­Ø§Ù„ Ø­Ø§Ø¶Ø± Ù†ØµØ¨ Ø§Ø³Øª\n",
            "âœ… persiantools Ø¯Ø± Ø­Ø§Ù„ Ø­Ø§Ø¶Ø± Ù†ØµØ¨ Ø§Ø³Øª\n",
            "âœ… khayyam Ø¯Ø± Ø­Ø§Ù„ Ø­Ø§Ø¶Ø± Ù†ØµØ¨ Ø§Ø³Øª\n",
            "âœ… pytrends Ø¯Ø± Ø­Ø§Ù„ Ø­Ø§Ø¶Ø± Ù†ØµØ¨ Ø§Ø³Øª\n",
            "âœ… telebot Ø¯Ø± Ø­Ø§Ù„ Ø­Ø§Ø¶Ø± Ù†ØµØ¨ Ø§Ø³Øª\n",
            "âœ… wordcloud Ø¯Ø± Ø­Ø§Ù„ Ø­Ø§Ø¶Ø± Ù†ØµØ¨ Ø§Ø³Øª\n",
            "\n",
            "ğŸ“Š Ø®Ù„Ø§ØµÙ‡ Ù†ØµØ¨:\n",
            "âœ… Ù†ØµØ¨ Ø´Ø¯Ù‡: 15\n",
            "âŒ Ù†Ø§Ù…ÙˆÙÙ‚: 0\n",
            "ğŸ‡®ğŸ‡· Ø®ÙˆØ´ Ø¢Ù…Ø¯ÛŒØ¯ Ø¨Ù‡ Ø³ÛŒØ³ØªÙ… ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø§Ø± Ø§ÛŒØ±Ø§Ù†!\n",
            "\n",
            "Ø¢ÛŒØ§ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯:\n",
            "1ï¸âƒ£ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ú©Ø§Ù…Ù„ Ùˆ Ø§Ø¬Ø±Ø§ÛŒ ØªØ¹Ø§Ù…Ù„ÛŒ\n",
            "2ï¸âƒ£ Ø§Ø¬Ø±Ø§ÛŒ Ø³Ø±ÛŒØ¹ Ù†Ù…Ø§ÛŒØ´ÛŒ\n",
            "3ï¸âƒ£ ÙÙ‚Ø· ØªØ­Ù„ÛŒÙ„ Ø±ÙˆØ²Ø§Ù†Ù‡\n",
            "\n",
            "Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ù…Ø§: 1\n",
            "\n",
            "ğŸ”§ ØªÙ†Ø¸ÛŒÙ… Ø§Ø·Ù„Ø§Ø¹Ø§Øª ØªÙ„Ú¯Ø±Ø§Ù…:\n",
            "Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§ Ø¯Ø± ØªÙ„Ú¯Ø±Ø§Ù…ØŒ Ù„Ø·ÙØ§Ù‹ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø²ÛŒØ± Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯:\n",
            "(Ø¯Ø± ØµÙˆØ±Øª Ø¹Ø¯Ù… ØªÙ…Ø§ÛŒÙ„ØŒ Enter Ø¨Ø²Ù†ÛŒØ¯)\n",
            "Bot Token: 7962358346:AAHxMMHpgKfNZ8eUnvwKALDnct5eoXxqr6s\n",
            "Chat ID: @andisharia_backup\n",
            "ğŸš€ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø³ÛŒØ³ØªÙ… ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø§Ø± Ø§ÛŒØ±Ø§Ù†...\n",
            "âœ… Ø§ØªØµØ§Ù„ Ø¨Ù‡ ØªÙ„Ú¯Ø±Ø§Ù… Ø¨Ø±Ù‚Ø±Ø§Ø± Ø´Ø¯\n",
            "âœ… Ø³ÛŒØ³ØªÙ… Ø¢Ù…Ø§Ø¯Ù‡ Ø§Ø³Øª\n",
            "\n",
            "========================================\n",
            "ğŸ‡®ğŸ‡· Ø³ÛŒØ³ØªÙ… ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø§Ø± Ø§ÛŒØ±Ø§Ù†\n",
            "========================================\n",
            "1ï¸âƒ£ ØªØ­Ù„ÛŒÙ„ Ø±ÙˆØ²Ø§Ù†Ù‡\n",
            "2ï¸âƒ£ ØªØ­Ù„ÛŒÙ„ Ù‡ÙØªÚ¯ÛŒ\n",
            "3ï¸âƒ£ ØªØ­Ù„ÛŒÙ„ Ù…Ø§Ù‡Ø§Ù†Ù‡\n",
            "4ï¸âƒ£ Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø³ÛŒØ³ØªÙ…\n",
            "5ï¸âƒ£ ØªØ³Øª Ø§ØªØµØ§Ù„ ØªÙ„Ú¯Ø±Ø§Ù…\n",
            "6ï¸âƒ£ Ù†Ù…Ø§ÛŒØ´ Ú¯Ø²Ø§Ø±Ø´ Ø¯Ø± Ú©Ù†Ø³ÙˆÙ„\n",
            "0ï¸âƒ£ Ø®Ø±ÙˆØ¬\n",
            "----------------------------------------\n",
            "Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ù…Ø§: 1\n",
            "==================================================\n",
            "ğŸ‡®ğŸ‡· Ø³ÛŒØ³ØªÙ… ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø§Ø± Ø§ÛŒØ±Ø§Ù† - Ø§Ø¬Ø±Ø§ÛŒ Ø±ÙˆØ²Ø§Ù†Ù‡\n",
            "==================================================\n",
            "\n",
            "ğŸ” Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø³ÛŒØ³ØªÙ…:\n",
            "   âœ… google_trends\n",
            "   âœ… text_processing\n",
            "   âœ… charts\n",
            "   âœ… machine_learning\n",
            "   âœ… telegram\n",
            "   âœ… web_scraping\n",
            "\n",
            "ğŸ“Š Ù…Ø±Ø­Ù„Ù‡ 1: Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§\n",
            "ğŸ“Š Ø´Ø±ÙˆØ¹ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§...\n",
            "ğŸ” Ø¯Ø±ÛŒØ§ÙØª Google Trends...\n",
            "âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ØªØ±Ù†Ø¯ Ø¨Ø±Ø§ÛŒ ['Ù…ÙˆØ¨Ø§ÛŒÙ„', 'Ú¯ÙˆØ´ÛŒ', 'Ù„Ù¾ ØªØ§Ù¾', 'Ú©Ø§Ù…Ù¾ÛŒÙˆØªØ±', 'ØªØ¨Ù„Øª']: The request failed: Google returned a response with code 400\n",
            "âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ØªØ±Ù†Ø¯ Ø¨Ø±Ø§ÛŒ ['Ù„Ø¨Ø§Ø³', 'Ú©ÙØ´', 'Ú©ÛŒÙ', 'Ø³Ø§Ø¹Øª', 'Ø¹Ø·Ø±']: The request failed: Google returned a response with code 400\n",
            "âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ØªØ±Ù†Ø¯ Ø¨Ø±Ø§ÛŒ ['Ú©ØªØ§Ø¨', 'ÙÛŒÙ„Ù…', 'Ø¨Ø§Ø²ÛŒ', 'Ù…ÙˆØ³ÛŒÙ‚ÛŒ', 'ØºØ°Ø§']: The request failed: Google returned a response with code 400\n",
            "âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ØªØ±Ù†Ø¯ Ø¨Ø±Ø§ÛŒ ['Ø±Ø³ØªÙˆØ±Ø§Ù†', 'Ø¢Ø´Ù¾Ø²ÛŒ', 'Ù†Ø§Ù†', 'Ø®Ø§Ù†Ù‡', 'Ø§Ø«Ø§Ø«ÛŒÙ‡']: The request failed: Google returned a response with code 400\n",
            "âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ØªØ±Ù†Ø¯ Ø¨Ø±Ø§ÛŒ ['Ø¯Ú©ÙˆØ±Ø§Ø³ÛŒÙˆÙ†', 'Ø¢Ø´Ù¾Ø²Ø®Ø§Ù†Ù‡', 'Ù…Ø§Ø´ÛŒÙ†', 'Ø®ÙˆØ¯Ø±Ùˆ', 'Ù…ÙˆØªÙˆØ±']: The request failed: Google returned a response with code 400\n",
            "âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ØªØ±Ù†Ø¯ Ø¨Ø±Ø§ÛŒ ['Ø¯ÙˆÚ†Ø±Ø®Ù‡', 'Ø³Ù„Ø§Ù…Øª', 'Ø¯Ø§Ø±Ùˆ', 'ÙˆØ±Ø²Ø´', 'ØªÙ†Ø§Ø³Ø¨ Ø§Ù†Ø¯Ø§Ù…']: The request failed: Google returned a response with code 400\n",
            "âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ØªØ±Ù†Ø¯ Ø¨Ø±Ø§ÛŒ ['Ø¢Ø±Ø§ÛŒØ´', 'Ø²ÛŒØ¨Ø§ÛŒÛŒ', 'Ù…Ø±Ø§Ù‚Ø¨Øª Ù¾ÙˆØ³Øª', 'Ø³ÙØ±', 'Ú¯Ø±Ø¯Ø´Ú¯Ø±ÛŒ']: The request failed: Google returned a response with code 400\n",
            "âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ØªØ±Ù†Ø¯ Ø¨Ø±Ø§ÛŒ ['Ù‡ØªÙ„', 'Ø¨Ù„ÛŒØ·', 'ØªØ­ØµÛŒÙ„', 'Ú©ÙˆØ±Ø³', 'Ø²Ø¨Ø§Ù†']: The request failed: Google returned a response with code 400\n",
            "âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ØªØ±Ù†Ø¯ Ø¨Ø±Ø§ÛŒ ['Ù…Ù‡Ø§Ø±Øª']: The request failed: Google returned a response with code 400\n",
            "ğŸ›’ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª...\n",
            "âœ… Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯:\n",
            "   - 0 Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡ ØªØ±Ù†Ø¯\n",
            "   - 50 Ù…Ø­ØµÙˆÙ„\n",
            "\n",
            "ğŸ§  Ù…Ø±Ø­Ù„Ù‡ 2: ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø§Ø±\n",
            "ğŸ§  Ø´Ø±ÙˆØ¹ ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø§Ø±...\n",
            "âœ… ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø§Ø± ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯\n",
            "\n",
            "ğŸ“ Ù…Ø±Ø­Ù„Ù‡ 3: ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§\n",
            "âœ… Ù†Ù…ÙˆØ¯Ø§Ø± Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯\n",
            "âœ… Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù†Ø¯\n",
            "\n",
            "ğŸ“¤ Ù…Ø±Ø­Ù„Ù‡ 4: Ø§Ø±Ø³Ø§Ù„ Ú¯Ø²Ø§Ø±Ø´ daily\n",
            "âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ù†Ù…ÙˆØ¯Ø§Ø±: A request to the Telegram API was unsuccessful. Error code: 400. Description: Bad Request: PHOTO_INVALID_DIMENSIONS\n",
            "âœ… Ú¯Ø²Ø§Ø±Ø´ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯\n",
            "\n",
            "ğŸ‰ ØªØ­Ù„ÛŒÙ„ Ø±ÙˆØ²Ø§Ù†Ù‡ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯!\n",
            "\n",
            "========================================\n",
            "ğŸ‡®ğŸ‡· Ø³ÛŒØ³ØªÙ… ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø§Ø± Ø§ÛŒØ±Ø§Ù†\n",
            "========================================\n",
            "1ï¸âƒ£ ØªØ­Ù„ÛŒÙ„ Ø±ÙˆØ²Ø§Ù†Ù‡\n",
            "2ï¸âƒ£ ØªØ­Ù„ÛŒÙ„ Ù‡ÙØªÚ¯ÛŒ\n",
            "3ï¸âƒ£ ØªØ­Ù„ÛŒÙ„ Ù…Ø§Ù‡Ø§Ù†Ù‡\n",
            "4ï¸âƒ£ Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø³ÛŒØ³ØªÙ…\n",
            "5ï¸âƒ£ ØªØ³Øª Ø§ØªØµØ§Ù„ ØªÙ„Ú¯Ø±Ø§Ù…\n",
            "6ï¸âƒ£ Ù†Ù…Ø§ÛŒØ´ Ú¯Ø²Ø§Ø±Ø´ Ø¯Ø± Ú©Ù†Ø³ÙˆÙ„\n",
            "0ï¸âƒ£ Ø®Ø±ÙˆØ¬\n",
            "----------------------------------------\n",
            "Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ù…Ø§: 2\n",
            "==================================================\n",
            "ğŸ‡®ğŸ‡· Ø³ÛŒØ³ØªÙ… ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø§Ø± Ø§ÛŒØ±Ø§Ù† - Ø§Ø¬Ø±Ø§ÛŒ Ù‡ÙØªÚ¯ÛŒ\n",
            "==================================================\n",
            "\n",
            "ğŸ“Š Ù…Ø±Ø­Ù„Ù‡ 1: Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§\n",
            "ğŸ“Š Ø´Ø±ÙˆØ¹ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§...\n",
            "ğŸ” Ø¯Ø±ÛŒØ§ÙØª Google Trends...\n",
            "âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ØªØ±Ù†Ø¯ Ø¨Ø±Ø§ÛŒ ['Ù…ÙˆØ¨Ø§ÛŒÙ„', 'Ú¯ÙˆØ´ÛŒ', 'Ù„Ù¾ ØªØ§Ù¾', 'Ú©Ø§Ù…Ù¾ÛŒÙˆØªØ±', 'ØªØ¨Ù„Øª']: The request failed: Google returned a response with code 400\n",
            "âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ØªØ±Ù†Ø¯ Ø¨Ø±Ø§ÛŒ ['Ù„Ø¨Ø§Ø³', 'Ú©ÙØ´', 'Ú©ÛŒÙ', 'Ø³Ø§Ø¹Øª', 'Ø¹Ø·Ø±']: The request failed: Google returned a response with code 400\n",
            "âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ØªØ±Ù†Ø¯ Ø¨Ø±Ø§ÛŒ ['Ú©ØªØ§Ø¨', 'ÙÛŒÙ„Ù…', 'Ø¨Ø§Ø²ÛŒ', 'Ù…ÙˆØ³ÛŒÙ‚ÛŒ', 'ØºØ°Ø§']: The request failed: Google returned a response with code 400\n",
            "âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ØªØ±Ù†Ø¯ Ø¨Ø±Ø§ÛŒ ['Ø±Ø³ØªÙˆØ±Ø§Ù†', 'Ø¢Ø´Ù¾Ø²ÛŒ', 'Ù†Ø§Ù†', 'Ø®Ø§Ù†Ù‡', 'Ø§Ø«Ø§Ø«ÛŒÙ‡']: The request failed: Google returned a response with code 400\n",
            "âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ØªØ±Ù†Ø¯ Ø¨Ø±Ø§ÛŒ ['Ø¯Ú©ÙˆØ±Ø§Ø³ÛŒÙˆÙ†', 'Ø¢Ø´Ù¾Ø²Ø®Ø§Ù†Ù‡', 'Ù…Ø§Ø´ÛŒÙ†', 'Ø®ÙˆØ¯Ø±Ùˆ', 'Ù…ÙˆØªÙˆØ±']: The request failed: Google returned a response with code 400\n",
            "âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ØªØ±Ù†Ø¯ Ø¨Ø±Ø§ÛŒ ['Ø¯ÙˆÚ†Ø±Ø®Ù‡', 'Ø³Ù„Ø§Ù…Øª', 'Ø¯Ø§Ø±Ùˆ', 'ÙˆØ±Ø²Ø´', 'ØªÙ†Ø§Ø³Ø¨ Ø§Ù†Ø¯Ø§Ù…']: The request failed: Google returned a response with code 400\n",
            "âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ØªØ±Ù†Ø¯ Ø¨Ø±Ø§ÛŒ ['Ø¢Ø±Ø§ÛŒØ´', 'Ø²ÛŒØ¨Ø§ÛŒÛŒ', 'Ù…Ø±Ø§Ù‚Ø¨Øª Ù¾ÙˆØ³Øª', 'Ø³ÙØ±', 'Ú¯Ø±Ø¯Ø´Ú¯Ø±ÛŒ']: The request failed: Google returned a response with code 400\n",
            "âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ØªØ±Ù†Ø¯ Ø¨Ø±Ø§ÛŒ ['Ù‡ØªÙ„', 'Ø¨Ù„ÛŒØ·', 'ØªØ­ØµÛŒÙ„', 'Ú©ÙˆØ±Ø³', 'Ø²Ø¨Ø§Ù†']: The request failed: Google returned a response with code 400\n",
            "âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ØªØ±Ù†Ø¯ Ø¨Ø±Ø§ÛŒ ['Ù…Ù‡Ø§Ø±Øª']: The request failed: Google returned a response with code 400\n",
            "ğŸ›’ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª...\n",
            "âœ… Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯:\n",
            "   - 0 Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡ ØªØ±Ù†Ø¯\n",
            "   - 50 Ù…Ø­ØµÙˆÙ„\n",
            "\n",
            "ğŸ§  Ù…Ø±Ø­Ù„Ù‡ 2: ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø§Ø±\n",
            "ğŸ§  Ø´Ø±ÙˆØ¹ ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø§Ø±...\n",
            "âœ… ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø§Ø± ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯\n",
            "\n",
            "ğŸ“ Ù…Ø±Ø­Ù„Ù‡ 3: ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§\n",
            "âœ… Ù†Ù…ÙˆØ¯Ø§Ø± Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯\n",
            "âœ… Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù†Ø¯\n",
            "\n",
            "ğŸ“¤ Ù…Ø±Ø­Ù„Ù‡ 4: Ø§Ø±Ø³Ø§Ù„ Ú¯Ø²Ø§Ø±Ø´ weekly\n",
            "âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ù†Ù…ÙˆØ¯Ø§Ø±: A request to the Telegram API was unsuccessful. Error code: 400. Description: Bad Request: PHOTO_INVALID_DIMENSIONS\n",
            "âœ… Ú¯Ø²Ø§Ø±Ø´ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯\n",
            "\n",
            "ğŸ‰ ØªØ­Ù„ÛŒÙ„ Ù‡ÙØªÚ¯ÛŒ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯!\n",
            "\n",
            "========================================\n",
            "ğŸ‡®ğŸ‡· Ø³ÛŒØ³ØªÙ… ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø§Ø± Ø§ÛŒØ±Ø§Ù†\n",
            "========================================\n",
            "1ï¸âƒ£ ØªØ­Ù„ÛŒÙ„ Ø±ÙˆØ²Ø§Ù†Ù‡\n",
            "2ï¸âƒ£ ØªØ­Ù„ÛŒÙ„ Ù‡ÙØªÚ¯ÛŒ\n",
            "3ï¸âƒ£ ØªØ­Ù„ÛŒÙ„ Ù…Ø§Ù‡Ø§Ù†Ù‡\n",
            "4ï¸âƒ£ Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø³ÛŒØ³ØªÙ…\n",
            "5ï¸âƒ£ ØªØ³Øª Ø§ØªØµØ§Ù„ ØªÙ„Ú¯Ø±Ø§Ù…\n",
            "6ï¸âƒ£ Ù†Ù…Ø§ÛŒØ´ Ú¯Ø²Ø§Ø±Ø´ Ø¯Ø± Ú©Ù†Ø³ÙˆÙ„\n",
            "0ï¸âƒ£ Ø®Ø±ÙˆØ¬\n",
            "----------------------------------------\n",
            "Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ù…Ø§: 3\n",
            "==================================================\n",
            "ğŸ‡®ğŸ‡· Ø³ÛŒØ³ØªÙ… ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø§Ø± Ø§ÛŒØ±Ø§Ù† - Ø§Ø¬Ø±Ø§ÛŒ Ù…Ø§Ù‡Ø§Ù†Ù‡\n",
            "==================================================\n",
            "\n",
            "ğŸ“Š Ù…Ø±Ø­Ù„Ù‡ 1: Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§\n",
            "ğŸ“Š Ø´Ø±ÙˆØ¹ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§...\n",
            "ğŸ” Ø¯Ø±ÛŒØ§ÙØª Google Trends...\n",
            "âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ØªØ±Ù†Ø¯ Ø¨Ø±Ø§ÛŒ ['Ù…ÙˆØ¨Ø§ÛŒÙ„', 'Ú¯ÙˆØ´ÛŒ', 'Ù„Ù¾ ØªØ§Ù¾', 'Ú©Ø§Ù…Ù¾ÛŒÙˆØªØ±', 'ØªØ¨Ù„Øª']: The request failed: Google returned a response with code 400\n",
            "âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ØªØ±Ù†Ø¯ Ø¨Ø±Ø§ÛŒ ['Ù„Ø¨Ø§Ø³', 'Ú©ÙØ´', 'Ú©ÛŒÙ', 'Ø³Ø§Ø¹Øª', 'Ø¹Ø·Ø±']: The request failed: Google returned a response with code 400\n",
            "âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ØªØ±Ù†Ø¯ Ø¨Ø±Ø§ÛŒ ['Ú©ØªØ§Ø¨', 'ÙÛŒÙ„Ù…', 'Ø¨Ø§Ø²ÛŒ', 'Ù…ÙˆØ³ÛŒÙ‚ÛŒ', 'ØºØ°Ø§']: The request failed: Google returned a response with code 400\n",
            "âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ØªØ±Ù†Ø¯ Ø¨Ø±Ø§ÛŒ ['Ø±Ø³ØªÙˆØ±Ø§Ù†', 'Ø¢Ø´Ù¾Ø²ÛŒ', 'Ù†Ø§Ù†', 'Ø®Ø§Ù†Ù‡', 'Ø§Ø«Ø§Ø«ÛŒÙ‡']: The request failed: Google returned a response with code 400\n",
            "âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ØªØ±Ù†Ø¯ Ø¨Ø±Ø§ÛŒ ['Ø¯Ú©ÙˆØ±Ø§Ø³ÛŒÙˆÙ†', 'Ø¢Ø´Ù¾Ø²Ø®Ø§Ù†Ù‡', 'Ù…Ø§Ø´ÛŒÙ†', 'Ø®ÙˆØ¯Ø±Ùˆ', 'Ù…ÙˆØªÙˆØ±']: The request failed: Google returned a response with code 400\n",
            "âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ØªØ±Ù†Ø¯ Ø¨Ø±Ø§ÛŒ ['Ø¯ÙˆÚ†Ø±Ø®Ù‡', 'Ø³Ù„Ø§Ù…Øª', 'Ø¯Ø§Ø±Ùˆ', 'ÙˆØ±Ø²Ø´', 'ØªÙ†Ø§Ø³Ø¨ Ø§Ù†Ø¯Ø§Ù…']: The request failed: Google returned a response with code 400\n",
            "âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ØªØ±Ù†Ø¯ Ø¨Ø±Ø§ÛŒ ['Ø¢Ø±Ø§ÛŒØ´', 'Ø²ÛŒØ¨Ø§ÛŒÛŒ', 'Ù…Ø±Ø§Ù‚Ø¨Øª Ù¾ÙˆØ³Øª', 'Ø³ÙØ±', 'Ú¯Ø±Ø¯Ø´Ú¯Ø±ÛŒ']: The request failed: Google returned a response with code 400\n",
            "âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ØªØ±Ù†Ø¯ Ø¨Ø±Ø§ÛŒ ['Ù‡ØªÙ„', 'Ø¨Ù„ÛŒØ·', 'ØªØ­ØµÛŒÙ„', 'Ú©ÙˆØ±Ø³', 'Ø²Ø¨Ø§Ù†']: The request failed: Google returned a response with code 400\n",
            "âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ØªØ±Ù†Ø¯ Ø¨Ø±Ø§ÛŒ ['Ù…Ù‡Ø§Ø±Øª']: The request failed: Google returned a response with code 400\n",
            "ğŸ›’ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª...\n",
            "âœ… Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯:\n",
            "   - 0 Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡ ØªØ±Ù†Ø¯\n",
            "   - 50 Ù…Ø­ØµÙˆÙ„\n",
            "\n",
            "ğŸ§  Ù…Ø±Ø­Ù„Ù‡ 2: ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø§Ø±\n",
            "ğŸ§  Ø´Ø±ÙˆØ¹ ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø§Ø±...\n",
            "âœ… ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø§Ø± ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯\n",
            "\n",
            "ğŸ“ Ù…Ø±Ø­Ù„Ù‡ 3: ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§\n",
            "âœ… Ù†Ù…ÙˆØ¯Ø§Ø± Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯\n",
            "âœ… Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù†Ø¯\n",
            "\n",
            "ğŸ“¤ Ù…Ø±Ø­Ù„Ù‡ 4: Ø§Ø±Ø³Ø§Ù„ Ú¯Ø²Ø§Ø±Ø´ monthly\n",
            "âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ù†Ù…ÙˆØ¯Ø§Ø±: A request to the Telegram API was unsuccessful. Error code: 400. Description: Bad Request: PHOTO_INVALID_DIMENSIONS\n",
            "âœ… Ú¯Ø²Ø§Ø±Ø´ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯\n",
            "\n",
            "ğŸ‰ ØªØ­Ù„ÛŒÙ„ Ù…Ø§Ù‡Ø§Ù†Ù‡ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯!\n",
            "\n",
            "========================================\n",
            "ğŸ‡®ğŸ‡· Ø³ÛŒØ³ØªÙ… ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø§Ø± Ø§ÛŒØ±Ø§Ù†\n",
            "========================================\n",
            "1ï¸âƒ£ ØªØ­Ù„ÛŒÙ„ Ø±ÙˆØ²Ø§Ù†Ù‡\n",
            "2ï¸âƒ£ ØªØ­Ù„ÛŒÙ„ Ù‡ÙØªÚ¯ÛŒ\n",
            "3ï¸âƒ£ ØªØ­Ù„ÛŒÙ„ Ù…Ø§Ù‡Ø§Ù†Ù‡\n",
            "4ï¸âƒ£ Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø³ÛŒØ³ØªÙ…\n",
            "5ï¸âƒ£ ØªØ³Øª Ø§ØªØµØ§Ù„ ØªÙ„Ú¯Ø±Ø§Ù…\n",
            "6ï¸âƒ£ Ù†Ù…Ø§ÛŒØ´ Ú¯Ø²Ø§Ø±Ø´ Ø¯Ø± Ú©Ù†Ø³ÙˆÙ„\n",
            "0ï¸âƒ£ Ø®Ø±ÙˆØ¬\n",
            "----------------------------------------\n",
            "Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ù…Ø§: 4\n",
            "\n",
            "ğŸ” Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø³ÛŒØ³ØªÙ…:\n",
            "   âœ… google_trends\n",
            "   âœ… text_processing\n",
            "   âœ… charts\n",
            "   âœ… machine_learning\n",
            "   âœ… telegram\n",
            "   âœ… web_scraping\n",
            "\n",
            "========================================\n",
            "ğŸ‡®ğŸ‡· Ø³ÛŒØ³ØªÙ… ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø§Ø± Ø§ÛŒØ±Ø§Ù†\n",
            "========================================\n",
            "1ï¸âƒ£ ØªØ­Ù„ÛŒÙ„ Ø±ÙˆØ²Ø§Ù†Ù‡\n",
            "2ï¸âƒ£ ØªØ­Ù„ÛŒÙ„ Ù‡ÙØªÚ¯ÛŒ\n",
            "3ï¸âƒ£ ØªØ­Ù„ÛŒÙ„ Ù…Ø§Ù‡Ø§Ù†Ù‡\n",
            "4ï¸âƒ£ Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø³ÛŒØ³ØªÙ…\n",
            "5ï¸âƒ£ ØªØ³Øª Ø§ØªØµØ§Ù„ ØªÙ„Ú¯Ø±Ø§Ù…\n",
            "6ï¸âƒ£ Ù†Ù…Ø§ÛŒØ´ Ú¯Ø²Ø§Ø±Ø´ Ø¯Ø± Ú©Ù†Ø³ÙˆÙ„\n",
            "0ï¸âƒ£ Ø®Ø±ÙˆØ¬\n",
            "----------------------------------------\n",
            "Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ù…Ø§: 6\n",
            "\n",
            "ğŸ“Š Ú©Ø¯Ø§Ù… Ú¯Ø²Ø§Ø±Ø´ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ø´ÙˆØ¯ØŸ\n",
            "1. Ø±ÙˆØ²Ø§Ù†Ù‡\n",
            "2. Ù‡ÙØªÚ¯ÛŒ\n",
            "3. Ù…Ø§Ù‡Ø§Ù†Ù‡\n",
            "Ø§Ù†ØªØ®Ø§Ø¨: 1\n",
            "\n",
            "==================================================\n",
            "\n",
            "ğŸ”¥ Ú¯Ø²Ø§Ø±Ø´ Ø±ÙˆØ²Ø§Ù†Ù‡ Ø¨Ø§Ø²Ø§Ø± Ø§ÛŒØ±Ø§Ù†\n",
            "ğŸ“… ØªØ§Ø±ÛŒØ®: 1404/05/05 - 08:53\n",
            "\n",
            "ğŸ“ˆ ØªØ±Ù†Ø¯Ù‡Ø§ÛŒ Ø¯Ø§Øº Ø§Ù…Ø±ÙˆØ²:\n",
            "\n",
            "ğŸš€ ØªØ±Ù†Ø¯Ù‡Ø§ÛŒ Ø¯Ø± Ø­Ø§Ù„ Ø±Ø´Ø¯:\n",
            "\n",
            "ğŸ“Š ÙˆØ¶Ø¹ÛŒØª Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§:\n",
            "ğŸŸ  ØªÚ©Ù†ÙˆÙ„ÙˆÚ˜ÛŒ: 0 (Ø¶Ø¹ÛŒÙ)\n",
            "ğŸŸ  Ù¾ÙˆØ´Ø§Ú©: 0 (Ø¶Ø¹ÛŒÙ)\n",
            "ğŸŸ  Ø²ÛŒØ¨Ø§ÛŒÛŒ: 0 (Ø¶Ø¹ÛŒÙ)\n",
            "ğŸŸ  Ø®Ø§Ù†Ù‡: 0 (Ø¶Ø¹ÛŒÙ)\n",
            "ğŸŸ  Ø®ÙˆØ¯Ø±Ùˆ: 0 (Ø¶Ø¹ÛŒÙ)\n",
            "\n",
            "ğŸ’¡ ÙØ±ØµØªâ€ŒÙ‡Ø§ÛŒ Ø§Ù…Ø±ÙˆØ²:\n",
            "\n",
            "ğŸ“‹ Ø®Ù„Ø§ØµÙ‡ Ø¢Ù…Ø§Ø±:\n",
            "â€¢ ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ Ø´Ø¯Ù‡: 0\n",
            "â€¢ ØªØ¹Ø¯Ø§Ø¯ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ÛŒ ÙØ¹Ø§Ù„: 0\n",
            "â€¢ ØªØ¹Ø¯Ø§Ø¯ ÙØ±ØµØªâ€ŒÙ‡Ø§ÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯Ù‡: 0\n",
            "\n",
            "==================================================\n",
            "\n",
            "========================================\n",
            "ğŸ‡®ğŸ‡· Ø³ÛŒØ³ØªÙ… ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø§Ø± Ø§ÛŒØ±Ø§Ù†\n",
            "========================================\n",
            "1ï¸âƒ£ ØªØ­Ù„ÛŒÙ„ Ø±ÙˆØ²Ø§Ù†Ù‡\n",
            "2ï¸âƒ£ ØªØ­Ù„ÛŒÙ„ Ù‡ÙØªÚ¯ÛŒ\n",
            "3ï¸âƒ£ ØªØ­Ù„ÛŒÙ„ Ù…Ø§Ù‡Ø§Ù†Ù‡\n",
            "4ï¸âƒ£ Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø³ÛŒØ³ØªÙ…\n",
            "5ï¸âƒ£ ØªØ³Øª Ø§ØªØµØ§Ù„ ØªÙ„Ú¯Ø±Ø§Ù…\n",
            "6ï¸âƒ£ Ù†Ù…Ø§ÛŒØ´ Ú¯Ø²Ø§Ø±Ø´ Ø¯Ø± Ú©Ù†Ø³ÙˆÙ„\n",
            "0ï¸âƒ£ Ø®Ø±ÙˆØ¬\n",
            "----------------------------------------\n"
          ]
        }
      ]
    }
  ]
}