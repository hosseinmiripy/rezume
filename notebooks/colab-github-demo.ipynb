{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hosseinmiripy/rezume/blob/main/notebooks/colab-github-demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ù†ØµØ¨ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ Ø¯Ø± Google Colab\n",
        "!pip install ccxt\n",
        "!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install matplotlib\n",
        "!pip install scikit-learn\n",
        "!pip install pmdarima\n",
        "!pip install xgboost\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRdf6D4QZagg",
        "outputId": "8c1db55e-2fae-4a3b-a450-7ba85f73a899"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ccxt\n",
            "  Using cached ccxt-4.4.50-py2.py3-none-any.whl.metadata (117 kB)\n",
            "Requirement already satisfied: setuptools>=60.9.0 in /usr/local/lib/python3.11/dist-packages (from ccxt) (75.1.0)\n",
            "Requirement already satisfied: certifi>=2018.1.18 in /usr/local/lib/python3.11/dist-packages (from ccxt) (2024.12.14)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.11/dist-packages (from ccxt) (2.32.3)\n",
            "Requirement already satisfied: cryptography>=2.6.1 in /usr/local/lib/python3.11/dist-packages (from ccxt) (43.0.3)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from ccxt) (4.12.2)\n",
            "Collecting aiohttp<=3.10.11 (from ccxt)\n",
            "  Downloading aiohttp-3.10.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting aiodns>=1.1.1 (from ccxt)\n",
            "  Downloading aiodns-3.2.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: yarl>=1.7.2 in /usr/local/lib/python3.11/dist-packages (from ccxt) (1.18.3)\n",
            "Collecting pycares>=4.0.0 (from aiodns>=1.1.1->ccxt)\n",
            "  Downloading pycares-4.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<=3.10.11->ccxt) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<=3.10.11->ccxt) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<=3.10.11->ccxt) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<=3.10.11->ccxt) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<=3.10.11->ccxt) (6.1.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=2.6.1->ccxt) (1.17.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.18.4->ccxt) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.18.4->ccxt) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.18.4->ccxt) (2.3.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from yarl>=1.7.2->ccxt) (0.2.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=2.6.1->ccxt) (2.22)\n",
            "Downloading ccxt-4.4.50-py2.py3-none-any.whl (5.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiodns-3.2.0-py3-none-any.whl (5.7 kB)\n",
            "Downloading aiohttp-3.10.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycares-4.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m288.6/288.6 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pycares, aiohttp, aiodns, ccxt\n",
            "  Attempting uninstall: aiohttp\n",
            "    Found existing installation: aiohttp 3.11.11\n",
            "    Uninstalling aiohttp-3.11.11:\n",
            "      Successfully uninstalled aiohttp-3.11.11\n",
            "Successfully installed aiodns-3.2.0 aiohttp-3.10.11 ccxt-4.4.50 pycares-4.5.0\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Collecting pmdarima\n",
            "  Downloading pmdarima-2.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.11/dist-packages (from pmdarima) (1.4.2)\n",
            "Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in /usr/local/lib/python3.11/dist-packages (from pmdarima) (3.0.11)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from pmdarima) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.11/dist-packages (from pmdarima) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.11/dist-packages (from pmdarima) (1.6.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from pmdarima) (1.13.1)\n",
            "Requirement already satisfied: statsmodels>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from pmdarima) (0.14.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (from pmdarima) (2.3.0)\n",
            "Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in /usr/local/lib/python3.11/dist-packages (from pmdarima) (75.1.0)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.11/dist-packages (from pmdarima) (24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.19->pmdarima) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.19->pmdarima) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.19->pmdarima) (2024.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22->pmdarima) (3.5.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.13.2->pmdarima) (1.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=0.19->pmdarima) (1.17.0)\n",
            "Downloading pmdarima-2.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pmdarima\n",
            "Successfully installed pmdarima-2.0.4\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.26.4)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.13.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ccxt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "import threading\n",
        "import time\n",
        "import os\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from pmdarima import auto_arima\n",
        "from multiprocessing import Pool\n",
        "import threading\n",
        "import time\n",
        "from multiprocessing import Pool\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random"
      ],
      "metadata": {
        "id": "aobdoen0ZgZG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- ØªÙ†Ø¸ÛŒÙ…Ø§Øª ØªÙ„Ú¯Ø±Ø§Ù… ---\n",
        "TELEGRAM_API_TOKEN = '7989027484:AAHtz4q396jSU2XmGMDOW27vjkmsDvN0i8w'\n",
        "CHANNEL_ID = '@hosseinbtb'\n",
        "\n",
        "# --- Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… Ø¨Ù‡ ØªÙ„Ú¯Ø±Ø§Ù… ---\n",
        "# def send_message_to_telegram(message):\n",
        "#     url = f'https://api.telegram.org/bot{TELEGRAM_API_TOKEN}/sendMessage'\n",
        "#     payload = {'chat_id': CHANNEL_ID, 'text': message, 'parse_mode': 'Markdown'}\n",
        "#     response = requests.post(url, data=payload)\n",
        "#     return response\n",
        "def send_message_to_telegram(message):\n",
        "    # Ú†Ú© Ú©Ø±Ø¯Ù† ÙˆØ¬ÙˆØ¯ Ú©Ù„Ù…Ù‡ \"ØªØ§ÛŒÙ… ÙØ±ÛŒÙ…\" Ø¯Ø± Ù…ØªÙ†\n",
        "    if 'ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…' in message:\n",
        "        url = f'https://api.telegram.org/bot{TELEGRAM_API_TOKEN}/sendMessage'\n",
        "        payload = {'chat_id': CHANNEL_ID, 'text': message, 'parse_mode': 'Markdown'}\n",
        "        response = requests.post(url, data=payload)\n",
        "        return response\n",
        "    else:\n",
        "        print(\"Ú©Ù„Ù…Ù‡ 'ØªØ§ÛŒÙ… ÙØ±ÛŒÙ…' Ø¯Ø± Ù…ØªÙ† Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª. Ù‡ÛŒÚ† Ù¾ÛŒØ§Ù…ÛŒ Ø§Ø±Ø³Ø§Ù„ Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯.\")\n",
        "        return None\n",
        "# --- Ø§Ø±Ø³Ø§Ù„ Ù†Ù…ÙˆØ¯Ø§Ø± Ø¨Ù‡ ØªÙ„Ú¯Ø±Ø§Ù… ---\n",
        "def send_chart_to_telegram(chart_path):\n",
        "    url = f'https://api.telegram.org/bot{TELEGRAM_API_TOKEN}/sendPhoto'\n",
        "    payload = {'chat_id': CHANNEL_ID}\n",
        "    files = {'photo': open(chart_path, 'rb')}\n",
        "    response = requests.post(url, data=payload, files=files)\n",
        "    return response\n",
        "\n",
        "def calculate_rsi(df, period=14):\n",
        "    delta = df['close'].diff()\n",
        "    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
        "    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
        "    rs = gain / loss\n",
        "    rsi = 100 - (100 / (1 + rs))\n",
        "    return rsi\n",
        "\n",
        "def calculate_market_trend(df):\n",
        "    df['MA_50'] = df['close'].rolling(window=50).mean()\n",
        "    df['MA_200'] = df['close'].rolling(window=200).mean()\n",
        "    rsi = calculate_rsi(df)\n",
        "\n",
        "    if df['MA_50'].iloc[-1] > df['MA_200'].iloc[-1] and rsi.iloc[-1] < 70:\n",
        "        return \"ØµØ¹ÙˆØ¯ÛŒ\"\n",
        "    elif df['MA_50'].iloc[-1] < df['MA_200'].iloc[-1] and rsi.iloc[-1] > 30:\n",
        "        return \"Ù†Ø²ÙˆÙ„ÛŒ\"\n",
        "    return \"Ø®Ù†Ø«ÛŒ\"\n",
        "\n",
        "\n",
        "def calculate_correlation(main_df, alt_df):\n",
        "    \"\"\"\n",
        "    Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ Ø¨ÛŒÙ† Ø¨ÛŒØªâ€ŒÚ©ÙˆÛŒÙ† Ùˆ Ø§Ø±Ø² Ø¯ÛŒÚ¯Ø±\n",
        "    \"\"\"\n",
        "    main_df = main_df['close'].pct_change()\n",
        "    alt_df = alt_df['close'].pct_change()\n",
        "    correlation = main_df.corr(alt_df)\n",
        "    return correlation\n",
        "\n",
        "def integrate_market_trend(symbol, df, market_trend):\n",
        "    signal = \"\"\n",
        "    if market_trend == \"ØµØ¹ÙˆØ¯ÛŒ\":\n",
        "        signal += f\"ğŸ“ˆ Ø¨Ø§Ø²Ø§Ø± Ú©Ù„ÛŒ ØµØ¹ÙˆØ¯ÛŒ Ø§Ø³Øª. Ø§Ø­ØªÙ…Ø§Ù„ Ø³ÙˆØ¯Ø¢ÙˆØ±ÛŒ Ø®Ø±ÛŒØ¯ Ø¨ÛŒØ´ØªØ± Ø§Ø³Øª.\\n\"\n",
        "    elif market_trend == \"Ù†Ø²ÙˆÙ„ÛŒ\":\n",
        "        signal += f\"ğŸ“‰ Ø¨Ø§Ø²Ø§Ø± Ú©Ù„ÛŒ Ù†Ø²ÙˆÙ„ÛŒ Ø§Ø³Øª. Ø§Ø­ØªÙ…Ø§Ù„ Ø³ÙˆØ¯Ø¢ÙˆØ±ÛŒ ÙØ±ÙˆØ´ Ø¨ÛŒØ´ØªØ± Ø§Ø³Øª.\\n\"\n",
        "    else:\n",
        "        signal += f\"ğŸ” Ø¨Ø§Ø²Ø§Ø± Ø®Ù†Ø«ÛŒ Ø§Ø³Øª. Ø§Ø­ØªÛŒØ§Ø· Ú©Ù†ÛŒØ¯.\\n\"\n",
        "    return signal\n",
        "\n",
        "def fetch_market_sentiment():\n",
        "    try:\n",
        "        response = requests.get(\"https://api.alternative.me/fng/\", timeout=10)\n",
        "        data = response.json()\n",
        "        sentiment = data['data'][0]['value_classification']\n",
        "        return f\"ğŸŒŸ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ø¨Ø§Ø²Ø§Ø±: {sentiment}\"\n",
        "    except requests.exceptions.RequestException:\n",
        "        return \"âš ï¸ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§Ø­Ø³Ø§Ø³Ø§Øª Ø¨Ø§Ø²Ø§Ø± Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª.\"\n",
        "\n",
        "def generate_signal_with_trend(df, fibonacci_levels, symbol, market_trend):\n",
        "    \"\"\"\n",
        "    ØªÙˆÙ„ÛŒØ¯ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø¨Ø§ Ø¯Ø± Ù†Ø¸Ø± Ú¯Ø±ÙØªÙ† Ø±ÙˆÙ†Ø¯ Ø¨Ø§Ø²Ø§Ø±\n",
        "    \"\"\"\n",
        "    price = df['close'].iloc[-1]\n",
        "    signal = f\"ğŸ” ØªØ­Ù„ÛŒÙ„ {symbol}:\\n\"\n",
        "    signal += f\"ğŸ“ˆ Ø±ÙˆÙ†Ø¯ Ú©Ù„ÛŒ Ø¨Ø§Ø²Ø§Ø±: {market_trend}\\n\"\n",
        "\n",
        "    for level, value in fibonacci_levels.items():\n",
        "        if abs(price - value) < 0.02 * price:\n",
        "            if market_trend == \"ØµØ¹ÙˆØ¯ÛŒ\":\n",
        "                signal += f\"ğŸ“ˆ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø®Ø±ÛŒØ¯: Ù‚ÛŒÙ…Øª Ù†Ø²Ø¯ÛŒÚ© Ø¨Ù‡ Ø³Ø·Ø­ ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ {level}\\n\"\n",
        "            elif market_trend == \"Ù†Ø²ÙˆÙ„ÛŒ\":\n",
        "                signal += f\"ğŸ“‰ Ø³ÛŒÚ¯Ù†Ø§Ù„ ÙØ±ÙˆØ´: Ù‚ÛŒÙ…Øª Ù†Ø²Ø¯ÛŒÚ© Ø¨Ù‡ Ø³Ø·Ø­ ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ {level}\\n\"\n",
        "    return signal\n",
        "\n",
        "# --- Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ ---\n",
        "def fetch_data(symbol, timeframe, limit=1000, max_retries=5, delay=2):\n",
        "    \"\"\"\n",
        "    Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø§ ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯ Ø¯Ø± ØµÙˆØ±Øª Ø¨Ø±ÙˆØ² Ø®Ø·Ø§ÛŒ Ø²Ù…Ø§Ù† Ù¾Ø§Ø³Ø®Ú¯ÙˆÛŒÛŒ\n",
        "    \"\"\"\n",
        "    exchange = ccxt.kucoin()\n",
        "    retries = 0\n",
        "    while retries < max_retries:\n",
        "        try:\n",
        "            ohlcv = exchange.fetch_ohlcv(symbol, timeframe=timeframe, limit=limit)\n",
        "            df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n",
        "            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
        "            df.set_index('timestamp', inplace=True)\n",
        "            return df\n",
        "        except ccxt.RequestTimeout as e:\n",
        "            print(f\"âš ï¸ Ø®Ø·Ø§ÛŒ Ø²Ù…Ø§Ù† Ù¾Ø§Ø³Ø®Ú¯ÙˆÛŒÛŒ Ø¨Ø±Ø§ÛŒ {symbol} Ø¯Ø± ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ… {timeframe}. ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯... ({retries + 1}/{max_retries})\")\n",
        "            retries += 1\n",
        "            time.sleep(delay + random.uniform(0, 1))  # ØªØ§Ø®ÛŒØ± Ø¨Ø§ Ø²Ù…Ø§Ù† ØªØµØ§Ø¯ÙÛŒ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ù‡Ø´ ÙØ´Ø§Ø± Ø±ÙˆÛŒ API\n",
        "        except Exception as e:\n",
        "            print(f\"ğŸš¨ Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡ Ø¨Ø±Ø§ÛŒ {symbol}: {e}\")\n",
        "            break\n",
        "\n",
        "    print(f\"âŒ ØªÙ„Ø§Ø´â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ {symbol} Ø¯Ø± ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ… {timeframe} Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯.\")\n",
        "    return None\n",
        "\n",
        "\n",
        "# --- Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø³Ø·ÙˆØ­ ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ ---\n",
        "def calculate_fibonacci_levels(df):\n",
        "    high_price = df['high'].max()\n",
        "    low_price = df['low'].min()\n",
        "    diff = high_price - low_price\n",
        "\n",
        "    # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ù†ÙˆØ³Ø§Ù† Ø¨Ø§Ø²Ø§Ø± Ú©Ø§ÙÛŒ Ø¨Ø§Ø´Ø¯\n",
        "    if diff < (high_price * 0.01):  # Ø§Ú¯Ø± ØªØºÛŒÛŒØ± Ù‚ÛŒÙ…Øª Ú©Ù…ØªØ± Ø§Ø² 1% Ø¨Ø§Ø´Ø¯\n",
        "        return {}\n",
        "\n",
        "    levels = {\n",
        "        '0%': high_price,\n",
        "        '23.6%': high_price - 0.236 * diff,\n",
        "        '38.2%': high_price - 0.382 * diff,\n",
        "        '50%': high_price - 0.5 * diff,\n",
        "        '61.8%': high_price - 0.618 * diff,\n",
        "        '100%': low_price\n",
        "    }\n",
        "    return levels\n",
        "\n",
        "# --- Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù¾Ø±Ø§ÛŒØ³ Ø§Ú©Ø´Ù† Ù…ÙˆÙÙ‚ ---\n",
        "def identify_price_action_pattern(df):\n",
        "    # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Pin Bar ØµØ¹ÙˆØ¯ÛŒ Ùˆ Ù†Ø²ÙˆÙ„ÛŒ\n",
        "    def is_pin_bar(df, i):\n",
        "        body = abs(df['open'].iloc[i] - df['close'].iloc[i])\n",
        "        upper_wick = df['high'].iloc[i] - max(df['open'].iloc[i], df['close'].iloc[i])\n",
        "        lower_wick = min(df['open'].iloc[i], df['close'].iloc[i]) - df['low'].iloc[i]\n",
        "\n",
        "        # Ø´Ø±Ø§ÛŒØ· Ø¨Ø±Ø§ÛŒ Pin Bar\n",
        "        if body < upper_wick and lower_wick > 2 * body:\n",
        "            return \"Pin Bar ØµØ¹ÙˆØ¯ÛŒ\" if df['close'].iloc[i] > df['open'].iloc[i] else \"Pin Bar Ù†Ø²ÙˆÙ„ÛŒ\"\n",
        "        return None\n",
        "\n",
        "    # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Engulfing\n",
        "    def is_engulfing(df, i):\n",
        "        if df['close'].iloc[i] > df['open'].iloc[i] and df['open'].iloc[i - 1] > df['close'].iloc[i - 1] and \\\n",
        "                df['close'].iloc[i] > df['open'].iloc[i - 1] and df['open'].iloc[i] < df['close'].iloc[i - 1]:\n",
        "            return \"Engulfing ØµØ¹ÙˆØ¯ÛŒ\"\n",
        "        elif df['close'].iloc[i] < df['open'].iloc[i] and df['open'].iloc[i - 1] < df['close'].iloc[i - 1] and \\\n",
        "                df['close'].iloc[i] < df['open'].iloc[i - 1] and df['open'].iloc[i] > df['close'].iloc[i - 1]:\n",
        "            return \"Engulfing Ù†Ø²ÙˆÙ„ÛŒ\"\n",
        "        return None\n",
        "\n",
        "    # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Doji\n",
        "    def is_doji(df, i):\n",
        "        body = abs(df['open'].iloc[i] - df['close'].iloc[i])\n",
        "        upper_wick = df['high'].iloc[i] - max(df['open'].iloc[i], df['close'].iloc[i])\n",
        "        lower_wick = min(df['open'].iloc[i], df['close'].iloc[i]) - df['low'].iloc[i]\n",
        "\n",
        "        # Ø´Ø±Ø§ÛŒØ· Ø¨Ø±Ø§ÛŒ Doji\n",
        "        if body <= (upper_wick + lower_wick) * 0.1:\n",
        "            return \"Doji\"\n",
        "        return None\n",
        "\n",
        "    for i in range(1, len(df)):\n",
        "        pin_bar = is_pin_bar(df, i)\n",
        "        engulfing = is_engulfing(df, i)\n",
        "        doji = is_doji(df, i)\n",
        "\n",
        "        # Ø§Ú¯Ø± Ø§Ù„Ú¯ÙˆÛŒ Ù…Ø´Ø®ØµÛŒ Ù¾ÛŒØ¯Ø§ Ø´Ø¯ØŒ Ø¢Ù† Ø±Ø§ Ø¨Ø§Ø² Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†ÛŒÙ…\n",
        "        if pin_bar:\n",
        "            return pin_bar\n",
        "        elif engulfing:\n",
        "            return engulfing\n",
        "        elif doji:\n",
        "            return doji\n",
        "\n",
        "    return None\n",
        "\n",
        "# --- ØªØ­Ù„ÛŒÙ„ Ø­Ø¬Ù… Ù…Ø¹Ø§Ù…Ù„Ø§Øª ---\n",
        "def analyze_volume(df):\n",
        "    avg_volume = df['volume'].mean()\n",
        "    last_volume = df['volume'].iloc[-1]\n",
        "\n",
        "    # ØªØ­Ù„ÛŒÙ„ Ø­Ø¬Ù… Ù…Ø¹Ø§Ù…Ù„Ø§Øª\n",
        "    if last_volume > avg_volume * 1.5:  # Ø­Ø¬Ù… Ø¨Ø§Ù„Ø§\n",
        "        return \"Ø­Ø¬Ù… Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø¨Ø§Ù„Ø§\"\n",
        "    elif last_volume < avg_volume * 0.5:  # Ø­Ø¬Ù… Ù¾Ø§ÛŒÛŒÙ†\n",
        "        return \"Ø­Ø¬Ù… Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ù¾Ø§ÛŒÛŒÙ†\"\n",
        "    return \"Ø­Ø¬Ù… Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø¹Ø§Ø¯ÛŒ\"\n",
        "\n",
        "# Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù…Ø§Ú˜ÙˆÙ„â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯\n",
        "def fetch_order_book(symbol):\n",
        "    exchange = ccxt.kucoin()\n",
        "    order_book = exchange.fetch_order_book(symbol)\n",
        "    return order_book\n",
        "\n",
        "def analyze_order_book(order_book):\n",
        "    large_bid_orders = [order for order in order_book['bids'] if order[1] > 100]\n",
        "    large_ask_orders = [order for order in order_book['asks'] if order[1] > 100]\n",
        "\n",
        "    if len(large_bid_orders) > len(large_ask_orders):\n",
        "        return \"Ø®Ø±ÛŒØ¯ Ù†Ù‡Ù†Ú¯ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯ (Ø³ÙØ§Ø±Ø´â€ŒÙ‡Ø§ÛŒ Ø¨Ø²Ø±Ú¯ Ø®Ø±ÛŒØ¯)\"\n",
        "    elif len(large_ask_orders) > len(large_bid_orders):\n",
        "        return \"ÙØ±ÙˆØ´ Ù†Ù‡Ù†Ú¯ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯ (Ø³ÙØ§Ø±Ø´â€ŒÙ‡Ø§ÛŒ Ø¨Ø²Ø±Ú¯ ÙØ±ÙˆØ´)\"\n",
        "    return \"Ø³ÙØ§Ø±Ø´â€ŒÙ‡Ø§ÛŒ Ø¹Ø§Ø¯ÛŒ\"\n",
        "\n",
        "def calculate_vwap(df):\n",
        "    cumulative_price_volume = (df['close'] * df['volume']).cumsum()\n",
        "    cumulative_volume = df['volume'].cumsum()\n",
        "    vwap = cumulative_price_volume / cumulative_volume\n",
        "    return vwap.iloc[-1]\n",
        "\n",
        "def calculate_obv(df):\n",
        "    obv = [0]\n",
        "    for i in range(1, len(df)):\n",
        "        if df['close'].iloc[i] > df['close'].iloc[i-1]:\n",
        "            obv.append(obv[-1] + df['volume'].iloc[i])\n",
        "        elif df['close'].iloc[i] < df['close'].iloc[i-1]:\n",
        "            obv.append(obv[-1] - df['volume'].iloc[i])\n",
        "        else:\n",
        "            obv.append(obv[-1])\n",
        "    return obv[-1]\n",
        "\n",
        "def analyze_on_chain_data():\n",
        "    try:\n",
        "        response = requests.get(\"https://api.some-onchain-data-provider.com/large-transactions\", timeout=10)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        large_transactions = [tx for tx in data if tx['value'] > 1000000]\n",
        "        if large_transactions:\n",
        "            return f\"ğŸš¨ ØªØ±Ø§Ú©Ù†Ø´â€ŒÙ‡Ø§ÛŒ Ø¨Ø²Ø±Ú¯ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯: {len(large_transactions)} ØªØ±Ø§Ú©Ù†Ø´\"\n",
        "        return \"ØªØ±Ø§Ú©Ù†Ø´â€ŒÙ‡Ø§ÛŒ Ø¹Ø§Ø¯ÛŒ\"\n",
        "    except requests.exceptions.RequestException:\n",
        "        return \"âš ï¸ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø²Ù†Ø¬ÛŒØ±Ù‡â€ŒØ§ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª.\"\n",
        "\n",
        "\n",
        "def analyze_order_flow(df):\n",
        "    avg_price_change = df['close'] - df['open']\n",
        "    order_flow = \"Ø®Ù†Ø«ÛŒ\"\n",
        "    if avg_price_change.iloc[-1] > 0:\n",
        "        order_flow = \"Ø¬Ø±ÛŒØ§Ù† Ø®Ø±ÛŒØ¯\"\n",
        "    elif avg_price_change.iloc[-1] < 0:\n",
        "        order_flow = \"Ø¬Ø±ÛŒØ§Ù† ÙØ±ÙˆØ´\"\n",
        "    return order_flow\n",
        "\n",
        "# --- Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ ØªØ­Ù„ÛŒÙ„ Ùˆ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ ---\n",
        "def analyze_and_predict(symbol, timeframe, account_balance, use_market_trend=False):\n",
        "    df = fetch_data(symbol, timeframe)\n",
        "    if df is None:\n",
        "        print(f\"âŒ Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ {symbol} Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯.\")\n",
        "        return\n",
        "\n",
        "\n",
        "    fibonacci_levels = calculate_fibonacci_levels(df)\n",
        "    order_book = fetch_order_book(symbol)  # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯ÙØªØ± Ø³ÙØ§Ø±Ø´\n",
        "    whale_activity = detect_whale_activity(df)\n",
        "\n",
        "    # Ø§Ù†ØªØ®Ø§Ø¨ Ù†ÙˆØ¹ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¢Ø±Ú¯ÙˆÙ…Ø§Ù†\n",
        "    if use_market_trend:\n",
        "        market_trend = calculate_market_trend(df)\n",
        "        signal = generate_signal_with_trend(df, fibonacci_levels, symbol, market_trend)\n",
        "    else:\n",
        "        signal = generate_signal(df, fibonacci_levels, symbol, order_book)\n",
        "\n",
        "    # Ø§Ø±Ø³Ø§Ù„ ØªØ­Ù„ÛŒÙ„ Ø¨Ù‡ ØªÙ„Ú¯Ø±Ø§Ù…\n",
        "    if whale_activity:\n",
        "        send_message_to_telegram(f\"ğŸ” {whale_activity}\\nÙ†Ù…Ø§Ø¯: {symbol} | ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…: {timeframe}\")\n",
        "    if signal and signal != \"Ù‡ÛŒÚ† Ø³ÛŒÚ¯Ù†Ø§Ù„ÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù†Ø´Ø¯.\":\n",
        "        plot_and_send_chart(df, fibonacci_levels, signal, timeframe, symbol)\n",
        "\n",
        "# Ú©Ø¯Ù‡Ø§ÛŒ Ø¯ÛŒÚ¯Ø± Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ± Ø¨Ø§Ù‚ÛŒ Ù…ÛŒâ€ŒÙ…Ø§Ù†Ù†Ø¯\n",
        "def generate_signal(df, fibonacci_levels, symbol, order_book, timeframe):\n",
        "    signal = f\"ğŸ” ØªØ­Ù„ÛŒÙ„ {symbol}:\\n\"\n",
        "\n",
        "    price = df['close'].iloc[-1]\n",
        "    pattern = identify_price_action_pattern(df)  # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ù¾Ø±Ø§ÛŒØ³ Ø§Ú©Ø´Ù†\n",
        "    volume_analysis = analyze_volume(df)  # ØªØ­Ù„ÛŒÙ„ Ø­Ø¬Ù… Ù…Ø¹Ø§Ù…Ù„Ø§Øª\n",
        "    order_book_analysis = analyze_order_book(order_book)  # ØªØ­Ù„ÛŒÙ„ Ø¯ÙØªØ± Ø³ÙØ§Ø±Ø´\n",
        "    order_flow = analyze_order_flow(df)  # ØªØ­Ù„ÛŒÙ„ Ø¬Ø±ÛŒØ§Ù† Ø³ÙØ§Ø±Ø´\n",
        "    vwap = calculate_vwap(df)  # Ù…Ø­Ø§Ø³Ø¨Ù‡ VWAP\n",
        "    obv = calculate_obv(df)  # Ù…Ø­Ø§Ø³Ø¨Ù‡ OBV\n",
        "    rsi = calculate_rsi(df)  # Ù…Ø­Ø§Ø³Ø¨Ù‡ RSI\n",
        "    on_chain_analysis = analyze_on_chain_data()  # ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø²Ù†Ø¬ÛŒØ±Ù‡â€ŒØ§ÛŒ\n",
        "\n",
        "    signal = f\"ğŸ” ØªØ­Ù„ÛŒÙ„ {symbol}:\\n\"\n",
        "    signal += f\"- Ø¯ÙØªØ± Ø³ÙØ§Ø±Ø´: {order_book_analysis}\\n\"\n",
        "    signal += f\"- Ø¬Ø±ÛŒØ§Ù† Ø³ÙØ§Ø±Ø´: {order_flow}\\n\"\n",
        "    signal += f\"- VWAP: {vwap:.2f}\\n\"\n",
        "    signal += f\"- OBV: {obv} (Ø´Ø§Ø®Øµ Ø¬Ø±ÛŒØ§Ù† Ø­Ø¬Ù…. OBV Ù…Ù†ÙÛŒ Ø¨Ù‡ Ù…Ø¹Ù†Ø§ÛŒ ÙØ´Ø§Ø± ÙØ±ÙˆØ´ Ø§Ø³Øª.)\\n\"\n",
        "    signal += f\"- RSI: {rsi.iloc[-1]:.2f}\\n\"\n",
        "    signal += f\"- Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø²Ù†Ø¬ÛŒØ±Ù‡â€ŒØ§ÛŒ: {on_chain_analysis}\\n\"\n",
        "\n",
        "    entry_price_buy, stop_loss_buy, take_profit_buy = calculate_entry_exit_ai(df, fibonacci_levels, \"buy\")\n",
        "    entry_price_sell, stop_loss_sell, take_profit_sell = calculate_entry_exit_ai(df, fibonacci_levels, \"sell\")\n",
        "\n",
        "    # Ø§ÙØ²ÙˆØ¯Ù† Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ù†Ù‚Ø§Ø· ÙˆØ±ÙˆØ¯ Ùˆ Ø®Ø±ÙˆØ¬ Ø¨Ù‡ Ø³ÛŒÚ¯Ù†Ø§Ù„\n",
        "    signal += f\"ğŸ“ˆ Ø³ÛŒÚ¯Ù†Ø§Ù„ buy:\\n\"\n",
        "    signal += f\"- Ù†Ù‚Ø·Ù‡ ÙˆØ±ÙˆØ¯: {entry_price_buy} Ø¯Ù„Ø§Ø±\\n\"\n",
        "    signal += f\"- Ø­Ø¯ Ø¶Ø±Ø±: {stop_loss_buy} Ø¯Ù„Ø§Ø±\\n\"\n",
        "    signal += f\"- Ø­Ø¯ Ø³ÙˆØ¯: {take_profit_buy} Ø¯Ù„Ø§Ø±\\n\"\n",
        "\n",
        "    signal += f\"ğŸ“‰ Ø³ÛŒÚ¯Ù†Ø§Ù„ sell:\\n\"\n",
        "    signal += f\"- Ù†Ù‚Ø·Ù‡ ÙˆØ±ÙˆØ¯: {entry_price_sell} Ø¯Ù„Ø§Ø±\\n\"\n",
        "    signal += f\"- Ø­Ø¯ Ø¶Ø±Ø±: {stop_loss_sell} Ø¯Ù„Ø§Ø±\\n\"\n",
        "    signal += f\"- Ø­Ø¯ Ø³ÙˆØ¯: {take_profit_sell} Ø¯Ù„Ø§Ø±\\n\"\n",
        "\n",
        "    # Ø¨Ø±Ø±Ø³ÛŒ Ù†Ø²Ø¯ÛŒÚ©ÛŒ Ù‚ÛŒÙ…Øª Ø¨Ù‡ Ø³Ø·ÙˆØ­ ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ Ùˆ ØªØ­Ù„ÛŒÙ„ VWAP Ùˆ OBV\n",
        "    for level, value in fibonacci_levels.items():\n",
        "        if abs(price - value) < 0.02 * price:  # Ø¨Ø±Ø±Ø³ÛŒ Ù†Ø²Ø¯ÛŒÚ©ÛŒ Ù‚ÛŒÙ…Øª Ø¨Ù‡ Ø³Ø·ÙˆØ­ ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ\n",
        "            if price < vwap and rsi.iloc[-1] < 33 and obv > 0 and order_flow == \"Ø¬Ø±ÛŒØ§Ù† Ø®Ø±ÛŒØ¯\":\n",
        "                signal += f\"ğŸ“ˆ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø®Ø±ÛŒØ¯ Ù…Ø¹ØªØ¨Ø±: ØªØ±Ú©ÛŒØ¨ RSIØŒ VWAPØŒ OBVØŒ Ùˆ Ø¬Ø±ÛŒØ§Ù† Ø³ÙØ§Ø±Ø´ ØªØ£ÛŒÛŒØ¯ Ø´Ø¯.\\n\"\n",
        "            elif price > vwap and rsi.iloc[-1] > 67 and obv < 0 and order_flow == \"Ø¬Ø±ÛŒØ§Ù† ÙØ±ÙˆØ´\":\n",
        "                signal += f\"ğŸ“‰ Ø³ÛŒÚ¯Ù†Ø§Ù„ ÙØ±ÙˆØ´ Ù…Ø¹ØªØ¨Ø±: ØªØ±Ú©ÛŒØ¨ RSIØŒ VWAPØŒ OBVØŒ Ùˆ Ø¬Ø±ÛŒØ§Ù† Ø³ÙØ§Ø±Ø´ ØªØ£ÛŒÛŒØ¯ Ø´Ø¯.\\n\"\n",
        "\n",
        "    # ØªØ­Ù„ÛŒÙ„ OBV Ø¨Ø±Ø§ÛŒ ØªØ£ÛŒÛŒØ¯ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§\n",
        "    if obv > 0 and \"Ø®Ø±ÛŒØ¯\" in order_book_analysis:\n",
        "        signal += \"ğŸ“ˆ Ø­Ø¬Ù… Ù…Ø«Ø¨Øª OBV Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯. Ø®Ø±ÛŒØ¯ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø§Ø´Ø¯.\\n\"\n",
        "    elif obv < 0 and \"ÙØ±ÙˆØ´\" in order_book_analysis:\n",
        "        signal += \"ğŸ“‰ Ø­Ø¬Ù… Ù…Ù†ÙÛŒ OBV Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯. ÙØ±ÙˆØ´ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø§Ø´Ø¯.\\n\"\n",
        "\n",
        "    if pattern == \"Pin Bar ØµØ¹ÙˆØ¯ÛŒ\" and rsi.iloc[-1] < 33:\n",
        "        signal += \"ğŸ“ˆ Ø§Ù„Ú¯ÙˆÛŒ ØµØ¹ÙˆØ¯ÛŒ (Pin Bar) Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯. Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø®Ø±ÛŒØ¯ Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø§Ø´Ø¯.\\n\"\n",
        "    elif pattern == \"Pin Bar Ù†Ø²ÙˆÙ„ÛŒ\" and rsi.iloc[-1] > 67:\n",
        "        signal += \"ğŸ“‰ Ø§Ù„Ú¯ÙˆÛŒ Ù†Ø²ÙˆÙ„ÛŒ (Pin Bar) Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯. Ù…Ù…Ú©Ù† Ø§Ø³Øª ÙØ±ÙˆØ´ Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø§Ø´Ø¯.\\n\"\n",
        "    elif pattern == \"Engulfing ØµØ¹ÙˆØ¯ÛŒ\" and rsi.iloc[-1] < 33:\n",
        "        signal += \"ğŸ“ˆ Ø§Ù„Ú¯ÙˆÛŒ ØµØ¹ÙˆØ¯ÛŒ Engulfing Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯. Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø®Ø±ÛŒØ¯ Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø§Ø´Ø¯.\\n\"\n",
        "    elif pattern == \"Engulfing Ù†Ø²ÙˆÙ„ÛŒ\" and rsi.iloc[-1] > 67:\n",
        "        signal += \"ğŸ“‰ Ø§Ù„Ú¯ÙˆÛŒ Ù†Ø²ÙˆÙ„ÛŒ Engulfing Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯. Ù…Ù…Ú©Ù† Ø§Ø³Øª ÙØ±ÙˆØ´ Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø§Ø´Ø¯.\\n\"\n",
        "    elif pattern == \"Doji\" and abs(rsi.iloc[-1] - 50) < 10:\n",
        "        signal += \"âš–ï¸ Ø§Ù„Ú¯ÙˆÛŒ Doji Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯. Ø¨Ø§Ø²Ø§Ø± Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¯Ø± ÙˆØ¶Ø¹ÛŒØª Ø¨ÛŒâ€ŒØ·Ø±Ù Ø¨Ø§Ø´Ø¯.\\n\"\n",
        "\n",
        "\n",
        "    # ØªØ­Ù„ÛŒÙ„ Ø­Ø¬Ù… Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø¨Ø±Ø§ÛŒ ØªÙ‚ÙˆÛŒØª ÛŒØ§ Ø±Ø¯ Ø³ÛŒÚ¯Ù†Ø§Ù„\n",
        "    if \"Ø­Ø¬Ù… Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø¨Ø§Ù„Ø§\" in volume_analysis:\n",
        "        signal += \"âš ï¸ Ù‡Ø´Ø¯Ø§Ø±: Ø­Ø¬Ù… Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø¨Ø§Ù„Ø§. Ø§Ø­ØªÙ…Ø§Ù„ ØªØºÛŒÛŒØ± Ù†Ø§Ú¯Ù‡Ø§Ù†ÛŒ Ø¯Ø± Ø±ÙˆÙ†Ø¯ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯.\\n\"\n",
        "\n",
        "    # ØªØ­Ù„ÛŒÙ„ ÙˆØ¶Ø¹ÛŒØª RSI Ø¯Ø± ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…â€ŒÙ‡Ø§ÛŒ 5 Ø¯Ù‚ÛŒÙ‚Ù‡ Ùˆ 15 Ø¯Ù‚ÛŒÙ‚Ù‡ Ø¨Ø±Ø§ÛŒ ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…â€ŒÙ‡Ø§ÛŒ 1 Ø³Ø§Ø¹ØªÙ‡ØŒ 4 Ø³Ø§Ø¹ØªÙ‡ Ùˆ 1 Ø±ÙˆØ²Ù‡\n",
        "    if timeframe in ['1h', '4h']:\n",
        "        df_5m = fetch_data(symbol, '5m')\n",
        "        df_15m = fetch_data(symbol, '15m')\n",
        "\n",
        "        if df_5m is not None and df_15m is not None:\n",
        "            rsi_5m = calculate_rsi(df_5m).iloc[-1]\n",
        "            rsi_15m = calculate_rsi(df_15m).iloc[-1]\n",
        "\n",
        "            signal += \"\\nÙˆØ¶Ø¹ÛŒØª RSI Ø¯Ø± ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…â€ŒÙ‡Ø§ÛŒ Ú©ÙˆÚ†Ú©ØªØ±:\\n\"\n",
        "            signal += f\"- RSI (5 Ø¯Ù‚ÛŒÙ‚Ù‡): {rsi_5m:.2f}\\n\"\n",
        "            signal += f\"- RSI (15 Ø¯Ù‚ÛŒÙ‚Ù‡): {rsi_15m:.2f}\\n\"\n",
        "\n",
        "            if price < vwap and rsi.iloc[-1] < 33 and rsi_5m < 33 and rsi_15m < 33:\n",
        "                signal += \"ğŸ“ˆ ØªØ£ÛŒÛŒØ¯ Ø¨ÛŒØ´ØªØ±: RSI Ø¯Ø± ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…â€ŒÙ‡Ø§ÛŒ Ú©ÙˆÚ†Ú©ØªØ± Ù†ÛŒØ² Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ø®Ø±ÛŒØ¯ Ø§Ø³Øª.\\n\"\n",
        "            elif price > vwap and rsi.iloc[-1] > 67 and rsi_5m > 67 and rsi_15m > 67:\n",
        "                signal += \"ğŸ“‰ ØªØ£ÛŒÛŒØ¯ Ø¨ÛŒØ´ØªØ±: RSI Ø¯Ø± ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…â€ŒÙ‡Ø§ÛŒ Ú©ÙˆÚ†Ú©ØªØ± Ù†ÛŒØ² Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ ÙØ±ÙˆØ´ Ø§Ø³Øª.\\n\"\n",
        "            else:\n",
        "                signal += \"âš ï¸ Ù‡Ø´Ø¯Ø§Ø±: RSI Ø¯Ø± ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…â€ŒÙ‡Ø§ÛŒ Ú©ÙˆÚ†Ú©ØªØ± ÙˆØ¶Ø¹ÛŒØª Ø®Ù†Ø«ÛŒ Ø¯Ø§Ø±Ø¯.\\n\"\n",
        "        else:\n",
        "            signal += \"âš ï¸ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…â€ŒÙ‡Ø§ÛŒ 5 Ø¯Ù‚ÛŒÙ‚Ù‡ Ùˆ 15 Ø¯Ù‚ÛŒÙ‚Ù‡ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª.\\n\"\n",
        "\n",
        "    # Ø§Ø±Ø³Ø§Ù„ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ù‡ ØªÙ„Ú¯Ø±Ø§Ù… Ø§Ú¯Ø± Ù…Ø¹ØªØ¨Ø± Ø¨Ø§Ø´Ø¯\n",
        "    if \"Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø®Ø±ÛŒØ¯\" in signal or \"Ø³ÛŒÚ¯Ù†Ø§Ù„ ÙØ±ÙˆØ´\" in signal:\n",
        "        send_message_to_telegram(signal)\n",
        "    else:\n",
        "        signal = \"Ù‡ÛŒÚ† Ø³ÛŒÚ¯Ù†Ø§Ù„ÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù†Ø´Ø¯.\"\n",
        "\n",
        "    return signal\n",
        "\n",
        "\n",
        "def calculate_risk_management_ai(entry_price, stop_loss, take_profit, account_balance, risk_percent=2):\n",
        "    volatility = abs(entry_price - stop_loss)  # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†ÙˆØ³Ø§Ù†Ø§Øª\n",
        "    risk_amount = account_balance * (risk_percent / 100)\n",
        "    position_size = risk_amount / volatility\n",
        "    return round(position_size, 2)\n",
        "\n",
        "# ØªØ§Ø¨Ø¹ Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ ATR\n",
        "def calculate_atr(df, window=14):\n",
        "    high_low = df['high'] - df['low']\n",
        "    high_close = (df['high'] - df['close'].shift(1)).abs()\n",
        "    low_close = (df['low'] - df['close'].shift(1)).abs()\n",
        "    tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)\n",
        "    atr = tr.rolling(window=window).mean()\n",
        "    return atr.iloc[-1]\n",
        "\n",
        "# ØªØ§Ø¨Ø¹ Ø¨Ø±Ø§ÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù†Ù‚Ø§Ø· Ø­Ù…Ø§ÛŒØª Ùˆ Ù…Ù‚Ø§ÙˆÙ…Øª\n",
        "def calculate_support_resistance(df):\n",
        "    high = df['high'].max()\n",
        "    low = df['low'].min()\n",
        "    return low, high\n",
        "\n",
        "# ØªØ§Ø¨Ø¹ Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø³Ø·ÙˆØ­ ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ\n",
        "def calculate_fibonacci_levels(df):\n",
        "    high_price = df['high'].max()\n",
        "    low_price = df['low'].min()\n",
        "    fibonacci_levels = {\n",
        "        \"level_0\": low_price,\n",
        "        \"level_23_6\": low_price + 0.236 * (high_price - low_price),\n",
        "        \"level_38_2\": low_price + 0.382 * (high_price - low_price),\n",
        "        \"level_50\": low_price + 0.5 * (high_price - low_price),\n",
        "        \"level_61_8\": low_price + 0.618 * (high_price - low_price),\n",
        "        \"level_100\": high_price\n",
        "    }\n",
        "    return fibonacci_levels\n",
        "\n",
        "# ØªØ§Ø¨Ø¹ Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù‚ÛŒÙ…Øª Ø¨Ø§ Ù…Ø¯Ù„ XGBoost\n",
        "def xgboost_predict(df, look_back=5):\n",
        "    try:\n",
        "        if len(df) < look_back:\n",
        "            raise ValueError(\"âš ï¸ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª.\")\n",
        "\n",
        "        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§\n",
        "        close_prices = df['close'].values\n",
        "        high_prices = df['high'].values\n",
        "        low_prices = df['low'].values\n",
        "\n",
        "        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø³Ø·ÙˆØ­ ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ\n",
        "        fibonacci_levels = calculate_fibonacci_levels(df)\n",
        "\n",
        "        # Ù…Ø­Ø§Ø³Ø¨Ù‡ ATR\n",
        "        atr = calculate_atr(df)\n",
        "\n",
        "        # Ø§ÛŒØ¬Ø§Ø¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆÛŒÚ˜Ú¯ÛŒ (X) Ùˆ Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§ (y)\n",
        "        X = []\n",
        "        y = []\n",
        "\n",
        "        for i in range(look_back, len(close_prices)):\n",
        "            # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ÛŒ Ú¯Ø°Ø´ØªÙ‡ Ø¨Ù‡â€ŒØ¹Ù†ÙˆØ§Ù† ÙˆÛŒÚ˜Ú¯ÛŒ\n",
        "            features = close_prices[i-look_back:i]\n",
        "            features = np.append(features, [atr])  # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ATR Ø¨Ù‡ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§\n",
        "            for level in fibonacci_levels.values():\n",
        "                features = np.append(features, level)  # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø³Ø·ÙˆØ­ ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ\n",
        "            X.append(features)\n",
        "            y.append(close_prices[i])\n",
        "\n",
        "        X = np.array(X)\n",
        "        y = np.array(y)\n",
        "\n",
        "        # ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ù‡ Ù…Ø¬Ù…ÙˆØ¹Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ÛŒ Ùˆ Ø¢Ø²Ù…Ø§ÛŒØ´ÛŒ\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
        "\n",
        "        # Ø³Ø§Ø®Øª Ù…Ø¯Ù„ XGBoost\n",
        "        model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, max_depth=5)\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù‚ÛŒÙ…Øª Ø¢ÛŒÙ†Ø¯Ù‡\n",
        "        predicted_price = model.predict(X_test[-1:].reshape(1, -1))\n",
        "\n",
        "        return predicted_price[0]\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Ø®Ø·Ø§ Ø¯Ø± Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù‚ÛŒÙ…Øª Ø¨Ø§ XGBoost: {e}\")\n",
        "        return None\n",
        "\n",
        "# ØªØ§Ø¨Ø¹ Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ ATR\n",
        "def calculate_atr(df, window=14):\n",
        "    high_low = df['high'] - df['low']\n",
        "    high_close = (df['high'] - df['close'].shift(1)).abs()\n",
        "    low_close = (df['low'] - df['close'].shift(1)).abs()\n",
        "    tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)\n",
        "    atr = tr.rolling(window=window).mean()\n",
        "    return atr.iloc[-1]\n",
        "\n",
        "# ØªØ§Ø¨Ø¹ Ø¨Ø±Ø§ÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù†Ù‚Ø§Ø· Ø­Ù…Ø§ÛŒØª Ùˆ Ù…Ù‚Ø§ÙˆÙ…Øª\n",
        "def calculate_support_resistance(df):\n",
        "    high = df['high'].max()\n",
        "    low = df['low'].min()\n",
        "    return low, high\n",
        "\n",
        "def calculate_entry_exit_ai(df, fibonacci_levels, signal_type, risk_reward_ratio=2, look_back=5):\n",
        "    # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ Ø³Ø·ÙˆØ­ ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ\n",
        "    if not fibonacci_levels:\n",
        "        raise ValueError(\"âš ï¸ Ø³Ø·ÙˆØ­ ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª.\")\n",
        "\n",
        "    # Ù‚ÛŒÙ…Øª ÙØ¹Ù„ÛŒ\n",
        "    current_price = df['close'].iloc[-1]\n",
        "\n",
        "    # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù‚ÛŒÙ…Øª Ø¨Ø¹Ø¯ÛŒ Ø¨Ø§ Ù…Ø¯Ù„ XGBoost\n",
        "    predicted_price = xgboost_predict(df, look_back=look_back)\n",
        "    if predicted_price is None:\n",
        "        raise ValueError(\"âš ï¸ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù‚ÛŒÙ…Øª Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯.\")\n",
        "\n",
        "    # Ù…Ø­Ø§Ø³Ø¨Ù‡ ATR Ø¨Ø±Ø§ÛŒ ØªØ¹ÛŒÛŒÙ† Ø­Ø¯ Ø¶Ø±Ø± Ùˆ Ø­Ø¯ Ø³ÙˆØ¯\n",
        "    atr = calculate_atr(df)\n",
        "\n",
        "    # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù†Ù‚Ø§Ø· Ø­Ù…Ø§ÛŒØª Ùˆ Ù…Ù‚Ø§ÙˆÙ…Øª\n",
        "    support, resistance = calculate_support_resistance(df)\n",
        "\n",
        "    # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø­Ø¯ Ø¶Ø±Ø± Ùˆ Ø­Ø¯ Ø³ÙˆØ¯ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ATR Ùˆ Ø³Ø·ÙˆØ­ Ø­Ù…Ø§ÛŒØª/Ù…Ù‚Ø§ÙˆÙ…Øª\n",
        "    if signal_type == \"buy\":\n",
        "        # Ø­Ø¯ Ø¶Ø±Ø± Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ± Ø§Ø² Ù‚ÛŒÙ…Øª ÙØ¹Ù„ÛŒ Ùˆ Ù†Ø²Ø¯ÛŒÚ© Ø¨Ù‡ Ø³Ø·Ø­ Ø­Ù…Ø§ÛŒØª\n",
        "        stop_loss = max(support, current_price - atr)  # Ù…ÛŒâ€ŒØªÙˆØ§Ù† ATR Ø±Ø§ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† ÙØ§ØµÙ„Ù‡ Ø¨Ø±Ø§ÛŒ Ø­Ø¯ Ø¶Ø±Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ø±Ø¯\n",
        "        # Ø­Ø¯ Ø³ÙˆØ¯ Ø¨Ø§ Ù†Ø³Ø¨Øª Ø±ÛŒØ³Ú©/Ø¨Ø§Ø²Ø¯Ù‡\n",
        "        take_profit = current_price + (current_price - stop_loss) * risk_reward_ratio\n",
        "    elif signal_type == \"sell\":\n",
        "        # Ø­Ø¯ Ø¶Ø±Ø± Ø¨Ø§Ù„Ø§ØªØ± Ø§Ø² Ù‚ÛŒÙ…Øª ÙØ¹Ù„ÛŒ Ùˆ Ù†Ø²Ø¯ÛŒÚ© Ø¨Ù‡ Ø³Ø·Ø­ Ù…Ù‚Ø§ÙˆÙ…Øª\n",
        "        stop_loss = min(resistance, current_price + atr)  # Ù…ÛŒâ€ŒØªÙˆØ§Ù† ATR Ø±Ø§ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† ÙØ§ØµÙ„Ù‡ Ø¨Ø±Ø§ÛŒ Ø­Ø¯ Ø¶Ø±Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ø±Ø¯\n",
        "        # Ø­Ø¯ Ø³ÙˆØ¯ Ø¨Ø§ Ù†Ø³Ø¨Øª Ø±ÛŒØ³Ú©/Ø¨Ø§Ø²Ø¯Ù‡\n",
        "        take_profit = current_price - (stop_loss - current_price) * risk_reward_ratio\n",
        "    else:\n",
        "        raise ValueError(\"âš ï¸ Ù†ÙˆØ¹ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø¨Ø§ÛŒØ¯ 'buy' ÛŒØ§ 'sell' Ø¨Ø§Ø´Ø¯.\")\n",
        "\n",
        "    # Ù†Ù‚Ø·Ù‡ ÙˆØ±ÙˆØ¯ Ø¨Ù‡ÛŒÙ†Ù‡ (Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù† Ø§Ø² Ù‚ÛŒÙ…Øª ÙØ¹Ù„ÛŒ Ø¨Ù‡â€ŒØ¹Ù†ÙˆØ§Ù† Ù†Ù‚Ø·Ù‡ ÙˆØ±ÙˆØ¯ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ø±Ø¯)\n",
        "    entry_price = current_price\n",
        "\n",
        "    # Ø¨Ø±Ø±Ø³ÛŒ Ù†Ø²Ø¯ÛŒÚ©ÛŒ Ù‚ÛŒÙ…Øª ÙØ¹Ù„ÛŒ Ø¨Ù‡ Ø³Ø·ÙˆØ­ ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ§ÛŒÛŒØ¯\n",
        "    for level, fib_price in fibonacci_levels.items():\n",
        "        if abs(current_price - fib_price) < 0.02 * current_price:\n",
        "            # Ø§Ú¯Ø± Ù‚ÛŒÙ…Øª Ù†Ø²Ø¯ÛŒÚ© Ø¨Ù‡ Ø³Ø·Ø­ ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ Ø¨Ø§Ø´Ø¯\n",
        "            if signal_type == \"buy\" and current_price < predicted_price:\n",
        "                entry_price = fib_price  # ØªØºÛŒÛŒØ± Ù†Ù‚Ø·Ù‡ ÙˆØ±ÙˆØ¯ Ø¨Ù‡ Ù†Ø²Ø¯ÛŒÚ©â€ŒØªØ±ÛŒÙ† Ø³Ø·Ø­ ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ\n",
        "            elif signal_type == \"sell\" and current_price > predicted_price:\n",
        "                entry_price = fib_price  # ØªØºÛŒÛŒØ± Ù†Ù‚Ø·Ù‡ ÙˆØ±ÙˆØ¯ Ø¨Ù‡ Ù†Ø²Ø¯ÛŒÚ©â€ŒØªØ±ÛŒÙ† Ø³Ø·Ø­ ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ\n",
        "\n",
        "    return round(entry_price, 2), round(stop_loss, 2), round(take_profit, 2)\n",
        "\n",
        "\n",
        "# --- Ù…Ø¯ÛŒØ±ÛŒØª Ø³Ø±Ù…Ø§ÛŒÙ‡ ---\n",
        "def calculate_risk_management(entry_price, stop_loss, take_profit, account_balance, risk_percent=2):\n",
        "    risk_amount = account_balance * (risk_percent / 100)\n",
        "    position_size = risk_amount / abs(entry_price - stop_loss)\n",
        "    return round(position_size, 2)\n",
        "\n",
        "# --- Ø±Ø³Ù… Ù†Ù…ÙˆØ¯Ø§Ø± Ùˆ Ø§Ø±Ø³Ø§Ù„ Ø³ÛŒÚ¯Ù†Ø§Ù„ ---\n",
        "def plot_and_send_chart(df, fibonacci_levels, signal, timeframe, symbol, entry_price=None, stop_loss=None, take_profit=None, rsi=None, vwap=None):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Ø±Ø³Ù… Ù†Ù…ÙˆØ¯Ø§Ø± Ù‚ÛŒÙ…Øª\n",
        "    plt.plot(df['close'], label='Ù‚ÛŒÙ…Øª Ø¨Ø³ØªÙ‡ Ø´Ø¯Ù†', color='blue', linewidth=1.5)\n",
        "\n",
        "    # Ø±Ø³Ù… Ø³Ø·ÙˆØ­ ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ\n",
        "    for level, value in fibonacci_levels.items():\n",
        "        plt.axhline(value, label=f'Ø³Ø·Ø­ ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ {level}', linestyle='--', alpha=0.6)\n",
        "\n",
        "    # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† VWAP Ø¨Ù‡ Ù†Ù…ÙˆØ¯Ø§Ø±\n",
        "    if vwap:\n",
        "        plt.axhline(vwap, label='VWAP', color='orange', linestyle='-.')\n",
        "\n",
        "    # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù†Ù‚Ø§Ø· ÙˆØ±ÙˆØ¯ØŒ Ø­Ø¯ Ø¶Ø±Ø± Ùˆ Ø­Ø¯ Ø³ÙˆØ¯\n",
        "    if entry_price:\n",
        "        plt.scatter(len(df) - 1, entry_price, color='green', label='Ù†Ù‚Ø·Ù‡ ÙˆØ±ÙˆØ¯', zorder=5)\n",
        "    if stop_loss:\n",
        "        plt.scatter(len(df) - 1, stop_loss, color='red', label='Ø­Ø¯ Ø¶Ø±Ø±', zorder=5)\n",
        "    if take_profit:\n",
        "        plt.scatter(len(df) - 1, take_profit, color='gold', label='Ø­Ø¯ Ø³ÙˆØ¯', zorder=5)\n",
        "\n",
        "    # Ø±Ø³Ù… Ù†Ù…ÙˆØ¯Ø§Ø± RSI (Ø¯Ø± ØµÙˆØ±Øª Ù…ÙˆØ¬ÙˆØ¯ Ø¨ÙˆØ¯Ù†)\n",
        "    if rsi is not None:\n",
        "        plt.twinx()  # Ù…Ø­ÙˆØ± Y Ø¯ÙˆÙ… Ø¨Ø±Ø§ÛŒ RSI\n",
        "        plt.plot(rsi, label='RSI', color='purple', linestyle='--', alpha=0.7)\n",
        "        plt.axhline(30, color='green', linestyle='--', alpha=0.5, label='RSI Ø§Ø´Ø¨Ø§Ø¹ ÙØ±ÙˆØ´')\n",
        "        plt.axhline(70, color='red', linestyle='--', alpha=0.5, label='RSI Ø§Ø´Ø¨Ø§Ø¹ Ø®Ø±ÛŒØ¯')\n",
        "\n",
        "    # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù†Ù…ÙˆØ¯Ø§Ø±\n",
        "    plt.title(f'Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù‚ÛŒÙ…Øª {symbol} ({timeframe})')\n",
        "    plt.xlabel('Ø²Ù…Ø§Ù†')\n",
        "    plt.ylabel('Ù‚ÛŒÙ…Øª')\n",
        "    plt.legend(loc='upper left')\n",
        "\n",
        "    # Ø°Ø®ÛŒØ±Ù‡ Ù†Ù…ÙˆØ¯Ø§Ø± Ùˆ Ø§Ø±Ø³Ø§Ù„ Ø¨Ù‡ ØªÙ„Ú¯Ø±Ø§Ù…\n",
        "    sanitized_symbol = symbol.replace('/', '_')\n",
        "    chart_path = f'chart_{sanitized_symbol}_{timeframe}.png'\n",
        "\n",
        "    plt.savefig(chart_path)\n",
        "    plt.close()\n",
        "\n",
        "    # Ø§Ø±Ø³Ø§Ù„ Ù†Ù…ÙˆØ¯Ø§Ø± Ùˆ Ù¾ÛŒØ§Ù… Ø¨Ù‡ ØªÙ„Ú¯Ø±Ø§Ù…\n",
        "    send_chart_to_telegram(chart_path)\n",
        "    os.remove(chart_path)\n",
        "\n",
        "    if signal != \"Ù‡ÛŒÚ† Ø³ÛŒÚ¯Ù†Ø§Ù„ÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù†Ø´Ø¯.\":\n",
        "        send_message_to_telegram(f\"ğŸ“Š Ù†ØªÛŒØ¬Ù‡ ØªØ­Ù„ÛŒÙ„ {symbol} Ø¯Ø± ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ… {timeframe}:\\n{signal}\")\n",
        "\n",
        "\n",
        "def detect_whale_activity(df):\n",
        "    \"\"\"\n",
        "    Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ ÙØ¹Ø§Ù„ÛŒØª Ù†Ù‡Ù†Ú¯â€ŒÙ‡Ø§ Ø¨Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ø­Ø¬Ù… Ùˆ Ù†ÙˆØ³Ø§Ù†Ø§Øª Ù‚ÛŒÙ…Øª\n",
        "    \"\"\"\n",
        "    # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ùˆ Ø§Ù†Ø­Ø±Ø§Ù Ù…Ø¹ÛŒØ§Ø± Ø­Ø¬Ù…\n",
        "    avg_volume = df['volume'].mean()\n",
        "    std_volume = df['volume'].std()\n",
        "\n",
        "    # Ø¨Ø±Ø±Ø³ÛŒ Ø­Ø¬Ù… Ù…Ø¹Ø§Ù…Ù„Ø§Øª ØºÛŒØ±Ù…Ø¹Ù…ÙˆÙ„ (Ø¨ÛŒØ´ Ø§Ø² 2 Ø¨Ø±Ø§Ø¨Ø± Ø§Ù†Ø­Ø±Ø§Ù Ù…Ø¹ÛŒØ§Ø± Ø§Ø² Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†)\n",
        "    high_volume = df['volume'].iloc[-1] > avg_volume + 2 * std_volume\n",
        "\n",
        "    # Ø¨Ø±Ø±Ø³ÛŒ ØªØºÛŒÛŒØ±Ø§Øª Ù‚ÛŒÙ…Øª Ù†Ø§Ú¯Ù‡Ø§Ù†ÛŒ\n",
        "    price_change = abs(df['close'].iloc[-1] - df['close'].iloc[-2])\n",
        "    avg_price_change = abs(df['close'] - df['close'].shift(1)).mean()\n",
        "    std_price_change = abs(df['close'] - df['close'].shift(1)).std()\n",
        "\n",
        "    # ØªØºÛŒÛŒØ±Ø§Øª Ù‚ÛŒÙ…Øª Ù†Ø§Ú¯Ù‡Ø§Ù†ÛŒ (Ø¨ÛŒØ´ Ø§Ø² 2 Ø¨Ø±Ø§Ø¨Ø± Ø§Ù†Ø­Ø±Ø§Ù Ù…Ø¹ÛŒØ§Ø± Ø§Ø² Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† ØªØºÛŒÛŒØ±Ø§Øª)\n",
        "    sudden_price_move = price_change > avg_price_change + 2 * std_price_change\n",
        "\n",
        "    # Ø¨Ø±Ø±Ø³ÛŒ Ø¢ÛŒØ§ Ø­Ø¬Ù… Ø¨Ø§Ù„Ø§ Ùˆ ØªØºÛŒÛŒØ± Ù‚ÛŒÙ…Øª Ù†Ø§Ú¯Ù‡Ø§Ù†ÛŒ Ù‡Ù…Ø²Ù…Ø§Ù† Ø±Ø® Ø¯Ø§Ø¯Ù‡â€ŒØ§Ù†Ø¯\n",
        "    if high_volume and sudden_price_move:\n",
        "        return \"ğŸš¨ ÙØ¹Ø§Ù„ÛŒØª Ù†Ù‡Ù†Ú¯ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯: Ø­Ø¬Ù… Ø¨Ø§Ù„Ø§ Ùˆ ØªØºÛŒÛŒØ±Ø§Øª Ù†Ø§Ú¯Ù‡Ø§Ù†ÛŒ Ù‚ÛŒÙ…Øª.\"\n",
        "    elif high_volume:\n",
        "        return \"âš ï¸ Ø­Ø¬Ù… Ù…Ø¹Ø§Ù…Ù„Ø§Øª ØºÛŒØ±Ù…Ø¹Ù…ÙˆÙ„ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯: Ù…Ù…Ú©Ù† Ø§Ø³Øª ÙØ¹Ø§Ù„ÛŒØª Ù†Ù‡Ù†Ú¯ Ø¨Ø§Ø´Ø¯.\"\n",
        "    elif sudden_price_move:\n",
        "        return \"âš ï¸ ØªØºÛŒÛŒØ±Ø§Øª Ù†Ø§Ú¯Ù‡Ø§Ù†ÛŒ Ù‚ÛŒÙ…Øª Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯: Ù…Ù…Ú©Ù† Ø§Ø³Øª ÙØ¹Ø§Ù„ÛŒØª Ù†Ù‡Ù†Ú¯ Ø¨Ø§Ø´Ø¯.\"\n",
        "    return None  # Ø¨Ø§Ø²Ú¯Ø´Øª Ù…Ù‚Ø¯Ø§Ø± None Ø¯Ø± ØµÙˆØ±Øª Ø¹Ø¯Ù… Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ\n",
        "\n",
        "def process_analysis(args):\n",
        "    symbol, timeframe, account_balance = args\n",
        "    print(f\"ØªØ­Ù„ÛŒÙ„ {symbol} Ø¯Ø± ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ… {timeframe}\")\n",
        "\n",
        "    # Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø±Ø§ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ù†ÛŒØ¯\n",
        "    df = fetch_data(symbol, timeframe)\n",
        "    fibonacci_levels = calculate_fibonacci_levels(df)\n",
        "    order_book = fetch_order_book(symbol)  # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯ÙØªØ± Ø³ÙØ§Ø±Ø´\n",
        "\n",
        "    # ØªÙˆÙ„ÛŒØ¯ Ø³ÛŒÚ¯Ù†Ø§Ù„\n",
        "    signal = generate_signal(df, fibonacci_levels, symbol, order_book, timeframe)  # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¢Ø±Ú¯ÙˆÙ…Ø§Ù† order_book\n",
        "\n",
        "    # whale_activity = detect_whale_activity(df)  # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ ÙØ¹Ø§Ù„ÛŒØª Ù†Ù‡Ù†Ú¯â€ŒÙ‡Ø§\n",
        "\n",
        "    # Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… ÙÙ‚Ø· Ø¯Ø± ØµÙˆØ±Øª Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ ÙØ¹Ø§Ù„ÛŒØª Ù†Ù‡Ù†Ú¯\n",
        "    # if whale_activity and \"ÙØ¹Ø§Ù„ÛŒØª Ù†Ù‡Ù†Ú¯\" in whale_activity:\n",
        "    #     end_message_to_telegram(f\"ğŸ” {whale_activity}\\nÙ†Ù…Ø§Ø¯: {symbol} | ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…: {timeframe}\")\n",
        "\n",
        "    if signal != \"Ù‡ÛŒÚ† Ø³ÛŒÚ¯Ù†Ø§Ù„ÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù†Ø´Ø¯.\":\n",
        "        plot_and_send_chart(df, fibonacci_levels, signal, timeframe, symbol)\n",
        "\n",
        "\n",
        "# --- Ø±Ø§Ø¨Ø· ÙˆØ¨ (Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ù…Ø¯ÛŒØ±ÛŒØª) ---\n",
        "# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ÙˆÙ„ÛŒÙ‡\n",
        "symbols = ['BTC/USDT', 'ETH/USDT', 'ADA/USDT', 'SUI/USDT', 'DOGE/USDT', 'SHIB/USDT', 'TON/USDT', 'PEPE/USDT',  'SOL/USDT', 'LTC/USDT', 'MAJOR/USDT', 'ATOM/USDT', 'OP/USDT', 'ENA/USDT', 'MEME/USDT', 'XRP/USDT']\n",
        "timeframes = ['5m', '15m', '1h', '4h']\n",
        "account_balance = 100  # Ù…ÙˆØ¬ÙˆØ¯ÛŒ Ø­Ø³Ø§Ø¨ Ø¨Ù‡ Ø¯Ù„Ø§Ø±\n",
        "\n",
        "# Ù…Ø¯ÛŒØ±ÛŒØª ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§\n",
        "def schedule_analysis(symbols, timeframes, account_balance):\n",
        "    while True:\n",
        "        tasks = [(symbol, timeframe, account_balance) for symbol in symbols for timeframe in timeframes]\n",
        "        with Pool(processes=4) as pool:\n",
        "            pool.map(process_analysis, tasks)\n",
        "        print(\"Ù…Ù†ØªØ¸Ø± ØªØ­Ù„ÛŒÙ„ Ø¨Ø¹Ø¯ÛŒ...\")\n",
        "        time.sleep(5)\n",
        "\n",
        "# Ø§Ø¬Ø±Ø§ÛŒ Ø³Ø±ÙˆØ±\n",
        "if __name__ == '__main__':\n",
        "    schedule_analysis(symbols, timeframes, account_balance)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxiGdigTZlIi",
        "outputId": "c209f3d1-e666-40a0-8c68-eb5bbe254048"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ØªØ­Ù„ÛŒÙ„ ADA/USDT Ø¯Ø± ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ… 5mØªØ­Ù„ÛŒÙ„ SUI/USDT Ø¯Ø± ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ… 5m\n",
            "ØªØ­Ù„ÛŒÙ„ BTC/USDT Ø¯Ø± ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ… 5m\n",
            "ØªØ­Ù„ÛŒÙ„ ETH/USDT Ø¯Ø± ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ… 5m\n",
            "\n",
            "ØªØ­Ù„ÛŒÙ„ ETH/USDT Ø¯Ø± ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ… 15m\n",
            "ØªØ­Ù„ÛŒÙ„ ADA/USDT Ø¯Ø± ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ… 15m\n",
            "ØªØ­Ù„ÛŒÙ„ BTC/USDT Ø¯Ø± ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ… 15m\n",
            "ØªØ­Ù„ÛŒÙ„ SUI/USDT Ø¯Ø± ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ… 15m\n",
            "ØªØ­Ù„ÛŒÙ„ ADA/USDT Ø¯Ø± ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ… 1h\n",
            "Ú©Ù„Ù…Ù‡ 'ØªØ§ÛŒÙ… ÙØ±ÛŒÙ…' Ø¯Ø± Ù…ØªÙ† Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª. Ù‡ÛŒÚ† Ù¾ÛŒØ§Ù…ÛŒ Ø§Ø±Ø³Ø§Ù„ Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯.\n",
            "ØªØ­Ù„ÛŒÙ„ ETH/USDT Ø¯Ø± ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ… 1h\n",
            "ØªØ­Ù„ÛŒÙ„ BTC/USDT Ø¯Ø± ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ… 1h\n",
            "ØªØ­Ù„ÛŒÙ„ SUI/USDT Ø¯Ø± ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ… 1h\n",
            "ØªØ­Ù„ÛŒÙ„ ADA/USDT Ø¯Ø± ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ… 4h\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "colab-github-demo.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}